{"path":"HS23/LinAlg/PV/cheatsheets/LinAlg-cheatsheet-jannis.pdf","text":"cos(α) sin(α) 0 π 2 π 3π 2 π 6 ( √3 2 , 1 2 )π 4 ( √2 2 , √2 2 ) 2π 6 ( 1 2 , √3 2 ) 5π 6 (− √3 2 , 1 2 ) 3π 4 (− √2 2 , √2 2 ) 4π 6 (− 1 2 , √3 2 ) − π 6 ( √3 2 , − 1 2 ) − π 4 ( √2 2 , − √2 2 )− 2π 6 ( 1 2 , − √3 2 ) − 5π 6( − √3 2 , − 1 2 ) − 3π 4 (− √2 2 , − √2 2 ) − 4π 6 (− 1 2 , − √3 2 ) Vectorspaces F-Vectorspace ⟨V ; +, 0, −, ·, 1⟩ (i) Additive albenian group ⟨V ; +, 0⟩ where + : V × V → V , 0 :→ V and − : V → V (ii) Scalar algebra ⟨V, F; ·, 1⟩ where · : F × V → V and 1 :→ F Subspace U of V Must be closed under (i) addition (∀u, v ∈ U u + v ∈ U ) (ii) scalar multiplication (∀v ∈ U, c ∈ F cv ∈ U ) Fundamental Subpaces C(A) = {Ax|x ∈ V } = C(AA⊤) span of the column vectors. R(A) = C(A⊤) = C(A⊤A) span of the row vectors. N (A) = {x ∈ V |Ax = 0} nullspace, N (A⊤) left nullspace. Complement Subspaces have no vectors incommon ex- cept for 0 and when combined are equivalent to the whole vectorspace. Orthogonal Subspaces are subspaces where all vectors of one subspace is orthogonal to all other vectors in all other orthogonal subspaces. N (A)/N (A⊤) orthogonal complement to C(A⊤)/C(A). Determinants det(A) = 0 ⇐⇒ A is sigular. C(A) ̸= F n det(A) ̸= 0 ⇐⇒ A is regular. C(A) = F n det(A) is linear in each row. | det(Q)| = 1 for any orthogonal matrix Q. det(cA) = c n det(A). A diagonal or triangular =⇒ det(A) = ∏n i=1 aii. det(AB) = det(A),det(A⊤) = det(A) Swapping rows of A changes the sign of det(A). Non swapping row ops on A do not change det(A). det [ A C 0 B ] = det(A) det(B) Choose row j then det(A) = ∑n i=1 aji det(Cji) where Cji is A without row j and column i. Solving LSEs Am×nx = b Overdetermined m < n Underdetermined m > n Number of solutions #of sol. r = n r < n r = m 1 ∞ r < m 0 / 1 0 / ∞ P A = LU Decomposition P is the permutation of the rows during gauss. L is a lower triangular containing the gauss operations. U is a upper triangular being the gaussed matrix. Solving LSEs with P A = LU solve Lc = P b for c and then U x = c for x. A = CR Decomposition C are the linear independent column of A. C(A) = C(C) R is the rref form of A. Projections projspan{a}(b) = aa ⊤ a⊤a b projC(A)(b) = A˜x where A⊤A˜x = A⊤b (normal eq) if A⊤A is invertible projC(A)(b) = A (A⊤A)−1 A⊤b LeastSquare fitting (x1,∗,xn,∗,y∗) to α1x1 + . . . αnxn = y for 0 ≤ ∗ ≤ m    x1,1 · · · x1,n ... . . . ... xm,1 · · · xm,n       α1 ... αn    =    y1 ... ym    fitting α0 + α1t = b [ α0 α1 ] = [ m Σm k=1tk Σm k=1tk Σm k=1t 2 k ]−1 [ Σm k=1bk Σm k=1tkbk ] = [ 1 m ∑m k=1 bk∑m k=1 tkbk∑m k=1 t2 k ] A = QR Decomposition R is a upper triangular matrix given by R = Q ⊤A. Q is a orthogonal matrix. Algorithm 1 Gram-Schmidt 1: q1 = a1 ∥a1∥ 2: for k = 2, . . . , n do 3: q′ k = ak − ∑k−1 i=1 (a ⊤ k qi)qi 4: qk = q′ k ∥q′ k∥ 5: end for Solving LeastSquare with A = QR Rˆx = Q ⊤b Pseudoinverse A† rank(A) = n then A†A = I where A† = (A⊤A)−1A⊤. rank(A) = m then AA† = I where A† = A(AAT ) −1. A = CR then A† = R(RR⊤) −1(C ⊤C) −1C ⊤ Eigenvalues and -vectors Av = λv Calculating λ: det(A − λI) = 0 Calculating v of λ: (A − λI)v = 0 A with distinct λ1, . . . , λk v1, . . . , vk linearly independent. {v1, . . . , vk} is a basis for C(A). are the same as the ones of A⊤. Geometric Multiplicity of λ: dim(N (A − λI)) Similar Matrices C = T −1AT Tr(A) = Tr(C), det(A) = det(C) Tr(A) = ∑n i=1 λi, det(A) = ∏n i=1 λi Spectral Theorem Any symmetric matrix A ∈ Rn×n has n real eigenvalues and an orthonormal basis of eigen-vectors of A. A = V ΛV ⊤ The columns of V are the eigen-vectors of A, Λ is a diagonal matrix with corresponding eigen-values. Am = V Λ mV ⊤ Raylight Quotient R(x) = x⊤Ax x⊤x Positive (Semi-) Definite eigen-values > / ≥ 0 ⇐⇒ x ⊤Ax > / ≥ 0 Gram-Matrix A⊤A A⊤A and AA⊤ have the same non-zero eigen-values. Cholesky Decomposition M = C ⊤C M symmetric PSD, C upper trianular. SVD A = U ΣV ⊤ U ∈ Rm×m orthogonal (U ⊤U = I) eigenvectors of AA⊤ V ∈ Rn×n orthogonal (V ⊤V = I) eigenvectors of A⊤A Σ ∈ Rm×n diagonal Σii = σi sigular value. Singular values are the square roots of the non-zero eigen- values of AA⊤ / A⊤A Calculate SVD (i) Caclulate A⊤A/AA⊤ (ii) Find eigenvalues λ1, . . . , λn/r of A⊤A/AA⊤ (iii) Σr =    λ1 · · · 0 ... . . . ... 0 · · · λn/r    (iv) Σ = [ Σr 0 0 0 ] (v) calculate eigenvectors v1, . . . , vn/r of A⊤A (vi) norm eigenvectors vi ∥vi∥ (vii) write V with the eigenvectors as columns (viii) Solve Ur = AV Σ−1 (ix) If Ur does not have the right dimensions, we have to apply gram-schmidt (x) A = U ΣV ⊤","libVersion":"0.3.2","langs":""}
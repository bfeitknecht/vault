{"path":"zyx/attachments/AuW-997C0FEE6465DFE7D6E3B527FB832627.pdf","text":"Algorithmen und Wahrscheinlichkeit D-INFK, ETH Zürich Angelika Steger Emo Welzl Stand: 11. März 2024 Inhaltsverzeichnis 1 Graphentheorie 1 1.1 Grundbegriffe & Notationen . . . . . . . . . . . . . . . . . . 1 1.1.1 Zusammenhang und Bäume . . . . . . . . . . . . . . 5 1.1.2 Gerichtete Graphen . . . . . . . . . . . . . . . . . . 10 1.1.3 Datenstrukturen . . . . . . . . . . . . . . . . . . . . 14 1.2 Bäume . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16 1.2.1 Algorithmus von Prim . . . . . . . . . . . . . . . . . 22 1.2.2 Algorithmus von Kruskal . . . . . . . . . . . . . . . 26 1.2.3 Exkurs: Shannon’s Switching Game . . . . . . . . . 29 1.3 Pfade . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32 1.4 Zusammenhang . . . . . . . . . . . . . . . . . . . . . . . . . 33 1.4.1 Artikulationsknoten . . . . . . . . . . . . . . . . . . 34 1.4.2 Brücken . . . . . . . . . . . . . . . . . . . . . . . . . 40 1.4.3 Block-Zerlegung . . . . . . . . . . . . . . . . . . . . 40 1.5 Kreise . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43 1.5.1 Eulertouren . . . . . . . . . . . . . . . . . . . . . . . 43 1.5.2 Hamiltonkreise . . . . . . . . . . . . . . . . . . . . . 47 1.5.3 Spezialfälle . . . . . . . . . . . . . . . . . . . . . . . 54 1.5.4 Das Travelling Salesman Problem . . . . . . . . . . 57 1.6 Matchings . . . . . . . . . . . . . . . . . . . . . . . . . . . . 61 1.6.1 Algorithmen . . . . . . . . . . . . . . . . . . . . . . 62 1.6.2 Der Satz von Hall . . . . . . . . . . . . . . . . . . . 71 1.7 Färbungen . . . . . . . . . . . . . . . . . . . . . . . . . . . . 76 2 Wahrscheinlichkeitstheorie 86 2.1 Grundbegriffe und Notationen . . . . . . . . . . . . . . . . . 86 2.2 Bedingte Wahrscheinlichkeiten . . . . . . . . . . . . . . . . 92 2.3 Unabhängigkeit . . . . . . . . . . . . . . . . . . . . . . . . . 101 ii 2.4 Zufallsvariablen . . . . . . . . . . . . . . . . . . . . . . . . . 108 2.4.1 Erwartungswert . . . . . . . . . . . . . . . . . . . . . 110 2.4.2 Varianz . . . . . . . . . . . . . . . . . . . . . . . . . 119 2.5 Wichtige diskrete Verteilungen . . . . . . . . . . . . . . . . 122 2.5.1 Bernoulli-Verteilung . . . . . . . . . . . . . . . . . . 123 2.5.2 Binomialverteilung . . . . . . . . . . . . . . . . . . . 123 2.5.3 Geometrische Verteilung . . . . . . . . . . . . . . . . 124 2.5.4 Poisson-Verteilung . . . . . . . . . . . . . . . . . . . 127 2.6 Mehrere Zufallsvariablen . . . . . . . . . . . . . . . . . . . . 128 2.6.1 Unabhängigkeit von Zufallsvariablen . . . . . . . . . 131 2.6.2 Zusammengesetzte Zufallsvariablen . . . . . . . . . . 134 2.6.3 Momente zusammengesetzter Zufallsvariablen . . . . 136 2.6.4 Waldsche Identität . . . . . . . . . . . . . . . . . . . 137 2.7 Abschätzen von Wahrscheinlichkeiten . . . . . . . . . . . . 139 2.7.1 Die Ungleichungen von Markov und Chebyshev . . . 140 2.7.2 Die Ungleichung von Chernoff . . . . . . . . . . . . . 143 2.8 Randomisierte Algorithmen . . . . . . . . . . . . . . . . . . 145 2.8.1 Reduktion der Fehlerwahrscheinlichkeit . . . . . . . 146 2.8.2 Sortieren und Selektieren . . . . . . . . . . . . . . . 150 2.8.3 Primzahltest . . . . . . . . . . . . . . . . . . . . . . 154 2.8.4 Target-Shooting . . . . . . . . . . . . . . . . . . . . 157 2.8.5 Finden von Duplikaten . . . . . . . . . . . . . . . . . 159 3 Algorithmen - Highlights 165 3.1 Graphenalgorithmen . . . . . . . . . . . . . . . . . . . . . . 165 3.1.1 Lange Pfade . . . . . . . . . . . . . . . . . . . . . . . 165 3.1.2 Flüsse in Netzwerken . . . . . . . . . . . . . . . . . . 172 3.1.3 Minimale Schnitte in Graphen . . . . . . . . . . . . 191 3.2 Geometrische Algorithmen . . . . . . . . . . . . . . . . . . . 197 3.2.1 Kleinster umschliessender Kreis . . . . . . . . . . . . 197 3.2.2 Konvexe Hülle . . . . . . . . . . . . . . . . . . . . . 206 Notationen N die natürlichen Zahlen: N = {1, 2, 3, . . .} N0 die natürlichen Zahlen und die Null: N0 = {0, 1, 2, 3, . . .} [n] die natürlichen Zahlen von 1 bis n: [n] = {1, 2, . . . , n} Z die ganzen Zahlen: Z = {. . . , −3, −2, −1, 0, 1, 2, 3, . . .} R die reellen Zahlen R + die positiven reellen Zahlen R\u0015 0 die nicht-negativen reellen Zahlen ln bezeichnet den natürlichen Logarithmus zur Basis e = 2.71828... log bezeichnet den Logarithmus zur Basis 2 |A| bezeichnet die Kardinalität (Anzahl Elemente) einer Menge A A \u0002 B das kartesische Produkt der Mengen A und B: A \u0002 B = {(a, b) | a 2 A, b 2 B} 2A die Potenzmenge von A: 2A = {X | X \u0012 A} \u0010 A k \u0011 die Menge der k-elementigen Teilmengen von A: \u0010 A k \u0011 = {X | X \u0012 A, |X| = k} G = (V, E) ein (ungerichteter) Graph mit Knotenmenge V und Kantenmenge E \u0012 \u0010 V 2 \u0011 D = (V, A) ein gerichteter Graph mit Knotenmenge V und Kantenmenge A \u0012 V \u0002 V . . . ! = min der Ausdruck auf der linken Seite soll minimiert werden Kapitel 1 Graphentheorie In der Vorlesung Algorithmen und Datenstrukturen des vergangenen Se- mesters haben wir bereits einige Graphalgorithmen kennen gelernt. In die- sem Kapitel fassen diese nochmals zusammen und fügen einige weitere hin- zu. Zunächst wiederholen wir die Sprache der Graphentheorie, die es uns oft erlaubt, komplizierte Zusammenhänge elegant auszudrücken. 1.1 Grundbegriffe & Notationen Ein Graph G ist ein Tupel (V, E), wobei V eine endliche, nichtleere Menge von Knoten (engl. vertices) ist. Die Menge E ist eine Teilmenge der zwei- elementigen Teilmengen von V, also E \u0012 \u0010 V 2 \u0011 := {{x, y} | x, y 2 V, x 6= y}. Die Elemente der Menge E bezeichnet man als Kanten (engl. edges). Einen Graphen kann man anschaulich sehr schön darstellen indem man jeden Knoten des Graphen durch einen Punkt (oder Kreis) repräsentiert und diese genau dann durch eine Linie verbindet, wenn im Graphen die entsprechenden Knoten durch eine Kante verbunden sind. Abbildung 1.1 illustriert dies an einigen Beispielen. Abbildung 1.1: Zwei Beispiele für Graphen. 1 KAPITEL 1. GRAPHENTHEORIE 2 Wenn wir vor allem auf die Struktur des Graphen, aber nicht so sehr auf die Bezeichnung der Knoten eingehen wollen, so lassen wir zuweilen der Übersichtlichkeit halber die Bezeichnung der Knoten weg. Abbildung 1.2 zeigt einige Beispiele hierfür: ein vollständiger Graph (engl. complete graph) Kn besteht aus n Knoten, die alle paarweise miteinander verbun- den sind. Ein Kreis (engl. cycle) Cn besteht aus n Knoten, die zyklisch miteinander verbunden sind. Ein Pfad (engl. path) Pn entsteht aus einem Kreis auf n Knoten, in dem wir eine beliebige Kante weglassen. Der d- dimensionale Hyperwürfel Qd hat die Knotenmenge {0, 1}d, also die Menge aller Sequenzen von d Nullen und Einsen, wobei zwei Knoten (a1, . . . , ad) und (b1, . . . , bd) genau dann durch eine Kante verbunden werden, wenn es eine und nur eine Koordinate i gibt, für die ai 6= bi gilt. Man über- prüft leicht, dass Q3 das „Skelett“ eines herkömmlichen (3-dimensionalen) Würfels ist. Abbildung 1.2: Der vollständige Graph K6, der Kreis C7 und der Pfad P5. Ein Graph heisst bipartit (engl. bipartite), wenn sich die Knotenmen- ge in zwei disjunkte Mengen A und B zerlegen lässt (wir verwenden die Notation V = A ] B dafür), sodass Kanten von G nur zwischen A und B verlaufen. Jede Kante e 2 E muss also einen Endpunkt in A und einen Endpunkt in B haben. Zum Beispiel sind Hyperwürfel und Pfade bipartit, und Kreise sind genau dann bipartit, wenn sie gerade Länge haben. Zuweilen betrachtet man auch eine etwas allgemeinere Form von Gra- phen und erlaubt sogenannte Schlingen (engl. loops), d.h. Kanten, die einen Knoten mit sich selbst verbinden. Ausserdem können Graphen mit Mehrfachkanten (engl. multiple edges) betrachtet werden, bei denen ein Knotenpaar durch mehr als eine Kante verbunden sein kann. Graphen, in denen auch Schleifen und Mehrfachkanten vorkommen können, nennt man auch Multigraphen. Wir werden solche in dieser Vorlesung jedoch, von we- nigen Ausnahmen abgesehen, auf die wir dann besonders hinweisen, nicht KAPITEL 1. GRAPHENTHEORIE 3 betrachten. Wenn wir daher von einem Graphen G = (V, E) sprechen mei- nen wir immer einen Graphen ohne Schleifen und ohne Multikanten. Für einen Knoten v 2 V eines Graphen G = (V, E) definieren wir die Nachbarschaft (engl. neighbourhood) NG(v) eines Knotens v 2 V durch NG(v) := {u 2 V | {v, u} 2 E}. Der Grad (engl. degree) von v bezeichnet die Größe der Nachbarschaft von v, also degG(v) := |NG(v)|. Die Schreibweisen „NG(v) := . . .“ und „degG(v) := . . .“ verdeutlichen, dass wir die Nachbarschaft oder den Grad des Knotens im Graphen G meinen. Wenn sich der Graph aus dem Zusam- menhang eindeutig ergibt, lassen wir den Index meist weg und schreiben einfach deg(v) für den Grad von v bzw. N(v) für die Nachbarschaft von v. Ein Graph G heisst k-regulär (engl. k-regular ), falls für alle Knoten v 2 V gilt, dass deg(v) = k. Beispiel 1.1. Der vollständige Graph Kn ist (n − 1)-regulär, die Kreise Cn sind jeweils 2-regulär, und der Hyperwürfel Qd ist d-regulär. Zwei Knoten u und v heissen adjazent (engl. adjacent ), wenn sie durch eine Kante verbunden sind. Die Knoten u und v nennt man dann auch die Endknoten der Kante {u, v}. Ein Knoten u und eine Kante e heissen inzident (engl. incident ), wenn u einer der Endknoten von e ist. Der folgende Satz stellt eine einfache, aber wichtige Beziehung zwischen den Knotengraden und der Gesamtanzahl der Kanten eines Graphen auf. Satz 1.2. Für jeden Graphen G = (V, E) gilt ∑ v2 V deg(v) = 2|E|. Beweis. Wir verwenden die Regel des doppelten Abzählens. Auf der linken Seite wird jede Kante {u, v} genau zweimal gezählt: einmal, wenn deg(u) betrachtet wird und zum zweiten Mal, wenn deg(v) betrachtet wird. Auf der rechten Seite wird jede Kante ebenfalls genau zweimal gezählt. In k-regulären Graphen gilt deg(v) = k für alle Knoten v und daher 2|E| = |V|k. Insbesondere kann es einen k-regulären Graphen auf n Knoten überhaupt nur dann geben, wenn das Produkt nk gerade ist. Allgemeiner lässt sich mit Hilfe des gerade bewiesenen Satzes leicht zeigen, dass in jedem beliebigen (auch nicht-regulären) Graphen die Anzahl der Knoten mit ungeradem Grad gerade sein muss. KAPITEL 1. GRAPHENTHEORIE 4 Korollar 1.3. Für jeden Graphen G = (V, E) gilt: Die Anzahl der Kno- ten mit ungeradem Grad ist gerade. Beweis. Wir teilen die Knotenmenge V in zwei Teile, die Menge Vg der Knoten mit geradem Grad und die Menge Vu der Knoten mit ungeradem Grad. Die Summe von beliebig vielen geraden Zahlen ist immer gerade. Die Summe von k ungeraden Zahlen ist hingegen genau dann gerade, wenn k gerade ist. Also ist∑ v2 V deg(v) = ∑ v2 Vg deg(v) + ∑ v2 Vu deg(v) genau dann gerade, wenn |Vu| dies ist. Nach Satz 1.2 muss obige Summe aber gerade sein, denn 2|E| ist ja immer gerade. Also ist |Vu| gerade. In der Formel aus Satz 1.2 werden auf der linken Seite alle Knotengrade aufsummiert. Teilen wir daher beide Seiten durch die Anzahl |V| aller Kno- ten, so erhalten wir links den durchschnittlichen Knotengrad und rechts 2|E|/|V|. Da es bei der Durchschnittsbildung immer Werte gibt die höch- stens so gross wie der Durchschnitt sind und solche die mindestens so gross sind, erhalten wir aus Satz 1.2 sofort auch die folgende Konsequenz. Korollar 1.4. In jedem Graph G = (V, E) ist der durchschnittliche Kno- tengrad gleich 2|E|/|V|. Insbesondere gibt es daher Knoten x, y 2 V mit deg(x) \u0014 2|E|/|V| und deg(y) \u0015 2|E|/|V|. Teilgraphen. Ein Graph H = (VH, EH) heisst (schwacher) Teilgraph eines Graphen G = (VG, EG), falls VH \u0012 VG und EH \u0012 EG gilt. Ist H ein Teilgraph von G, so schreiben wir auch H \u0012 G. Gilt sogar EH = EG \\ \u0010 VH 2 \u0011 , so nennen wir H einen induzierten Teilgraphen von G und schreiben H = G[VH]. Abbildung 1.3 illustriert dies an einigen Beispielen. Einen Teilgraphen eines Graphen erhält man also, indem man aus dem ur- sprünglichen Graphen beliebig Kanten und/oder Knoten (und alle inziden- ten Kanten) entfernt. Um einen induzierten Teilgraphen zu erhalten, muss KAPITEL 1. GRAPHENTHEORIE 5 man etwas mehr aufpassen. Hier wird verlangt, dass je zwei Knoten, die im ursprünglichen Graphen verbunden waren und die beide im Teilgraph vorhanden sind, auch im induzierten Teilgraphen miteinander verbunden sind. Um einen induzierten Teilgraphen zu erhalten, darf man somit nur Knoten (und die mit ihnen verbundenen Kanten) aus dem ursprünglichen Graphen entfernen, man darf jedoch nicht eine Kante zwischen Knoten entfernen und beide Knoten im Graphen belassen. Ist G = (V, E) ein Graph und v ein Knoten von G, so bezeichnen wir mit G − v := G[V \\ {v}] den Teilgraphen, den wir erhalten indem wir v und alle zu v inzidenten Kanten löschen. Abbildung 1.3: Der Graph G (links) und einige induzierte Teilgraphen des Graphen G (rechts). 1.1.1 Zusammenhang und Bäume Eine Sequenz von Knoten h v1, . . . , vki heisst Weg (engl. walk ), wenn für jedes i 2 {1, . . . , k − 1} eine Kante von vi nach vi+1 existiert. Für eine Kante e und einen Weg W = h v1, . . . , vki schreiben wir e 2 W wenn es ein i gibt, so dass e = {vi, vi+1} gilt. Die Länge eines Weges ist die Anzahl der Schritte, also in diesem Fall k − 1. Die Knoten v1 und vk nennt man auch den Start- bzw. Endknoten des Weges; einen Weg mit Startknoten s und Endknoten t nennen wir auch kurz einen s-t-Weg. Zuweilen, wenn es auf die Richtung nicht ankommt, bezeichnen wir auch beide Knoten als Endknoten des Weges. Ein Pfad von s nach t (oder auch kurz s-t-Pfad, engl. s-t-path) s-t-Weg, der keinen Knoten mehrfach benutzt. Ein Weg h v1, . . . , vki mit v1 = vk heisst Zyklus (oder auch: geschlossener Weg, engl. closed walk ). Ein Zyklus ist also ein Weg in dem Start- und Endknoten übereinstimmen. KAPITEL 1. GRAPHENTHEORIE 6 Ein Zyklus h v1, . . . , vki heisst Kreis (engl. cycle), wenn er Länge mindestens 3 hat und die Knoten v1, . . . , vk−1 alle paarweise verschieden sind. Es zeigt sich leicht, dass zwei Knoten s und t genau dann durch einen Pfad verbunden sind, wenn sie durch einen Weg verbunden sind; in der Tat ist nämlich ein kürzester s-t-Weg (wenn denn einer existisiert) stets auch ein s-t-Pfad. Wir nennen einen Graphen G = (V, E) zusammenhängend (engl. connec- ted) falls es für je zwei Knoten s, t 2 V einen s-t-Pfad in G gibt. Einen zusammenhängenden Teilgraphen C \u0012 G der bezüglich dieser Eigenschaft maximal ist1 nennt man eine Zusammenhangskomponente. Die Knoten- mengen der verschiedenen Zusammenhangskomponenten von G sind genau die Äquivalenzklassen der Äquivalenzrelation R := {(s, t) 2 V 2 | G enthält einen s-t-Pfad}. von G; insbesondere bilden sie eine Partition der Knotenmenge V. Ein Graph der keinen Kreis enthält, heisst kreisfrei. Ist ein Graph G = (V, E) zusammenhängend und kreisfrei, so nennt man ihn Baum (engl. tree). Aber Achtung: diese Definition heisst nicht, dass er auch wie ein Baum aussieht. Zum Beispiel sind alle in Abbildung 1.4 dargestellten Gra- phen Bäume. Abbildung 1.4: Einige Beispiele für Bäume. Im vergangenen Semester haben Sie bereits Suchbäume als eine wich- tige Datenstruktur für eine effiziente Organisation von Daten kennen ge- lernt. Suchbäume tragen das Wort ‘Baum’ im Namen und sie erfüllen beide Kriterien der obigen Definition: sie sind zusammenhängend und kreisfrei. Darüber hinaus haben sie aber noch eine weitere wichtige Eigenschaft: sie 1D.h. jeder Teilgraph H 6= C mit C \u0012 H \u0012 G ist nicht zusammenhängend. KAPITEL 1. GRAPHENTHEORIE 7 besitzen eine Wurzel an der der Suchbaum quasi ‘aufgehängt’ ist. In der Sprache der Graphentheorie nennt man einen Suchbaum daher auch einen gewurzelten Baum (engl. rooted tree). In dieser Vorlesung folgen wir der in der Wissenschaft üblichen Sprechweise: in der Graphentheorie ist ein Baum nicht gewurzelt. Für Bäume gilt die schöne und wichtige Eigenschaft, dass es für beliebige Knoten x, y 2 V genau einen x-y-Pfad gibt. Dass es mindestens einen solchen Pfad gibt folgt aus der Tatsache, dass ein Baum zusammenhängend ist, dass es nur höchstens einen solchen Pfad gibt folgt aus der Tatsache, dass ein Baum kreisfrei ist. Ist T = (V, E) ein Baum und v 2 V ein Knoten mit Grad deg(v) = 1, so heisst v ein Blatt (engl. leaf ). Lemma 1.5. Ist T = (V, E) ein Baum mit |V| \u0015 2 Knoten, so gilt: a) T enthält mindestens zwei Blätter, b) ist v 2 V ein Blatt, so ist der Graph T − v ebenfalls ein Baum. Beweis. Wir zeigen zunächst Eigenschaft a). Wähle eine beliebige Kante e 2 E und laufe von den beiden Knoten der Kante aus durch den Graphen „bis es nicht weiter geht“. Da T ein Baum und daher kreisfrei ist, kann man beim Weiterlaufen nie auf einen Knoten stossen, der schon in dem Pfad enthalten ist (denn sonst hätten wir einen Kreis gefunden) und somit müssen beide Richtungen in je einem Blatt enden. Für die Eigenschaft b) überlegen wir uns Folgendes: T 0 := T − v ist sicherlich kreisfrei, da T kreisfrei war, und durch die Wegnahme von Knoten und Kanten keine Kreise entstehen können. Um einzusehen, dass T 0 auch zusammenhängend ist, betrachten wir zwei beliebige Knoten x, y 2 V \\ {v} und zeigen, dass x und y in T 0 durch einen Pfad verbunden sind. Da T ein Baum ist, ist T sicherlich zusammenhängend. In T gibt es also einen Pfad P, der x und y verbindet. Da in einem Pfad alle inneren Knoten Grad zwei haben, kann v in diesem Pfad nicht enthalten sein. Der Pfad P ist somit auch im Graphen T 0 enthalten, was zu zeigen war. Es ist nicht schwer daraus auch noch einen weitere wichtige Eigenschaft eines Baumes herzuleiten: ein Baum mit Knotenmenge V enthält genau |V| − 1 Kanten. Der folgende Satz fasst die verschiedenen Eigenschaften von Bäumen zusammen. KAPITEL 1. GRAPHENTHEORIE 8 Satz 1.6. Ist G = (V, E) ein Graph auf |V| \u0015 1 Knoten, so sind die folgenden Aussagen äquivalent: (a) G ist ein Baum, (b) G ist zusammenhängend und kreisfrei, (c) G ist zusammenhängend und |E| = |V| − 1, (d) G ist kreisfrei und |E| = |V| − 1, (e) für alle x, y 2 V gilt: G enthält genau einen x-y-Pfad. Beweis. Die folgenden Implikationen zeigen die gewünschte Äquivalenz. (a) ⇔ (b) Das gilt per Definition eines Baums. (a) ⇒ (c) Wir müssen zeigen, dass jeder Baum auf n Knoten genau n − 1 Kanten besitzt. Dazu verwenden wir vollständige Induktion nach n. Für n = 1 ist die Aussage klar. Sei also n \u0015 2. Wir nehmen an, dass (c) für alle Bäume mit n − 1 Knoten gilt, und wollen (c) für alle Bäume mit n Knoten zeigen. Sei daher T = (V, E) ein beliebiger Baum mit n Knoten. Nach Lemma 1.5 enthält T ein Blatt u, und der Graph T − v = (V 0 , E 0 ) ist ein Baum mit |V 0 | = n−1 Knoten. Da u ein Blatt war, besitzt T 0 ausserdem |E 0 | = |E| − 1 Kanten. Nun können wir auf T 0 die Induktionsvoraussetzung anwenden, und erhalten |E| − 1 = |E 0 | I.V. = |V 0 | − 1 = n − 2. Daraus folgt |E| = n − 1, wie gewünscht. (c) ⇒ (d) Sei G ein zusammenhängender Graph mit n Knoten und n − 1 Kanten. Zu zeigen ist, dass G kreisfrei ist. Angenommen, G enthielte einen Kreis C = h u1, u2, . . . , uk, u1i . Betrachten wir den Graphen G = (V, E \\ {u1, uk}), der aus G durch Löschen der Kante {u1, uk} entsteht. Dieser ist immer noch zusammenhängend, denn für je zwei Knoten v, w 2 V gibt es (weil G zusammenhängend ist) einen Weg von v nach w in G, und falls dieser Weg über die Kante {u1, uk} führt, kann man diese in G 0 durch den Weg u1, u2, . . . , uk ersetzen. Wir können also bei Existenz eines Kreise eine Kante entfernen, sodass der Graph immer noch zusammenhängend bleibt. Dies wiederholen wir so lange, bis keine Kreise mehr übrig sind. Danach ist der entstehende Graph G 0 aber zusammenhängend und kreisfrei, also ein Baum. Wegen der schon bewiesenen Implikation (a) ⇒ (c) hat G 0 genau n − 1 Kanten. Dies steht im Widerspruch dazu, dass G auch n − 1 Kanten KAPITEL 1. GRAPHENTHEORIE 9 hatte, und wir mindestens eine Kante (im ersten Schritt) gelöscht haben. Also kann G keinen Kreis enthalten haben. (d) ⇒ (a) Sei G ein kreisfreier Graph mit n Knoten und n − 1 Kanten. Es ist zu zeigen, dass G zusammenhängend ist. Jede Zusammenhangskompo- nente von G ist zusammenhängend (nach Definition) und kreisfrei (da G kreisfrei ist), also ein Baum. Seien die Komponenten C1 = (V1, E1), . . . , Ck = (Vk, Ek). Dann ist V = ˙ S k i=1Vi und E = ˙ S k i=1Ei. Da die Komponenten Bäume sind, besagt die schon bewiesene Richtung (a) ⇒ (c) aber |Ei| = |Vi| − 1 für alle i 2 {1, . . . , k}. Daher gilt |V| − 1 = |E| = k∑ i=1 |Ei| = k∑ i=1 (|Vi| − 1) = 0 @ k∑ i=1 |Vi| 1 A − k = |V| − k. Vergleicht man die linke und die rechte Seite, so erhält man k = 1. Es gibt also genau eine Zusammenhangskomponente, und G ist zusammenhängend. (a) ⇒ (e) Sei G ein Baum. Da G zusammenhängend ist, gibt es für jedes Paar von Knoten u, v mindestens einen Pfad von u nach v in G. Ange- nommen es gäbe für ein Paar u, v zwei verschiedene Pfade von u nach v, zum Beispiel h u1, u2, . . . , uri und h v1, v2, . . . , vsi , wobei u1 = v1 = u und ur = vs = v, und wobei wir s \u0014 r annehmen. Sei i 2 {2, . . . , s} minimal mit ui 6= vi (ein solches i existiert, weil die Pfade verschieden sind und im gleichen Knoten starten bzw. enden). Sei j 2 {i + 1, . . . , r} minimal mit uj 2 {vi+1, . . . , vs} und k 2 {i+1, . . . , r} minimal mit vk = uj. Dann kann man sich leicht überlegen, dass C := h ui−1, ui, . . . , uj−1, uj, vk−1, vk−2, . . . , vi+1, vii ein Kreis ist. Dies widerspricht der Kreisfreiheit von G. Daher gibt es genau einen u-v-Pfad für jedes Paar u, v. (e) ⇒ (a) Da G für jedes Paar u, v einen Pfad von u nach v enthält, ist G zusammenhängend. Wir nehmen zum Widerspruch an, dass es einen Kreis C = h u1, . . . , uk, u1i in G gäbe. Dann wären aber P1 := h u1, u2, . . . , uki und P2 := h u1, uki zwei verschiedene Pfade von u1 nach uk, denn C hat per De- finition mindestens Länge 3. Dies ist ein Widerspruch zu der Eindeutigkeit des u1-uk-Pfades, also muss G auch kreisfrei gewesen sein. Bäume sind Graphen, die kreisfrei und zusammenhängend sind. Ver- zichtet man auf die Bedingung ’zusammenhängend’ so nennt man die ent- KAPITEL 1. GRAPHENTHEORIE 10 sprechenden Graphen Wälder. Ein Wald W = (V, E) ist also ein Graph, der kreisfrei ist. Jede Zusammenhangskomponente eines Waldes ist dann na- türlich ein Baum. Und die Anzahl der Zusammenhangskomponenten lässt sich unmittelbar aus der Kantenanzahl ablesen: Lemma 1.7. Ein Wald G = (V, E) enthält genau |V| − |E| viele Zusam- menhangskomponenten. Beweis. Wie beweisen das Lemma durch Induktion über |E|. Wenn E = ; ist, dann ist jeder Knoten eine einzelne Zusammenhangskomponente und der Graph G besteht daher aus genau |V| Komponenten. Die Aussage des Lemmas ist in diesem Fall also richtig. Nehmen wir für den Induktions- schritt daher an, dass die Aussage für einen Graphen G 0 = (V, E 0 ) gilt und e 62 E 0 eine Kante ist, so dass G = (V, E 0 [ {e}) noch immer kreisfrei ist. Dann kann die Kante e nicht innerhalb einer Zusammenhangskompo- nente von G 0 verlaufen (denn dann würden wir einen Kreis erhalten), sie verbindet daher zwei verschiedene Komponenten – weshalb sich die An- zahl Zusammenhangskomponenten um eins reduziert. Die Behauptung des Lemmas gilt daher auch für den Graphen G = (V, E 0 [ {e}), was zu zeigen war. 1.1.2 Gerichtete Graphen In Graphen sind Kanten durch zweielementige Mengen von Knoten gege- ben. Insbesondere gilt daher (wie immer bei Mengen), dass {u, v} = {v, u} gilt. In sogenannten gerichteten Graphen sind die Kanten zusätzlich noch orientiert, eine Kante wird also nicht mehr durch eine zweielementige Men- ge, sondern durch ein geordnetes Paar dargestellt. Dies führt zu folgender Definition: ein gerichteter Graph oder auch kurz Digraph (engl. directed graph oder auch kurz digraph) D ist ein Tupel (V, A), wobei V eine (end- liche) Menge von Knoten ist und A \u0012 V \u0002 V eine Menge von gerichteten Kanten (engl. arcs). Man beachte, dass der Ausdruck ’gerichteter Graph’ grammatisch et- was irreführend ist, da er den Eindruck erweckt, ein gerichteter Graph sei eine spezielle Art von Graph. Das ist jedoch nicht so. Graphen und ge- richtete Graphen sind verschiedene (wenn auch eng verwandte) Konzepte. Wenn wir besonders betonen wollen, dass wir das erste Konzept meinen, KAPITEL 1. GRAPHENTHEORIE 11 dann sprechen wir auch von ’ungerichteten Graphen’. Allgemein ist aber mit ’Graph’ immer ’ungerichteter Graph’ gemeint. Man beachte auch den Unterschied in der Schreibweise von Kanten in ungerichteten und gerich- teten Graphen. In einem ungerichteten Graphen ist eine Kante zwischen zwei Knoten u und v eine zweielementige Teilmenge von V und wir no- tieren sie daher in der üblichen Mengenschreibweise {u, v}. In gerichteten Graphen ist eine Kante hingegen ein Element des Kreuzproduktes V \u0002 V. Entsprechend verwenden wir hier die Tupelschreibweise (u, v). Graphisch wird eine gerichtete Kante (u, v) als Pfeil von u nach v dargestellt. Gemäss Definition sind in gerichteten Graphen formal auch Schleifen (x, x) zugelassen. Analog zu ungerichteten Graphen werden wir in diesem Skript jedoch davon ausgehen, dass ein gerichteter Graph weder Schleifen noch Mehrfachkanten enthält. Man beachte aber, dass es bei gerichteten Graphen dennoch zwischen zwei Knoten x und y mehr als eine Kante geben kann, nämlich (x, y) und (y, x). Diese gelten nicht als Mehrfachkanten, denn es sind ja verschieden orientierte Kanten. Für Knoten v definieren wir den Aus-Grad durch deg+(v) := |{(x, y) 2 A | x = v}| und den In-Grad durch deg−(v) := |{(x, y) 2 A | y = v}|. Analog zu Satz 1.2 für ungerichtete Graphen zeigt man: Satz 1.8. Für jeden gerichteten Graphen D = (V, A) gilt: ∑ v2 V deg−(v) = ∑ v2 V deg+(v) = |A| . Die meisten Definitionen für Graphen lassen sich sinngemäss auch auf gerichtete Graphen übertragen. Wir werden im Folgenden nur einige davon näher betrachten. Ein gerichteter Weg in einem gerichteten Graphen D = (V, A) ist eine Folge W = h v1, . . . , vki von Knoten aus V, so dass (vi, vi+1) 2 A für alle i = 1, . . . , k − 1. Die Länge des gerichteten Weges entspricht wie im un- gerichteten Fall der Anzahl der Schritte, ist also hier k − 1. Die Knoten v1 und vk nennt man Start- bzw. Endknoten des gerichteten Weges. Ein KAPITEL 1. GRAPHENTHEORIE 12 gerichteter Pfad ist ein gerichteter Weg, in dem alle Knoten paarweise verschieden sind. Ein gerichteter Zyklus ist ein gerichteter Weg in dem Start- und Endknoten identisch sind. Ein gerichteter Kreis ist ein gerich- teter Weg C = h v1, . . . , vk, v1i der Länge mindestens 2, in dem die Knoten v1, . . . , vk paarweise verschieden sind. Beachte, dass diese Definition eines Kreises von der Definition in ungerichteten Graphen etwas abweicht: ein ungerichteter Kreis muss Länge mindestens 3 haben. Insbesondere ist also in einem gerichteten Graphen D = (V, A) die Folge h v, u, vi ein Kreis, wenn (u, v) und (v, u) in A sind; andererseits ist in einem ungerichteten Graphen der Zyklus h v, u, vi nie ein Kreis. Azyklische Graphen; stark und schwach zusammenhängende Graphen. Kreisfreie ungerichtete Graphen sind als Bäume bzw. Wälder bekannt. Wir werden sie im Abschnitt 1.2 genauer studieren. Bei gerichteten Graphen müssen wir bei der Definition von Kreisfreiheit sehr präzise vorgehen, denn hier ist a priori überhaupt nicht klar, was kreisfrei bedeuten soll. Betrachten wir hierzu die beiden Digraphen in Abbildung 1.5: Der Linke ist offensichtlich kreisfrei. Wie sieht es aber mit dem Rechten aus? Ignorieren wir die Ori- entierung der Kanten, so enthält er Kreise. Andererseits enthält er aber keinen gerichteten Kreis. Solche Graphen haben einen eigenen Namen. Abbildung 1.5: Zwei DAGs. Ein gerichteter Graph D = (V, A) heisst azyklisch (engl. acyclic), wenn er keinen gerichteten Kreis enthält. Azyklische gerichtete Graphen werden oft auch kurz als DAG bezeichnet, von engl. Directed Acyclic Graph. DAGs (und nur diese) haben die schöne Eigenschaft, dass man ihre Kno- ten so nummerieren kann, dass alle Kanten vom kleineren zum grösseren Knoten zeigen. Man nennt so eine Nummerierung auch topologische Sor- tierung. Im vergangenen Semester haben Sie gesehen, wie man in DAGs KAPITEL 1. GRAPHENTHEORIE 13 so eine Sortierung bestimmen kann: man gebe die kleinste Nummer einem Knoten mit Eingangsgrad Null und wiederhole dann diese Vorgehnsweise auf dem Teilgraphen ohne den kleinsten Knoten. Wenn man sich die Grade merkt (und geschickt updated) erhält man so einen Algorithmus dessen Laufzeit linear in der Anzahl Knoten und Kanten ist. Satz 1.9. Für jeden DAG D = (V, A) kann man in Zeit O(|V| + |A|) eine topologische Sortierung berechnen. Jedem gerichteten Graphen kann man einen ungerichteten Graphen zu- ordnen, indem man die Orientierung der Kanten ignoriert (und ggf. ent- stehende Multikanten durch eine einzige Kante ersetzt). Diesen Graphen nennt man auch den zugrunde liegenden Graphen. Bei der Übertragung einer Definition von Graphen auf Digraphen erhält man oft zwei verschiedene Definitionen, abhängig davon, ob man die Ori- entierung der Kanten berücksichtigt oder lediglich den zugrunde liegenden Graphen betrachtet. Betrachten wir dies am Beispiel von u-v-Pfaden. Für zwei Knoten u und v kann man drei Fälle unterscheiden: a) es gibt einen gerichteten u-v- Pfad, b) es gibt keinen gerichteten u-v-Pfad, aber es gibt einen u-v-Pfad im zugrunde liegenden Graphen und c) es gibt überhaupt keinen u-v-Pfad. Da der Zusammenhangsbegriff über die Existenz von u-v-Pfaden defi- niert ist, ergeben sich konsequenter Weise auch verschiedene Zusammen- hangsbegriffe. Ein gerichteter Graph D = (V, A) heisst stark zusammenhängend (engl. strongly connected), wenn für jedes Paar von Knoten u, v 2 V ein gerichteter u-v-Pfad existiert. Ein gerichteter Graph D = (V, A) heisst (schwach) zusammenhängend (engl. weakly connected), wenn der zu- grunde liegende Graph zusammenhängend ist. Beispiel 1.10. Die folgende Abbildung 1.6 zeigt links einen schwach zusammenhängenden Digraphen, der nicht stark zusammenhängend ist (was daran zu erkennen ist, dass es keine Kante gibt, die vom rechten Dreieck zum linken gerichtet ist) und rechts einen stark zusammenhängenden Digraphen. Beispiel 1.11. Jeder DAG dessen zugrunde liegender Graph zusammenhängend ist, ist schwach zusammenhängend, aber nicht stark zusammenhängend. Letzteres sieht man ein, in dem man sich zunächst überlegt, dass die Definition des starken Zusammenhangs im- pliziert, dass der Graph gerichtete Kreise enthält. Betrachtet man beispielsweise eine be- liebige Kante (x, y), so bildet diese zusammen mit einem gerichteten y-x-Pfad (der nach KAPITEL 1. GRAPHENTHEORIE 14 Abbildung 1.6: Ein schwach zusammenhängend Graph (links) und ein stark zusammenhängend Graph (rechts). Definition des starken Zusammenhangs existieren muss) einen gerichteten Kreis. Gerich- tete Kreise kann ein azyklischer Graph anderseits nach Definition nicht enthalten, d.h. ein DAG kann nicht stark zusammenhängend sein. 1.1.3 Datenstrukturen Im vorigen Semester haben Sie bereits die beiden grundlegenden Möglich- keiten kennen gelernt, wie man einen Graphen (gerichtet oder ungerichtet) speichern kann: mit einer Adjazenzmatrix oder mit Adjazenzlisten. Beides ist besonders einfach, wenn die Knotenmenge V = [n] = {1, . . . , n} ist, wobei n = |V|. Die Adjazenzmatrix AG ist dann eine n \u0002 n Matrix gegeben durch AG = (aij)n i,j=1 mit aij := { 1 falls {i, j} 2 E, 0 sonst. Für ungerichtete Graphen ist AG eine symmetrische 0-1-Matrix mit Nullen auf der Hauptdiagonalen. Man überlegt sich leicht, dass umgekehrt auch jede solche Matrix einem Graphen entspricht. Für gerichtete Graphen passt man obige Definition sinngemäss an und enthält dann ebenfalls eine 0-1-Matrix mit Nullen auf der Hauptdiagonalen, die aber nunmehr nicht symmetrisch sein muss. Wieder gilt auch: jede 0-1-Matrix mit Nullen auf der Hauptdiagonalen entspricht genau einem gerichteten Graphen. Beispiel 1.12. Die folgende Abbildung 1.7 zeigt einen gerichteten Graphen G und die zu- gehörige Adjazenzmatrix AG. Im vorigen Semester haben Sie bereits Beispiele dafür gesehen, dass es, je nach Aufgabe, sinnvoll sein kann die eine oder die andere Datenstruktur zu verwenden. Wollen wir zum Beispiel mit Breiten- oder Tiefensuche te- sten, ob ein Graph zusammenhängend ist, so bieten sich Adjazenzlisten an. KAPITEL 1. GRAPHENTHEORIE 15 Abbildung 1.7: Der Graph G und die zugehörige Adjazenzmatrix AG. Denn dann ist die Laufzeit O(|V| + |E|), während die Verwendung eine Ad- jazenzmatrix immer zu einer Laufzeit von mindestens O(|V| 2) führt. Wenn daher |E| ˝ |V| 2 gilt (was immer gegeben ist, wenn der Durchschnittsgrad o(|V|) ist), ist eine Breiten- oder Tiefensuche also schneller (unter Umstän- den sogar viel schneller) wenn mann Adjazenzlisten statt einer Adjazenz- matrix verwendet. Die Verwendung von Adjazenzmatrizen erlaub andererseits die Verwen- dung von Hilfsmitteln aus der linearen Algebra. So haben Sie haben zum Beispiel auch bereits gesehen, dass man mit Hilfe von Matrizenmultiplika- tionen die Anzahl Wege der Länge k zwischen allen Knotenpaaren i, j 2 V bestimmen kann: Satz 1.13. Sei G = (V, E) bzw. D = (V, A) ein ungerichteter bzw. gerichteter Graph mit Knotenmenge V = [n] und M die zugehörige Adjazenzmatrix. Dann entspricht der Eintrag mk ij der i-ten Zeile und j-ten Spalte der Matrix M k der Anzahl gerichteter Wege der Länge (genau) k von i nach j. Auch zu anderen Parametern einer Matrix, wie zum Beispiel dem Rang oder den Eigenwerten, kann man Eigenschaften des zugehörigen Graphen in Verbindung bringen. Dieses überlassen wir aber weiterführenden Vorle- sungen. KAPITEL 1. GRAPHENTHEORIE 16 1.2 Bäume Im vorigen Abschnitt haben wir Bäume als eine wichtige graphentheore- tische Struktur kennen gelernt: ein Graph ist ein Baum, wenn er kreisfrei und zusammenhängend ist. Ebenfalls kennen gelernt haben wir den Begriff eines Teilgraphen: ein Graph H = (VH, EH) ist (schwacher) Teilgraph eines Graphen G = (V, E), wenn VH \u0012 V gilt und zusätzlich auch EH \u0012 E. In diesem Sinne könnten wir also beispielsweise nach einem grössten Baum fragen der in G enthalten ist, wobei wir „Grösse“ interpretieren als „mög- lichst viele Kanten“. Betrachten wir als Beispiel den vollständigen Graphen auf der Knoten- menge V = [n]. Wir erinnern uns: vollständig heisst, dass alle möglichen Kanten auch tatsächlich vorhanden sind. Für n \u0015 3 enthält der vollstän- dige Graph aber (je nach Grösse von n sogar sehr viele) Kreise. Ein Baum ist aber kreisfrei. Eine Möglichkeit einen Baum zu erhalten besteht da- her darin, einfach so lange Kanten aus Kreisen zu entfernen, bis wir einen Baum erhalten. Dieses Verfahren funktioniert in der Tat, und zwar nicht nur für den vollständigen Graphen, sondern für jeden zusammenhängenden Graphen. Satz 1.14. Ist G = (V, E) ein zusammenhängender Graph, so findet der folgende Algorithmus einen Baum T = (V, ET ) mit ET \u0012 E: G 0 ← G while (G 0 enthält einen Kreis) wähle einen beliebigen Kreis C in G 0 und entferne eine be- liebige Kante des Kreises C aus der Kantenmenge von G 0 return G 0 Um die Korrektheit dieses Satzes zu beweisen, überlegen wir uns zu- nächst eine wichtige Eigenschaften eines zusammenhängenden Graphen. Lemma 1.15. Ist G = (V, E) ein zusammenhängender Graph, C ein Kreis in G und e eine Kante in C, so ist der Graph Ge = (V, E \\ {e}) (sprich: der Graph den wir aus G erhalten in dem wir die Kante e löschen) ebenfalls zusammenhängend. Beweis. Zu zeigen ist, dass es für je zwei Knoten x, y in V mindestens KAPITEL 1. GRAPHENTHEORIE 17 einen Weg von x nach y in Ge gibt. Da G zusammenhängend ist, gibt es aber in G auf jeden Fall einen x-y-Pfad, nennen wir ihn P. Falls die Kante e = {u, v} nicht zu P gehört, so ist P auch ein Pfad in Ge; in diesem Fall sind wir fertig. Im anderen Fall enthält P die Kante e. Insbesondere gibt es in Ge dann einen Pfad h x, a1, . . . , ak, ui von x zu einem der Endpunkte der Kante e, sagen wir zu u. Ebenso gibt enthält Ge einen Pfad h y, b1, . . . , bℓ, vi von y zu dem anderen Endpunkt von e, hier also v. Da jedoch (nach An- nahme) die Kante e auf einem Kreis C liegt, enthält Ge ausserdem noch einen u-v-Pfad h u, c1, . . . , cm, vi . Insgesamt enthält Ge also den x-y-Weg h x, a1, . . . , ak, u, c1, . . . , cm, v, bℓ, . . . , b1, yi , was zu zeigen war. Mit diesem Lemma ist der Beweis von Satz 1.14 nunmehr ein Kinder- spiel. Beweis von Satz 1.14. Da nach Annahme G zusammenhängend ist, ist der Graph G 0 nach der Initialisierung (als Graph G) sicherlich auch zusam- menhängend. Lemma 1.15 garantiert uns weiterhin, dass wir den Zusam- menhang von G 0 während der while-Schleife nicht zerstören. Nach Beendi- gung der while-Schleife ist der Graph G 0 also noch immer zusammenhän- gend, er ist aber auch kreisfrei (weil die while-Schliefe ja terminiert hat), also ist G 0 kreisfrei und zusammenhängend, sprich: ein Baum. Aus Satz 1.14 folgt: jeder zusammenhängende Graph enthält einen Baum auf der gleichen Knotenmenge. Solch einem Baum nennt man auch Spann- baum (engl. spanning tree). Auch wenn wir jetzt wissen, dass jeder zusam- menhängende Graph (mindestens) einen Spannbaum enthält, so bleibt die Frage: wie finden wir einen „schönsten“ Spannbaum? – Bevor wir diese Fra- ge beantworten können müssen wir uns zunächst darauf verständigen, was „schön“ überhaupt meint. Dies ist a priori nicht so klar. Wir könnten zum Beispiel darauf bestehen, dass alle Grade so klein wie möglich sind. Also beispielsweise einen Baum suchen in dem alle Grade kleiner gleich 2 sind, also (Übung!) einen Baum suchen, der de facto ein Pfad ist. Wie wir in Ab- schnitt 1.5.2 sehen werden ist dies kein ganz einfaches Problem. Zunächst wollen wir daher keine Restriktion über die Grade in dem Baum erheben sondern betrachten statt dessen eine gewichtete Variante des Spannbaum- problems. Minimaler Spannbaum KAPITEL 1. GRAPHENTHEORIE 18 Gegeben: ein zusammenhängender Graph G = (V, E) und eine Kosten- funktion c : E → R. Gesucht: ein Baum T = (V, ET ) mit ET \u0012 E und ∑ e2 ET c(e) ! = min. Einen solchen Spannbaum T , der die Summe ∑ e2 ET c(e) minimiert, nennt man auch einen minimalen Spannbaum (engl. minimum spanning tree oder MST ). Bevor wir uns konkrete Algorithmen für dieses Problem ansehen, versuchen wir zunächst etwas Gefühl für dieses Problem zu ent- wickeln. Ein Schnitt in einem Graphen ist gegeben durch eine Menge S \u0012 V mit ; 6 = S und S 6= V und besteht aus allen Kanten mit einem Endknoten in S und dem anderen in V \\ S. Mit E(S, V \\ S) bezeichnen wir die Menge die- ser Kanten (siehe Abbildung 1.8). Da jeder Pfad von einem Knoten in S zu einem Knoten in V \\S mindestens eine Kante aus E(S, V \\S) enthält, wissen wir insbesondere dass auch jeder (minimale) Spannbaum mindestens eine Kante aus E(S, V \\ S) enthalten muss. Im Idealfall ist das diejenige mit dem kleinsten Gewicht unter allen Kanten in E(S, V \\ S). Betrachten wir statt einem Schnitt einen Kreis C, so wissen wir umgekehrt, dass jeder (mini- male) Spannbaum mindestens eine Kante von C nicht enthält. Im Idealfall ist das diejenige mit dem grösstem Gewicht unter allen Kanten in C. Diese Beobachtungen machen wir jetzt präzise. Abbildung 1.8: Ein Schnitt E(S, V \\ S) in dem Graphen G = (V, E). Lemma 1.16. Sei G = (V, E) ein zusammenhängender Graph und sei S \u0012 V mit ; 6 = S und S 6= V. Für jede Kante ^e in E(S, V \\ S) mit c(^e) = min {c(e) | e 2 E(S, V \\ S)} gilt dann: a) es gibt einen minimalen Spannbaum T \u0003 in G, der ^e enthält. b) gilt c(^e) < c(e) für alle Kanten e 2 E(S, V \\ S), e 6= ^e, so ist ^e in allen minimalen Spannbäume in G enthalten. Beweis. Da G nach Annahme zusammenhängend ist, enthält G sicherlich KAPITEL 1. GRAPHENTHEORIE 19 Abbildung 1.9: Illustration zum Beweis von Lemma 1.16. einen Spannbaum (nach Satz 1.14). Es gibt daher mindestens einen mini- malen Spannbaum (vielleicht auch mehrere). Sei T ein solcher. Ist ^e in T enthalten, so haben wir a) bereits gezeigt. Nehmen wir daher an, dass ^e nicht in T enthalten ist. Nach Annahme gehört einer der Endknoten von ^e zur Menge S, der andere nicht: sei daher ^e = {x, y} mit x 2 S und y 62 S. Da T ein Spannbaum ist, gibt es in T einen Pfad von x nach y. Wegen x 2 S und y 62 S muss dieser daher eine Kante e 0 = {x 0 , y 0 } enthalten mit x 0 2 S und y 0 62 S und somit e 0 2 E(S, V \\ S). Nach Wahl von e gilt daher c(^e) \u0014 c(e 0 ). Der Baum T 0 := T + ^e − e 0 ist daher ebenfalls ein minima- ler Spannbaum, der ^e im Gegensatz zu T enthält, womit a) bewiesen ist (Abbildung 1.9). Die Aussage b) folgt jetzt ganz analog: gäbe es einen mi- nimalen Spannbaum T , der ^e nicht enthält, so könnten wir wie zuvor einen Spannbaum T 0 konstruieren, wobei aber jetzt, wegen der Annahme in b), gelten würde: c(T 0 ) < c(T ), was nicht sein kann, da T bereits ein minimaler Spannbaum war. Dieser Widerspruch zeigt, dass b) gilt. Lemma 1.17. Sei G = (V, E) ein zusammenhängender Graph und sei C ein Kreis in G. Für jede Kante ^e 2 C mit c(^e) = max {c(e) | e 2 C} gilt dann: a) es gibt einen minimalen Spannbaum T \u0003 in G, der ^e nicht enthält. b) gilt c(^e) > c(e) für alle Kanten e 2 C, e 6= ^e, so gilt ^e 62 T für alle minimalen Spannbäume in G. Beweis. Wie zuvor betrachten wir einen beliebigen minimalen Spannbaum T in G. Sei ^e = {x, y} und C = h x, a1, . . . , ak, y, xi . Ist ^e nicht in T enthalten, so haben wir a) bereits gezeigt. Nehmen wir daher an, dass ^e in T enthalten ist. Wir entfernen ^e aus T , sei also T 0 := T − ^e. Im Folgenden bezeichnen wir mit S die Menge der Knoten, die in T 0 durch einen Pfad mit x verbunden KAPITEL 1. GRAPHENTHEORIE 20 sind, und mit S 0 die Menge der Knoten, die in T 0 durch einen Pfad mit y verbunden sind. Nach Lemma 1.7 besteht T 0 aus genau zwei Komponenten, weshalb S 0 = V \\ S gilt. Wir betrachten nun den x-y-Pfad C 0 := h x, a1, . . . , ak, yi , der aus C ent- steht, indem wir die Kante ^e weglassen. Da x 2 S und y 2 V \\ S ist, enthält C 0 eine Kante e 0 = {x 0 , y 0 } mit x 0 2 S und y 0 2 V \\ S. Wir sehen nun, dass T 0 +e 0 ein Baum sein muss (siehe Abbildung 1.10): erstens ist T 0 +e 0 zusam- menhängend, denn die Kante e 0 verbindet ja die Zusammenhangskompo- nenten S und V \\S von T 0 , und zweitens ist T 0 +e 0 kreisfrei, denn sonst hätte schon T 0 eine Kante enthalten, die zwischen S und V \\S verläuft. Nach Wahl von ^e gilt c(^e) \u0015 c(e 0 ) und damit c(T 0 + e 0 ) = c(T ) − c(^e) + c(e 0 ) \u0014 c(T ). Da T nach Annahme ein minimaler Spannbaum war, ist daher auch T 0 + e 0 ein minimaler Spannbaum, und zwar einer der ^e nicht enthält. Womit wir a) gezeigt haben. Die Aussage b) folgt jetzt wieder ganz analog: gäbe es einen minimalen Spannbaum T , der ^e enthält, könnten wir wie zuvor einen Spannbaum T 0 + e 0 konstruieren, wobei aber jetzt, wegen der Annahme in b), gelten würde: c(T 0 + e 0 ) < c(T ), was nicht sein kann, da T bereits ein minimaler Spannbaum war. Dieser Widerspruch zeigt, dass b) gilt. Abbildung 1.10: Illustration zum Beweis von Lemma 1.17. Aus diesen beiden Lemmas leiten wir jetzt einen Algorithmus ab. Aus- gehend von einem Graphen G = (V, E) mit Kostenfunktion c : E → R und ungefärbten Kanten, färben wir die Kanten iterativ (so lange es geht) in dem wir eine (beliebige) der beiden folgenden Regeln anwenden: Blaue Regel Gegeben: eine Menge S \u0012 V mit ; 6 = S und S 6= V , so dass keine Kante in E(S, V \\ S) blau gefärbt ist. Färbe: eine ungefärbte Kante ^e 2 E(S, V \\ S) mit c(^e) = min{c(e) | e 2 E(S, V \\ S)} blau. KAPITEL 1. GRAPHENTHEORIE 21 Rote Regel Gegeben: ein Kreis C in G, so dass keine Kante in C rot gefärbt ist. Färbe: eine ungefärbte Kante ^e 2 C mit c(^e) = max {c(e) | e 2 C} rot. Satz 1.18. Ist G = (V, E) ein zusammenhängender Graph mit Kosten- funktion c : E → R, so gilt für jede Ausführungsreihenfolge der blauen und roten Regel: lässt sich keine der beiden Regeln mehr anwenden, so sind alle Kanten gefärbt und die blauen Kanten bilden einen mi- nimalen Spannbaum. Beweis. Wir zeigen zunächst, dass die folgenden beiden Invarianten gelten: Schnitt: für jede Menge S \u0012 V mit ; 6 = S und S 6= V gibt es eine Kante ^e 2 E(S, V \\ S) mit c(^e) = min{c(e) | e 2 E(S, V \\ S)}, die ungefärbt oder blau gefärbt ist. Kreis: für jeden Kreis C in G gibt es eine Kante ^e 2 C mit c(^e) = max {c(e) | e 2 C}, die ungefärbt oder rot gefärbt ist. Offenbar gelten beide Bedingungen zu Beginn des Algorithmus, da dann alle Kanten noch ungefärbt sind. Wir zeigen daher, dass die Anwendung der roten oder blauen Regel nicht dazu führen kann, dass eine der Invarianten nicht mehr gilt. Dazu überlegen wir uns zunächst, dass eine Anwendung der blauen Regel die Invariante Schnitt nicht zerstören kann (da wir hier ja eine Kante blau färben) und umgekehrt eine Anwendung der roten Regel die Invariante Kreis nicht zerstören kann. Weiter überlegen wir uns, dass ein Kreis C und ein Schnitt E(S, V \\ S) sich immer in einer geraden Anzahl Kanten überschneiden, denn der Kreis muss ja genauso oft von S nach V \\ S gehen wie von V \\ S nach S. Wenn wir daher die blaue Regel anwenden, so gilt für jeden Kreis C: entweder ist keine Kante von C durch die blaue Regel tangiert oder es muss es noch eine weitere Kante in C geben, die (nach Definition der blauen Regel) nicht blau gefärbt ist und deren Gewicht mindestens so gross ist wie das Gewicht derjenigen Kante, die blau gefärbt wird. Eine Anwendung der blauen Regel kann daher die Invariante Kreis nicht zerstören. Wenn wir andererseits die rote Regel anwenden, so gilt für jeden Schnitt E(S, V \\ S): entweder ist keine Kante des Schnittes E(S, V \\ S) durch die rote Regel tangiert oder es muss es noch eine weitere Kante in E(S, V \\ S) geben, die (nach Definition der roten Regel) nicht rot gefärbt ist und deren Gewicht höchstens so gross ist wie das Gewicht derjenigen KAPITEL 1. GRAPHENTHEORIE 22 Kante, die rot gefärbt wird. Eine Anwendung der roten Regel kann daher die Invariante Schnitt nicht zerstören. Somit folgt: die Invarianten Schnitt und Kreis gelten insbesonde- re auch am Ende des Algorithmus. Wir betrachten jetzt den Teilgraphen H = (V, Eblau), wobei mit Eblau die Menge der blauen Kanten gemeint ist. Wäre dieser nicht zusammenhängend, so gäbe es eine Menge S so dass alle Kanten aus E(S, V \\ S) entweder rot oder ungefärbt sind. Wegen der In- variante Schnitt gibt es dann eine ungefärbte Kante ^e 2 E(S, V \\ S) mit c(^e) = min {c(e) | e 2 E(S, V \\ S)}, und daher könnten wir die blaue Regel auf die Menge S anwenden. Also wissen wir, dass der Teilgraph aus den blauen Kanten zusammenhängend ist. Ebenso kann H keinen Kreis enthal- ten, denn die Invariante Kreis impliziert insbesondere, dass jeder Kreis eine ungefärbte oder rote Kante enthalten muss, also nicht ganz blau sein kann. Der blaue Teilgraph H ist also ein Spannbaum. Wegen der Invari- ante Kreis wissen wir ausserdem, dass es keine ungefärbte Kante {x, y} geben kann, denn auf den Kreis, der aus {x, y} und dem x-y-Pfad in H besteht, könnten wir die rote Regel anwenden. Daraus folgt, dass H der einzige Spannbaum ist, der keine rote Kante enthält. Wegen Lemma 1.17 wissen wir zusätzlich: es gibt einen minimalen Spannbaum, der keine der rot gefärbten Kanten enthält (denn statt die Kante rot zu färben, könnten wir sie alternativ auch löschen). Der blaue Teilgraph ist daher nicht nur ein Spannbaum, sondern sogar ein minimaler Spannbaum, was zu zeigen war. In den nächsten beiden Abschnitten werden wir Satz 1.18 anwenden, um zwei klassische Algorithmen für das Finden minimaler Spannbäume herzuleiten. 1.2.1 Algorithmus von Prim Als erstes betrachten wir einen Algorithmus, der de facto ohne die rote Regel auskommt. Genauer gesagt wird der Algorithmus zunächst n − 1 mal die blaue Regel anwenden. Und da aus Satz 1.18 insbesondere folgt, dass danach nur noch die rote Regel anwendbar ist, können wir uns diese Schritte dann auch sparen. In der Literatur ist dieser Algorithmus als Algorithmus von Prim bekannt, benannt nach Robert Prim, einem amerikanischen Wissenschaftler, der einen entsprechenden Algorithmus 1957 publizierte, KAPITEL 1. GRAPHENTHEORIE 23 offenbar in Unkenntnis eines ähnlichen Verfahrens, das Vojtěch Jarník bereits 1930 auf tschechisch veröffentlichte. Wir gehen folgendermassen vor: wähle einen beliebigen (Start-)Knoten v 2 V S := {v} while S 6= V do wähle eine (beliebige) Kante ^e 2 E(S, V \\ S) mit c(^e) = min{c(e) | e 2 E(S, V \\ S)} färbe ^e blau sei ^e = {^v, ^x} mit ^v 2 S und ^x 62 S: füge ^x zu S hinzu Offenbar wächst die Menge S in jedem Durchlauf der while-Schleife um genau einen Knoten, und daher wird die Schleife genau n − 1 mal ausgeführt. Wir überlegen uns zunächst, dass dieser Algorithmus wirklich einen minimalen Spannbaum bestimmt. Hierfür zeigen wir: liegen zu Beginn einer Iteration der while-Schleife alle blau gefärbten Kanten in dem durch die Menge S induzierten Subgraphen, so gilt dies auch am Ende. In der Tat: aus der Konstruktion des Algorithmus folgt unmittelbar, dass alle Endpunkte der neu blau gefärbten Kante ^e am Ende der while-Schleife ebenfalls zu S gehören (und alle andere tun das nach Annahme sowieso). Verwenden wir nun noch, dass zu Beginn des Algorithmus keine Kante blau gefärbt ist und daher die Menge S = {v} alle (nicht vorhandenen) blauen Kanten enthält, so können wir somit folgern, dass jede der n−1 Iterationen der while-Schleife einer korrekten Anwendung der blauen Regel entspricht. Daher bilden die blauen Kanten am Ende einen minimalen Spannbaum. Nachdem wir die Korrektheit des Algorithmus eingesehen haben, über- legen wir uns nun noch, wie man den Algorithmus effizient implementieren kann. Eine naive Implementierung würde einfach in jeder der n−1 Iteratio- nen der while-Schleife die komplette Kantenliste durchlaufen und für jede Kante (in konstanter Zeit) entscheiden, ob sie zu dem aktuellen Schnitt E(S, V \\ S) gehört und unter allen solchen eine minimale Kante auswählen. Damit erhalten wir einen Algorithmus mit Laufzeit O(|V| \u0001 |E|). Um dies zu verbessern, überlegen wir uns zunächst, dass sich die Menge S in jedem Durchlauf der while-Schleife nur um genau einen Knoten ändert. Um diese Knoten effizient zu finden, definieren wir zwei Parameter: 8 x 62 S : σ[x] := min {c(^v, x) | ^v 2 N(x) \\ S}, pred[x] := ein ^v 2 S so dass c(^v, x) = σ[x]. KAPITEL 1. GRAPHENTHEORIE 24 Anschaulich bedeutet dies: für jeden Knoten x 2 V \\ S bezeichnet σ[x] das Gewicht einer leichtesten Kante von x in die Menge S (falls es keine solche Kante gibt, das Minimum also über eine leere Menge geht, so ist σ[x] definitionsgemäss gleich +∞). Beachte: σ[x] gibt nur das Gewicht einer leichtesten Kanten an. Um eine solche Kante auch wirklich zu finden (um sie in den minimalen Spannbaum einfügen zu können), müssen wir uns auch noch einen Knoten aus S merken, der zusammen mit x solch eine billigste Kante bildet. Dies ist die Aufgabe des Parameters pred[x]. Jetzt müssen wir uns noch überlegen, wie wir diese Parameter effizient berechnen. Die Initialisierung ist einfach: für alle x 2 N(v) setzen wir σ[x] = c(v, x) und pred[x] = v, für alle übrigen Knoten x 2 V \\ S setzen wir σ[x] = ∞ und pred[x] = undef (für: undefined), um anzudeuten, dass es von diesem x keine Kante in die Menge S gibt. Auch der Update der Werte innerhalb der while-Schleife lässt sich einfach realisieren. Da in der while- Schleife jeweils nur der Knoten ^x zur Menge S hinzugefügt wird, müssen wir nur die Nachbarn von ^x in die Menge V \\ S betrachten, denn nur für diese kann σ[x] sich ändern. Für jeden solchen Knoten x 2 N(^x) \\ (V \\ S) vergleichen wir die Kosten c(^x, x) der Kante von ^x zu x mit dem Wert σ[x], dem Gewicht einer leichtesten Kante von x in die Menge S. Falls c(^x, x) < σ[x], so setzen wir σ[x] = c(^x, x) und pred[x] = ^x. Was uns jetzt noch fehlt, ist ein Verfahren, das es uns erlaubt innerhalb der while-Schleife jeweils den „besten“ Knoten ^x effizient zu bestimmen. Hierfür bietet sich die Datenstruktur der sogenannten PriorityQueues an. Diese unterstützen drei Arten von Operationen: Insert, ExtractMin, DecreaseKey, die jeweils genau das tun was ihr Name besagt: ein neues Element mit einem dazugehörenden Schlüssel einfügen, dasjenige Element mit dem kleinsten Schlüssel auslesen (und aus der Datenstruktur entfer- nen), und den Schlüssel eines Elementes verringern. Nach all diesen Vorüberlegungen erhalten wir jetzt folgende Implemen- tierung des Algorithmus von Prim. KAPITEL 1. GRAPHENTHEORIE 25 Algorithmus von Prim (G, c) 1: wähle einen beliebigen (Start-)Knoten v 2 V 2: S ← {v} 3: for all x 2 V \\ S do 4: if x 2 N(v) then 5: σ[x] ← c(v, x) und pred[x] ← v 6: else 7: σ[x] ← ∞ und pred[x] ← undef 8: T ← ; ▷ Initialisiere Spannbaum 9: Q ← ; ▷ Initialisiere PriorityQueue 10: for all x 2 V \\ S do 11: Insert(Q, x, σ[x]) ▷ füge x mit dem Schlüssel σ[x] ein 12: while S 6= V do 13: ^x ← ExtractMin(Q) 14: S ← S [ {^x} 15: T ← T + {^x, pred[^x]} 16: for all x 2 N(^x) \\ (V \\ S) do 17: if c(^x, x) < σ[x] then 18: σ[x] ← c(^x, x) und pred[x] ← ^x 19: DecreaseKey(Q, x, σ[x]) 20: return T ▷ T is ein minimaler Spannbaum Die Laufzeit des Algorithmus von Prim lässt sich jetzt einfach abschät- zen. Die Initialisierung wird dominiert durch die n − 1 Insert-Aufrufe. In- nerhalb der while-Schleife (die n − 1 mal durchlaufen wird, einmal für jede Kante des Spannbaums) wird in jeder Iteration ein Mal die Operation Ex- tractMin aufgerufen. Wenn der Graph mit Adjazenzlisten abgespeichert ist, so benötigt die forall-Schleife für jeden Knoten ^x Lautzeit proportional zu deg(^x) \u0001 h Laufzeit von DecreaseKeyi . Wegen ∑ ^x2 V deg(^x) = 2|E| (vgl. Lemma 1.2) erhalten wir folgende Schranke für Laufzeit des Algorithmus von Prim: O(|V| \u0001 h Laufzeit von Inserti + |V| \u0001 h Laufzeit von ExtractMini + |E| \u0001 h Laufzeit von DecreaseKeyi ). Die konkrete Laufzeit des Algorithmus von Prim hängt davon ab, wie wir die PriorityQueue implementieren. Wir könnten zum Beispiel ein Array KAPITEL 1. GRAPHENTHEORIE 26 verwenden. Dann benötigt jedes Insert und jedes DecreaseKey nur O(1) Zeit, ein ExtractMin jedoch O(|V|). Als Laufzeit für den Algorithmus von Prim erhalten wir damit O(|V| + |V| 2 + |E|) = O(|V| 2). Alternativ können wir die aus dem ersten Teil der Vorlesung bekannten Min-Heaps verwenden. Für diese benötigen alle drei Operationen nur Laufzeit O(log |V|). Damit erhalten wir: Satz 1.19. Der Algorithmus von Prim berechnet für zusammenhän- gende Graphen G = (V, E) mit Gewichtsfunktion c : E → R, die mit Adjazenzlisten gespeichert sind, in Zeit O(min{|V| 2, |E| \u0001 log |V|}) einen minimalen Spannbaum. Die beste bekannte Laufzeit erhält man, wenn man statt den Min-Heaps sogenannte Fibonacci-Heaps verwendet. Damit reduziert sich die asympto- tische Laufzeit des Algorithmus von Prim auf O(|V|\u0001 log |V|+|E|). Allerdings sind hierbei die in der O-Notation verborgenen Konstanten relativ gross, so dass für praktische Zwecke die Verwendung eines Min-Heaps oft effizienter ist. 1.2.2 Algorithmus von Kruskal Der amerikanischer Mathematiker Joseph Kruskal hat 1956 folgenden Algorithmus für das Minimale Spannbaum Problem vorgestellt: sortiere die Kantenmenge E so dass gilt: E = {e1, . . . , em} und c(e1) \u0014 c(e2) \u0014 \u0001 \u0001 \u0001 \u0014 c(em) S := {v} for i = 1 to m do wenn die Endpunkte von ei durch einen blauen Pfad verbunden sind: färbe ei rot ansonsten: färbe ei blau Wir überlegen uns zunächst, dass der Algorithmus die rote bzw. blaue Regel korrekt anwendet. In der Tat: wenn die Endpunkte Kante der Kan- te ei durch einen blauen Pfad verbunden sind, so können wir wegen der aufsteigenden Sortierung der Kanten die rote Regel für den zugehörigen Kreis anwenden. Ansonsten befinden sich die Endpunkte der Kante ei in KAPITEL 1. GRAPHENTHEORIE 27 verschiedenen Zusammenhangskomponenten S und S 0 des durch die blau gefärbten Kanten gegebenen Teilgraphen. Offenbar gibt es dann auch keine roten Kanten mit einem Endpunkt in S und einem in V \\S, denn wir färben eine Kante ja nur rot, wenn zwischen ihren Endpunkten ein blauer Pfad läuft. Wegen der aufsteigenden Sortierung der Kanten können wir die blaue Regel zum Beispiel für Menge S anwenden. Satz 1.18 garantiert uns also, dass der Algorithmus von Kruskal einen minimalen Spannbaum findet. Wie aber können wir ihn effizient implemen- tieren? Eine naive Implementierung würde in jeder Iteration der for-Schleife eine Breiten- oder Tiefensuche für den Teilgraphen mit den blau gefärb- ten Kanten ausführen, um zu entscheiden ob die Endpunkte der gegebenen Kante durch einen blauen Pfad verbunden sind. Dies führt zu einer Laufzeit von O(|E| \u0001 |V|) (da der blaue Teilgraph höchstens |V| − 1 Kanten enthält). Eine effizientere Implementierung erhalten wir wiederum mit der Ver- wendung einer geeigneten Datenstruktur. In diesem Fall ist dies die soge- nannten Union-Find-Struktur. Dies ist eine Datenstruktur für folgendes Problem. Gegeben sei eine endliche Menge X, partitioniert in (disjunkte) Mengen Xi, wobei jede Menge Xi durch ein in ihr enthaltenes Element repräsentiert wird. Die Datenstruktur unterstützt nun die folgenden drei Operationen: • Insert(X, x): füge das Element x zur Menge X hinzu; dieses bildet eine neue (einelementige) Menge Xi, • Find(X, x): gib den Repräsentanten derjenigen Menge Xi aus, die x enthält, • Union(X, x, y): vereinige die beiden Mengen Xi und Xj, die x bzw. y enthalten. Die grundlegende Idee für die Realisierung dieser Datenstruktur ist sehr einfach. Jede Menge wird durch einen gewurzelten und zur Wurzel hin ge- richteten Baum (einen sogenannten intree) dargestellt. Speichern wir dann an der Wurzel des Baumes den Repräsentanten der zugehörigen Menge Xi, so kann man beispielsweise ein Find dadurch realisieren, dass man den Baum entlang der zur Wurzel hin gerichteten Kanten durchläuft und den dort gespeicherten Repräsentanten ausgibt. Die einzelnen Versionen dieser Datenstruktur unterscheiden sich darin, wie man die Bäume im Detail aufbaut. Hier wollen wir eine ganz einfache KAPITEL 1. GRAPHENTHEORIE 28 Version betrachten, in der alle Bäume Tiefe 1 haben. Ein Find lässt sich daher immer in O(1) Zeit ausführen. Zeitaufwendiger ist jedoch die Union Operation, denn hier müssen wir ja alle Knoten eines der beiden Bäume unter die Wurzel des anderen Baumes hängen. Um den Aufwand hierfür wenigstens etwas unter Kontrolle zu halten, vereinbaren wir noch Folgen- des: an der Wurzel jedes Baumes speichern wir die Anzahl der Knoten ab, die in dem Baum enthalten sind. Dann können wir also immer die Knoten des kleineren Bäume unter die Wurzel des grösseren Baumes hängen. Auf den ersten Blick hilft dies nicht viel: für zwei Bäume mit je |X|/2 Knoten benötigt ein einziger Aufruf der Union Operation trotzdem Laufzeit Θ(|X|). Eine amortisierte Analyse erlaubt uns jedoch folgende Beobachtung: je- der Knoten aus X kann während einer beliebigen Folge von Union-Aufrufen höchstens log |X| oft umgehängt werden. Dies sieht man wie folgt ein: nach dem Einfügen in die Datenstruktur (mit Insert) bildet der Knoten seine eigene Menge, also einen Baum mit genau einem Knoten. Jedes Mal wenn der Knoten bei einem Aufruf von Union an eine neue Wurzel angehängt, so befindet er sich danach in einem Baum mit mindestens doppelt so vielen Knoten wie vorher (da wir ja die Knoten des kleineren Baumes umhän- gen). Nach k-maligem Umhängen befindet sich der Knoten also in einem Baum mit mindestens 2k vielen Knoten. Da aber kein Baum mehr als |X| viele Knoten enthalten kann, können wir den Knoten höchstens log |X| oft umhängen. Damit erhalten wir: Satz 1.20. Eine Union-Find-Struktur für eine Menge X kann so imple- mentiert werden, dass jedes Insert und jedes Find nur Zeit O(1) be- nötigt und eine beliebige Folge von Union Operationen eine Gesamt- Laufzeit von O(|X| \u0001 log |X|) hat. Für den Algorithmus von Kruskal können wir diese Datenstruktur ver- wenden, in dem wir als Menge X die Knotenmenge V unseres Graphen wählen und als Mengen Xi die Knotenmengen der Zusammenhangskompo- nenten des blauen Teilgraphen. Damit ergibt sich dann folgende Implemen- tierung: KAPITEL 1. GRAPHENTHEORIE 29 Algorithmus von Kruskal (G, c) 1: sortiere die Kantenmenge E so dass gilt: 2: E = {e1, . . . , em} und c(e1) \u0014 c(e2) \u0014 \u0001 \u0001 \u0001 \u0014 c(em) 3: T ← ; ▷ Initialisiere Spannbaum 4: X ← ; ▷ Initialisiere Union-Find-Struktur 5: for all v 2 V do 6: Insert(X, v) 7: for i = 1 to m do 8: seien x und y die Endpunkte von ei, also ei = {x, y} 9: if Find(X, x) 6= Find(X, y) then 10: T ← T + ei 11: Union(X, x, y) 12: return T ▷ minimaler Spannbaum Die Analyse der Laufzeit ist jetzt sehr einfach: die Sortierung der Kan- tenmenge (z.B. mit Quicksort) erfordert O(|E| log |E|) = O(|E| log |V|) Ope- rationen, da |E| \u0014 |V| 2 ist. Die for-schleife wird |E| mal durchlaufen, die beiden Find-Aufrufe benötigen hierbei jeweils nur O(1) Zeit; die Gesamt- laufzeit für alle Union-Aufrufe ist nach Satz 1.20 beschränkt durch O(|V| \u0001 log |V|). Somit erhalten wir: Satz 1.21. Der Algorithmus von Kruskal berechnet für zusammenhän- gende Graphen G = (V, E) mit Gewichtsfunktion c : E → R, die mit Adjazenzlisten gespeichert sind, in Zeit O(|E|\u0001 log |V|) einen minimalen Spannbaum. 1.2.3 Exkurs: Shannon’s Switching Game Zum Abschluss dieses Abschnittes über Spannbäume betrachten wir noch ein Spiel bei dem wir einige der Begriffe und Argumentationsweisen die- ses Abschnittes nochmals vertiefen können. Zwei Spieler, nennen wir sie Blau und Rot färben die Kanten eines zu Beginn ungefärbten Graphen G = (V, E) abwechselnd mit ihrer Farbe: Blau färbt eine Kante blau, dann Rot eine Kante rot, dann wieder Blau eine Kante blau, usw. Wobei beide Spieler immer nur ungefärbte Kanten färben dürfen. Gewonnen hat wer KAPITEL 1. GRAPHENTHEORIE 30 zuerst einen Spannbaum in seiner Farbe hat. Leider ist dieses Spiel für den Spieler Rot ziemlich unattraktiv: denn Rot kann nicht gewinnen. Dies sieht man wie folgt ein. Angenommen es gäbe eine Strategie mit der Rot gewinnen könnte. Strategie heisst hier: für jede Spielsituation (Teil der Kan- ten blau bzw. rot gefärbt) eine Wahl für die nächste rot zu färbende Kante. Wenn es so eine Strategie für Rot gäbe ... dann könnte auch Blau danach spielen (mit den die Farben blau und rot vertauscht). Und da Blau be- ginnt, hätte dann Blau zuerst einen Spannbaum. Dieses Argument nennt man Strategie-Klau (engl. strategy stealing). Es zeigt, dass es bei einem solchen, wie man sagt symmetrischen, Spiel nur zwei mögliche Ergebnisse geben kann: der erste Spieler gewinnt oder das Spiel endet unentschieden. Um das Spiel für beide Spieler attraktiv zu halten, betrachten man daher häufig statt einer symmetrischen Variante eine unsymmetrische. Die beiden Spieler nennt man dabei hierbei oft auch Maker und Breaker. Wir werden gleich sehen wieso. In unserem Fall hat Maker die Aufgabe einen Spannbaum zu erzeugen. Maker gewinnt, wenn ihm das gelingt. Gelingt ihm das nicht, so hat Breaker gewonnen. Die Regeln sind dabei analog zu oben: Maker färbt die Kanten in seiner Farbe, Breaker darf jeweils eine ungefärbte Kante löschen. Wir nehmen an, dass Breaker den ersten Zug hat. Für welche Graphen kann Maker gewinnen? – Der Satz von Shannon beantwortet diese Frage: Satz 1.22. Für einen G = (V, E) gibt es genau dann eine Gewinnstrate- gie für Maker, wenn G zwei kantendisjunkten Spannbäume enthält. Beweis. Wir zeigen zunächst, dass es eine Gewinnstrategie für Maker gibt, wenn G zwei kantendisjunkte Spannbäume enthält. Hierfür benötigen wir das Konzept der Kantenkontraktion, das für Multigraphen definiert ist. Bei der Kontraktion einer Kante e = {u, v} verschmelzen wir die beiden Knoten u und v zu einem neuen Knoten xu,v, der nun zu allen Kanten inzident ist, zu denen u oder v inzident war, wobei wir alle Kanten zwischen u und v löschen. Um die Strategie für Maker zu erläutern betrachten wir zunächst ein Beispiel. Nehmen wir an, dass G der vollständige Graph auf vier Knoten ist, also G = K4. Breaker beginnt und entfernt eine beliebige Kante. Als nächstes wählt Maker die Kante zwischen den anderen beiden Knoten. Die folgende Abbildung illustriert diese Vorgehensweise. KAPITEL 1. GRAPHENTHEORIE 31 In der linken Abbildung markiert die rote Kante die von Breaker gewählte Kante und die blaue Kante die von Maker gewählte Kante. In der nächsten Abbildung haben wir die Kante von Breaker gelöscht und die Kante von Maker kontrahiert. Jetzt klar wie Maker spielen muss: sobald Breaker eine der parallelen Kanten nimmt, nimmt Maker die andere. Die rechte Abbildung zeigt einen der möglichen Spannbäume für Maker (welcher genau sich ergibt, hängt davon ab, welche Kanten Breaker entfernt). Mit dieser Vorüberlegung sind wir jetzt bereit, die Strategie für Ma- ker zu formulieren. Genauer zeigen wir durch Induktion über die Anzahl Knoten: ist G = (V, E) ein Multigraph mit zwei kantendisjunkten Spann- bäumen T und T 0 , so gibt es eine Gewinnstrategie für Maker. Für |V| = 2 ist dies offensichtlich richtig. Denn die Annahme, dass es zwei kantendis- junkte Spannbäume gibt, impliziert, dass es zwischen den beiden Knoten aus V mindestens zwei Kanten geben muss. Von diesen kann Breaker in seinem ersten Zug nur eine entfernen und Maker kann daher ebenfalls eine solche Kante wählen, die dann bereits einen Spannbaum bildet. Betrachten wir nun den Induktionsschritt. Sei e die Kante, die Brea- ker in seinem ersten Zug wählt. Ohne Einschränkung sei diese in T . (Falls e weder in T noch in T 0 ist, so wählen wir als e eine beliebige Kante aus T ). Durch Entfernen von e zerfällt T in zwei Komponenten. Da T 0 ebenfalls ein Spannbaum ist, enthält T 0 mindestens eine Kante, die zwischen diesen beiden Komponenten verläuft. Solch eine Kante wählt Maker. Nennen wir sie e 0 . Wenn wir nun e 0 kontrahieren, so sind T − e und T 0 − e 0 kantendis- junkte Spannbäume im kontrahierten Graphen. Und da dieser Graph einen Knoten weniger enthält als G folgt aus der Induktionsannahme, dass es eine Gewinnstrategie für Maker im kontrahierten Graphen gibt. Das war es, was wir zeigen wollten! Sei nun andererseits G ein Graph, der keine zwei kantendisjunkte Spann- bäume enthält. Wenn G gar keinen Spannbaum enthält, so muss sich Brea- ker nicht sonderlich anstrengen um zu gewinnen. Nehmen wir daher an, dass G mindestens einen Spannbaum enthält. Breaker wählt sich einen solchen Spannbaum, wir nennen ihn T , beliebig. Nach Annahme gibt es kei- KAPITEL 1. GRAPHENTHEORIE 32 nen zu T kantendisjunkten zweiten Spannbaum. Breaker wählt sich daher nun einen zu T kantendisjunkten Wald F mit möglichst vielen Kanten. Falls F aus weniger als |V| − 2 Kanten besteht, so zeigt sich Breaker grosszügig und fügt noch in G noch einige zusätzliche Kanten hinzu, bis es einen zu T kantendisjunkten Wald mit |V| − 2 Kanten gibt. Man beachte: wenn der Graph mehr Kanten enthält, so wird es für Maker leichter zu gewinnen. Wir werden aber zeigen, dass Maker trotz dieser zusätzlichen Kanten noch immer nicht gewinnen kann. Hier ist die Strategie für Breaker. Da F ein Wald mit |V| − 2 Kanten ist, besteht F aus zwei Zusammenhangskomponen- ten. Da T ein Spannbaum ist, gibt es daher mindestens eine Kante in T , die diese beiden Komponenten verbindet. Solch ein Kante e wählt Breaker für seinen ersten Zug. Danach kontrahiert er (in Gedanken) diese Kante. Der neu entstandene Graph G 0 enthält jetzt zwei kantendisjunkte Spannbäume: F und T − e. Im Graph G 0 hat jetzt Maker den ersten Zug. Breaker kann daher jetzt so tun als wäre er Maker – und die Strategie aus dem ersten Teil des Beweises anwenden – um in dem Graphen G 0 einen Spannbaum zu erhalten. Zusammen mit der Kante e ist dies ein Spannbaum in G. Und da es, nach Annahme, keinen dazu kantendisjunkten zweiten Spannbaum in G gibt, können Makers Kanten nicht ebenfalls einen Spannbaum enthalten. Also hat Breaker gewonnen! 1.3 Pfade Im ersten Teil der Vorlesung wurden verschiedene Algorithmen vorgestellt, um kürzeste Pfade zwischen zwei gegebenen Knoten (oder auch allen Kno- tenpaaren) zu finden. Kürzeste Pfade Gegeben: ein zusammenhängender Graph G = (V, E), zwei Knoten s, t 2 V und eine Kostenfunktion c : E → R. Gesucht: ein s-t-Pfad P in G mit ∑ e2 P c(e) ! = min. In diesem Skript führen wir fürs erste nur die Namen der dort vorge- stellten Algorithmen an: • Algorithmus von Dijkstra • Algorithmus von Floyd-Warshall KAPITEL 1. GRAPHENTHEORIE 33 • Algorithmus von Bellman-Ford • Algorithmus von Johnson 1.4 Zusammenhang Wir erinnern uns: ein Graph ist genau dann zusammenhängend, wenn es zwischen je zwei Knoten des Graphen einen Pfad gibt. Dieser Begriff des Zusammenhangs sagt aber nichts über den Grad oder die Intensität des Zusammenhangs aus. Darauf wollen wir in diesem Abschnitt eingehen. Definition 1.23. Ein Graph G = (V, E) heisst k-zusammenhängend, falls |V| \u0015 k + 1 und für alle Teilmengen X \u0012 V mit |X| < k gilt: Der Graph G[V \\ X] ist zusammenhängend. Eine Teilmenge X \u0012 V der Knoten, für die G[V \\ X] nicht zusammen- hängend ist, nennt man auch (Knoten-)Separator. Genauer: Sind u, v 2 V und ist X \u0012 V \\ {u, v} eine Knotenmenge, für die u und v in verschiede- nen Zusammenhangskomponenten von G[V \\ X] liegen, so nennt man X einen u-v-Separator. Ein Graph G = (V, E) ist also genau dann k-zusam- menhängend, wenn jeder Separator mindestens Grösse k hat (die einzige Ausnahme ist der vollständige Graph mit k Knoten, der per Definition k−1 zusammenhängend ist). Je grösser daher k, desto „zusammenhängender“ ist der Graph. Insbesondere ist ein k zusammenhängender Graph auch k − 1 zusammenhängend (usw.). Statt die Entfernung von Knoten zu erlauben, könnten wir auch nur Kanten entfernen. Dann erhält man den Begriff des Kanten-Zusammenhangs: Definition 1.24. Ein Graph G = (V, E) heisst k-kanten-zusammen- hängend, falls für alle Teilmengen X \u0012 E mit |X| < k gilt: Der Graph (V, E \\ X) ist zusammenhängend. Auch hier gilt also: Ein Graph G = (V, E) ist genau dann k-kanten-zu- sammenhängend, wenn man mindestens k Kanten (oder mehr) entfernen muss, um den Zusammenhang des Graphen zu zerstören. Analog zu Kno- tenseparatoren nennt man eine solche Kantenmenge X \u0012 V einen Kanten- KAPITEL 1. GRAPHENTHEORIE 34 separator (bzw. einen u-v-Kantenseparator, wenn u, v 2 V nach Entfernen von X in verschiedenen Zusammenhangskomponenten liegen.) Eine andere Möglichkeit einen starken Zusammenhang zu fordern wä- re, für alle Knotenpaare u, v 2 V, u 6= v, statt nur einen Pfad (wie in der Definition des Zusammenhangs) die Existenz von k Pfaden zu fordern, die (ausser u und v) paarweise keine Knoten bzw. Kanten gemeinsam ha- ben. Man spricht hier auch von k intern-knoten-disjunkten bzw. kanten- disjunkten Pfaden. Der Satz von Karl Menger (1902-1985) zeigt, dass beide Begriffe in der Tat äquivalent sind. Wir werden später sehen, dass der Satz von Menger nur ein Spezialfall eines viel allgemeineren Satzes ist. Deshalb verschieben wir den Beweis auf später (Abschnitt 3.1.2). Satz 1.25 (Menger). Sei G = (V, E) ein Graph und u, v 2 V, u 6= v. Dann gilt: a) Jeder u-v-Knotenseparator hat Grösse mindestens k ⇐⇒ Es gibt mindestens k intern-knotendisjunkte u-v-Pfade. b) Jeder u-v-Kantenseparator hat Grösse mindestens k ⇐⇒ Es gibt mindestens k kantendisjunkte u-v-Pfade. 1.4.1 Artikulationsknoten Ist ein Graph zusammenhängend, aber nicht 2-zusammenhängend, so gibt es mindestens einen Knoten v mit der Eigenschaft, dass G[V \\ {v}] nicht zu- sammenhängend ist. Knoten mit dieser Eigenschaft nennt man Artikulati- onsknoten. In diesem Abschnitt werden wir zeigen, wie man die Tiefensu- che so modifizieren kann, dass sie en passant auch alle Artikulationsknoten bestimmt. Hier zur Erinnerung die rekursive Variante der Tiefensuche, wie sie im letzten Semester eingeführt wurde. DFS-Visit(G, v) 1: Markiere v als besucht 2: for all {v, w} 2 E do 3: if w ist noch nicht besucht then 4: DFS-Visit(G, w) Ein Aufruf von DFS-Visit(G, v) besucht alle Knoten in der Zusammen- KAPITEL 1. GRAPHENTHEORIE 35 hangskomponente, die v enthält. Wenn der Graph zusammenhängend ist, was wir in diesem Abschnitt annehmen wollen, so besucht ein Aufruf von DFS-Visit daher alle Knoten. Als erstes modifizieren wir den Algorith- mus so, dass er jedem Knoten statt einem Label „besucht“ eine Nummer zuordnet, und zwar in der Reihenfolge in der die Knoten besucht werden. D.h. der Startknoten s erhält die Nummer 1, der erste Nachbar von s, der besucht wird, die Nummer 2, usw. 2 Diese Nummern speichern wir in einem Array dfs[ ] ab. Dieses Array initialisieren wir in einem Rahmenprogramm: DFS(G, s) 1: 8 v 2 V : dfs[v] ← 0 2: num ← 0 3: T ← ; 4: DFS-Visit(G, s) Insbesondere bedeutet daher dfs[w] = 0, dass der Knoten w noch nicht be- sucht wurde. In der Variable num speichern wir zu jedem Zeitpunkt die An- zahl der bereits besuchten Knoten und in der Menge die gefundenen Kanten des Tiefensuchbaumes. Die Prozedur DFS-Visit verändern wir hierfür wie folgt: DFS-Visit(G, v) 1: num ← num + 1 2: dfs[v] ← num 3: for all {v, w} 2 E do 4: if dfs[w] = 0 then 5: T ← T + {v, w} 6: DFS-Visit(G, w) Nach diesen Vorarbeiten kommen wir auf unser Artikulationsknotenpro- blem zurück. Einen Artikulationsknoten kann es nur dann geben, wenn der Graph zusammenhängend ist. Dies können wir in der Routine DFS(G, s) leicht testen: nach Rückkehr von DFS-Visit(G, s) muss dfs[v] > 0 für alle 2Diese DFS-Nummern entsprechen fast genau den Pre-Nummern aus dem letzten Semester. Allerdings waren diese mit den Post-Nummern verwoben, wodurch die Pre- Nummern eine Teilmenge von {1, . . . , 2|V|} bilden. Die DFS-Nummern bilden dagegen die Menge {1, . . . , |V|}. Die daraus resultierende Sortierung der Knoten ist jedoch dieselbe. KAPITEL 1. GRAPHENTHEORIE 36 Knoten v 2 V gelten. Wir nehmen im Folgenden an, dass dies gilt und stellen uns die Frage, wie wir einem Knoten v 2 V ansehen können, ob er ein Artikulationsknoten ist. Für den Startknoten s ist dies einfach: er ist genau dann ein Artikula- tionsknoten, wenn s in dem Tiefensuchbaum T Grad mindestens zwei hat. (Den einfachen Beweis hierfür überlassen wir dem Leser.) Für einen Kno- ten v 6= s ist dies etwas komplizierter. Um etwas Intuition zu gewinnen richten wir die Kanten des Graphen wie folgt: alle Kanten des Tiefensuch- baum T richten wir von dem Knoten mit der kleineren dfs-Nummer zu dem Knoten mit der grösseren dfs-Nummer; wir nennen diese Kanten auch Baumkanten. Alle übrigen Kanten richten wir umgekehrt: vom Knoten mit der grösseren dfs-Nummer zu dem Knoten mit der kleineren dfs-Nummer; entsprechend nennen wir diese Kanten Restkanten. Im letzten Semester wurden die Restkanten noch weiter in forward-/back-/cross-Kanten unter- teilt. Diese Unterteilung ist für uns aber nicht relevant. Ausserdem wurde DFS auch für gerichtete Graphen diskutiert, in welchen die Orientierung der Rest-Kanten komplizierter ist. Man kann sich aber leicht überlegen, dass sich für ungerichtete Graphen die Orientierung der Kanten aus dem Vorsemester zu der hier beschriebenen Orientierung vereinfacht. Mit Hilfe dieser gerichteten Kanten können wir jedem Knoten neben seiner dfs-Nummer eine weitere Nummer zuordnen. Dazu definieren wir für alle Knoten v 2 V: low[v] := kleinste dfs-Nummer, die man von v aus durch einen Pfad aus (beliebig vielen) Baumkanten und maximal einer Restkante erreichen kann. Beachte, dass aus der Definition folgt: für alle Knoten v 2 V: low[v] \u0014 dfs[v], denn diesen Wert erhält man, wenn man den leeren Pfad betrachtet. Abgesehen vom leeren Pfad kann man sich auf Pfade beschränken, bei denen es genau eine Restkante gibt und diese Restkante den Abschluss des Pfades bildet. Denn einen Pfad, der mit einer Baumkante endet, kann man immer durch Weglassen dieser letzten Baumkante verbessern, da eine Baumkante ja die dfs-Nummer vergrössert. Beispiel 1.26. Um diese Definition zu veranschaulichen, betrachten wir ein Beispiel. Die folgende Abbildung zeigt einen Graphen und ein mögliches Ergebnis einer Tiefensuche, die wir in dem Knoten ganz links starten. Die Zahl an jedem Knoten entspricht dem dfs-Wert des Knotens, die fetten Kanten sind die Kanten des gefundenen Spannbaums T : KAPITEL 1. GRAPHENTHEORIE 37 1 2 3 4 5 6 7 8 9 10 11 12 Die low-Werte lassen sich jetzt daraus berechnen. In der nachfolgenden Abbildung sind sie jeweils an zweiter Stelle eingetragen: 1/1 2/1 3/1 4/4 5/4 6/4 7/4 8/4 9/1 10/10 11/10 12/10 Die Artikulationsknoten des Graphen sind die Knoten mit den dfs-Nummern 1, 3, 4 und 10. Für den Startknoten 1 kennen wir schon den Grund: er hat in dem Baum T Grad 2. Für die Knoten 3, 4 und 10 (und nur für diese!) gilt: im Baum T gibt es einen Nachbarknoten, dessen low-Wert mindestens so gross ist wie der dfs-Wert des (Artikulations-)Knotens. Für den Knoten 3 ist dies der Knoten 4, für den Knoten 4 der Knoten 5 und für den Knoten 10 der Knoten 11. Betrachten wir einen Knoten v 6= s. Wenn v ein Artikulationsknoten ist, so besteht G[V \\ {v}] aus mindestens zwei Zusammenhangskomponenten, eine – wir nennen sie Z1 – die den Startknoten s enthält und mindestens KAPITEL 1. GRAPHENTHEORIE 38 einer weiteren Z2. Da jeder Pfad von s zu einem Knoten in Z2 den Knoten v enthalten muss, wissen wir dass gelten muss: 1 = dfs[s] < dfs[v] < dfs[w] für alle w 2 Z2. Und da G[Z2] eine Zusammenhangskomponente in G[V \\ {v}] ist, kann es keine Kanten von einem Knoten w aus Z2 zu einem Knoten in V \\ ({v} [ Z2) geben. Der low-Wert eines jeden Knotens in Z2 ist daher mindestens dfs[v]. Nehmen wir nun an, dass der Knoten v 6= s kein Artikulationsknoten ist. Seien w0, w1, . . . , ws die Nachbarknoten von v in T . Genau einer dieser Knoten hat einen dfs-Wert kleiner als derjenige von v. Ohne Einschränkung sei dies w0. Der Baum T sieht also wie folgt aus: s v w0 . . .w1 w2 wℓ Nach Konstruktion des DFS-Algorithmus kann es keine Kante zwischen irgend zwei der an den Knoten w1, . . . , wℓ verankerten Teilbäume geben. Da andererseits nach Annahme v kein Artikulationsknoten ist, muss es aus jedem dieser Bäume eine Restkante zu einem Knoten mit kleinerer dfs- Nummer als v geben, denn sonst wäre dieser Baum in G[V \\ {v}] nicht in derselben Komponente wie w0. Insgesamt haben wir daher gezeigt: v ist Artikulationsknoten ⇐⇒ v = s und s hat in T Grad mindestens zwei, oder v 6= s und es gibt w 2 V mit {v, w} 2 E(T ) und low[w] \u0015 dfs[v]. Die low-Werte kann man effizient berechnen, in dem man diese jeweils mit dfs[v] initialisiert, für jeden Nachfolgerknoten gegebenenfalls anpasst und den kleinsten gefundenen Wert retourniert. Damit ergibt sich dann folgender Algorithmus: KAPITEL 1. GRAPHENTHEORIE 39 DFS-Visit(G, v) 1: num ← num + 1 2: dfs[v] ← num 3: low[v] ← dfs[v] 4: isArtVert[v] ← false 5: for all {v, w} 2 E do 6: if dfs[w] = 0 then 7: T ← T + {v, w} 8: val ← DFS-Visit(G, w) 9: if val \u0015 dfs[v] then 10: isArtVert[v] ← true 11: low[v] ← min{low[v], val} 12: else dfs[w] 6= 0 and {v, w} 62 T 13: low[v] ← min{low[v], dfs[w]} 14: return low[v] Wir müssen dabei beachten, dass die Berechnung von isArtVert[v] durch DFS-Visit(G, v) für den Startknoten v = s falsch sein könnte. Wir müssen die Rahmenprozedur deshalb noch durch eine Abfrage ergänzen, um diesen Sonderfall zu korrigieren: DFS(G, s) 1: 8 v 2 V : dfs[v] ← 0 2: num ← 0 3: T ← ; 4: DFS-Visit(G, s) 5: if s hat in T Grad mindestens zwei then 6: isArtVert[s] ← true 7: else 8: isArtVert[s] ← false Damit erhalten wir folgenden Satz: Satz 1.27. Für zusammenhängende Graphen G = (V, E), die mit Ad- jazenzlisten gespeichert sind, kann man in Zeit O(|E|) alle Artikula- KAPITEL 1. GRAPHENTHEORIE 40 tionsknoten berechnen. 1.4.2 Brücken Artikulationsknoten sind Zertifikate dafür, dass ein zusammenhängender Graph nicht 2-zusammenhängend ist. Analog hierfür sind Brücken Zer- tifikate, dass ein zusammenhängender Graph nicht 2-kanten-zusammen- hängend ist. Formal definieren wir hierfür: eine Kante e 2 E in einem zusammenhängenden Graphen G = (V, E) heisst Brücke, wenn der Graph (V, E \\ {e}) nicht zusammenhängend ist. Beispiel 1.26 (Fortsetzung) Der Graph aus Beispiel 1.26 enthält zwei Brücken: die Kanten zwischen den Knoten mit dfs-Nummern 3 und 4 bzw. 1 und 10. Aus der Definition einer Brücke folgt sofort, dass ein Spannbaum immer alle Brücken des Graphen enthalten muss. Insbesondere kommen daher als Brücken nur die Kanten eines Tiefensuchbaumes in Frage. Ebenfalls sieht man sofort, dass jeder in einer Brücke enthaltene Knoten entweder ein Artikulationsknoten des Graphen ist oder in G Grad Eins hat. Verwenden wir jetzt wieder die im vorigen Abschnitt eingeführten Nummerierungen dfs und low, so sieht man leicht ein: eine (gerichtete) Kante (v, w) des Tiefensuchbaumes T ist genau dann eine Brücke, wenn low[w] > dfs[v]. Damit lässt sich also der Tiefensuchalgorithmus aus dem vorigen Abschnitt so anpassen, dass er nicht nur alle Artikulationsknoten sondern zudem auch alle Brücken berechnet. Satz 1.28. Für zusammenhängende Graphen G = (V, E), die mit Ad- jazenzlisten gespeichert sind, kann man in Zeit O(|E|) alle Artikula- tionsknoten und alle Brücken berechnen. 1.4.3 Block-Zerlegung Wie können wir die Berechnung von Artikulationsknoten und Brücken nun algorithmisch nutzen? Hierzu zunächst eine Proposition/Definition des Konzepts Block. 3 3Manchmal nennt man Blöcke auch 2-Zusammenhangskompenten. Das ist aber nicht ganz konsequent, denn ein Block kann auch aus einer einzigen Kante bestehen. Diese ist dann automatisch eine Brücke. KAPITEL 1. GRAPHENTHEORIE 41 Definition/Proposition 1.29. Sei G = (V, E) ein zusammenhängender Graph. Für e, f 2 E definieren wir eine Relation durch e ∼ f :⇐⇒ e = f oder es gibt einen gemeinsamen Kreis durch e und f. Dann ist diese Relation eine Äquivalenzrelation. Wir nennen die Äqui- valenzklassen Blöcke. Beweis. Wir müssen uns überlegen, dass die Relation eine Äquivalenzre- lation ist. Sie ist offenbar reflexiv und symmetrisch. Die Transitivität ist etwas schwieriger direkt zu zeigen ist. Hier hilft aber der Satz von Menger weiter. Nehmen wir an, dass für e = {ue, ve}, f = {uf, vf}, g = {ug, vg} 2 E gilt, dass e ∼ f und f ∼ g. Dann müssen wir zeigen, dass e ∼ g gilt. Wir können annehmen, dass e, f, g paarweise verschieden sind, da die Aussage sonst trivial wird. Wir fügen nun einen “Mittelknoten” we in die Kante e ein, d.h. we ist zu ue und ve adjazent, und diese beiden Verbindungen ersetzen die Kante e. Ebenso fügen wir Mittelknoten wf bzw. wg in f bzw. g ein. Dann impliziert e ∼ f, dass es im neuen Graphen zwei intern knoten- disjunkte Wege von we nach wf gibt. (Die beiden Abschnitte des Kreises durch e und f.) Ebenso gibt es wegen f ∼ g zwei intern knotendisjunkte Wege von wf nach wg. Nach dem Satz von Menger gibt es also keinen we- wf-Separator der Grösse 1, und auch keinen wf-wg-Separator der Grösse 1. Da man weder we von wf noch wf von wg trennen kann, gibt es auch kei- nen we-wg-Separator der Grösse 1. Wiederum nach dem Satz von Menger heisst das, dass es zwei intern knotendisjunkte Pfade von we nach wg gibt. Damit liegen e und g in G auf einem Kreis. Man überlegt sich nun leicht, dass sich zwei Blöcke – wenn überhaupt – nur in einem Artikulationsknoten schneiden können. Wir können für einen Graphen G daher einen Graphen T , die sogenannte Block-Zerlegung von G, wie folgt definieren, siehe auch Abbildung 1.11. T ist ein bipartiter Graph mit Knotenmenge V = A ] B, wobei A die Menge der Artikulationsknoten von G und B die Menge der Blöcke von G ist. (Jeder Block entspricht also einem Knoten in T ). Wir verbinden einen Artikulationsknoten a 2 A mit einem Block b 2 B genau dann, wenn a inzident zu einer Kante in b ist. Dann ist T immer noch zusammenhängend, wenn es T war. Ausserdem ist T kreisfrei, denn jeder Kreis in T liesse sich in einen Kreis in G übersetzen, KAPITEL 1. GRAPHENTHEORIE 42 der Kanten aus mindestens zwei verschiedenen Blöcken enthält – ein Wi- derspruch, denn Kanten auf einem Kreis liegen ja per Definition immer im selben Block. Der Graph T ist also ein Baum. Abbildung 1.11: Ein Graph und seine Block-Zerlegung. Mit den Algorithmen aus den vorigen Abschnitten lässt sich die Block- Zerlegung eines Graphen in linearer Zeit bestimmen. Eine solche Block- Zerlegung kann trivial sein und nur aus einem einzigen Block bestehen. Wenn sie aber aus mehreren Blöcken besteht, dann hat man algorithmisch viel gewonnen. Die meisten Probleme lassen sich auf natürlich Art und Weise an Artikulationsknoten in Teilprobleme zerlegen, sodass man einen Ansatzpunkt für Divide-and-Conquer oder für Dynamische Programmie- rung hat. Dynamische Programmierung funktioniert übrigens oft immer noch, wenn man etwas grössere Separatoren hat. Auf manchen Graphklas- sen hat man immer vergleichsweise kleine Separatoren. So hat zum Beispiel jeder planare Graph einen Separator der Grösse O(q |V|), der sich auch ef- fizient bestimmen lässt. Wir verweisen auf weiterführende Vorlesungen zur Graphentheorie für Details. Es ist aber eine gute Übung, sich zu überlegen, wie man klassische Probleme (all-pairs shortest paths, Matchings, Färb- barkeit, ...) in Teilprobleme zerlegen kann, wenn man einen Separator der Grösse s = 2 in einem Graphen hat. KAPITEL 1. GRAPHENTHEORIE 43 1.5 Kreise In diesem Abschnitt wollen wir zwei Arten von besonderen “Kreisen” in Graphen betrachten: Kreise die alle Kanten bzw. alle Knoten des Graphen genau einmal enthalten. 1.5.1 Eulertouren Die erste Art eines solchen “Kreises” (wie wir gleich sehen werden ist dieser Kreis genau genommen ein Zyklus, daher die Anführungsstriche) geht auf Euler zurück. Leonhard Euler (1707–1783) war ein Schweizer Mathema- tiker. Er gilt als einer der bedeutendsten und produktivsten Mathematiker, die je gelebt haben. Er hat zu zahlreichen Gebieten der Mathematik und Physik bedeutende Beiträge geliefert. Im Jahre 1736 veröffentlichte er eine Arbeit, die sich mit dem Problem beschäftigte, ob es möglich sei, einen Rundgang durch Königsberg zu machen, bei dem man alle Brücken über die Pregel genau einmal überquert. Diese Arbeit gilt als Ursprung der Gra- phentheorie. Definition 1.30. Eine Eulertour in einem Graphen G = (V, E) ist ein geschlossener Weg (Zyklus), der jede Kante des Graphen genau ein- mal enthält. Enthält ein Graph eine Eulertour, so nennt man ihn eulersch. Enthält G eine Eulertour, so ist der Grad deg(v) aller Knoten v 2 V gerade, denn aus jedem Knoten geht man genauso oft „hinein“ wie „her- aus“. Für zusammenhängende Graphen gilt sogar die Umkehrung. Hiervon überzeugen wir uns, indem wir einen Algorithmus angeben, der in einem zusammenhängenden Graphen G = (V, E), in dem alle Knotengrade gerade sind, eine Eulertour findet. Hierfür gehen wir wie folgt vor. Zunächst wählen wir einen beliebigen Knoten v 2 V und stellen uns einen Läufer vor, der in v startet. Dieser läuft einen beliebigen Weg W ab und löscht jede benutzte Kante aus dem Graphen. Insbesondere benutzt er also jede Kante höchstens einmal. Der Läufer bleibt erst stehen, wenn er einen isolierten Knoten erreicht, also einen Knoten, von dem keine Kante mehr ausgeht. Wir werden nun zeigen, dass der Weg W ein Zyklus ist, also wieder in v endet. Dazu nehmen wir zwecks Widerspruch an, dass der Weg KAPITEL 1. GRAPHENTHEORIE 44 in einem Knoten u 6= v enden würde. Nehmen wir weiter an, dass W den Knoten u zuvor schon k-mal besucht hatte, für ein k 2 N0. Dann wurden bei jedem der k Besuche zwei zu u inzidente Kanten gelöscht (eine beim Hinein- und eine beim Hinauslaufen). Ausserdem wurde beim finalen Besuch eine inzidente Kante gelöscht (beim Hereinlaufen). Insgesamt wurden also 2k+1 zu u inzidente Kanten gelöscht, was eine ungerade Anzahl ist. Da der Grad von u in G, aber gerade war, ist er nach Löschen der Kanten in W noch ungerade, also insbesondere nicht 0. Dies ist aber ein Widerspruch, weil der Läufer ja nur in einem isolierten Knoten enden darf. Also haben wir gezeigt, dass W ein Zyklus ist. Falls W alle Kanten des Graphen enthält, so ist W die gesuchte Euler- tour. Sonst beobachten wir dass im verbleibenden Graphen nach wie vor alle Grade gerade sind, weil es zu jedem Knoten in W eine gerade An- zahl von inzidenten Kanten gibt (möglicherweise 0). Nun suchen wir auf W einen Knoten v 0 , von dem noch mindestens eine Kante ausgeht. Es muss einen solchen Knoten geben, weil sonst die von W besuchten Knoten nicht in derselben Zusammenhangskomponente wie die restlichen Kanten wären, was im Widerspruch zum Zusammenhang von G steht. Wie zuvor lassen wir den Läufer einen Zyklus W 0 suchen, diesmal aber von v 0 aus startend. Nach wie vor löscht der Läufer jede besuchte Kante aus dem Graphen. Dann vereinen wir die beiden Zyklen W und W 0 zu einem neuen Zyklus W2, in- dem wir zunächst W bis zum Knoten v 0 , dann den Zyklus W 0 und dann den Rest des Zyklus W ablaufen. Wiederum gilt: falls W2 alle Kanten des Graphen enthält, so ist W2 die gesuchte Eulertour. Falls nicht, finden wir einen Knoten v 0 2 auf W2, von dem noch mindestens eine Kante ausgehen, und und verfahren wiederum wie oben. Zur Realisierung des Algorithmus müssen wir |E|-mal von einem gege- benen Knoten eine inzidente Kante finden, und diese Kante anschliessend aus dem Graphen löschen. Mit geeigneten Datenstrukturen sind bei Ope- rationen in Zeit O(1) möglich. Ebenso können wir zwei Zyklen in Zeit O(1) zu einem Zyklus kombinieren, wenn wir sie als verlinkte Listen speichern. Die einzige Schwierigkeit ist es, jeweils einen Knoten v 0 auf W zu finden, von dem noch Kanten ausgehen. Dazu benutzen wir folgenden Trick. Neben dem bisherigen Läufer, den wir als schnellen Läufer S bezeichnen, benut- zen wir auch einen langsamen Läufer L. Der langsame Läufer startet im selben Knoten v wie der schnelle Läufer. Er bewegt sich jedoch grundsätz- lich nur, wenn der schnelle Läufer in einem isolierten Knoten feststeckt. In KAPITEL 1. GRAPHENTHEORIE 45 start v v Abbildung 1.12: Der erste (schwarz) und zweite (rot) Weg des schnellen Läufers S. Nach dem ersten Weg bleibt der schnelle Läufer stecken. Da- nach bewegt sich der langsame Läufer entlang der ersten Kante nach v und entdeckt, dass es von dort noch unbenutzte Kanten gibt. Dann läuft der schnelle Läufer von v aus die rote Tour ab und vereinigt die beiden. Ansch- liessend läuft der langsame Läufer die restliche Tour ab (erst den roten Teil, dann den restlichen schwarzen), entdeckt aber keine weitere ausgehenden Kanten. Abbildung 1.13: Die Wege von S und L vereint. dem Fall läuft der langsame Läufer den Weg W entlang. An jedem Kno- ten u prüft er, ob noch Kanten von u ausgehen. Falls ja, startet S einen weiteren Zyklus von u ausgehend und aktualisiert W. Dann setzt L seine Suche mit dem aktualisierten Weg W fort. Wir beachten, dass sich der Teil von W, den L schon zurückgelegt hat, durch die Operationen von S nicht ändert, da von diesem Teilweg ja keine Kanten mehr ausgehen. Dies setzen wir fort, bis L den Weg W einmal komplett abgelaufen hat. Danach wissen wir, dass von den Knoten auf W keine Kanten mehr ausgehen, dass W also die finale Eulertour ist. Die zusätzliche Zeit, die wir für L aufwenden müssen, ist O(|E|), da er ja jede Kante im Graphen genau einmal abläuft. Insgesamt läuft der Algorithmus damit in Zeit O(|E|). In diesem Beispiel- code sieht man in RandomtourG, wie aus dem Graphen die Kanten nach und nach entfernt werden: KAPITEL 1. GRAPHENTHEORIE 46 Eulertour(G, vstart) 1: // Schneller Läufer 2: W ←RandomtourG(vstart) 3: // Langsamer Läufer 4: vlangsam ← Startknoten von W. 5: while vlangsam ist nicht letzter Knoten in W do 6: v ← Nachfolger von vlangsam in W 7: if NG(v) 6= ; then 8: W 0 ← RandomtourG(v) 9: // Ergänze W = W1 + h vi + W2 um die 10: // Tour W 0 = h v 0 1 = v, v 0 2, . . . , v 0 ℓ−1, v 0 ℓ = vi 11: W ← W1 + W 0 + W2 12: vlangsam ← Nachfolger von vlangsam in W 13: return W RandomtourG(vstart) 1: v ← vstart 2: W ← h vi 3: while NG(v) 6= ; do 4: Wähle vnext aus NG(v) beliebig. 5: Hänge vnext an die Tour W an. 6: e ← {v, vnext} 7: Lösche e aus G. 8: v ← vnext 9: return W Wir haben damit den folgenden Satz gezeigt. Satz 1.31. a) Ein zusammenhängender Graph G = (V, E) ist genau dann eulersch, wenn der Grad aller Knoten gerade ist. b) In einem zusammenhängenden, eulerschen Graphen kann man eine Eulertour in Zeit O(|E|) finden. Dieser Satz gilt generell auch für Multigraphen, da der obige Algorithmus analog auch auf Multigraphen funktioniert. KAPITEL 1. GRAPHENTHEORIE 47 Damit ist über Eulertouren eigentlich alles gesagt: Wir wissen, wie wir einem Graphen ansehen können, ob er eine solche Tour enthält. Und wie wir die Tour, wenn sie denn existiert, effizient finden können. Damit können wir uns dem zweiten Problem zuwenden: der Suche nach einem Kreis, der jeden Knoten des Kreises genau einmal enthält. Wie wir gleich sehen werden, ist dieses Problem ungleich schwieriger. 1.5.2 Hamiltonkreise In diesem Abschnitt interessieren wir uns für Kreise (diesmal wirklich für Kreise!), die jeden Knoten des Graphen genau einmal enthalten. Als Anwen- dungsbeispiel kann man sich hier ein Rechnernetz vorstellen, in dem man im Hintergrund einen Prozess laufen lassen möchte, der zyklisch alle Knoten durchläuft und so für einen Informationsaustausch oder eine Synchronisa- tion der Rechner sorgt. Gesucht ist hierfür ein Kreis, der alle Knoten des Graphen enthält. Erstmals wurde dieses Problem von William Hamilton (1805–1865) betrachtet. Hamilton war ein irisches Universalgenie: In sei- ner Jugend entwickelte er den Ehrgeiz, genauso viele Sprachen zu sprechen wie er Jahre alt war (dies hat er angeblich bis zu seinem siebzehnten Le- bensjahr durchgehalten), schon vor Beendigung seines Studiums wurde er zum Königlichen Irischen Astronomen ernannt. Die nach ihm benannten Kreise untersuchte er im Zusammenhang mit einem von ihm entwickelten Geschicklichkeitsspiel. Definition 1.32. Ein Hamiltonkreis in einem Graphen G = (V, E) ist ein Kreis, der alle Knoten von V genau einmal durchläuft. Enthält ein Graph einen Hamiltonkreis, so nennt man ihn hamiltonsch. Beispiel 1.33. Nicht jeder Graph enthält einen Hamiltonkreis. Für den Würfel H3 ist es nicht schwer einen Hamiltonkreis zu finden (durch fette Kanten symbolisiert). Der rechts dargestellte, sogenannte Petersen-Graph, benannt nach dem dänischen Mathematiker Julius Petersen (1839–1910), enthält andererseits keinen Hamiltonkreis. KAPITEL 1. GRAPHENTHEORIE 48 Ein klassisches Anwendungsbeispiel ist das Problem des Handlungsrei- senden (engl. Traveling Salesman Problem). Ein Vertreter möchte zum Be- such seiner Kunden seine Rundreise möglichst effizient organisieren. Stellt man sich hier die zu besuchenden Städte als Knoten eines Graphen vor und verbindet zwei Städte, wenn es eine direkte Flugverbindung zwischen diesen beiden Städten gibt, so gibt es genau dann eine Rundreise durch alle Städte, bei der keine Stadt mehrfach besucht wird, wenn der Graph einen Hamiltonkreis enthält. (Für realistischere Varianten dieses Problems ver- sieht man die Kanten des Graphen beispielsweise noch mit Kosten und wird dann nach einem Hamilitonkreis suchen, der die Gesamtkosten minimiert.) Ein exponentieller Algorithmus Wie sieht es mit Algorithmen für das Finden eines Hamiltonkreises aus? Dies stellt sich als schwieriges Problem heraus. Richard Karp hat 1972 bewiesen, dass das zugehörige Entscheidungsproblem „Gegeben ein Graph G = (V, E), enthält G einen Hamiltonkreis?“ N P -vollständig ist. Auf die Definition und Bedeutung des Begriffs N P -Vollständigkeit kann hier nicht weiter eingegangen werden (das ist Thema einer Einführungsvorlesung zur Theoretischen Informatik). Gesagt sei hier nur, dass dies impliziert, dass man davon ausgeht4, dass es keinen Algorithmus gibt, der entscheidet, ob ein Graph hamiltonsch ist und dessen Laufzeit polynomiell in der Grösse des Graphen (also in der Anzahl Knoten und Kanten) ist. Ob ein Graph einen Hamiltonkreis enthält, lässt sich natürlich dadurch testen, dass man für jeden möglichen Hamiltonkreis (davon gibt es 1 2(n−1)! viele – Übung!) nachsieht, ob alle für ihn notwendigen Kanten in dem Graphen vorhanden sind. Statt die Details hierfür auszuführen, geben wir im Folgenden einen Algorithmus an, dessen Komplexität “nur” exponentiell in der Anzahl Knoten des Graphen ist5. Hierfür kommt einmal mehr das 4In der Vorlesung Theoretische Informatik werden Sie die Komplexitätsklassen P und N P kennen lernen. P steht für Probleme, die man in polynomieller Laufzeit (in der Grösse der Eingabe) lösen bzw. entscheiden kann. N P -vollständige Probleme sind die “schwierigsten” Probleme in der Klasse N P . Man geht allgemein davon aus, dass P 6 = N P , aber dies wurde noch nicht bewiesen. 5Zur Einordnung: Es gilt k! \u0015 (k/2)k/2 für alle k 2 N. Im Binärsystem ist die Stel- lenzahl von k! daher log2(k!) \u0015 k/2 log(k/2) = Θ(k log k). Dagegen hat 2 k nur k Stellen im Binärsystem. Die Stellenzahl von k! ist also asymptotisch grösser als die von 2k. Das bedeutet, dass 1 2 (n−1)! asymptotisch viel(!) grösser ist als 2 n. Zum Vergleich: n 2 hat ’nur’ KAPITEL 1. GRAPHENTHEORIE 49 Prinzip der dynamischen Programmierung zum Einsatz. Sei G = (V, E) ein Graph, wobei wir annehmen wollen, das V = [n] gilt. Zunächst überlegen wir uns, dass es genügt zu testen, ob es ein x 2 N(1) gibt, für das es einen 1-x-Pfad gibt, der alle Knoten aus V = [n] enthält. In der Tat: Wenn es einen Hamiltonkreis in G gibt, so enthält dieser Kreis den Knoten 1 und eine Kante von 1 zu einem Nachbar x 2 N(1). Der Hamitonkreis ohne diese Kante ist dann der gesuchte 1-x-Pfad. Um zu testen, ob es solch ein x 2 N(1) gibt, definieren wir für alle Teilmengen S \u0012 [n] mit 1 2 S und für alle x 2 S mit x 6= 1: PS,x := { 1, es gibt in G einen 1-x-Pfad, der genau die Knoten aus S enthält 0, sonst. Dann gilt: G enthält einen Hamiltonkreis ⇐⇒ 9 x 2 N(1) mit P[n],x = 1 und wir können die Werte PS,x mit Hilfe der dynamischen Programmierung berechnen. Dazu überlegen wir uns zunächst, dass für die Mengen S = {1, x} offenbar gilt: PS,x = 1 genau dann, wenn {1, x} 2 E. Damit haben wir die Initialisierung geschafft. Für die Rekursion von Mengen der Grösse s auf Mengen der Grösse s + 1, für s \u0015 2, überlegen wir uns zunächst folgendes: PS,x ist genau dann gleich Eins, wenn es ein x 0 2 N(x) gibt mit x 0 6= 1 und PS\\{x},x 0 = 1, denn ein 1-x-Pfad mit Knoten aus S muss ja einen Nachbarn x 0 von x als vorletzten Knoten enthalten. Und der Pfad von 1 bis zu diesem Knoten x 0 ist dann ein 1-x 0 -Pfad, der genau die Knoten aus S \\ {x} enthält. Es gilt also: PS,x = max{PS\\{x},x 0 | x 0 2 S \\ N(x), x 0 6= 1}. Damit erhalten wir folgenden Algorithmus: doppelt so viele Stellen wie n, der Unterschied zwischen n 2 und n ist also viel geringer. KAPITEL 1. GRAPHENTHEORIE 50 Hamiltonkreis (G = ([n], E)) 1: // Initialisierung 2: for all x 2 [n], x 6= 1 do 3: P{1,x},x := { 1, falls {1, x} 2 E 0, sonst 4: // Rekursion 5: for all s = 3 to n do 6: for all S \u0012 [n] mit 1 2 S und |S| = s do 7: for all x 2 S, x 6= 1 do 8: PS,x = max{PS\\{x},x 0 | x 0 2 S \\ N(x), x 0 6= 1}. 9: // Ausgabe 10: if 9 x 2 N(1) mit P[n],x = 1 then 11: return G enthält Hamiltonkreis 12: else 13: return G enthält keinen Hamiltonkreis Satz 1.34. Algorithmus Hamiltonkreis ist korrekt und benötigt Spei- cher O(n \u0001 2n) und Laufzeit O(n 2 \u0001 2n), wobei n = |V|. Beweis. Die Korrektheit des Algorithmus haben wir bereits gezeigt. Der benötigte Speicherplatz wird dominiert durch die Anzahl Werte PS,x die wir berechnen müssen. Dies sind 2n−1 viele Mengen S und jeweils höchstens n−1 viele verschiedene Werte für x. (Genau genommen müssen wir uns jeweils nur die Werte für alle Mengen der Grösse s und diejenigen der Grösse s + 1 merken. Wenn man dies durchrechnet, führt dies zu O(p n \u0001 2n), aber darauf wollen wir hier nicht eingehen.) Die Laufzeit wird dominiert durch die dreifache for-Schleife. Diese lässt sich wie folgt abschätzen: n∑ s=3 ∑ S\u0012 [n],12 S,|S|=s ∑ x2 S,x6=1 O(n) = n∑ s=3 n − 1 s − 1 ! \u0001 (s − 1) \u0001 O(n) = O(n 22n), wie behauptet. Hier haben wir verwendet, dass ∑n−1 s=0 \u0010 n−1 s \u0011 = 2n−1 ist. KAPITEL 1. GRAPHENTHEORIE 51 Verbesserung: exponentielle Laufzeit, aber polynomieller Speicher6 Wir haben also einen Algorithmus gesehen, der exponentielle Laufzeit und Speicher benötigt. Da das Problem N P -vollständig ist, wäre es auch höchst überraschend, wenn wir einen Algorithmus mit polynomieller Laufzeit fin- den könnten. Aber ist der hohe Speicherbedarf ebenfalls notwendig? Tat- sächlich ist ein zu hoher Speicherbedarf in der Regel noch verheerender als eine hohe Laufzeit. Für Hamiltonkreise stellt sich heraus, dass man den Speicherbedarf elegant und drastisch verringern kann, indem man zählt, wie viele Hamiltonkreise es gibt. Dazu brauchen wir ein zentrales Prinzip aus der Kombinatorik, das Prinzip der Inklusion und Exklusion, auch Siebformel genannt. Satz 1.35. (Siebformel, Prinzip der Inklusion/Exklusion) Für end- liche Mengen A1, . . . , An (n \u0015 2) gilt: \f \f \f \f \f n[ i=1 Ai \f \f \f \f \f = n∑ l=1 (−1)l+1 ∑ 1\u0014 i1<\u0001\u0001\u0001 <il\u0014 n |Ai1 \\ \u0001 \u0001 \u0001 \\ Ail| = n∑ i=1 |Ai| − ∑ 1\u0014 i1<i2\u0014 n |Ai1 \\ Ai2| + ∑ 1\u0014 i1<i2<i3\u0014 n |Ai1 \\ Ai2 \\ Ai3| − \u0001 \u0001 \u0001 + (−1)n+1 \u0001 |A1 \\ \u0001 \u0001 \u0001 \\ An|. Es wäre nicht schwer, wenn auch etwas technisch, Satz 1.35 direkt zu be- weisen. Wir werden jedoch später sehen, dass die Siebformel in der obigen Form nur ein Spezialfall von einer allgemeinen Aussage aus der Wahrschein- lichkeitstheorie ist (Satz 2.5). Diese Verallgemeinerung hat einen elegante- ren und natürlichen Beweis (Beispiel 2.36), deshalb verzichten wir an dieser Stelle auf den Beweis von Satz 1.35. Wir illustrieren die grundlegenden Ideen hinter Satz 2.5 jedoch, indem wir die Spezialfälle n = 2 und n = 3 explizit betrachten. Für n = 2 lautet die Formel |A1 [ A2| = |A1| + |A2| − |A1 \\ A2|. Diese ist sehr leicht zu begründen: Wenn wir die Elemente aus A1 [ A2 zählen wollen, dann können wir erst die Elemente aus A1 zählen, und dann 6Dieser Abschnitt wird in der Vorlesung nicht behandelt und ist daher auch nicht prüfungsrelevant. KAPITEL 1. GRAPHENTHEORIE 52 die Elemente aus A2. Wenn wir das tun, haben wir alle Elemente aus A1\\ A2 jedoch doppelt gezählt, und müssen diese daher wieder abziehen. Für n = 3 lautet die Formel |A1[ A2[ A3| = |A1|+|A2|+|A3|−|A1\\ A2|−|A1\\ A3|−|A2\\ A3|+|A1\\ A2\\ A3|. Abbildung 1.14 veranschaulicht den Fall n = 3. Man überzeuge sich, dass durch die im Satz angegebene Summe die Elemente in jeder der sieben farblich markierten Teilmengen A1 \\ (A2 [ A3), . . . , A1 \\ A2 \\ A3 jeweils genau einmal gezählt werden. Abbildung 1.14: Illustration zur Inklusion-Exklusion-Formel für n = 3. Wie können wir das Prinzip der Inklusion und Exklusion nun ausnut- zen, um Hamiltonkreise zu zählen? Sei dazu wieder G = (V, E) ein Graph mit Knotenmenge V = [n]. Erinnern wir uns, dass das Zählen von We- gen deutlich einfacher als das Zählen von Pfaden ist. Daher wählen wir zunächst einen beliebigen Startknoten s 2 V und definieren für alle Teil- mengen S \u0012 [n] mit v 62 S die folgende Grösse: WS := {Wege der Länge n in G mit Start- und Endknoten s, der keine Knoten in S besucht}. Zunächst halten wir fest, dass wir die Grösse der Menge WS effizient be- stimmen können: Ist AS die Adjazenzmatrix des induzierten Teilgraphen G[V \\S], dann steht |WS| im Eintrag (s, s) der Matrix (AS)n, siehe Satz 1.13. Zur Berechnung von (AS)n brauchen wir n − 1 Matrixmultiplikationen (oder O(log n) Matrixmultiplikation durch iteriertes Quadrieren), und je- de Matrixmultiplikation können wir mit dem Algorithmus von Strassen in Zeit O(n 2.81) ausführen. Insgesamt brauchen wir also Zeit O(n 3.81) (oder O(n 2.81 log n)) und Speicher O(n 2). Um die Verbindung zu Hamiltonkreisen herzustellen, beobachten wir für S = ; , dass die Menge W; jeden Weg der Länge n mit Start- und KAPITEL 1. GRAPHENTHEORIE 53 Endknoten s enthält. Insbesondere sind also alle Hamiltonkreise darin ent- halten – sogar je zweimal, denn man kann jeden Hamiltonkreis in beiden Richtungen ablaufen. Die Menge W; enthält aber noch viele ungewünschte Wege, nämlich Wege der Länge n, die nicht alle Knoten besuchen. Diese ungewünschten Wege können wir beschreiben als S n i=1 W{i}, denn die Men- ge W{i} enthält ja gerade die Wege, die den Knoten i nicht enthalten. Wir halten also fest: Zahl der Hamiltonkreise = 1 2 |W; | − \f \f \f \f \f n[ i=1 W{i} \f \f \f \f \f ! = 1 2 0 @ |W; | + n∑ l=1 (−1)l ∑ 1\u0014 i1<\u0001\u0001\u0001 <il\u0014 n |W{i1} \\ \u0001 \u0001 \u0001 \\ W{il}| 1 A = 1 2 0 @ |W; | + n∑ l=1 (−1)l ∑ 1\u0014 i1<\u0001\u0001\u0001 <il\u0014 n |W{i1,...,il}| 1 A , wobei wir im zweiten Schritt die Siebformel eingesetzt haben. Im dritten Schritt haben wir W{i1} \\ \u0001 \u0001 \u0001 \\ W{il} = W{i1,...,il} benutzt, was eine reine Umschreibung ist – in beiden Fällen geht es um die Menge der Wege, die keinen der Knoten i1, . . . , il enthalten. Dank dieser Formel können wir leicht einen speichereffizienten Algorith- mus zum Zählen von Hamiltonkreisen angeben. Zähle_Hamiltonkreise (G = ([n], E)) 1: s := 1. // willkürlich gewählt 2: Z := |W; |. 3: for all S \u0012 [n] mit s 62 S und S 6= ; do 4: Berechne |WS|. // mit der Adjazenzmatrix von G[V \\ S]. 5: Z := Z + (−1)|S||WS|. 6: Z := Z/2. 7: return Z // Zahl der Hamiltonkreise in G Da die for-Schleife über O(2n) Teilmengen läuft, erhalten wir folgenden Satz. 7 7In unserem Modell, dass jede ganze Zahl mit Platz O(1) gespeichert werden kann. Die hier auftretenden Zahlen sind sehr gross. Zum Beispiel ist das Endergebnis für den vollständigen Graphen ja 1 2 (n − 1)!, was eine Zahl mit Θ(n log n) vielen Stellen ist. Aber auch unter Berücksichtigung dieser grossen Zahlen bleibt der Speicherbedarf polynomiell. KAPITEL 1. GRAPHENTHEORIE 54 Satz 1.36. Der Algorithmus Zähle_Hamiltonkreise berechnet die Zahl der Hamiltonkreise in G = (V, E) und benötigt Speicher O(n 2) und Laufzeit O(n 2.81 log n \u0001 2n), wobei n = |V|. 1.5.3 Spezialfälle Erinnern wir uns: Ob ein Graph eine Eulertour enthält kann man einfach dadurch entscheiden, dass man sich die Grade aller Knoten ansieht. Für das Problem des Hamiltonkreises ist nichts ähnliches bekannt und (da das Problem N P -vollständig ist) geht man auch davon aus, dass es keine ähnli- che schöne und elegante Charakterisierung gibt. Für einige Spezialfälle gibt es eine Charakterisierung jedoch sehr wohl. In diesem Abschnitt wollen wir einige solche Ergebnisse vorstellen. Als erstes betrachten wir Gittergraphen Mm,n. Beispiel 1.37. Wann ist ein Gittergraph Mm,n hamiltonsch? – Betrachten wir zunächst ein Beispiel. Für das 4 \u0002 5 Gitter ist ein Hamiltonkreis schnell gefunden: Schnell sieht man auch ein, dass man auf ähnliche Weise immer dann einen Hamilton- kreis in Mm,n finden kann, falls m oder n gerade ist. Falls hingegen sowohl m als auch n ungerade, so gibt es keinen Hamiltonkreis. Dies können wir wie folgt einsehen. Sei [m]\u0002 [n] die Knotenmenge des m \u0002 n Gitters. Dann sind zwei Knoten (i, j) und (k, ℓ) genau dann benachbart, falls |i−k|+|j−ℓ| = 1. Bezeichnen wir i+j mod 2 die Parität des Knoten (i, j), folgt sofort, dass benachbarte Knoten unterschiedliche Parität haben. Damit ergibt sich: In einem Weg gerader Länge haben Anfangs- und Endpunkt gleiche Parität, in einem Weg ungerader Länge ist die Parität unterschiedlich. Betrachte nun einen Hamiltonkreis, falls denn so einer existiert. Er hat die Länge mn. Ein solcher Kreis ist ein Weg der einerseits im gleichen Knoten endet wie er beginnt, andererseits, ist mn ungerade, ist die Parität von Anfangs- und Endknoten unterschiedlich – offensichtlich ein Widerspruch. In obigem Beispiel haben wir ein sogenanntes Paritätsargument ver- wendet. Dieses können wir noch verallgemeinern. Den (einfachen) Beweis hierfür überlassen wir dem Leser. KAPITEL 1. GRAPHENTHEORIE 55 Lemma 1.38. Ist G = (A ] B, E) ein bipartiter Graph mit |A| 6= |B|, so kann G keinen Hamiltonkreis enthalten. Als nächstes betrachten wir einen d-dimensionalen Hyperwürfel Hd. Wir erinnern uns: Die Knotenmenge von Hd ist {0, 1}d, also die Menge aller 0- 1-Folgen der Länge d. Und zwei Knoten sind genau dann durch eine Kante verbunden, wenn ihre beiden 0-1-Folgen sich an genau einer Stelle unter- scheiden. Für d = 3 haben wir bereits auf Seite 47 gesehen, dass H3 einen Hamiltonkreis enthält. Für d = 2 ist das ebenfalls leicht einzusehen, da ein H2 nichts anderes ist als ein Kreis der Länge vier. Es gilt aber ganz allgemein: Der d-dimensionale Hyperwürfel enthält für jedes d \u0015 2 einen Hamiltonkreis. Wir zeigen dies durch Induktion über d. Für d = 2, 3 haben wir dies bereits gezeigt. Für den Induktionsschritt d ⇒ d + 1 gehen wir wie folgt vor. Zunächst betrachten wir alle Knoten im (d + 1)-dimensionalen Hyperwürfel, für welche die letzte Koordinate 0 ist. Diese Punkte induzie- ren (indem man die letzte Koordinate “ignoriert”) einen d-dimensionalen Hyperwürfel und wir wissen daher nach der Induktionsannahme, dass es einen Kreis durch alle diese Punkte gibt. Statt diesem Kreis betrachten wir jetzt nur einen Pfad durch alle diese Knoten, und zwar jenen, der im Kno- ten 00 . . . 0 des Hd beginnt. Schreiben wir diesen Pfad jetzt zweimal hin, und zwar einmal vorwärts und einmal rückwärts, so können wir die erste Kopie hinten um eine Null ergänzen und die zweite Kopie durch eine Eins, und erhalten so einen Pfad von 0 . . . 00 nach 0 . . . 01 durch alle Knoten des Hd+1. Und da die beiden Knoten 0 . . . 00 und 0 . . . 01 benachbart sind, ist dies dann ein Hamiltonkreis für Hd+1. Das folgende Schaubild illustriert diese Konstruktion für d = 2: ? ? ? ? ? ? ? ? ? y 0 0 0 0 1 0 1 1 0 1 0 0 x ? ? ? ? ? ? ? ? ? 1 0 1 1 1 1 0 1 1 0 0 1 Einen Hamiltonkreis im d-dimensionalen Hyperwürfel kann man auch be- nutzen, um eine Codierung der ersten 2d natürlichen Zahlen zu erhalten, die eine oftmals sehr nützliche zusätzliche Eigenschaft haben. KAPITEL 1. GRAPHENTHEORIE 56 Beispiel 1.39. Üblicherweise codiert man natürliche Zahlen durch den sogenannten Binär- code, dem die Darstellung einer Zahl als Summe von Zweierpotenzen zugrunde liegt: 45 codiert man wegen 45 = 1 \u0001 25 + 0 \u0001 24 + 1 \u0001 2 3 + 1 \u0001 22 + 1 \u0001 21 + 1 \u0001 2 0 beispielsweise als 101101. Für manche Anwendungen hat der Binärcode jedoch einige gravierende Nachtei- le. Überträgt man beispielsweise die einzelnen Ziffern der Zahl parallel, so können leichte Zeitverschiebungen bei der Übertragung zu seltsamen Effekten führen. Ändert sich bei- spielsweise der Wert 3 (Binärcode 011) auf den Wert 4 (Binärcode 100), so kann eine zu schnelle Übertragung der führenden Ziffer dazu führend, dass wir kurzzeitig den Wert 7 (Binärcode 111) empfangen. Solche Artefakte verhindert der sogenannte Gray-Code, be- nannte nach dem amerikanischen Physiker Frank Gray (1887-1969), welcher 1953 ein Patent auf dieses Verfahren erhielt. Der Gray-Code ist ein stetiger Code, bei dem sich benachbarte Codewörter nur in einer einzigen binären Ziffer unterscheiden. Dies erreichen wir, indem wir die Zahl i als den i-ten Knoten eines Hamiltonkreises im Hd codieren. Mit den Gittergraphen und dem d-dimensionalen Hyperwürfel haben wir zwei spezielle Graphklassen kennengelernt, für die wir sehr leicht ent- scheiden können, ob es einen Hamiltonkreis gibt und, falls ja, einen solchen auch sofort angeben können. Ähnliches gilt für Graphen, die sehr viele Kanten haben. Satz 1.40 (Dirac). Wenn G = (V, E) ein Graph mit |V| \u0015 3 Knoten ist, in dem jeder Knoten mindestens |V|/2 Nachbarn hat, dann ist G hamiltonsch. Beweis. Wir beweisen den Satz durch Widerspruch. Nehmen wir also an, es gibt einen Graphen G = (V, E) mit |V| \u0015 3, in dem jeder Knoten mindestens |V|/2 Nachbarn hat, der aber nicht hamiltonsch ist. Zunächst überlegen wir uns, dass G zusammenhängend ist. Dazu betrachten wir zwei beliebige Knoten x, y 2 V, x 6= y, und zeigen, dass es in G einen x-y-Pfad gibt. Wenn {x, y} 2 E, so ist das klar. Ansonsten folgt aus deg(x), deg(y) \u0015 |V|/2, dass N(x)\\ N(y) nicht leer sein kann; es gibt dann also einen x-y-Pfad der Länge zwei. Nun betrachten wir einen (beliebigen) längsten Pfad P in G. Mit an- deren Worten: Wir nehmen an, dass P = h v1, . . . , vki ein Pfad ist und es keinen Pfad in G gibt, der mehr Kanten enthält als der Pfad P. Schnell überlegt man sich, dass alle Nachbarn von v1 und vk Knoten des Pfades P sein müssen, denn sonst könnten wir den Pfad P ja verlängern. Als näch- stes überlegen wir uns, dass es ein 2 \u0014 i \u0014 k geben muss mit vi 2 N(v1) und vi−1 2 N(vk). Dies gilt, da nach Annahme v1 zu mindestens |V|/2 vielen Knoten vi mit 2 \u0014 i \u0014 k benachbart ist. Wäre vk zu keinem der entsprechen- KAPITEL 1. GRAPHENTHEORIE 57 den Knoten vi−1 benachbart, könnte vk nur zu höchstens k−1−|V|/2 < |V/2| Knoten benachbart sein, im Widerspruch zu unserer Annahme. Es gibt al- so solch einen Knoten vi. Und h v1, vi, vi+1, . . . , vk, vi−1, vi−2, . . . , v2i ist dann ein Kreis der Länge k. Für k = n wäre dies ein Hamiltonkreis, den es nach Annahme nicht gibt. Also ist k < n und somit existieren Knoten in V, welche nicht auf diesem Kreis liegen. Da wir aber bereits wissen, dass G zusammenhängend ist, wissen wir auch, dass mindestens einer der Knoten dieses Kreises mit einem solchen Knoten ^v ausserhalb des Kreises benach- bart sein muss – und wir erhalten daher einen Pfad der Länge k + 1, indem wir von ^v zum Kreis laufen und von dort dann einmal den Kreis entlang. Da es aber, nach Wahl von P, in G keine Pfade der Länge k + 1 geben kann, haben wir unseren gewünschten Widerspruch. Unser Widerspruchsbeweis zeigt: Jeder Graph G = (V, E) mit minima- lem Grad |V|/2 ist hamiltonsch. Wie aber findet man einen Hamiltonkreis effizient? – Dazu überlegen wir uns zunächst, dass unser Beweis ja eigent- lich recht konstruktiv war. Denn wir haben ein Verfahren angegeben, mit dem wir in Zeit O(|V|) aus einem Pfad der Länge k < n einen Pfad der Länge k + 1 machen können bzw. aus einem Pfad der Länge n einen Ha- miltonkreis. Beginnen wir daher mit einem beliebigen Pfad der Länge 1 (einer Kante), so erhalten wir auf diese Weise nach O(|V| 2) Schritten einen Hamiltonkreis. Beispiel 1.41. Die Schranke |V|/2 aus Satz 1.40 ist bestmöglich, wie das folgende Beispiel zeigt. Nehmen wir an, dass |V| ungerade ist. Wir partitionieren V in V1 und V2 mit |V1| = (|V|−1)/2 und |V2| = (|V|+1)/2 und betrachten den vollständig bipartiten Graphen G = (V1 ] V2, V1 \u0002 V2). Dann hat G minimalen Grad (|V| − 1)/2, kann aber keinen Hamiltonkreis enthalten, da jeder Kreis in G abwechselnd Knoten aus V1 und V2 enthalten muss, V1 aber nur (|V| − 1)/2 viele Knoten enthält. (Die Konstruktion für |V| gerade ist ähnlich und sei dem Leser überlassen.) 1.5.4 Das Travelling Salesman Problem Eine Verallgemeinerung der Frage, ob ein Graph hamiltonsch ist, ist das sogenannte Travelling Salesman Problem (oder deutsch: das Problem des Handlungsreisenden). Travelling Salesman Problem Gegeben: ein vollständiger Graph Kn und eine Funktion ℓ : \u0010 [n] 2 \u0011 → N0, die jeder Kante des Graphen eine Länge zuordnet KAPITEL 1. GRAPHENTHEORIE 58 Gesucht: ein Hamiltonkreis C in Kn mit ∑ e2 C ℓ(e) = min{∑ e2 C 0 ℓ(e) | C 0 ist ein Hamiltonkreis in Kn}. Leicht sieht man ein, dass das Travelling Salesman Problem allgemeiner ist als die Frage ob ein Graph hamiltonsch ist. Dazu definieren wir für einen Graphen G = (V, E) mit V = [n] Knoten eine Gewichtsfunktion ℓ durch ℓ({u, v}) = { 0, falls {u, v} 2 E 1, sonst. Dann gilt offenbar: die Länge eines minimalen Hamiltonkreises in Kn bzgl. der Funktion ℓ ist genau dann Null, wenn G einen Hamiltonkreis enthält. Das Travelling Salesman Problem ist daher sicherlich nicht einfacher zu lösen als die Frage, ob ein Graph hamiltonsch ist. Allerdings erlaubt uns die Formulierung als Optimierungsproblem eine differenziertere Antwort: statt nur Ja oder Nein können wir jetzt auch die Güte einer nicht opti- malen Lösung bewerten. Sei dazu wie oben Kn ein vollständiger Graph mit Gewichtsfunktion ℓ : \u0010 [n] 2 \u0011 → N0. Bezeichnen wir mit opt(Kn, ℓ) die Länge einer optimale Lösung, also opt(Kn, ℓ) := min{∑ e2 C ℓ(e) | C ist ein Hamiltonkreis in Kn} so können wir nunmehr jeden Hamiltonkreis in Kn mit der optimalen Lö- sung vergleichen. Entsprechend spricht man von einem α-Approximations- algorithmus, wenn der Algorithmus immer einen Hamiltonkreis C findet mit ∑ e2 C ℓ(e) \u0014 α \u0001 opt(Kn, ℓ). Leider gilt jedoch: Satz 1.42. Gibt es für ein α > 1 einen α-Approximationsalgorithmus für das Travelling Salesman Problem mit Laufzeit O(f(n)), so gibt es auch einen Algorithmus, der für alle Graphen auf n Knoten in Laufzeit O(f(n)) entscheidet, ob sie hamiltonsch sind. KAPITEL 1. GRAPHENTHEORIE 59 Beweis. Um diesen Satz einzusehen, müssen wir uns nur daran erinnern, dass für die Gewichtsfunktion ℓ, die wir eben eingeführt haben, gilt: opt(Kn, ℓ) = 0 genau dann wenn G hamiltonsch ist. Wegen α \u0001 0 = 0, für alle α > 1, muss ein α-Approximationsalgorithmus daher, wenn G hamiltonsch ist, immer einen Hamiltonkreis in G finden. Fügen wir andererseits eine eigentlich sehr natürliche Annahme an die Gewichtsfunktion ℓ hinzu, so ändert sich die Situation grundlegend. Hierfür definieren wir das, wie man sagt, metrische Problem des Handlungsreisen- den wie folgt: Metrisches Travelling Salesman Problem Gegeben: ein vollständiger Graph Kn und eine Funktion ℓ : \u0010 [n] 2 \u0011 → N0 mit ℓ({x, z}) \u0014 ℓ({x, y}) + ℓ({y, z}) für alle x, y, z 2 [n] Gesucht: ein Hamiltonkreis C in Kn mit ∑ e2 C ℓ(e) = min{∑ e2 C 0 ℓ(e) | C 0 ist ein Hamiltonkreis in Kn}. Die Bedingung ℓ({x, z}) \u0014 ℓ({x, y}) + ℓ({y, z}) nennt man auch Dreiecksun- gleichung. Sie besagt anschaulich: die direkte Verbindung zwischen zwei Knoten x und z darf nicht länger sein als der “Umweg” über einen Kno- ten y. Satz 1.43. Für das Metrische Travelling Salesman Problem gibt es einen 2-Approximationsalgorithmus mit Laufzeit O(n 2). Beweis. Wir berechnen zunächst einen minimalen Spannbaum; dies geht in Zeit O(n 2), vgl. Satz 1.19. Anschliessend verwenden wir diesen Spann- baum um daraus einen Hamiltonkreis zu berechnen. Die folgende Zeichnung illustriert dies: Wir laufen also den Baum ‘aussen rum’ ab. Dabei wird jede Kante zwei Mal durchlaufen. Die Gesamtlänge des entsprechenden (geschlossenen) Weges KAPITEL 1. GRAPHENTHEORIE 60 ist daher 2mst(Kn, ℓ), wobei mst(Kn, ℓ) die Länge eines minimalen Spann- baum für den Kn mit Gewichtsfunktion ℓ sei. Als nächstes laufen wir diesen Weg nochmals ab, lassen dabei aber alle Knoten aus, die wir bereits be- sucht haben. Laufen wir zum Beispiel bei dem Knoten links oben los, so erhalten wir dadurch den folgenden Hamiltonkreis: Nach Annahme erfüllt ℓ die Dreiecksungleichung. Daher wird die Länge des Weges durch das Auslassen von Knoten sicher nicht länger (vielleicht sogar kürzer, aber das interessiert uns hier nicht). Wir erhalten somit auf diese Weise einen Hamiltonkreis mit Länge höchstens 2mst(Kn, ℓ). Aus jedem Hamiltonkreis wird durch Weglassen einer beliebigen Kan- te ein Spannbaum. Daher gilt für die Länge opt(Kn, ℓ) eines minimalen Hamiltonkreises: mst(Kn, ℓ) \u0014 opt(Kn, ℓ). Insbesondere gilt daher für die Länge ℓ(C) = ∑ e2 C ℓ(e) des von uns gefun- den Hamiltonkreises C, dass ℓ(C) \u0014 2opt(Kn, ℓ). Wir müssen uns nun noch überlegen, wie wir unser obiges anschauliche Argument algorithmisch realisieren können. Dies ist verblüffend einfach: wir verdoppeln einfach jede Kante des minimalen Spannbaums. Dadurch erhält jeder Knoten geraden Grad und wir können daher in Zeit O(n) eine Eulertour finden (vgl. Satz 1.31); diese entspricht dem Weg aus unserer ersten Zeichnung. Ausgehend von einem beliebigen Knoten durchlaufen wir anschliessend die Eulertour (die nach Konstruktion aus genau 2(n − 1) Kanten besteht); dabei merken wir uns für jeden Knoten, ob wir ihn schon durchlaufen haben. Immer wenn wir einen Knoten treffen, in dem wir schon einmal waren, lassen wir diesen Knoten aus (formal: wir ersetzen die beiden Kanten vor und nach diesem Knoten durch die entsprechende direkte Verbindung). Auf diese Weise erhalten wir dann, wiederum in Zeit O(n), einen Hamiltonkreis mit Länge \u0014 2opt(Kn, ℓ),. KAPITEL 1. GRAPHENTHEORIE 61 Im nächsten Abschnitt werden wir sehen, dass wir – mit einem zusätz- lichen Trick – den Faktor 2 aus Satz 1.43 sogar durch 3/2 ersetzen können. 1.6 Matchings Betrachten wir das folgende Zuordnungsproblem. Gegeben ist eine Menge von Rechnern mit verschiedenen Leistungsmerkmalen (Speicher, Geschwin- digkeit, Plattenplatz, etc.) und eine Menge von Jobs mit unterschiedlichen Leistungsanforderungen an die Rechner. Gibt es eine Möglichkeit, die Jobs so auf die Rechner zu verteilen, dass alle Jobs gleichzeitig bearbeitet werden können? Graphentheoretisch können wir das Problem wie folgt formulieren: Wir symbolisieren jeden Job und jeden Rechner durch einen Knoten und verbinden einen Job mit einem Rechner genau dann, wenn der Rechner die Leistungsanforderungen des Jobs erfüllt. Gesucht ist dann eine Auswahl der Kanten, die jedem Job genau einen Rechner zuordnet und umgekehrt je- dem Rechner höchstens einen Job. Eine solche Teilmenge der Kanten nennt man ein Matching des Graphen. Definition 1.44. Eine Kantenmenge M \u0012 E heisst Matching in einem Graphen G = (V, E), falls kein Knoten des Graphen zu mehr als einer Kante aus M inzident ist, oder formal ausgedrückt, wenn e \\ f = ; für alle e,f 2 M mit e 6= f. Man sagt ein Knoten v wird von M überdeckt, falls es eine Kante e 2 M gibt, die v enthält. Ein Matching M heisst perfektes Matching, wenn jeder Knoten durch genau eine Kante aus M überdeckt wird, oder, anders ausgedrückt, wenn |M| = |V|/2. Beispiel 1.45. Ein Graph enthält im Allgemeinen sehr viele Matchings. Beispielsweise ist M = {e} für jede Kante e 2 E ein Matching. Abbildung 1.15. zeigt ein Matching (links) und ein perfektes Matching (Mitte). Nicht jeder Graph enthält jedoch ein perfektes Matching. Für Graphen mit einer ungeraden Anzahl an Knoten ist dies klar. Es gibt aber sogar Graphen mit beliebig vielen Knoten, deren grösstes Matching aus einer einzigen Kante besteht. Als Beispiel, die sogenannten Sterngraphen (im Bild rechts), deren Kantenmenge genau aus den zu einem Knoten inzidenten Kanten besteht. KAPITEL 1. GRAPHENTHEORIE 62 Abbildung 1.15: Matchings Meist interessiert man sich dafür in einem Graphen ein möglichst gros- ses Matching zu finden. Hier ist es zunächst wichtig, dass man sich klar macht, dass es zwei verschiedene Arten gibt, wie man “möglichst gross” interpretieren kann. Definition 1.46. Sei G = (V, E) ein Graph und M ein Matching in G. • M heisst inklusionsmaximal, falls gilt M[ {e} ist kein Matching für alle Kanten e 2 E \\ M. • M heisst kardinalitätsmaximal, falls gilt |M| \u0015 |M 0 | für alle Matchings M 0 in G. (In der englischsprachigen Literatur hat sich die folgende abkürzende Schreibwei- se eingebürgert: Ein maximal matching bezeichnet ein inklusionsmaximales Mat- ching, während ein maximum matching ein kardinalitätsmaximales Matching ist.) Ein inklusionsmaximales Matching hat also die Eigenschaft, dass man keine Kante mehr hinzufügen kann, ohne die Matching-Eigenschaft zu zerstören. Ein solches Matching muss aber nicht unbedingt kardinalitätsmaximal sein. Dies sieht man sehr schön an einem Pfad mit drei Kanten: Das Matching, das nur aus der mittleren Kante besteht ist inklusionsmaximal, aber nicht kardinalitätsmaximal. Ein kardinalitätsmaximales Matching erhält man, wenn man die beiden äusseren Kanten wählt. Ein kardinalitätsmaximales Matching ist immer auch inklusionsmaximal. 1.6.1 Algorithmen Ein inklusionsmaximales Matching kann man sehr einfach mit einem Greedy- Algorithmus bestimmen: KAPITEL 1. GRAPHENTHEORIE 63 Greedy-Matching (G) 1: M ← ; 2: while E 6= ; do 3: wähle eine beliebige Kante e 2 E 4: M ← M [ {e} 5: lösche e und alle inzidenten Kanten in G Satz 1.47. Der Algorithmus Greedy-Matching bestimmt in Zeit O(|E|) ein inklusionsmaximales Matching MGreedy für das gilt: |MGreedy| \u0015 1 2 |Mmax|, wobei Mmax ein kardinalitätsmaximales Matching sei. Beweis. Dass MGreedy ein inklusionsmaximales Matching ist, folgt unmit- telbar aus der Konstruktion des Matchings: Wenn immer wir eine Kante zum Matching hinzufügen, löschen wir genau alle Kanten aus dem Gra- phen, die zukünftig nicht mehr zum Matching hinzugefügt werden können. Und wir wiederholen dies, bis keine Kante mehr vorhanden ist. Um die Ungleichung zu zeigen, betrachten wir die exklusive Disjunkti- on (auch exklusives Oder oder Exor genannt) MGreedy\b Mmax := (MGreedy[ Mmax) \\ (MGreedy \\ Mmax) der beiden Matchings. Da MGreedy inklusionsma- ximal ist, muss jede Kante aus Mmax mindestens eine Kante aus MGreedy berühren. Da Mmax ein Matching ist, kann andererseits jeder Knoten aus MGreedy (von denen es 2|MGreedy| viele gibt), nur eine Kante von MMax berühren. Aus beiden Fakten zusammen folgt daher |Mmax| \u0014 2|MGreedy|, woraus sich die behauptete Ungleichung durch eine elementare Umformung ergibt. Im Beweis von Satz 1.47 ist uns erstmals ein Konzept begegnet, das sich bei der Behandlung von Matchings als immens nützlich erwiesen hat: die Betrachtung des Exor von zwei Matchings. Wir wollen dies hier noch etwas genauer ausführen. Seien M1 und M2 zwei beliebige Matchings in einem Graphen G. Was können wir über M1\b M2 sagen? – Zum einen wissen wir, dass jeder Knoten in dem Graphen GM = (V, M1 \b M2) Grad höchstens zwei hat. Die Zusam- KAPITEL 1. GRAPHENTHEORIE 64 menhangskomponenten des Graphen GM sind daher alles Pfade und/oder Kreise, wobei alle Kreise gerade Länge haben müssen. (Warum?!). Nehmen wir nun zusätzlich an, dass |M1| < |M2| gilt. Was können wir nun über die Zusammenhangskomponenten in der Vereinigung M1 [ M2 sagen? – Wir wissen bereits: Die Zusammenhangskomponenten sind Kreise und/oder Pfade. Jede Komponente, die ein Kreis oder ein Pfad mit gera- der Länge ist, enthält jeweils gleich viele Kanten aus M1 und M2. Wegen |M1| < |M2| muss es daher in M1 [ M2 eine Zusammenhangskomponente geben, die ein Pfad P ist, der mehr Kanten aus M2 als aus M1 enthält. Da sich Kanten aus M1 und M2 abwechseln, kann ein solcher Pfad höchstens eine Kante mehr aus M2 enthalten, nämlich wenn die beiden äusseren Kan- ten von P (d.h., die erste und die letzte Kante von P) zu M2 gehören. Ist |M2| = |M1| + k, muss es sogar mindestens k solche Pfade geben. Wir kön- nen einen solchen Pfad P verwenden, um aus dem Matching M1 ein neues Matching M 0 1 zu erhalten, das eine Kante mehr enthält. Dazu tauschen wir die Kanten in P: Wir setzen M 0 1 := M1 \b P, wobei wir P hier als Menge von Kanten behandeln. Man sagt daher auch: P ist ein M1-augmentierender Pfad. Formal ist ein M-augmentierender Pfad (für ein beliebiges Matching M) definiert durch: Die beiden Endknoten von P werden durch M nicht überdeckt (haben also in M Grad Null) und P besteht abwechselnd aus Kanten, die nicht zu M gehören, und Kanten aus M. Insbesondere haben wir damit den folgenden Satz gezeigt. Satz 1.48 (Satz von Berge). Ist M ein Matching in einem Graphen G = (V, E), das nicht kardinalitätsmaximal ist, so existiert ein aug- mentierender Pfad zu M. Beweis. Ist M nicht kardinalitätsmaximal, so gibt es ein grösseres Mat- ching M 0 . Wie eben schon gezeigt, gibt es in M \b M 0 eine Zusammen- hangskomponente, die mehr Kanten aus M 0 als aus M enthält. Dieser ist ein augmentierender Pfad für M. Mit diesen Ideen erhält man wie folgt einen Algorithmus zur Bestim- mung eines kardinalitätsmaximalen Matchings: Wir starten mit einem Mat- ching, das aus einer einzigen (beliebigen) Kante besteht. Solange das Mat- ching noch nicht kardinalitätsmaximal ist, gibt es einen augmentierenden Pfad, der es uns erlaubt, das Matching zu vergrössern. Spätestens nach KAPITEL 1. GRAPHENTHEORIE 65 |V|/2 − 1 vielen solcher Schritte ist das Matching dann maximal, denn ein Matching kann ja nicht mehr als |V|/2 viele Kanten enthalten. Bleibt die Frage, wie man augmentierende Pfade effizient bestimmen kann. Zu- mindest für bipartite Graphen geht das recht einfach mit einer modifizier- ten Breitensuche. Damit erhält man dann einen Algorithmus mit Laufzeit O((|V| + |E|) \u0001 |E|). Schauen wir uns dazu die Subroutine genauer an, die zu einem gegebenen Matching in einem bipartiten Graphen einen augmentie- renden Pfad findet. augmenting_path (G = (A ] B, E), M) 1: L0 := {unüberdeckte Knoten in A} 2: Markiere alle Knoten aus L0 als besucht. 3: if L0 = ; then 4: return M ist maximal 5: for all i = 1 to n do 6: if i ungerade then 7: Li := {unbesuchte Nachbarn von Li−1 via Kanten in E \\ M} 8: else 9: Li := {unbesuchte Nachbarn von Li−1 via Kanten in M} 10: Markiere alle Knoten aus Li als besucht. 11: if Li enthält unüberdeckten Knoten v then 12: Finde Pfad P von L0 nach v durch backtracking 13: return P // terminiert Algorithmus 14: return M ist schon maximal Schauen wir uns die Layers Li noch etwas genauer an, die der Algo- rithmus erzeugt, siehe Abbildung 1.16. Zunächst halten wir fest, dass ein augmentierender Pfad immer ungerade Länge hat, denn er hat eine Kante aus E \\ M mehr als Kanten in M. Deshalb muss solch ein Pfad in biparti- ten Graphen immer einen Endpunkt in A und einen Endpunkt in B haben. Deshalb genügt es, mit unüberdeckten Knoten aus A zu starten. Danach wechseln die Layer zwischen den partiten Mengen A und B ab. Knoten aus B erreichen wir daher grundsätzlich über Kanten aus E \\ M, und Knoten aus A über die (eindeutig bestimmte) inzidente Kante aus M. Insbesondere liegen alle unüberdeckten Knoten, die der Algorithmus besucht, im ersten und letzten Layer. Mit dieser modifizierten Breitensuche kann man daher einen augmentie- KAPITEL 1. GRAPHENTHEORIE 66 Abbildung 1.16: Der Layer-Graph, der von der Breitensuche zum Auffinden eines augmentierenden Pfades erzeugt wird. renden Pfad, wenn es denn einen gibt (wenn es keinen gibt, ist das aktuelle Matching kardinalitätsmaximal), in Zeit O(|E|) finden. Da wir höchstens |V|/2 oft augmentieren müssen, erhalten wir damit insgesamt einen Algo- rithmus mit Laufzeit O(|V||E|). Mit einer kleinen Modifikation (und einer genaueren Analyse) kann man die Laufzeit sogar auf O(q |V||E|) reduzieren. Dies ist der sogenannte Algorithmus von Hopcroft und Karp. Der Algorithmus von Hopcroft und Karp Die oben geschilderte Breitensuche hat einen schönen Nebeneffekt. Sie fin- det nicht nur irgendeinen augmentierenden Pfad, sondern wir können sie auch benutzen um eine (inklusions-) maximale Menge kürzester augmen- tierenden Pfad(e) zu finden. Hierfür stellen wir fest, dass wir die Layer- Struktur mit etwas Glück nicht nur einen augmentierenden Pfad liefert, sondern möglicherweise mehrere, falls im letzten Layer Lk mehrere unüber- deckte Knoten liegen. Dazu wählen wir einen solchen Knoten v1 aus Lk aus, finden einen augmentierenden Pfad P1 von L0 zu v1, und löschen P1 aus der Layerstruktur. Danach wählen wir einen weiteren unüberdeckten Knoten v2 aus Lk (falls vorhanden) und schauen, ob es zu diesem noch einen aug- KAPITEL 1. GRAPHENTHEORIE 67 mentierenden Pfad gibt. Dies können wir tun, indem wir alle Kanten im Layergraph nach oben richten, und in diesem gerichteten Graphen dann eine Tiefensuche von v2 aus starten, bis wir auf L0 stossen oder die Tiefen- suche erfolglos abbricht. Falls wir L0 erreichen, haben wir einen weiteren augmentierenden Pfad P2 gefunden, der disjunkt zu P1 ist. Dann löschen wir alle besuchten Knoten aus der Layerstruktur und wiederholen das Ganze, bis wir alle unüberdeckten Knoten aus Lk abgearbeitet haben. Der Gesamt- aufwand bleibt bei O(|V| + |E|), weil wir ja jede Kante und jeden Knoten nach Besuch löschen. Auf diese Weise finden wir nicht nur einen einzelnen Pfad, sondern eine Menge S aus augmentierenden Pfaden mit: • Alle Pfade in S haben dieselbe minimale Länge k (d.h. k ist die Länge eines kürzesten augmentierenden Pfades). • Alle Pfade in S sind paarweise disjunkt. • S ist inklusionsmaximal mit dieser Eigenschaft, d.h. es lässt sich kein weiterer augmentierender Pfad der Länge k zu S hinzufügen, ohne die zweite Bedingung zu verletzen. Da die Pfade disjunkt sind, können wir M entlang aller dieser Pfade parallel augmentieren, denn ein augmentierender Pfad P ändert den Sta- tus überdeckt/unüberdeckt ja nur für die Knoten auf P. Fügen wir diesen kleinen Trick zu unserem Algorithmus hinzu, so erhalten wir den folgen- den Algorithmus von Hopcroft und Karp zur Berechnung eines maximalen Matchings in bipartiten Graphen. Wir formulieren den Pseudocode so, dass er gut lesbar ist, auch wenn eine Implementierung mehrere Schritte mit- einander verzahnen würde. maximal_matching (G = (A \b B, E)) (Hopcroft und Karp) 1: M := {e} für irgendeine Kante e 2 E. 2: while es gibt noch augmentierende Pfade do 3: k := Länge eines kürzesten augmentierenden Pfades 4: Finde eine inklusionsmaximale Menge S von paarweise disjunkten augmentierenden Pfaden der Länge k. 5: for all P aus S do 6: M := M \b P. // augmentiere entlang der Pfade aus S 7: return M KAPITEL 1. GRAPHENTHEORIE 68 Erstaunlicherweise macht dieser harmlos scheinende Trick den Algorith- mus wesentlich schneller. Satz 1.49. Der Algorithmus von Hopcroft und Karp durchläuft die while-Schleife nur O(q |V|) Mal. Er berechnet daher ein maximales Matching in einem bipartiten Graphen in Zeit O(q |V| \u0001 (|V| + |E|)). Beweis. Wir haben uns bereits von der Korrektheit überzeugt und skiz- ziert, warum jeder Durchlauf der while-Schleife in Zeit O(|V| + |E|) möglich ist. Die spannende Frage bleibt daher, warum der Algorithmus die while- Schleife nur O(q |V|) Mal durchläuft. Dazu sammeln wir einige weitere Er- kenntnisse zu augmentierenden Pfaden. Im Folgenden behandeln wir Pfade weiter als Kollektion von Kanten, d.h. mit |P| bezeichnen wir die Zahl der Kanten im Pfad P. 1) Ist M ein Matching, P ein kürzester augmentierender Pfad von M, und P 0 ein augmentierender Pfad für M \b P, so gilt |P 0 | \u0015 |P| + 2|P \\ P 0 |. Insbesondere: Augmentieren wir M sukzessive mit kürzesten aug- mentierenden Pfaden, so können die Längen dieser Pfade nicht ab- nehmen. Um 1) zu zeigen, schauen wir uns das Matching ˜M := M\b P\b P 0 an, das wir nach Augmentieren mit P und P 0 erhalten. Wir wissen, dass | ˜M| = |M| + 2. Deshalb muss |M \b ˜M| mindestens zwei disjunkte Pfade enthalten, die aug- mentierende Pfade für M sind. Aber weil P ein kürzester augmentierender Pfad für M ist, haben diese Pfade je mindestens Länge |P|. Andererseits erfüllt die Verknüpfung \b die normalen Kommutativitäts- und Assozia- tivgesetze, daher ist M \b ˜M = M \b M \b P \b P 0 = P \b P 0 . Insgesamt ist also |P \b P 0 | = |M \b ˜M| \u0015 2|P|. Schliesslich setzen wir noch ein, dass |P \b P 0 | = |P [ P 0 | − |P \\ P 0 | = |P| + |P 0 | − 2|P \\ P 0 | nach Definition von \b ist, und erhalten |P| + |P 0 | − 2|P \\ P 0 | = |P \b P 0 | \u0015 2|P|, was nach Umformen 1) ergibt. 2) Mit jedem Durchlaufen der while-Schleife erhöht sich k um minde- stens 2. KAPITEL 1. GRAPHENTHEORIE 69 Dies ist eine Konsequenz von 1), wie wir nun sehen werden. Zunächst be- trachten wir, was passiert, während wir M mit den Pfaden der Länge k aus S augmentieren. Nachdem wir mit dem ersten Pfad P 2 S augmentiert haben, erhalten wir ein Matching M 0 = M \b P. Laut 1) hat dieses keinen augmentierenden Pfad, der echt kürzer als k wäre. Damit sind die weiteren Pfade in S also nicht nur kürzeste augmentierende Pfade für M, sondern auch für M 0 und induktiv auch für alle weiteren Matchings, die wir in die- sem Schritt erhalten. Der Algorithmus von Hopcroft und Karp augmentiert also immer entlang kürzester Pfade, auch in allen Zwischenschritten. Sei nun ˜M das Matching, das wir erhalten, nachdem wir mit allen Pfa- den aus S augmentiert haben. 2) behauptet, dass der kürzeste augmentie- rende Pfad für ˜M mindestens Länge k + 2 hat. Sei ˜P ein solcher Pfad. Wir haben gerade schon gesehen, dass |˜P| \u0015 k ist. Wir unterscheiden zwei Fälle. Der erste Fall ist, dass ˜P disjunkt ist zu allen Pfaden in S. Da S inklusi- onsmaximal ist, muss dann |˜P| \u0015 k + 1 sein, und sogar |˜P| \u0015 k + 2, weil augmentierende Pfade ungerade Länge haben. Der andere Fall ist, dass ˜P einen Pfad P aus S in mindestens einem Knoten v schneidet. ˜M überdeckt alle Knoten aus P, da es ja durch Augmentieren mit P entstanden ist. Al- so ist auch v durch eine Kante e 2 ˜M überdeckt, die durch P hinzugefügt wurde. Die Kante e ist also einerseits in P. Andererseits ist auch e 2 ˜P, weil augmentierende Pfade wie ˜P die Matching-Kanten von allen überdeckten Knoten auf dem Pfad enthalten. Also ist e 2 P \\ ˜P, und damit P \\ ˜P 6= ; . Schliesslich können wir ohne Einschränkung annehmen, dass der Pfad P von allen Pfaden aus S als letztes verarbeitet wurde, weil die Reihenfolge der Pfade aus S ja beliebig ist. Damit sind wir in der Situation von 1), und können folgern, dass |˜P| \u0015 |P| + 2|P \\ ˜P| \u0015 k + 2 ist. Wir haben in beiden Fällen also |˜P| \u0015 k + 2 gesehen, und damit ist 2) bewiesen. 3) Sei M ein Matching, für das der kürzeste augmentierende Pfad Länge k hat, und M 0 ein beliebiges anderes Matching. Dann gilt |M 0 | \u0014 |M| + |V| k + 1 . Um dies zu sehen, nehmen wir an, dass |M 0 | > |M| ist, da die Aussage sonst trivial ist. Dann wissen wir schon, dass M\b M 0 mindestens |M 0 |−|M| disjunkte Pfade besitzt, die augmentierende Pfade für M sind. Auf jedem solchen Pfad liegen mindestens k + 1 Knoten (da er Länge mindestens k KAPITEL 1. GRAPHENTHEORIE 70 hat). Zusammen liegen auf diesen Pfaden also mindestens (|M 0 |−|M|)\u0001 (k+1) viele Knoten. Andererseits gibt es im Graphen nur |V| viele Knoten. Also ist (|M 0 | − |M|) \u0001 (k + 1) \u0014 |V|, woraus 3) durch Umformung folgt. Aus 1), 2) und 3) können wir nun das Theorem beweisen. Zunächst besagt 2), dass nach den ersten d q |V|/2e Durchläufen der while-Schleife k \u0015 q |V| gilt. An diesem Punkt besagt 3) aber, dass ein maximale Matching Mmax erfüllt: |Mmax| \u0014 |M| + |V|/(k + 1) \u0014 |M| + q |V|, bzw. |M| \u0015 |Mmax| − q |V|. Mit jedem weiteren Durchlauf der while-Schleife erhöht sich aber die Grösse von M um mindestens 1. Nach spätestens q |V| weiteren Durchläufen erreicht |M| also die Grösse |Mmax|, und der Algorithmus terminiert. Weitere Matching-Algorithmen In Kapitel 3 der Vorlesung werden wir noch weitere, alternative Algo- rithmen für das Finden von Matchings in bipartiten Graphen kennenler- nen. Mit (deutlich) mehr Aufwand kann man auch zeigen, dass man so- gar in beliebigen Graphen ein (kardinalitäts-)maximales Matching in Zeit O(q |V| \u0001 (|V| + |E|)) finden kann. Das überlassen wir aber Spezialvorlesun- gen. Stattdessen betrachten wir hier noch kurz eine gewichtete Variante des Problems: Satz 1.50. Ist n gerade und ℓ : \u0010 [n] 2 \u0011 → N0 ein Gewichtsfunktion des vollständigen Graphen Kn, so kann man in Zeit O(n 3) ein minimales perfektes Matching finden, also ein perfektes Matching M mit ∑ e2 M ℓ(e) = min{ ∑ e2 M 0 ℓ(e) | M 0 perfektes Matching in Kn}. Der Beweis dieses Satz sprengt ebenfalls den Rahmen dieser Einführungs- vorlesung. Wir wollen hier jedoch noch eine Konsequenz dieses Satzes her- leiten. Satz 1.51. Für das Metrische Travelling Salesman Problem gibt es einen 3/2-Approximationsalgorithmus mit Laufzeit O(n 3). Beweis. Die Grundidee dieses Algorithmus ist ähnlich zu der Idee des 2- Approximationsalgorithmus aus Satz 1.43: Wir berechnen zunächst einen KAPITEL 1. GRAPHENTHEORIE 71 minimalen Spannbaum T , dann modifizieren wir diesen, sodass wir in dem neuen Graphen eine Eulertour finden können. In einem letzten Schritt lau- fen wir dann diese Eulertour ab und verkürzen sie hierbei schrittweise (in- dem wir Knoten, in denen wir schon waren, auslassen) so lange, bis wir einen Hamiltonkreis haben. Der Unterschied der beiden Algorithmen be- steht darin, wie wir die Modifikation des Spannbaums vornehmen, damit der Graph eulersch wird. In Satz 1.43 haben wir einfach jede Kante von T verdoppelt. Nun gehen wir wie folgt vor. Wir bezeichnen mit S die Menge derjenigen Knoten, die in T einen ungeraden Grad haben. Da |S| gerade ist (vgl. Korollar 1.3), gibt es in Kn[S] ein perfektes Matching. Unter allen solchen Matchings wählen wir eines mit minimalem Gewicht. Aus Satz 1.50 wissen wir, dass wir ein solches minimales perfektes Matching, nennen wir es M, in Zeit O(n 3) finden können. Im (Multi-) Graph T [ M hat dann jeder Knoten geraden Grad und wir können daher, jetzt wieder ganz analog zum Beweis von Satz 1.43, einen Hamiltonkreis C finden mit ℓ(C) \u0014 ℓ(M) + ℓ(T ). Wir wissen bereits, dass ℓ(T ) = mst(Kn, ℓ) \u0014 opt(Kn, ℓ). Wir zeigen nun noch, dass ℓ(M) \u0014 1 2 opt(Kn, ℓ), woraus dann folgt, dass ℓ(C) \u0014 3 2 opt(Kn, ℓ), und der Algorithmus also ein 3/2-Approximationsalgorithmus ist. Um einzusehen, dass ℓ(M) \u0014 1 2 opt(Kn, ℓ) gilt, betrachten wir einen Ha- miltonkreis Copt der Länge ℓ(Copt) = opt(Kn, ℓ). Die Knoten aus S zerlegen Copt in |S| viele Pfade. Da ℓ die Dreiecksungleichung erfüllt, können wir jeden dieser Pfade zu einer Kante reduzieren, ohne die Länge des Kreises zu erhöhen. D.h., wir haben jetzt einen Kreis Cs, dessen Knoten genau die Knoten aus S sind und für den gilt: ℓ(Cs) \u0014 ℓ(Copt) = opt(Kn, ℓ). Der Kreis Cs lässt sich als Vereinigung von zwei Matchings (mit jeweils |S|/2 Kanten) schreiben: Cs = M1 [ M2, wobei mindestens eines dieser beiden Matchings Länge \u0014 1 2 ℓ(Cs) haben muss (denn sonst wäre die Summe ja grösser als ℓ(Cs)). Da wir M als minimales perfektes Matching in Kn[S] gewählt ha- ben, gilt daher ℓ(M) \u0014 1 2ℓ(Cs) \u0014 1 2 opt(Kn, ℓ), wie behauptet. 1.6.2 Der Satz von Hall Wir erinnern uns: Ein Graph G = (V, E) heisst bipartit, wenn man die Knotenmenge V so in zwei Mengen A und B partitionieren kann, dass alle Kanten in E je einen Knoten aus A und einen Knoten aus B enthalten. KAPITEL 1. GRAPHENTHEORIE 72 Bipartite Graphen schreiben wir dann entsprechend als G = (A ] B, E). Der folgende Satz von Philip Hall (1904–1982) gibt eine notwendige und hinreichende Bedingung an, unter der ein Matching in einem bipartiten Graphen existiert, welches alle Knoten einer Partition überdeckt. Zur For- mulierung des Satzes führen wir noch eine abkürzende Schreibweise für die Nachbarschaft einer Knotenmenge X \u0012 V ein: N(X) := [ v2 X N(v). Satz 1.52 (Satz von Hall, Heiratssatz). Für einen bipartiten Graphen G = (A ] B, E) gibt es genau dann ein Matching M der Kardinalität |M| = |A|, wenn gilt |N(X)| \u0015 |X| für alle X \u0012 A. (1.1) Beweis. Wir beweisen zuerst die notwendige Bedingung (also die „⇒“- Richtung des Satzes). Sei M ein Matching der Kardinalität |M| = |A|. In dem durch M gegebenen Teilgraphen H = (A ] B, M) hat jede Teilmenge X \u0012 A nach Definition eines Matchings genau |X| Nachbarn. Wegen M \u0012 E gilt daher auch |N(X)| \u0015 |X| für alle X \u0012 A. Die hinreichende Bedingung (die „⇐“-Richtung) beweisen wir durch Induktion über die Kardinalität a = |A| der Menge A. Für a = 1 impliziert die Bedingung (1.1), angewandt auf die Menge X = A, dass der (einzige) Knoten in A zu mindestens einer Kante inzident ist. Jede solche Kante ist dann ein Matching, das die Bedingung des Satzes erfüllt. Nehmen wir daher an, dass a > 1 und dass die Behauptung für alle bipartiten Graphen mit |A| < a gilt. Wir unterscheiden zwei Fälle. Gilt die Bedingung (1.1) für alle Mengen ; 6 = X ⊊ A sogar mit > statt nur mit \u0015 , so wählen wir eine beliebige Kante e = {x, y} des Graphen, fügen e zum Matching hinzu und betrachten den Graphen G 0 , den wir erhalten, wenn wir die Knoten x und y (und alle inzidenten Kanten) löschen. Da die Bedingung (1.1) für alle Mengen ; 6 = X ⊊ A mit > erfüllt war (und wir nur einen Knoten aus der Menge B gelöscht haben), ist die Bedingung (1.1) für den Graphen G 0 noch immer erfüllt. Aus der Induktionsannahme folgt daher, dass wir die Kante e durch ein Matching M 0 so ergänzen können, dass dann alle Knoten in A überdeckt werden. KAPITEL 1. GRAPHENTHEORIE 73 Falls die Bedingung (1.1) nicht für alle Mengen ; 6 = X ⊊ A mit > erfüllt ist, so gibt es mindestens eine Menge ; 6 = X0 ⊊ A, für die |N(X0)| = |X0| gilt. Unser Plan ist jetzt, die Induktionsannahme auf die beiden induzierten, knotendisjunkten Graphen G 0 = G[X0 ] N(X0)] und G 00 = G[A \\ X0 ] B \\ N(X0)] anzuwenden. Die Bedingung (1.1) ist offensichtlich für den Graphen G 0 erfüllt. Sie gilt aber auch für den Graphen G 00 , wie wir uns jetzt noch überlegen. Betrachte eine beliebige Menge X \u0012 A \\ X0. Da (1.1) für den Graphen G gilt, wissen wir |X| + |X0| = |X [ X0| (1.1) \u0014 |N(X [ X0)| = |N(X0)| + |N(X) \\ N(X0)|. Wegen |N(X0)| = |X0| folgt daraus |X| \u0014 |N(X) \\ N(X0)| = |N(X) \\ (B \\ N(X0))|. D.h., die Nachbarschaft von X in dem Graphen G 00 besteht aus mindestens |X| Knoten. Und da dies für alle Mengen X \u0012 A \\ X0 gilt, ist die Bedingung (1.1) daher für den Graphen G 00 erfüllt. Aus der Indukti- onsannahme folgt daher: Es gibt ein Matching M 0 in G 0 , das alle Knoten in X0 überdeckt, und ein Matching M 00 in G 00 , das alle Knoten in A \\ X0 überdeckt. M = M 0 [ M 00 ist dann ein Matching in G mit |M| = |A|. Aus dem Satz von Hall folgt unmittelbar, dass k-reguläre bipartite Gra- phen immer ein perfektes Matching enthalten. Es gilt sogar noch mehr: Wir können die Kantenmenge als Vereinigung von perfekten Matchings schreiben! Satz 1.53. Sei G = (A ] B, E) ein k-regulärer bipartiter Graph. Dann gibt es M1, . . . , Mk so dass E = M1 ] . . . ] Mk und alle Mi, 1 \u0014 i \u0014 k, perfekte Matchings in G sind. Beweis. Wir überlegen uns zunächst, dass jeder k-reguläre bipartite Graph in der Tat ein perfektes Matching enthält. Dazu betrachten wir eine beliebi- ge Menge X \u0012 A und den induzierten Graphen G 0 = G[X [ N(X)]. Offenbar ist G 0 auch bipartit; die entsprechende Partition ist gegeben durch X] N(X). Da G k-regulär ist, hat in G 0 jeder Knoten in X ebenfalls Grad k und jeder Knoten in N(X) Grad höchstens k. Da in bipartiten Graphen die Summe der Grade der Knoten “links” immer gleich der Summe der Grade “rechts” ist, folgt daraus: |N(X)| \u0015 |X| und die Bedingung (1.1) des Satzes von Hall ist damit erfüllt. Daraus folgt also, dass G ein perfektes Matching M1 ent- hält. Entfernen wir dieses, so erhalten wir einen (k − 1)-regulären Graphen, KAPITEL 1. GRAPHENTHEORIE 74 der somit ebenfalls ein perfektes Matching M2 enthält. Fahren wir entspre- chend fort, bis der Graph 1-regulär ist (und daher ein perfektes Matching ist), so erhalten wir dadurch die im Satz behauptete Partitionierung in perfekte Matchings. Satz 1.53 garantiert, dass ein k-regulärer bipartiter Graph ein perfektes Matching enthält. Aber kann man ein solches effizient finden? Ja, man kann: Es gibt einen Algorithmus, der in Zeit O(|E|) ein solches Matching findet. Wir zeigen dies hier nur für Werte für k, die eine Zweierpotenz sind. Hierfür ist der Algorithmus sogar sehr elegant. Der allgemeine Fall ist deutlich schwieriger. Satz 1.54. Ist G = (V, E) ein 2k-regulärer bipartiter Graph, so kann man in Zeit O(|E|) ein perfektes Matching bestimmen. Beweis. Da G 2k-regulär und bipartit ist, erfüllt jede Zusammenhangskom- ponente von G die Euler-Bedingung. Wir können daher in Zeit O(|E|) für jede Komponente eine Eulertour bestimmen (vgl. Satz 1.31). Wir laufen diese Touren jetzt einmal ab, wobei wir jede zweite Kante in der Tour aus dem Graphen entfernen. Der übrig gebliebene Graph ist jetzt 2k−1-regulär - und wir können daher das Verfahren wiederholen. Nach k Iterationen ist der Graph 20-regulär – und also ein perfektes Matching. Um die Laufzeit abzuschätzen gehen wir wie folgt vor. Wir wissen aus Satz 1.31, dass man eine Eulertour in Zeit O(|E|) bestimmen kann. Wollen wir in jeder Zusammenhangskomponente eine Eulertour finden, so sieht man leicht ein, dass das ebenfalls in Gesamtzeit O(|E|) möglich ist. Statt der O()-Notation verwenden wir jetzt die folgende Schreibweise: Es gibt ein C > 0, sodass der Algorithmus aus Satz 1.31 für jeden eulerschen Gra- phen G = (V, E) in höchstens C|E| Schritten eine Eulertour pro Kompo- nente bestimmt. Für unseren Ausgangsgraphen benötigt der Algorithmus daher höchstens C|E| Schritte. Dann laufen wir die Eulertouren einmal ab und löschen jede zweite Kante. Dies geht sicherlich in C 0 |E| Schritten. Nun haben wir einen Graphen mit |E|/2 Kanten. In der nächsten Iteration be- nötigen wir daher nur noch höchstens C|E|/2 Schritte, um die Eulertouren zu bestimmen und höchstens C 0 |E|/2 Schritte für das Löschen von jeder zweiten Kante. Allgemein gilt daher: In der i-ten Iteration kann man in (C + C 0 )|E|/2i−1 Schritten die Anzahl Kanten um die Hälfte reduzieren. KAPITEL 1. GRAPHENTHEORIE 75 Insgesamt benötigen wir daher höchstens k∑ i=1 (C + C 0 )|E|/2i−1 \u0014 ∑ i\u0015 0 (C + C 0 )|E|/2i = 2(C + C 0 )|E| Schritte, um ein perfektes Matching zu bestimmen. Es ist verlockend anzunehmen, dass der Algorithmus auch für nicht- bipartite Graphen so funktioniert. Dies ist aber nicht so: Nach Wegnahme jeder zweiten Kante der Eulertour kann es passieren, dass der übrig ge- bliebene Graph nicht mehr zusammenhängend ist. In bipartiten Graphen ist das nicht weiter schlimm: Wir können den Algorithmus einfach auf je- de Zusammenhangskomponente anwenden. Bei nicht-bipartiten Graphen kann es aber für k = 1 passieren, dass eine solche Komponente eine ungera- de Anzahl an Knoten, und damit auch an Kanten enthält. In dem Fall hat auch die Eulertour eine ungerade Länge, wir können also nicht jede zweite Kante löschen. Da die Komponente eine ungerade Anzahl an Knoten hat, kann auch überhaupt kein perfektes Matching mehr existieren. Beispiel 1.55. Aus Satz 1.53 wissen wir, dass jeder k-reguläre bipartite Graph ein perfektes Matching enthält. Für nicht-bipartite Graphen gilt dies jedoch nicht immer: Ungerade Kreise oder vollständige Graphen auf ungerade vielen Knoten sind hier einfache Gegen- beispiele. Dass diese Graphen kein perfektes Matching enthalten, sieht man sofort daran, dass sie ungerade viele Knoten enthalten. Für Gegenbeispiele auf gerade vielen Knoten muss man sich etwas mehr Mühe geben. Die folgende Abbildung zeigt ein Beispiel für k = 3: Die hier verwendete Idee lässt sich auch leicht verallgemeinern. Wir erläutern sie noch für k = 4 und überlassen alle weiteren Fälle dem Leser. Man wähle sich einen beliebigen Graphen auf sieben Knoten, in dem sechs der Knoten Grad vier haben und einer Grad zwei. Dann nimmt man acht Kopien hiervon und vier weitere Knoten. Die vier neuen Knoten und die acht Knoten vom Grad zwei verbinde man durch einen bipartiten Graphen, in dem die neuen Knoten Grad vier haben, die übrigen acht Knoten jeweils Grad zwei. Und schon haben wir einen 4-regulären Graphen, der kein perfektes Matching haben kann. KAPITEL 1. GRAPHENTHEORIE 76 1.7 Färbungen Viele Probleme kann man darauf zurückführen, dass man in einem entspre- chend definierten Graphen eine Partition der Knotenmenge findet, sodass Kanten nur zwischen Knoten in verschiedenen Klassen der Partition ver- laufen. Im Mobilfunk erhält man so beispielsweise eine Zuordnung von Fre- quenzen zu Sendern, bei der benachbarte Sender verschiedene Frequenzen benutzen. Im Compilerbau verwendet man diesen Ansatz, um eine Zuord- nung von Variablen auf die Register des Prozessors zu finden, sodass gleich- zeitig verwendete Variablen in verschiedenen Registern gespeichert werden, und in der Stunden- oder Prüfungsplanung entspricht eine Partition einer Menge von Kursen oder Prüfungen, die gleichzeitig stattfinden können. Statt von einer Partition der Knotenmenge spricht man meist von einer Knotenfärbung bzw. nur kurz Färbung des Graphen. In diesem Abschnitt führen wir diese formal ein und zeigen einige grundlegende Eigenschaften. Definition 1.56. Eine (Knoten-)Färbung (engl. (vertex) colouring) eines Graphen G = (V, E) mit k Farben ist eine Abbildung c : V → [k], sodass gilt c(u) 6= c(v) für alle Kanten {u, v} 2 E. Die chromatische Zahl (engl. chromatic number ) χ(G) ist die mi- nimale Anzahl Farben, die für eine Knotenfärbung von G benötigt wird. Beispiel 1.57. Ein vollständiger Graph auf n Knoten hat chromatische Zahl n. Kreise gera- der Länge haben chromatische Zahl 2, Kreise ungerader Länge haben chromatische Zahl 3. Bäume auf mindestens zwei Knoten haben immer chromatische Zahl 2. (Warum?!) Graphen mit chromatischer Zahl k nennt man auch k-partit (engl. k-partite). Die Motivation für diese Namensgebung sollte klar sein: Ein Graph G = (V, E) ist genau dann k-partit, wenn man seine Knotenmenge V so in k Mengen V1, . . . , Vk partitionieren kann, dass alle Kanten Knoten aus verschiedenen Mengen verbinden. Besonders wichtig ist der Fall k = 2. In diesem Fall nennt man den Graphen bipartit. Der folgende Satz stellt eine einfache, aber wichtige Charakterisierung bipartiter Graphen dar. KAPITEL 1. GRAPHENTHEORIE 77 Satz 1.58. Ein Graph G = (V, E) ist genau dann bipartit, wenn er keinen Kreis ungerader Länge als Teilgraphen enthält. Beweis. Die eine Richtung folgt sofort aus Beispiel 1.57: ungerade Kreise haben chromatische Zahl 3, sie können daher in einem bipartiten Graphen nicht enthalten sein. Die andere Richtung sieht man ebenfalls schnell ein. Man startet einfach in einem beliebigen Knoten s eine Breitensuche (ohne Einschränkung sei G zusammenhängend) und färbt einen Knoten genau dann mit Farbe 1 (bzw. 2), wenn sein Abstand d[v] zu s gerade (ungerade) ist. Da es keinen Kreis ungerader Länge gibt, kann es keine Kante geben, deren Endknoten dadurch die gleiche Farbe erhalten. Ein klassisches Graphfärbungsproblem ist das Färben von politischen Landkarten, bei dem benachbarte Länder unterschiedliche Farben bekom- men sollen. Historisch geht dieses Problem bis ins 19. Jahrhundert zurück. Lange wurde vermutet, dass für das Färben von Landkarten vier Farben im- mer ausreichen, aber erst 1977 wurde dieses sogenannte Vierfarbenproblem von Appel und Haken gelöst. Hierbei nimmt man an, dass das Gebiet ei- nes jeden Landes zusammenhängend ist und dass Länder, die nur in einem einzigen Punkt aneinanderstossen, gleich gefärbt werden dürfen. Satz 1.59 (Vierfarbensatz). Jede Landkarte lässt sich mit vier Farben färben. Der Beweis dieses Satzes ist sehr aufwendig. Er besteht aus einem theo- retischen Teil, in dem das allgemeine Problem auf endlich viele Probleme reduziert wird, und einem Computerprogramm, das alle endlichen Fälle überprüft. Wie kann man eine Färbung eines Graphen mit möglichst wenigen Far- ben bestimmen? Für die Entscheidung ob ein Graph bipartit ist, genügt eine einfache Breitensuche. Im Allgemeinen ist das Färben von Graphen jedoch ein schwieriges Problem. Schon die scheinbar einfache Frage „Gege- ben ein Graph G = (V, E), gilt χ(G) \u0014 3?“ ist N P -vollständig. Das heisst aber, dass es (unter der Annahme P 6 = N P ) keinen Algorithmus gibt, der die chromatische Zahl in polynomieller Laufzeit berechnet. In der Praxis wird man sich daher mit Annäherungen an die optimale Lösung zufrieden geben müssen. KAPITEL 1. GRAPHENTHEORIE 78 Der folgende Algorithmus berechnet eine Färbung, indem er die Knoten des Graphen in einer beliebigen Reihenfolge v1, v2, . . . , vn besucht und dem aktuellen Knoten jeweils die kleinste Farbe zuordnet, die noch nicht für einen benachbarten Knoten verwendet wird. Greedy-Färbung (G) 1: wähle eine beliebige Reihenfolge der Knoten: V = {v1, . . . , vn} 2: c[v1] ← 1 3: for i = 2 to n do 4: c[vi] ← min {k 2 N | k 6= c(u) für alle u 2 N(vi) \\ {v1, . . . , vi−1}} Es ist klar, dass der Algorithmus eine zulässige Färbung berechnet, denn die Farbe eines Knotens unterscheidet sich nach Konstruktion immer von den Farben seiner Nachbarn. Wie viele Farben verwendet der Algorithmus im schlimmsten Fall? Da jeweils die kleinste Farbe gewählt wird, die nicht schon für einen Nachbarknoten verwendet wird, tritt der schlimmste Fall ein, wenn die Nachbarknoten von vi in den Farben 1, . . . , deg(vi) gefärbt sind. In diesem Fall bekommt der neue Knoten die Farbe deg(vi) + 1. Insge- samt werden vom Algorithmus also höchstens ∆(G) + 1 Farben verwendet. Dabei bezeichnet ∆(G) := maxv2 V deg(v) den maximalen Grad eines Kno- tens in G. Satz 1.60. Sei G ein zusammenhängender Graph. Für die Anzahl Far- ben C(G), die der Algorithmus Greedy-Färbung benötigt, um die Knoten des Graphen G zu färben, gilt χ(G) \u0014 C(G) \u0014 ∆(G) + 1. Ist der Graph als Adjazenzliste gespeichert, findet der Algorithmus die Färbung in Zeit O(|E|). Beweis. Dass der Algorithmus mit ∆(G) + 1 Farben auskommt, haben wir bereits eingesehen. Nach Definition der chromatischen Zahl können auch nicht weniger als χ(G) verwendet worden sein, weshalb die behauptete Un- gleichung folgt. Wie sieht es nun mit der Implementierung des Algorithmus aus? Hierzu überlegen wir uns, dass ein Knoten mit Grad d höchstens d bereits gefärbte Nachbarn haben kann und daher insbesondere eine der er- sten d + 1 Farben unter seinen Nachbarn nicht vorkommt. Um den Knoten KAPITEL 1. GRAPHENTHEORIE 79 vi zu färben, können wir daher wie folgt vorgehen: Wir initialisieren ein Array der Länge deg(vi) + 1 mit false, laufen dann über alle Nachbarn von v und setzen für jeden mit einer Farbe \u0014 deg(vi) + 1 gefärbten Nachbarn den entsprechenden Eintrag im Array auf true. Anschliessend durchlau- fen wir das Array bis wir einen Eintrag false finden (den es geben muss) und verwenden diese Farbe für den Knoten vi. Wir können also vi in Zeit O(deg(vi)) färben und somit alle Knoten in Zeit O(∑ v2 V deg(v)) = O(|E|), wie behauptet. Die Anzahl Farben, die der Algorithmus tatsächlich verwendet, hängt im Allgemeinen stark von der Reihenfolge ab, in der die Knoten betrachtet werden. Es gibt beispielsweise immer eine Reihenfolge, bei der man mit χ(G) Farben auskommt (Übungsaufgabe!), aber da wir diese Reihenfolge nicht kennen, kann der Algorithmus auch deutlich mehr Farben verwenden. Beispiel 1.61. Betrachten wir den Graphen Bn mit 2n Knoten, der aus dem vollständigen bipartiten Graphen Kn,n entsteht, indem man die Kanten zwischen gegenüberliegenden Knoten entfernt. Da der Graph Bn bipartit ist, könnte er eigentlich mit zwei Farben gefärbt werden; es ist aber nicht schwer einzusehen, dass es auch eine Reihenfolge der Knoten gibt, für die der Greedy-Algorithmus n Farben benötigt (Übung!). Im Allgemeinen ist es sehr schwer, eine gute Reihenfolge für den Greedy- Algorithmus zu bestimmen. Es gibt jedoch zwei Situationen, in denen man in Laufzeit O(|E|) eine Reihenfolge der Knoten bestimmen kann, bei der zumindest eine Farbe eingespart wird. Beispiel 1.62. Sei G = (V, E) ein zusammenhängender Graph mit Maximalgrad ∆(G). Wei- ter nehmen wir an, dass es einen Knoten v 2 V gibt mit deg(v) < ∆(G). Wenn wir jetzt eine Breiten- oder Tiefensuche in v starten und die Knoten in umgekehrter Reihenfolge nummerieren, wie sie vom Algorithmus durchlaufen werden (der Knoten v ist also der Knoten vn), so hat jeder Knoten vi mit i < n mindestens einen Nachbarn vj mit j > i und daher höchstens ∆(G) − 1 gefärbte Nachbarn. Der Knoten vn hat nach Wahl ebenfalls nur ∆(G)−1 gefärbte Nachbarn. Der Greedy-Algorithmus benötigt daher für diese Reihenfolge der Knoten höchstens ∆(G) Farben. Beispiel 1.63. Sei G = (V, E) ein zusammenhängender k-regulärer Graph, in dem es min- destens einen Artikulationsknoten gibt. Wir wissen bereits aus Abschnitt 1.4.1, dass wir mit einer modifizierten Tiefensuche in Zeit O(|E|) einen solchen Artikulationsknoten v be- stimmen können. Seien V1, . . . , Vs die Knotenmengen der Zusammenhangskomponenten von G − v, wobei s \u0015 2. Dann erfüllen alle Graphen Gi := G[Vi [ {v}], 1 \u0014 i \u0014 s, die Annahme von Beispiel 1.62 – und können daher jeweils mit k Färben gefärbt werden. Durch eventuelles Vertauschen von Farben können wir zudem sicherstellen, dass in allen Graphen G1, . . . , Gs der Knoten v die gleiche Farbe bekommen hat. Die Färbungen der Graphen Gi ergeben daher zusammen eine k-Färbung des Graphen G. KAPITEL 1. GRAPHENTHEORIE 80 Die beiden obigen Beispiele zeigen Situationen, in denen der Greedy- Algorithmus für Graphen mit Maximalgrad k mit k Farben auskommt. Es gibt jedoch auch k-reguläre Graphen, für die wir k + 1 Farben benötigen. Vollständige Graphen und ungerade Kreise sind solche Beispiele. Für beide gilt: χ(G) = ∆(G) + 1. Brooks hat 1941 bewiesen, dass dies die beiden einzigen Graphtypen sind, für die χ(G) = ∆(G) + 1 gilt: Satz 1.64 (Satz von Brooks). Ist G = (V, E) ein zusammenhängender Graph, der weder vollständig ist noch ein ungerader Kreis ist, also G 6= Kn und G 6= C2n+1, so gilt χ(G) \u0014 ∆(G) und es gibt einen Algorithmus, der die Knoten des Graphen in Zeit O(|E|) mit ∆(G) Farben färbt. Beweis. Sei G ein von Kn und C2n+1 verschiedener zusammenhängender Graph. Wegen Beispiel 1.62 und 1.63 wissen wir, dass wir annehmen dür- fen, dass alle Knoten Grad ∆(G) haben und es keinen Artikulationsknoten gibt. Da G kein vollständiger Graph ist, aber dennoch zusammenhängend ist, muss es einen Knoten v geben, der zwei Nachbarn v1, v2 2 N(v) mit v1 6= v2 und {v1, v2} 62 E besitzt. Nun unterscheiden wir zwei Fälle. Wenn G \\ {v1, v2} zusammenhängend ist, so können wir wie in Beispiel 1.62 den Graphen G[V \\ {v1, v2}] ausgehend von v mit einer Breiten- oder Tiefen- suche durchlaufen. Nummerieren wir die Knoten dann wie folgt: Zuerst v1 und v2, dann alle übrigen Knoten, wieder in umgekehrter Reihenfolge wie sie von der Breiten- oder Tiefensuche gefunden wurden (sodass also der Knoten v wiederum der letzte Knoten vn ist), so folgt leicht, dass der Greedy-Algorithmus für diese Reihenfolge der Knoten mit ∆(G) Farben auskommt. Was ist nun, wenn G\\{v1, v2} nicht zusammenhängend ist? – Dann gehen wir ähnlich vor wie in Beispiel 1.63. Seien V1, . . . , Vs die Knotenmengen der Zusammenhangskomponenten von G[V \\{v1, v2}], wobei s \u0015 2. Betrachte die Graphen Gi := G[Vi [ {v1, v2}], 1 \u0014 i \u0014 s. Wenn in all diesen Graphen einer der beiden Knoten v1 und v2 Grad höchstens ∆(G) − 2 hat, dann können wir zu all diesen Graphen jeweils die Kante {v1, v2} hinzufügen und die Graphen dann wie in Beispiel 1.62 mit ∆(G) Farben färben, wobei v1 und KAPITEL 1. GRAPHENTHEORIE 81 v2 wegen der Kante {v1, v2} jeweils verschiedene Farben bekommen müssen. Durch eventuelles Vertauschen von Farben können wir daher sicherstellen, dass in allen Graphen G1, . . . , Gs die Knoten v1 und v2 jeweils die gleichen, voneinander verschiedenen, Farben haben. Die Färbungen der Graphen Gi ergeben daher zusammen eine ∆(G)-Färbung des Graphen G. Was nun, wenn in einem Graphen, sagen wir in G1, beide Knoten v1 und v2 Grad grösser als ∆(G) − 2 haben? Die Grade von v1 in den verschiedenen Gi können sich zu höchstens ∆(G) aufsummieren, daher kann der Grad von v1 und v2 in den anderen Gi jeweils höchstens eins sein. Wenn der Grad von v1 in einem der Gi Null wäre, so wäre v2 ein Artikulationsknoten, und umgekehrt. Da wir dies ausgeschlossen haben, muss also s = 2 gelten, und v1 und v2 haben beide jeweils exakt einen Nachbarn u1 bzw. u2 in G2. Dann färben wir G1 und G2 wie in Beispiel 1.62 jeweils mit ∆(G) Farben. Falls ∆(G) > 2, so können wir nach einem eventuellen Farbtausch in G2 die Knoten u1 und u2 so färben, dass sie nicht dieselbe Farbe wie v1 bzw. v2 in G1 haben. Wieder bilden daher die Färbungen der Graphen Gi zusammen eine ∆(G)-Färbung des Graphen G. Falls hingegen ∆(G) = 2 ist, so handelt es sich bei G um einen Kreis, da G zusammenhängend ist. Da wir ungerade Kreise ausgeschlossen haben, muss G ein Kreis mit einer geraden Knotenzahl sein, und damit ist χ(G) = 2 = ∆(G). Es ist nicht besonders schwer, aber eine gute Übung, sich zu überlegen, dass es beliebig grosse Graphen mit Maximalgrad k gibt, für die die chro- matische Zahl gleich k ist. Satz 1.64 ist daher bestmöglich. Andererseits ist es nicht immer so, dass der maximale Grad die chromatische Zahl be- stimmt. Ein Stern ist hierfür ein schönes Beispiel: den Grad des zentralen Knotens können wir beliebig gross machen, der Stern ist dennoch immer mit zwei Farben färbbar. Unser nächster Satz gibt ein Kriterium für Situationen an, in denen wir die chromatische Zahl unabhängig vom maximalen Grad beschränken können. Satz 1.65. Ist G = (V, E) ein Graph und k 2 N eine natürliche Zahl mit der Eigenschaft, dass jeder induzierte Subgraph von G einen Knoten mit Grad höchstens k enthält, so gilt χ(G) \u0014 k + 1 und eine (k + 1)- Färbung lässt sich in Zeit O(|E|) finden. KAPITEL 1. GRAPHENTHEORIE 82 Beweis. Nach Annahme gibt es einen Knoten mit Grad höchstens k. Die- sen nennen wir vn (falls es mehrere solche Knoten gibt, wählen wir einen beliebig) und entfernen vn aus dem Graphen und adaptieren die Grade der übrigen Knoten entsprechend. Wieder gilt: Es gibt einen Knoten mit Grad höchstens k, wir wählen einen solchen, nennen ihn vn−1, entfernen ihn aus dem Graphen und adaptieren die Grade der übrigen Knoten entspre- chend. Fahren wir analog fort, so erhalten wir eine Reihenfolge v1, . . . , vn der Knoten, sodass für alle 2 \u0014 i \u0014 n gilt: vi hat in dem durch die Knoten- menge {v1, . . . , vi} induzierten Subgraphen Grad höchstens k. Färben wir daher die Knoten v1, . . . , vn in dieser Reihenfolge, so wissen wir dass für alle 2 \u0014 i \u0014 n gilt: Wenn wir vi färben wollen, so hat vi höchstens k bereits gefärbte Nachbarn. Wenn uns daher k + 1 Farben zur Verfügung stehen, kommt mindestens eine dieser Farben nicht bei den Nachbarn von vi vor und kann daher für vi verwendet werden. Mit anderen Worten: k+1 Farben genügen, um mit diesem Verfahren für jeden Knoten eine zulässige Farbe zu finden. Wir überlegen uns nun noch, dass wir dieses Verfahren tatsächlich mit Laufzeit O(|E|) implementieren können. Dazu benötigen wir zwei Ideen. Zum einen führen wir ein Array d[] ein, das für jeden Knoten und Zeit- punkt 1 \u0014 i \u0014 n den Grad des Knoten v in dem durch die noch nicht ent- fernten Knoten induzierten Graphen G[V \\ {vi+1, . . . , vn}] enthält. Dies ist einfach: zu Beginn des Algorithmus entspricht d[v] genau dem Grad deg(v) des Knoten v im Graphen G. Für jeden neu gefundenen Knoten vn, vn−1, . . . benötigen wir Zeit O(deg(vi)), um das Array anzupassen (wir müssen ja genau für jeden Nachbarn von vi den Wert um eins reduzieren). Insgesamt benötigen wir hierfür also Zeit O(|E|). Nun müssen wir uns noch überlegen, wie wir jeweils einen Knoten vom Grad höchstens k in dem Subgraphen G[V \\ {vi+1, . . . , vn}] effizient finden können. Dazu müssen wir zum einen wissen, welche Knoten wir schon entfernt haben. Dies lässt sich einfach durch ein Boolesches Array removed[] realisieren, das wir für jeden Knoten v 2 V mit false initialisieren. Damit könnten wir die Knoten vi jeweils finden, in dem wir jeweils das Array d[] nach einem Knoten v durchsuchen mit d[v] \u0014 k und removed[v] = false. Dies würde aber jeweils Zeit O(|V|) benötigen und, für alle Knoten zusammen, zu einer Laufzeit von O(|V| 2) führen. Effizienter geht es, wenn wir zusätzlich noch eine Datenstruktur Q verwenden, die zu jedem Zeitpunkt alle noch nicht entfernten Knoten mit Grad höchstens k enthält. Genauer gehen wir wie folgt vor: Nach der In- KAPITEL 1. GRAPHENTHEORIE 83 itialisierung von d[] und immer, wenn wir die Werte von d[] updaten, fügen wir alle Knoten mit d[v] \u0014 k und removed[v] = false in Q ein und setzen für diese Knoten removed[v] auf true, damit sie später nicht nochmals in Q eingefügt werden. Als neuen Knoten vi können wir dann in jeder Runde einen beliebigen Knoten aus Q wählen, d.h. wir können Q zum Beispiel als Stapel oder auch als Schlange implementieren. Durch die Verwendung von Q reduziert sich die Wahl von vi von O(|V|) auf O(1) und die Gesamt- laufzeit für das Bestimmen der Reihenfolge der Knoten v1, . . . , vn ist daher O(|E|). Wie bereits im Beweis von Satz 1.60 können wir das eigentliche Färben des Graphen ebenfalls in Zeit O(|E|) implementieren. Satz 1.66 (Mycielski-Konstruktion). Für alle k \u0015 2 gibt es einen drei- ecksfreien Graphen Gk mit χ(Gk) \u0015 k. Beweis. Wir beweisen den Satz durch Induktion über k. Für k = 2 ist nichts zu zeigen: Der Graph, der aus einer einzigen Kante besteht, erfüllt bereits alle Bedingungen des Satzes. Sei also k \u0015 2 und Gk ein dreiecksfreier Graph mit χ(Gk) \u0015 k. Wir konstruieren daraus einen neuen Graphen Gk+1, indem wir zu Gk einige zusätzliche Knoten und Kanten hinzufügen. Seien v1 . . . , vn die Knoten des Graphen Gk. Für jeden Knoten vi fügen wir einen neuen Knoten wi hinzu und verbinden ihn mit allen Nachbarn von vi in Gk. Zusätzlich fügen wir noch einen Knoten z hinzu und verbinden ihn mit allen Knoten w1, . . . , wn. Abbildung 1.17: Die Mycielski-Konstruktion für k = 3 und k = 4, und die allgemeine Konstruktionsvorschrift von k auf k + 1. KAPITEL 1. GRAPHENTHEORIE 84 Wir überlegen uns zunächst, dass der neue Graph kein Dreieck enthält. Da die Knoten wi nicht untereinander verbunden sind, ist der Knoten z sicherlich in keinem Dreieck enthalten. Analog kann es kein Dreieck geben, das zwei Knoten wi und wj enthält. Da aber wi in Gk genau zu den Nach- barn von vi verbunden ist, kann wi auch in keinem Dreieck mit zwei Knoten aus Gk liegen (denn Gk ist ja nach Annahme dreiecksfrei). Also ist der neue Graph Gk+1 in der Tat dreiecksfrei. Nehmen wir nun an, er würde sich mit k Farben färben lassen. Dann kommt wegen dem Knoten z mindestens eine der k Farben nicht unter den Nachbarn von z vor. Ohne Einschränkung sei dies die Farbe k. Da alle Knotenpaare vi und wi dieselben Nachbarn in Gk haben, können wir die mit k gefärbten Knoten in Gk sicherlich in die Farbe des ’Partnerknotens’ wi umfärben, woraus folgt, dass sich Gk mit k − 1 Farben färben lässt, im Widerspruch zur Annahme. Also gibt es keine Färbung von Gk+1 mit k Farben und die chromatische Zahl von Gk+1 ist daher mindestens k + 1, was zu zeigen war. Man kann sogar zeigen: Für alle k, ℓ \u0015 2 gibt es Graphen Gk,ℓ, sodass Gk,ℓ keinen Kreis der Länge höchstens ℓ enthält, aber dennoch gilt: χ(Gk,ℓ) \u0015 k. Den Beweis dieses Satzes überlassen wir aber Spezialvorlesungen. Den Abschnitt schliessen wir mit einem überraschend schwierigen algo- rithmischen Problem. Nehmen wir an, jemand verspricht uns, dass der zu färbende Graph chromatische Zahl drei hat. Dann wissen wir: Es gibt eine Reihenfolge der Knoten für die der Greedy-Algorithmus nur drei Farben benötigt. Diese kennen wir aber nicht. Dennoch wollen wir mit möglichst wenigen Farben auskommen. Der folgende Satz zeigt uns, dass uns zumin- dest O(q |V|) genügen. In Anbetracht der Tatsache, dass der Graph ja in Wirklichkeit 3-färbbar ist, ist dies nicht besonders eindrucksvoll. Es ist aber fast das beste was bekannt ist: Es ist bekannt, dass das Färben mit vier Farben NP-schwer ist und dass andererseits O(|V| 0.211) (statt der von uns benötigten O(|V| 0.5)) Farben ausreichen. Satz 1.67. Jeden 3-färbbaren Graphen G = (V, E) kann man in Zeit O(|E|) mit O(q |V|) Farben färben. Beweis. Wir überlegen uns zunächst: Ist G = (V, E) ein 3-färbbarer Graph und v 2 V ein beliebiger Knoten in G, so ist der durch die Nachbarschaft von v induzierte Subgraph G[N(v)] bipartit. In der Tat: In einer 3-Färbung KAPITEL 1. GRAPHENTHEORIE 85 von G müssen alle Nachbarn von v eine andere Farbe bekommen als der Knoten v; für die Knoten in N(v) stehen daher nur zwei Farben zur Ver- fügung – und der Graph G[N(v)] ist daher bipartit und wir können die Nachbarschaft daher mit einer Breitensuche in linearer Zeit (genauer: li- near in der Anzahl Kanten in der Nachbarschaft von v) mit zwei Farben färben. Damit ergibt sich folgende Idee für einen Algorithmus: Solange es einen Knoten mit “grossem” Grad gibt, wählen wir einen solchen und färben ihn und seine Nachbarn mit drei (neuen) Farben. Sobald es keinen Knoten mit grossem Grad mehr gibt, wenden wir auf den restlichen Graphen den Satz von Brooks an. Eine gute Wahl für “grossen” Grad ist der Wert p n. Denn dann färben wir höchstens n/p n = p n Knoten nach der ersten Re- gel (und benötigen dafür maximal 3p n Farben) und für die Anwendung des Satzes von Brooks benötigen wir ebenfalls nur p n Farben. Insgesamt kommen wir also sicher mit 4p n Farben aus. (Die Konstante 4 lässt sich durch eine bessere Wahl des Grenzwertes noch leicht reduzieren, an der Grössenordnung p n ändert sich dadurch jedoch nichts.) Kapitel 2 Wahrscheinlichkeitstheorie und randomisierte Algorithmen Über die Jahre haben stochastische Konzepte in der Informatik eine wach- sende Bedeutung gewonnen. Einige (algorithmische) Beispiele wurden im ersten Teil der Vorlesung bereits aufgegriffen. Die Grundlagen des Hashings beruhen beispielsweise auf Aussagen über die Verteilung bestimmter Er- eignisse. Auch dass der Sortieralgorithmus QuickSort zu Recht das Wort „schnell“ in seinem Namen trägt (und nicht etwa „SlowSort“ genannt wird, was in Anbetracht seiner WorstCase Laufzeit von Ω(n 2) auf den ersten Blick durchaus angebracht scheint), verdankt er seiner sehr effizienten Per- formance bei einer zufälligen Wahl der Pivotelemente. Der Einfluss der Stochastik auf die Informatik geht aber weit über die Algorithmik hinaus. Jegliche Art von Kryptographie, wie wir sie heutzutage in vielen Bereichen des täglichen Lebens verwenden, wäre ohne Stochastik so nicht möglich. Aber beim sogenannten verteilten Rechnen oder auch bei der Entwicklung von Verfahren für Roboter, die sich eigenständig koordi- nieren sollen, spielt der Zufall eine grosse Rolle. In diesem Kapitel werden wir die Grundlagen der Stochastik entwickeln und an Beispielen illustrieren. 2.1 Grundbegriffe und Notationen Einem stochastischen Experiment liegt immer ein Wahrscheinlichkeitsraum (eine Menge Ω) zugrunde, zusammen mit Wahrscheinlichkeiten für die Ele- mente dieser Menge. Die folgende Definition formalisiert dies. 86 KAPITEL 2. WAHRSCHEINLICHKEITSTHEORIE 87 Definition 2.1. Ein diskreter Wahrscheinlichkeitsraum ist bestimmt durch eine Ergebnismenge Ω = {ω1, ω2, . . .} von Elementarereig- nissen. Jedem Elementarereignis ωi ist eine (Elementar-)Wahr- scheinlichkeit Pr[ωi] zugeordnet, wobei wir fordern, dass 0 \u0014 Pr[ωi] \u0014 1 und ∑ ω2 Ω Pr[ω] = 1. Eine Menge E \u0012 Ω heisst Ereignis. Die Wahrscheinlichkeit Pr[E] eines Ereignisses ist definiert durch Pr[E] := ∑ ω2 E Pr[ω]. Ist E ein Ereignis, so bezeichnen wir mit ¯E := Ω \\ E das Komplemen- tärereignis zu E. Ein Wahrscheinlichkeitsraum mit Ω = {ω1, . . . , ωn} heisst endlicher Wahrscheinlichkeitsraum. Wir werden uns in diesem Kapitel oft auf end- liche Wahrscheinlichkeitsräume beschränken. Bei unendlichen Wahrschein- lichkeitsräumen werden wir gewöhnlich nur den Fall Ω = N0 betrachten. Man kann den Begriff des Wahrscheinlichkeitsraumes auch auf überab- zählbare Mengen wie Ω = R erweitern. Hierbei treten jedoch einige zusätz- liche Schwierigkeiten auf und wir werden die Behandlung dieses Themas daher auf weiterführende Vorlesungen verschieben. Für die Wahrschein- lichkeitstheorie für diskrete (endliche oder abzählbar unendliche) Mengen verwendet man oft auch den Begriff (elementare) Stochastik. Auf diese wer- den wir uns in dieser Vorlesung beschränken. Aus der Definition 2.1 folgen sofort einige elementare, aber sehr nützli- che Konsequenzen. Lemma 2.2. Für Ereignisse A, B gilt: 1. Pr[; ] = 0, Pr[Ω] = 1. 2. 0 \u0014 Pr[A] \u0014 1. 3. Pr[ ¯A] = 1 − Pr[A]. KAPITEL 2. WAHRSCHEINLICHKEITSTHEORIE 88 4. Wenn A \u0012 B, so folgt Pr[A] \u0014 Pr[B]. Ebenso elementar ist der folgende Satz, der nichtsdestrotrotz einen hochtrabenden Namen trägt. Satz 2.3 (Additionssatz). Wenn die Ereignisse A1, . . . , An paarweise disjunkt sind (also wenn für alle Paare i 6= j gilt, dass Ai \\ Aj = ; ), so gilt Pr \" n[ i=1 Ai # = n∑ i=1 Pr[Ai]. Für eine unendliche Menge von disjunkten Ereignissen A1, A2, . . . gilt analog Pr \" ∞[ i=1 Ai # = ∞∑ i=1 Pr[Ai]. Die Annahme aus Satz 2.3, dass die Ereignisse paarweise disjunkt sind, ist essentiell. Ohne diese ist die Aussage im Allgemeinen nicht wahr. Beispiel 2.4. Wir werfen einen normalen sechsseitigen Würfel. Hier ist Ω = {1, 2, 3, 4, 5, 6} und jedes der sechs Elementarereignisse hat die Wahrscheinlichkeit 1/6. Betrachten wir jetzt die Ereignisse A = {1, 3, 5} (Augenzahl ist ungerade) und B = {5, 6} (Augenzahl ist mindestens fünf), so sind diese Ereignisse nicht disjunkt. Tatsächlich gilt Pr[A [ B] = Pr[{1, 3, 5, 6}] = 4 6 6= 3 6 + 2 6 = Pr[A] + Pr[B]. Für den allgemeinen Fall gilt jedoch der folgende Satz. Satz 2.5. (Siebformel, Prinzip der Inklusion/Exklusion) Für Ereignisse A1, . . . , An (n \u0015 2) gilt: Pr \" n[ i=1 Ai # = n∑ l=1 (−1)l+1 ∑ 1\u0014 i1<\u0001\u0001\u0001 <il\u0014 n Pr[Ai1 \\ \u0001 \u0001 \u0001 \\ Ail] = n∑ i=1 Pr[Ai] − ∑ 1\u0014 i1<i2\u0014 n Pr[Ai1 \\ Ai2] + ∑ 1\u0014 i1<i2<i3\u0014 n Pr[Ai1 \\ Ai2 \\ Ai3] − \u0001 \u0001 \u0001 +(−1)n+1 \u0001 Pr[A1 \\ \u0001 \u0001 \u0001 \\ An]. Ein besonderer Speziallfall tritt auf, wenn wir Satz 2.5 auf den Wahr- scheinlichkeitsraum Ω = A1 [ \u0001 \u0001 \u0001 [ An mit Pr[ω] = 1/|Ω| anwenden, wo- KAPITEL 2. WAHRSCHEINLICHKEITSTHEORIE 89 bei A1, . . . , An beliebige endliche Mengen sind. Dann erhalten wir nämlich (nach ausmultiplizieren mit |Ω|) die nützliche Formel \f \f \f \f n[ i=1 Ai \f \f \f \f = n∑ l=1 (−1)l+1 ∑ 1\u0014 i1<\u0001\u0001\u0001 <ik\u0014 n |Ai1 \\ \u0001 \u0001 \u0001 \\ Ail|, die ebenfalls oft als Siebformel bezeichnet wird. Es ist auch nicht schwer, wenn auch etwas technisch, Satz 2.5 direkt zu beweisen. Statt dies jedoch hier zu tun, verschieben wir den Beweis auf ein späteres Kapitel (Beispiel 2.36), in dem uns einige dann zur Verfügung stehende zusätzliche Techniken ermöglichen etwas Rechnung einzusparen. Wir illustrieren die grundlegenden Ideen hinter Satz 2.5 jedoch, indem wir noch die Spezialfälle n = 2 und n = 3 explizit betrachten. Für n = 2 setzen wir X := A1 \\A2 = A1 \\(A1 \\ A2). X ist so gewählt, dass X und A1 \\ A2 sowie X und A2 disjunkt sind. Deshalb können wir den Additionssatz anwenden: Pr[A1] = Pr[X [ (A1 \\ A2)] = Pr[X] + Pr[A1 \\ A2]. Wegen A1 [ A2 = X [ A2 folgt daraus Pr[A1 [ A2] = Pr[X [ A2] = Pr[X] + Pr[A2] = Pr[A1] − Pr[A1 \\ A2] + Pr[A2] und wir haben die Behauptung für n = 2 gezeigt. Abbildung 2.1 veranschaulicht den Fall n = 3. Man überzeuge sich, dass durch die im Satz angegebene Summe die Elementarereignisse in jeder der sieben Teilmengen A \\ (B [ C), . . . , A \\ B \\ C jeweils genau einmal gezählt werden. Abbildung 2.1: Illustration zur Inklusion-Exklusion-Formel für n = 3. Für n \u0015 4 werden die Formeln aus Satz 2.5 recht lang und umständlich. In diesem Fall gibt man sich deshalb oft mit der folgenden einfachen Ab- schätzung zufrieden, die in der Literatur nach George Boole (1815–1864) benannt ist. In der Informatikliteratur wird hierfür oft auch der Begriff KAPITEL 2. WAHRSCHEINLICHKEITSTHEORIE 90 „Union Bound“ verwendet, der sehr schön beschreibt, was die Ungleichung besagt: Wir beschränken die Wahrscheinlichkeit der Vereinigung durch die Summe der Einzelwahrscheinlichkeiten. Korollar 2.6. (Boolesche Ungleichung, Union Bound) Für Ereignisse A1, . . . , An gilt Pr \" n[ i=1 Ai # \u0014 n∑ i=1 Pr[Ai]. Analog gilt für eine unendliche Folge von Ereignissen A1, A2, . . ., dass Pr [S ∞ i=1 Ai] \u0014 ∑∞ i=1 Pr[Ai]. Beweis. Wir betrachten zunächst den endlichen Fall. Für jedes i \u0015 1 setzen wir Bi := Ai\\(A1[\u0001 \u0001 \u0001[ Ai−1); dann gilt offenbar Pr[Bi] \u0014 Pr[Ai]. Ausserdem sind je zwei Mengen Bi und Bj mit i 6= j disjunkt und es gilt S n i=1 Ai = S n i=1 Bi. Nach dem Additionssatz ist dann Pr \u0014 n[ i=1 Ai \u0015 = Pr \u0014 n[ i=1 Bi \u0015 = n∑ i=1 Pr[Bi] \u0014 n∑ i=1 Pr[Ai]. Die entsprechende Aussage für eine unendliche Folge von Ereignissen be- weist man analog. Wahl der Wahrscheinlichkeiten Wenn wir Wahrscheinlichkeitsräume und die damit verbundene Theorie einsetzen wollen, müssen wir zunächst die Frage beantworten, wie bei einer konkreten Anwendung die Wahrscheinlichkeiten der Elementarereignisse sinnvoll festgelegt werden können. Einen ersten Anhaltspunkt liefert ein Prinzip, das nach Pierre-Simon Laplace (1749–1827) benannt ist. La- place leistete bedeutende Beiträge zu zahlreichen Gebieten. Insbesondere beschäftigte er sich neben der Mathematik mit Astronomie, Physik und Chemie. Unter Napoleon war er auch kurz als Minister des Inneren tätig, wurde allerdings bereits nach sechs Wochen wieder abgelöst, da er sich auch der unbedeutendsten Probleme selbst annahm. Prinzip von Laplace: Wenn nichts dagegen spricht, gehen wir davon aus, dass alle Elementarereignisse gleich wahrscheinlich sind. KAPITEL 2. WAHRSCHEINLICHKEITSTHEORIE 91 Bei der Anwendung des Prinzips von Laplace gilt für alle Elementarer- eignisse Pr[ω] = 1/|Ω|. Daraus erhalten wir für ein beliebiges Ereignis E die Formel Pr[E] = |E| |Ω|. Wir sagen dann auch, dass das Ergebnis des modellierten Zufallsexperi- ments auf Ω uniform verteilt oder gleichverteilt ist. Im informationstheoretischen Sinn besitzt der Wahrscheinlichkeitsraum mit Pr[ω] = 1/|Ω| für alle ω 2 Ω die grösstmögliche Entropie („Unord- nung“). Jede Abweichung von der Gleichwahrscheinlichkeit bedeutet, dass wir in das Modell zusätzliche Information einfliessen lassen (und dadurch die Entropie verringern). Das Prinzip von Laplace besagt nun, dass es nicht sinnvoll ist, bei der Modellierung eines Systems Wissen „vorzugaukeln“, wenn man nicht über entsprechende Anhaltspunkte verfügt. Wenn zusätzliches Wissen über das zu modellierende Experiment vor- handen ist und die Bedingungen für die einzelnen Elementarereignisse so- mit nicht mehr als symmetrisch angesehen werden können, so müssen die Elementarwahrscheinlichkeiten diesen Umständen angepasst werden. Wenn beispielsweise auf einem Würfel die Seite mit der „Sechs“ durch eine weitere „Eins“ ersetzt wird, so ist anschaulich klar, dass die Eins nun eine doppelt so grosse Wahrscheinlichkeit erhalten sollte wie alle anderen Elementarer- eignisse. Beschreibung von Wahrscheinlichkeitsräumen und Ereignissen Die vollständige und mathematisch exakte Darstellung eines Wahrschein- lichkeitsraumes, sowie entsprechender Ereignisse, ist bei vielen Anwendun- gen recht kompliziert. Aus diesem Grund haben sich dafür einige Konven- tionen eingebürgert, auf die wir im Folgenden kurz eingehen werden. Als Beispiel für einen etwas komplizierteren Wahrscheinlichkeitsraum betrachten wir ein Kartenspiel mit zwei Spielern, die wir A und B nennen. Jeder Spieler erhält fünf Karten. Nach dem Prinzip von Laplace gehen wir davon aus, dass jede Auswahl der zweimal fünf Karten aus den 52 Karten im gesamten Kartenspiel (französisches Blatt mit den Farben Kreuz, Pik, Herz, Karo und den Werten 2, 3, . . . , 9, 10, Bube, Dame, König, Ass, also 4 \u0001 13 = 52 Karten) gleich wahrscheinlich ist. KAPITEL 2. WAHRSCHEINLICHKEITSTHEORIE 92 Als Ergebnismenge könnten wir beispielsweise definieren Ω := {(X, Y) | X, Y \u0012 C, X \\ Y = ; , |X| = |Y| = 5, wobei C = {| , \u0000 , ~ , } } \u0002 {2, 3, . . . , 9, 10, B, D, K, A} }. Die Komponenten X und Y eines Elementarereignisses (X, Y) 2 Ω entspre- chen hierbei den Karten, die A und B erhalten. An diesem Beispiel sieht man, dass es oft recht mühsam ist, eine Kodie- rung für die Ergebnismenge aufzuschreiben. In der Praxis verzichtet man deshalb häufig darauf und auch wir werden in Zukunft nicht immer eine explizite Darstellung von Ω angeben. Allerdings sollte man sich stets klar- machen, wie eine solche Darstellung im Prinzip auszusehen hätte. Wem bei einem Beispiel nicht klar ist, auf welche Weise Ω kodiert werden könnte, sollte sich auf jeden Fall über eine exakte Darstellung Gedanken machen und gegebenenfalls versuchen, diese aufzuschreiben. Wenn man keine formale Darstellung von Ω angibt, muss man auch die Ereignisse informell angeben. Wenn wir beispielsweise die Wahrscheinlich- keit untersuchen wollen, dass Spieler A vier Asse erhält, so „definieren“ wir das entsprechende Ereignis E durch E := „Spieler A hat vier Asse“, anstatt zu schreiben E := {(X, Y) 2 Ω | X = {(f1, w1), . . . , (f5, w5)} und w1 = . . . = w4 = A}. Wenn wir uns die Mühe sparen wollen, einem Ereignis einen Namen zu geben, schreiben wir oft auch nur Pr[ „Spieler A hat vier Asse“ ] für die Wahrscheinlichkeit, dass Spieler A vier Asse hat. 2.2 Bedingte Wahrscheinlichkeiten Durch das Bekanntwerden zusätzlicher Information verändern sich Wahr- scheinlichkeiten. Nehmen wir zum Beispiel an, dass wir bei einem Würfel die geraden Zahlen rot markieren, verdeckt würfeln und dann den Würfel KAPITEL 2. WAHRSCHEINLICHKEITSTHEORIE 93 aus der Ferne betrachten. In diesem Fall können wir zwar die gewürfel- te Augenzahl nicht ablesen, aber wir können bereits an der Farbe erken- nen, ob eine gerade oder eine ungerade Augenzahl gefallen ist. Dadurch werden manche Elementarereignisse wahrscheinlicher, während andere un- wahrscheinlicher bzw. unmöglich werden. Beispiel 2.7. Zwei Spieler, wir nennen sie wieder A und B, spielen eine Runde Poker. Die beiden verwenden dazu das auf Seite 91 vorgestellte Experiment (52 Karten, 5 Karten pro Spieler, keine getauschten Karten). A ist sehr zufrieden mit seinen Karten, denn er hält vier Asse und eine Herz Zwei in der Hand. B kann dieses Blatt nur überbieten, wenn sie einen Straight Flush (fünf Karten einer Farbe in aufsteigender Reihenfolge, zum Beispiel Kreuz 9, 10, Bube, Dame, König) hat. Die Wahrscheinlichkeit für das Ereignis F := „B hat einen Straight Flush“ beträgt Pr[F] = |F| |Ω| = 3 \u0001 8 + 7 \u0000 52−5 5 \u0001 = 31 1533939 = 2,02... \u0001 10−5. Diese Rechnungen bedürfen noch einiger Erläuterung: Das Blatt von B wird zufällig aus den 52 − 5 Karten gewählt, die A nicht besitzt. Bei allen Farben ausser Herz kann der Straight Flush bei den acht Karten 2, 3, 4, 5, 6, 7, 8 oder 9 beginnen. Bei Herz fällt die Zwei weg, da diese Karte ja im Besitz von A ist. Die äusserst geringe Wahrscheinlichkeit von F würde A sehr beruhigen, wenn er nicht die Karten gezinkt hätte und deshalb erkennen könnte, dass B nur Kreuz in der Hand hält. A beginnt also noch einmal zu rechnen: Wir setzen nun |Ω 0 | = \u0000 12 5 \u0001 , da das Blatt von B aus den zwölf Kreuzkarten gewählt wird, die nicht in der Hand von A sind. Ferner bezeichne F 0 das Ereignis, dass B einen Straight Flush der Farbe Kreuz hat. Wir erhalten mit derselben Argumentation wie oben |F 0 | = 8. In unserem neuen Wahrscheinlichkeitsraum gilt Pr[F 0 ] = |F 0 | |Ω 0 | = 8 \u0000 12 5 \u0001 = 8 792 ˇ 0,01 . Die Wahrscheinlichkeit für einen Sieg von B ist also drastisch gestiegen, wenn sie auch absolut gesehen noch immer nicht besonders gross ist. Beispiel 2.7 zeigt, wie zusätzliche Information den Wahrscheinlichkeits- raum und damit die Wahrscheinlichkeit eines Ereignisses beeinflussen kann. Mit A|B (sprich: „A bedingt auf B“ oder „A gegeben B“) bezeichnen wir das Ereignis, dass A eintritt, wenn wir bereits wissen, dass das Ereignis B auf jeden Fall eintritt. Beispiel 2.7 (Fortsetzung) Sei K das Ereignis, dass B nur Kreuzkarten in der Hand hat. In unserem Beispiel entspricht F 0 im neuen Wahrscheinlichkeitsraum Ω 0 somit dem Ereignis F|K im Wahrscheinlichkeitsraum Ω. Welche Eigenschaften sollte eine sinnvolle Definition von Pr[A|B] erfül- len? Die folgenden Punkte macht man sich zu dieser Frage recht schnell klar: KAPITEL 2. WAHRSCHEINLICHKEITSTHEORIE 94 1. Pr[B|B] = 1, denn wenn wir wissen, dass B sicher eintritt, dann soll- te die Wahrscheinlichkeit für das Eintreten von B gleich Eins sein. Ebenso fordern wir Pr[B|¯B] = 0. 2. Die Bedingung auf Ω sollte keine Auswirkungen auf die Wahrschein- lichkeit eines beliebigen Ereignisses A haben, da die Aussage „Ω ist eingetreten“ keine zusätzliche Information liefert. Wir fordern also Pr[A|Ω] = Pr[A]. 3. Wenn wir wissen, dass B eingetreten ist, dann kann ein Ereignis A nur dann eintreten, wenn zugleich auch A \\ B eintritt. Die Wahr- scheinlichkeiten Pr[A|B] sollten daher für ein festes B proportional zu Pr[A \\ B] sein. Diese Überlegungen führen zu folgender Definition. Definition 2.8. A und B seien Ereignisse mit Pr[B] > 0. Die bedingte Wahrscheinlichkeit Pr[A|B] von A gegeben B ist definiert durch Pr[A|B] := Pr[A \\ B] Pr[B] . Der Leser überzeuge sich, dass Definition 2.8 die zuvor aufgelisteten Eigen- schaften erfüllt. Beispiel 2.7 (Fortsetzung) Erinnern wir uns: Da A die Karten gezinkt hat, kann er erken- nen, dass B nur Kreuzkarten in der Hand hält, das Ereignis K also eingetreten ist. Gesucht ist die Wahrscheinlichkeit des Ereignisses F, dass B einen Straight Flush in der Hand hält, unter dieser Bedingung. Gemäss Definition 2.8 berechnen wir dazu zunächst Pr[F \\ K] = 8 |Ω| und Pr[K] = \u0000 12 5 \u0001 |Ω| = |Ω 0 | |Ω| . Daraus folgt Pr[F|K] = Pr[F \\ K] Pr[K] = 8 |Ω| |Ω 0 | |Ω| = 8 |Ω 0 | , und wir erhalten also dasselbe Ergebnis wie bei unseren vorigen, auf direkten Überlegungen basierenden Rechnungen. Die bedingten Wahrscheinlichkeiten der Form Pr[ \u0001 |B] bilden für ein beliebiges Ereignis B \u0012 Ω mit Pr[B] > 0 einen neuen Wahrscheinlichkeits- raum über Ω. Die Wahrscheinlichkeiten der Elementarereignisse ωi berech- KAPITEL 2. WAHRSCHEINLICHKEITSTHEORIE 95 nen sich durch Pr[ωi|B]. Man überprüft leicht, dass dadurch Definition 2.1 erfüllt ist: ∑ ω2 Ω Pr[ω|B] = ∑ ω2 Ω Pr[ω \\ B] Pr[B] = ∑ ω2 B Pr[ω] Pr[B] = Pr[B] Pr[B] = 1. Damit gelten alle Rechenregeln für Wahrscheinlichkeiten auch für bedingte Wahrscheinlichkeiten. Beispielsweise erhalten wir die Regeln Pr[; |B] = 0 oder Pr[ ¯A|B] = 1 − Pr[A|B]. Den bedingten Wahrscheinlichkeitsraum kann man sich so vorstellen, dass die Wahrscheinlichkeiten für Elementarereignisse ausserhalb von B auf Null gesetzt werden. Die Wahrscheinlichkeiten für Elementarereignisse in B werden dann so skaliert, dass die Summe aller Wahrscheinlichkeiten wieder Eins ergibt. Zur Skalierung ist der Faktor 1/Pr[B] nötig, da wir die Wahrscheinlichkeit für alle Elementarereignisse ω 2 ¯B auf Null setzen und die Summe der verbleibenden Elementarwahrscheinlichkeiten somit gleich Pr[B] ist. Beim Umgang mit Wahrscheinlichkeiten im Allgemeinen und mit be- dingten Wahrscheinlichkeiten im Besonderen ist es erforderlich, sehr sorg- fältig vorzugehen und nie die formalen Definitionen aus den Augen zu ver- lieren, da man sonst leicht zu voreiligen Schlüssen verleitet wird. Das fol- gende Problem stellt ein berühmtes Beispiel hierfür dar. Beispiel 2.9. (Zweikinderproblem) Wir sind zu Gast bei einer Familie mit zwei Kindern. Wir nehmen an, dass bei der Geburt eines Kindes beide Geschlechter gleich wahrscheinlich sind. Wie gross ist die Wahrscheinlichkeit, dass beide Kinder der Familie Mädchen sind, wenn wir wissen dass sie mindestens ein Mädchen haben? Die Frage verführt zur spontanen Antwort 1 2 , da für das Geschlecht des unbekannten Kindes immer noch zwei Möglichkeiten bestehen. Von diesen ist scheinbar keine bevorzugt, da das Geschlecht des Geschwisterkindes keine Auswirkung auf das Geschlecht des bislang unbekannten Kindes hat. Bei genauerem Hinsehen stellt man aber fest, dass die Ergebnismenge so zu definieren ist: Ω := {mm, mj, jm, jj}. Hierbei ist das Geschlecht (j für „Junge“ und m für „Mädchen“) der Kinder in der Reihenfolge ihrer Geburt angetragen. Wir bedingen auf das Ereignis M := {mm, mj, jm} und interessieren uns für A := {mm} und die Wahrscheinlichkeit Pr[A|M]. Aus der Definition der bedingten Wahrscheinlichkeit folgt Pr[A|M] = Pr[A \\ M] Pr[M] = 1/4 3/4 = 1 3 . Die Wahrscheinlichkeit 1/3 folgt daraus, dass wir wussten, dass eines der beiden Kinder ein Mädchen ist (aber nicht, welches). Wissen wir, dass das ältere Kind ein Mädchen ist, KAPITEL 2. WAHRSCHEINLICHKEITSTHEORIE 96 so folgt Pr[A| „älteres Kind ist ein Mädchen“] = Pr[{mm}] Pr[{mj, mm}] = 1/4 2/4 = 1 2 . Kennen wir andererseits noch gar kein Kind, so erhalten wir Pr[A] = Pr[{mm} = 1 4 . Wir sehen: die Wahrscheinlichkeit eines Ereignisses hängt sehr davon ab, welche Informa- tionen uns bereits bekannt sind. Es ist daher wichtig, sich immer sehr genau zu überlegen, ob bzw. auf welches Ereignis wir bedingen müssen. Häufig verwendet man Definition 2.8 in der Form Pr[A \\ B] = Pr[B|A] \u0001 Pr[A] = Pr[A|B] \u0001 Pr[B]. (2.1) Anschaulich bedeutet dies: Um auszurechnen, mit welcher Wahrscheinlich- keit A und B zugleich eintreten, genügt es, die Wahrscheinlichkeiten zu multiplizieren, dass zunächst A eintritt und dann noch B unter der Bedin- gung, dass A schon eingetreten ist. Bei mehr als zwei Ereignissen führt dies zu folgender Rechenregel. Satz 2.10. (Multiplikationssatz) Seien die Ereignisse A1, . . . , An ge- geben. Falls Pr[A1 \\ \u0001 \u0001 \u0001 \\ An] > 0 ist, gilt Pr[A1 \\ \u0001 \u0001 \u0001 \\ An] = Pr[A1] \u0001 Pr[A2|A1] \u0001 Pr[A3|A1 \\ A2] \u0001 \u0001 \u0001 Pr[An|A1 \\ \u0001 \u0001 \u0001 \\ An−1]. Beweis. Zunächst halten wir fest, dass alle bedingten Wahrscheinlichkeiten wohldefiniert sind, da Pr[A1] \u0015 Pr[A1 \\ A2] \u0015 . . . \u0015 Pr[A1 \\ \u0001 \u0001 \u0001 \\ An] > 0. Die rechte Seite der Aussage im Satz können wir gemäss der Definition der bedingten Wahrscheinlichkeit umschreiben zu Pr[A1] 1 \u0001 Pr[A1 \\ A2] Pr[A1] \u0001 Pr[A1 \\ A2 \\ A3] Pr[A1 \\ A2] \u0001 \u0001 \u0001 Pr[A1 \\ . . . \\ An] Pr[A1 \\ . . . \\ An−1] . Offensichtlich kürzen sich alle Terme bis auf Pr[A1 \\ . . . \\ An]. Mit Hilfe von Satz 2.10 können wir ein klassisches Problem der Wahrschein- lichkeitsrechnung lösen: KAPITEL 2. WAHRSCHEINLICHKEITSTHEORIE 97 Beispiel 2.11. (Geburtstagsproblem) Wir möchten folgende Frage beantworten: Wie gross ist die Wahrscheinlichkeit, dass in einer m-köpfigen Gruppe zwei Personen am selben Tag Geburtstag haben? Dieses Problem formulieren wir folgendermassen um: Man werfe m Bälle zufällig und gleich wahrscheinlich in n Körbe. Wie gross ist die Wahrscheinlichkeit, dass nach dem Experiment jeder Ball allein in seinem Korb liegt? Im Fall des Geburts- tagsproblems gilt (wenn man von Schaltjahren absieht und Gleichwahrscheinlichkeit der Geburtstage annimmt) n = 365. Für m > n folgt aus dem Schubfachprinzip, dass es immer einen Korb mit mehr als einem Ball gibt. Wir fordern deshalb 0 < m \u0014 n. Zur Berechnung der Lösung stellen wir uns vor, dass die Bälle nacheinander geworfen werden. Ai bezeichne das Ereignis „Ball i landet in einem noch leeren Korb“. Das gesuchte Ereignis „Alle Bälle liegen allein in einem Korb“ bezeichnen wir mit A. Nach Satz 2.10 können wir Pr[A] berechnen durch Pr[A] = Pr [\\ m i=1Ai] = Pr[A1] \u0001 Pr[A2|A1] \u0001 Pr[A3|A2 \\ A1] \u0001 \u0001 \u0001 Pr[Am| \\ m−1 i=1 Ai]. Pr[Aj| \\ j−1 i=1 Ai] bezeichnet die Wahrscheinlichkeit, dass der j-te Ball in einer leeren Urne landet, wenn bereits die vorherigen j − 1 Bälle jeweils allein in einer Urne gelandet sind. Wenn unter dieser Bedingung Aj eintritt, so muss der j-te Ball in eine der n − (j − 1) leeren Urnen fallen, die aus Symmetriegründen jeweils mit derselben Wahrscheinlichkeit gewählt werden. Daraus folgt Pr[Aj| \\ j−1 i=1 Ai] = n − (j − 1) n = 1 − j − 1 n . Mit der Abschätzung 1 − x \u0014 e−x und wegen Pr[A1] = 1 erhalten wir Pr[A] = m∏ j=2 \u0012 1 − j − 1 n \u0013 \u0014 m∏ j=2 e−(j−1)/n = e −(1/n)\u0001 ∑m−1 j=1 j = e −m(m−1)/(2n). Abbildung 2.2 zeigt den Verlauf der Funktion f(m) := e−m(m−1)/(2\u0001 365). Bei 50 Personen ist die Wahrscheinlichkeit, dass mindestens zwei Personen am selben Tag Geburtstag haben, bereits grösser als 95%. KAPITEL 2. WAHRSCHEINLICHKEITSTHEORIE 98 0 10 20 30 40 50 60 70 80 0 0.5 1 mf(m) Abbildung 2.2: Die Funktion f(m) = e−m(m−1)/(2\u0001 365). Analysen ähnlich der in Beispiel 2.11 werden insbesondere für die Unter- suchung von Hash-Verfahren benötigt. Aufgabe von Hash-Verfahren ist es, m Datensätze möglichst gut (und effizient) in n Speicherplätze einzuord- nen. Wenn zwei Datensätze demselben Speicherplatz zugeordnet werden, so spricht man von einer Kollision. Da Kollisionen unerwünschte Ereignisse darstellen, möchte man das Verfahren so auslegen, dass Kollisionen nur sel- ten auftreten. Das Geburtstagsproblem beantwortet die Frage, mit welcher Wahrscheinlichkeit keine einzige Kollision auftritt, wenn man die Datensät- ze zufällig verteilen würde. Die in der Praxis verwendeten Verfahren (die so genannten Hash-Funktionen) garantieren zwar keine „völlige“ Gleichver- teilung, aber die Abweichungen sind im Allgemeinen so gering, dass die obigen Abschätzungen zumindest näherungsweise zutreffen. Beispiel 2.12. Wir nehmen an, dass die Datensätze aus einem Universum K stammen. Da Datensätze auf einem Rechner durch eine Folge von Bits codiert werden, nehmen wir im Folgenden an, dass K \u0012 N0 gilt. Nehmen wir weiter an, dass K = [p], wobei p eine Primzahl ist, so können wir für jedes Paar a, b 2 K mit a 6= 0 eine Hash-Funktion wie folgt definieren: hab : K → [n] k 7→ ((ak + b) mod p) mod n. Die Annahme, dass p eine Primzahl ist, impliziert, dass es für jedes k 0 2 K genau ein k 2 K gibt mit k 0 = (ak + b) mod p (für Nicht-Primzahlen p gilt dies nicht). Die Funktion hab hat daher für alle Paare a, b 2 K mit a 6= 0 die Eigenschaft, dass |h−1 ab(i)| \u0014 d p/ne . Das heisst, die Funktion hab verteilt die Elemente aus K gleichmässig auf den Speicher [n]. Aus der Vorlesung Algorithmen und Datenstrukturen wissen Sie schon, dass die Funktionen hab sogar eine universelle Familie von Hashfunktionen bildet. Dies bedeutet, dass für alle k1, k2 2 K mit k1 6= k2 und für eine uniform zufällig gezogene Hashfunktion gilt: Pr[hab(k1) = hab(k2)] \u0014 1/n. KAPITEL 2. WAHRSCHEINLICHKEITSTHEORIE 99 Ausgehend von der multiplikativen Darstellung der bedingten Wahr- scheinlichkeit in (2.1) zeigen wir den folgenden Satz. Satz 2.13. (Satz von der totalen Wahrscheinlichkeit) Die Ereignisse A1, . . . , An seien paarweise disjunkt und es gelte B \u0012 A1 [ . . . [ An. Dann folgt Pr[B] = n∑ i=1 Pr[B|Ai] \u0001 Pr[Ai]. Analog gilt für paarweise disjunkte Ereignisse A1, A2, . . . mit B \u0012 S ∞ i=1 Ai, dass Pr[B] = ∞∑ i=1 Pr[B|Ai] \u0001 Pr[Ai]. Beweis. Wir zeigen zunächst den endlichen Fall. Wir halten fest, dass B = (B \\ A1) [ \u0001 \u0001 \u0001 [ (B \\ An). Da für beliebige i, j mit i 6= j gilt, dass Ai \\ Aj = ; ist, sind auch die Ereignisse B\\ Ai und B\\ Aj disjunkt. Wegen (2.1) gilt Pr[B\\ Ai] = Pr[B|Ai]\u0001 Pr[Ai]. Wir wenden nun den Additionssatz an: Pr[B] = Pr[B \\ A1] + \u0001 \u0001 \u0001 + Pr[B \\ An] = Pr[B|A1] \u0001 Pr[A1] + \u0001 \u0001 \u0001 + Pr[B|An] \u0001 Pr[An] und haben damit die Behauptung gezeigt. Da der Additionssatz auch für unendlich viele Ereignisse A1, A2, . . . gilt, kann dieser Beweis direkt auf den unendlichen Fall übertragen werden. Der Satz von der totalen Wahrscheinlichkeit ermöglicht häufig eine ein- fachere Berechnung komplexer Wahrscheinlichkeiten, indem man die Er- gebnismenge Ω geschickt in mehrere Fälle zerlegt und diese getrennt be- trachtet. Das folgende bekannte Problem lässt sich mit dieser Technik recht einfach lösen. Beispiel 2.14. (Ziegenproblem) Die Kandidatin einer Fernsehshow darf zwischen drei Tü- ren wählen, um ihren Gewinn zu ermitteln. Hinter einer davon befindet sich ein teures Auto, während hinter den beiden anderen als Trostpreis jeweils eine Ziege wartet. Um die Spannung zu steigern, öffnet der Showmaster, nachdem die Kandidatin gewählt hat, eine der beiden übrigen Türen, hinter der sich (wie er weiss) eine Ziege befindet, und bietet KAPITEL 2. WAHRSCHEINLICHKEITSTHEORIE 100 der Kandidatin an, die Tür noch einmal zu wechseln. Würden Sie an ihrer Stelle dieses Angebot annehmen? Wir betrachten die Ereignisse A := „Kandidatin hat bei der ersten Wahl das Auto gewählt“ und G := „Kandidatin gewinnt nach Wechseln der Tür“. Zu berechnen ist Pr[G]. Offensichtlich gilt Pr[G|A] = 0, da die Kandidatin nach dem Wechseln die „richtige“ Tür verlässt. Ferner erhalten wir Pr[G| ¯A] = 1, da die Kandidatin nach der ersten Wahl vor einer Ziege stand und die zweite Ziege vom Showmaster aufgedeckt wurde. Folglich muss sich hinter der verbleibenden Tür das Auto befinden. Mit dem Satz von der totalen Wahr- scheinlichkeit schliessen wir, dass Pr[G] = Pr[G|A] \u0001 Pr[A] + Pr[G| ¯A] \u0001 Pr[ ¯A] = 0 \u0001 1 3 + 1 \u0001 2 3 = 2 3 . Es zahlt sich also aus, die Tür zu wechseln. Mit Hilfe von Satz 2.13 erhalten wir leicht einen weiteren nützlichen Satz. Satz 2.15. (Satz von Bayes) Die Ereignisse A1, . . . , An seien paarwei- se disjunkt. Ferner sei B \u0012 A1 [ \u0001 \u0001 \u0001 [ An ein Ereignis mit Pr[B] > 0. Dann gilt für ein beliebiges i = 1, . . . , n Pr[Ai|B] = Pr[Ai \\ B] Pr[B] = Pr[B|Ai] \u0001 Pr[Ai] ∑n j=1 Pr[B|Aj] \u0001 Pr[Aj] . Analog gilt für paarweise disjunkte Ereignisse A1, A2, . . . mit B \u0012 S ∞ i=1 Ai, dass Pr[Ai|B] = Pr[Ai \\ B] Pr[B] = Pr[B|Ai] \u0001 Pr[Ai] ∑∞ j=1 Pr[B|Aj] \u0001 Pr[Aj] . Mit dem Satz von Bayes kann man gewissermassen die Reihenfolge der Bedingung umdrehen. Dieses Verfahren kommt insbesondere bei der Ent- wicklung von medizinischen Tests sehr oft zur Anwednung. Beispiel 2.16. Wir betrachten einen medizinischen Test zur Früherkennung einer bestimm- ten Krebsart. Der Test ist binär, das heisst, er kann entweder positiv oder negativ ausfallen. Wir definieren uns einen Wahrscheinlichkeitsraum dadurch, dass wir den Test auf einen KAPITEL 2. WAHRSCHEINLICHKEITSTHEORIE 101 zufälligen Patienten anwenden. Dann können folgende Ereignisse eintreten: P = „der Test ist positiv“, N = „der Test ist negativ“, K = „der Patient hat Krebs“, G = „der Patient hat nicht Krebs“. Es gibt nun zwei Arten von Fehlern, die bei dem Test auftreten können: Entweder der Test fällt bei einem gesunden Patienten positiv aus (Fehler 1. Art, false positive) oder der Test fällt bei einem kranken Patienten negativ aus (Fehler 2. Art, false negative). Bezeichnen wir mit F1 und F2 die Ereignisse, dass ein Fehler 1. bzw. 2. Art eintritt, so gilt also Pr[F1] = Pr[P|G] und Pr[F2] = Pr[N|K]. Bei einem guten Test sind offenbar beide Wahrscheinlichkeiten möglichst klein. Die Fehlerwahrscheinlichkeiten lassen sich empirisch ermitteln. Für dieses Beispiel nehmen wir an, dass ein Fehler 1. Art mit Wahrscheinlichkeit Pr[F1] = 0.02 und ein Fehler 2. Art mit Wahrscheinlichkeit Pr[F2] = 0.01 eintritt, also beide Arten von Fehler relativ selten sind. Was bedeutet es nun für einen Patienten, wenn sein Test positiv ausfällt? Hierfür müssen wir Pr[K|P] betrachten, also die Wahrscheinlichkeit, dass der Patient tat- sächlich krank ist, gegeben, dass sein Test positiv war. Dabei ist noch die Angabe wichtig, wie häufig die Krankheit insgesamt ist. Hier nehmen wir an, dass von dieser speziellen Krebsart etwa 0.5% der Bevölkerung betroffen ist, das heisst also Pr[K] = 0.005. Nach dem Satz von Bayes (mit B = P, A1 = K und A2 = G), gilt nun Pr[K|P] = Pr[P|K] \u0001 Pr[K] Pr[P|K] \u0001 Pr[K] + Pr[P|G] \u0001 Pr[G] Nach den Angaben haben wir Pr[P|G] = Pr[F1] = 0.02, Pr[K] = 0.005 und Pr[G] = 1 − Pr[K] = 0.995. Nach Definition der bedingten Wahrscheinlichkeit gilt ausserdem Pr[N|K] + Pr[P|K] = (Pr[N \\ K] + Pr[P \\ K])/Pr[K] und, da P und K komplementäre Ereignisse sind, somit Pr[N \\ K] + Pr[P \\ K] = Pr[K] und also Pr[N|K] + Pr[P|K] = 1. Damit folgt Pr[P|K] = 1 − Pr[F2] = 0.99. Daher ist Pr[K|P] = 0.99 \u0001 0.005 0.99 \u0001 0.005 + 0.02 \u0001 0.995 = 0.1991..., es ist also immer noch eher unwahrscheinlich, dass der Patient wirklich krank ist. 2.3 Unabhängigkeit Bei einer bedingten Wahrscheinlichkeit Pr[A|B] kann der Fall auftreten, dass die Bedingung auf B, also das Vorwissen, dass B eintritt, keinen Ein- fluss auf die Wahrscheinlichkeit hat, mit der wir das Eintreten von A erwar- ten. In diesem Fall gilt also Pr[A|B] = Pr[A] und wir nennen die Ereignisse A und B unabhängig. Bevor wir diesen Begriff formalisieren, betrachten wir zunächst ein einführendes Beispiel. KAPITEL 2. WAHRSCHEINLICHKEITSTHEORIE 102 Beispiel 2.17. Wir untersuchen das Zufallsexperiment „Zweimaliges Würfeln mit einem sechsseitigen Würfel“. Als Ergebnismenge verwenden wir Ω := {(i, j) | 1 \u0014 i, j \u0014 6}. Dabei bezeichnet das Elementarereignis (i, j) den Fall, dass im ersten Wurf die Zahl i und im zweiten Wurf die Zahl j gewürfelt wurde. Alle Elementarereignisse erhalten nach dem Prinzip von Laplace die Wahrscheinlichkeit 1 36 . Ferner definieren wir die Ereignisse A := Augenzahl im ersten Wurf ist gerade, B := Augenzahl im zweiten Wurf ist gerade. Es gilt Pr[A] = Pr[B] = 1 2 . Wie gross ist Pr[B|A]? Nach unserer Intuition sollte gelten Pr[B|A] = Pr[B] = 1 2 , da der Ausgang des ersten Wurfs den zweiten Wurf nicht beeinflusst (der Würfel ist „gedächtnislos“). Folglich gewinnen wir durch die Bedingung, dass A ein- getreten ist, keine wesentliche Information in Bezug auf das Ereignis B hinzu. Wir rechnen dies nun auch noch formal nach. Es gilt B \\ A = {(2, 2), (2, 4), (2, 6), (4, 2), (4, 4), (4, 6), (6, 2), (6, 4), (6, 6)} und somit Pr[B|A] = Pr[B \\ A] Pr[A] = 9 36 1 2 = 1 2 = Pr[A]. Damit haben wir nachgewiesen, dass das Eintreffen des Ereignisses A keine Auswirkungen hat auf die Wahrscheinlichkeit, mit der das Ereignis B eintrifft. Die folgende Definition formalisiert den Begriff der Unabhängigkeit. Definition 2.18. Die Ereignisse A und B heissen unabhängig, wenn gilt Pr[A \\ B] = Pr[A] \u0001 Pr[B]. Wenn Pr[B] 6= 0 ist, so können wir Definition 2.18 umformen zu Pr[A] = Pr[A \\ B] Pr[B] = Pr[A|B]. Pr[A|B] zeigt also für unabhängige Ereignisse A und B das Verhalten, das wir erwartet haben. Beispiel 2.17 (Fortsetzung) Bei den Ereignissen A und B ist die Unabhängigkeit klar, da offensichtlich kein kausaler Zusammenhang zwischen den Ereignissen besteht. Wir be- trachten nun noch ein weiteres Ereignis: C := Summe der Augenzahlen beider Würfe beträgt 7. KAPITEL 2. WAHRSCHEINLICHKEITSTHEORIE 103 Da das Ereignis C beide Würfe berücksichtigt, könnte es durchaus sein, dass C von A beeinflusst wird. Wir rechnen jedoch nach, dass A \\ C = {(2, 5), (4, 3), (6, 1)} und damit Pr[A \\ C] = 3 36 = 1 12 = 1 2 \u0001 1 6 = Pr[A] \u0001 Pr[C] bzw. Pr[C|A] = Pr[C]. Damit haben wir nachgewiesen, dass A und C unabhängig sind. Analog zeigt man die Unabhängigkeit von B und C. Die Unabhängigkeit von A und C bedeutet intuitiv: Wenn wir wissen, dass A eingetreten ist, so ändert sich dadurch nichts an der Wahrschein- lichkeit, mit der wir das Ereignis C erwarten. Bei der Untersuchung von Ereignis C ist es uns deshalb egal, ob A eintritt oder nicht. In Beispiel 2.17 haben wir gesehen, dass für die zwei Ereignisse A und C die Bedingung der Unabhängigkeit erfüllt ist, obwohl sie nicht wie die Ereignisse A und B in Beispiel 2.17 „physikalisch“ getrennt sind. Unabhängige Ereignisse haben viele „schöne“ Eigenschaften, von denen wir noch einige kennen lernen werden. Die Analyse eines Zufallsexperiments wird deshalb stark vereinfacht, wenn man zeigen kann, dass die dabei be- trachteten Ereignisse unabhängig sind. Auch für mehr als zwei Ereignisse kann man Unabhängigkeit definie- ren. Besonders einfach ist dies wieder, wenn die Ereignisse „physikalisch“ getrennt sind, da man für jedes eine neuen Münzwurf durchführt. Das fol- gende Beispiel zeigt eine interessante Anwendung hierfür. Beispiel 2.19 (Visuelle Kryptographie). Sagen wir, wir haben ein Bild, das nur aus schwar- zen und weissen Pixeln besteht. Mathematisch stellen wir uns das Bild als eine n \u0002 m- Matrix von Nullen und Einsen vor, wobei eine 0 ein schwarzes Pixel darstellt. Zum Beispiel betrachten wir folgendes Bild des Buchstaben W: Wir wollen dieses Bild nun verschlüsseln. Hierfür folgen wir einer Idee, die 1994 von Moni Naor und Adi Shamir entwickelt wurde. Wir zerlegen unser Bild B in zwei Bilder B1 und B2, die jeweils doppelt so gross sind, also Dimension 2n \u0002 2m haben; hierfür ersetzen wir jedes Pixel von B durch 2\u0002 2-Blöcke in B1 und B2, wie folgt: ■ 7→ ( , ) oder ( , ) 7→ ( , ) oder ( , ), KAPITEL 2. WAHRSCHEINLICHKEITSTHEORIE 104 wobei die Auswahl für jedes Pixel durch einen fairen und unabhängigen Münzwurf getrof- fen wird. Für das obige Bild eines W erhalten wir zum Beispiel die Bilder: Diese zwei Bilder sind, wie man leicht sieht, nicht voneinander unabhängig. Jedoch sind innerhalb von B1 alle 2\u0002 2-Blöcke voneinander unabhängig, denn jeder Block ist ja oder mit Wahrscheinlichkeit je 1/2, und zwar unabhängig davon, ob das ursprüngliche Pixel in B schwarz oder weiss ist. Das Gleiche gilt für B2. Das heisst, auf sich allein gestellt enthalten weder B1 noch B2 irgend eine Information über das ursprüngliche Bild. Was passiert aber, wenn wir beide Bilder übereinanderlegen, wobei wir uns die weissen Stellen als Transparent vorstellen? Dann erhalten wir das Bild: Wir haben also das ursprüngliche Bild wiedergefunden, wenn die Rekonstruktion auch nicht ganz perfekt ist, da die ursprünglich weissen Pixel jetzt ‘grau’ sind. Auf diese Art kann mit Transparenten ein schwarz-weisses Bild effizient und sicher verschlüsseln. In Beispiel 2.17 haben wir gesehen, dass zwei Ereignisse unabhängig sein können, obwohl dies aus der Definition der Ereignisse nicht sofort er- sichtlich ist. Wenn wir mehr als zwei Ereignisse betrachten, so wird die Situation noch komplizierter. Es kann zum Beispiel sein, dass von drei Er- eignissen jeweils zwei unabhängig sind, dass aber die Bedingung auf zwei Ereignisse Einfluss auf die Wahrscheinlichkeit eines dritten Ereignisses hat. Das folgende Beispiel veranschaulicht dies. Beispiel 2.20. Wir werfen zwei ideale Münzen M1 und M2. (Das Wort ideal bringt hier zum Ausdruck, dass wir annehmen wollen, dass bei jedem Münzwurf die beiden Ergebnisse „Kopf“ K und „Zahl“ Z mit gleicher Wahrscheinlichkeit fallen.) Unser Wahrscheinlichkeits- raum besteht also aus den vier Elementarereignissen (K, K), (K, Z), (Z, K), (Z, Z), wobei jedes mit Wahrscheinlichkeit 1/4 eintritt. Wir betrachten die Ereignisse A := „M1 zeigt Kopf“ = {(K, K), (K, Z)} B := „M2 zeigt Kopf“ = {(K, K), (Z, K)} C := „die Resultate sind verschieden“ = {(K, Z), (Z, K)}. KAPITEL 2. WAHRSCHEINLICHKEITSTHEORIE 105 Nun sind A und B voneinander unabhängig, denn Pr[A \\ B] = 1/4 = Pr[A]Pr[B]. Ebenso überprüft man leicht, dass B und C voneinander unabhängig sind; und genauso A und C. Allerdings sind A, B, und C zusammen nicht voneinander unabhängig, denn falls je zwei Ereignisse eintreten, so tritt auf keinen Fall das Dritte ein, also insbesondere Pr[A \\ B \\ C] = 0 6= 1/8 = Pr[A]Pr[B]Pr[C]. Beispiel 2.20 zeigt, dass es für die Definition der Unabhängigkeit von n Ereignissen A1, . . . , An nicht genügt, die paarweise Unabhängigkeit der Ereignisse zu verlangen. Wir müssen zudem fordern, dass Pr[A1\\\u0001 \u0001 \u0001\\ An] = Pr[A1] \u0001 \u0001 \u0001 Pr[An] gilt. Es ist allerdings auch nicht ausreichend nur diese Bedingung zu fordern, wir unser nächstes Beispiel zeigt. Beispiel 2.21. Wir wählen eine zufällige Zahl zwischen 1 und 8 und betrachten die Ereignisse A := „die Zahl ist in {1, 2, 3, 4}“ und B := „die Zahl ist in {1, 5, 6, 7}“. Ausserdem sei C = B. Dann gilt Pr[A \\ B \\ C] = Pr[A \\ B] = 1/8 = Pr[A]Pr[B]Pr[C], aber Pr[A \\ B] = 1/8 6= Pr[A]Pr[B], das heisst, A und B sind nicht unabhängig. Die vorstehenden Beispiele motivieren, dass wir für die Definition der Unabhängikeit von mehreren Ereignissen fordern müssen, dass alle Teil- mengen die Unabhängigkeitsbedingung ebenfalls erfüllen. Dies führt zu folgender Definition. Definition 2.22. Die Ereignisse A1, . . . , An heissen unabhängig, wenn für alle Teilmengen I \u0012 {1, . . . , n} mit I = {i1, . . . , ik} gilt, dass Pr[Ai1 \\ \u0001 \u0001 \u0001 \\ Aik] = Pr[Ai1] \u0001 \u0001 \u0001 Pr[Aik]. (2.2) Eine unendliche Familie von Ereignissen Ai mit i 2 N heisst unab- hängig, wenn (2.2) für jede endliche Teilmenge I \u0012 N erfüllt ist. Das folgende Lemma zeigt eine Bedingung, die äquivalent ist zu Defi- nition 2.22, aber manchmal mit geringerem Aufwand überprüft werden kann. KAPITEL 2. WAHRSCHEINLICHKEITSTHEORIE 106 Lemma 2.23. Die Ereignisse A1, . . . , An sind genau dann unabhängig, wenn für alle (s1, . . . , sn) 2 {0, 1}n gilt, dass Pr[As1 1 \\ \u0001 \u0001 \u0001 \\ Asn n ] = Pr[As1 1 ] \u0001 \u0001 \u0001 Pr[Asn n ], (2.3) wobei A0 i = ¯Ai und A1 i = Ai. Beweis. Zunächst zeigen wir, dass aus (2.2) die Bedingung (2.3) folgt. Wir beweisen dies durch Induktion über die Anzahl der Nullen in s1, . . . , sn. Wenn s1 = \u0001 \u0001 \u0001 = sn = 1 gilt, so ist nichts zu zeigen. Andernfalls gelte ohne Einschränkung s1 = 0. Aus dem Additionssatz folgt dann Pr[ ¯A1 \\ As2 2 \\ \u0001 \u0001 \u0001 \\ Asn n ] = Pr[As2 2 \\ \u0001 \u0001 \u0001 \\ Asn n ] −Pr[A1 \\ As2 2 \\ \u0001 \u0001 \u0001 \\ Asn n ]. Darauf können wir die Induktionsannahme anwenden und erhalten Pr[ ¯A1 \\ A s2 2 \\ \u0001 \u0001 \u0001 \\ Asn n ] = Pr[As2 2 ] \u0001 \u0001 \u0001 Pr[Asn n ] − Pr[A1] \u0001 Pr[As2 2 ] \u0001 \u0001 \u0001 Pr[Asn n ] = (1 − Pr[A1]) \u0001 Pr[As2 2 ] \u0001 \u0001 \u0001 Pr[Asn n ], woraus die Behauptung wegen 1 − Pr[A1] = Pr[ ¯A1] folgt. Die Gegenrichtung zeigen wir nicht in voller Allgemeinheit, sondern rechnen nur nach, dass die Aussage Pr[A1 \\ A2] = Pr[A1] \u0001 Pr[A2] aus (2.3) folgt. Der allgemeine Beweis verwendet genau denselben Ansatz, ist aber etwas umständlich aufzuschreiben. Es gilt wegen des Satzes von der totalen Wahrscheinlichkeit, dass Pr[A1 \\ A2] = ∑ s3,...,sn2 {0,1} Pr[A1 \\ A2 \\ As3 3 \\ \u0001 \u0001 \u0001 \\ Asn n ] = ∑ s3,...,sn2 {0,1} Pr[A1] \u0001 Pr[A2] \u0001 Pr[A s3 3 ] \u0001 \u0001 \u0001 Pr[Asn n ] = Pr[A1] \u0001 Pr[A2] \u0001 ∑ s32 {0,1} Pr[As3 3 ] \u0001 . . . \u0001 ∑ sn2 {0,1} Pr[Asn n ] = Pr[A1] \u0001 Pr[A2], und es folgt die Behauptung. KAPITEL 2. WAHRSCHEINLICHKEITSTHEORIE 107 Definition 2.22 und Lemma 2.23 besagen anschaulich: Um zu überprü- fen, ob n Ereignisse unabhängig sind, muss man entweder alle Teilmengen untersuchen oder den Schnitt aller Ereignisse betrachten, wobei an belie- biger Stelle Ereignisse komplementiert werden können. In beiden Fällen bleibt die Eigenschaft erhalten, dass die Wahrscheinlichkeit des Schnitts der Ereignisse dem Produkt der einzelnen Wahrscheinlichkeiten entspricht. Aus der Darstellung in Lemma 2.23 folgt die wichtige Beobachtung, dass für zwei unabhängige Ereignisse A und B auch die Ereignisse ¯A und B (und analog auch A und ¯B bzw. ¯A und ¯B) unabhängig sind. Auch bei Ereig- nissen, die durch Vereinigung unabhängiger Ereignisse entstehen, können solche Aussagen getroffen werden, wie das folgende Lemma zeigt. Lemma 2.24. Seien A, B und C unabhängige Ereignisse. Dann sind auch A \\ B und C bzw. A [ B und C unabhängig. Beweis. Die Unabhängigkeit von A \\ B und C folgt aus Pr[(A \\ B) \\ C] = Pr[A]Pr[B]Pr[C] = Pr[A \\ B]Pr[C]. Mit der Inklusion-Exklusion-Formel gilt Pr[(A [ B) \\ C] = Pr[(A \\ C) [ (B \\ C)] = Pr[A \\ C] + Pr[B \\ C] − Pr[A \\ B \\ C] = Pr[C] \u0001 (Pr[A] + Pr[B] − Pr[A \\ B]) = Pr[A [ B] \u0001 Pr[C], und daraus folgt die Unabhängigkeit von A [ B und C. Wie wir später noch genauer sehen werden, sind unabhängige Zufalls- zahlen für randomisierte Algorithmen von grosser Bedeutung. In der Theo- rie ist es kein Problem, die Existenz solcher Zufallszahlen anzunehmen, aber in der Praxis stellt sich die Frage, wie ein deterministischer Computer über- haupt zufällige Zahlen erzeugen kann. Die Antwort ist offenbar: überhaupt nicht, wenn wir von spezialisierter Hardware absehen, die etwa besonde- re physikalische Effekte ausnutzt. Dennoch hat jede Programmiersprache mindestens eine Funktion, um „Zufallszahlen“ zu generieren. Diese Zahlen sind aber nicht zufällig, sondern folgen einem deterministischen Gesetz; die dadurch erzeugte Folge sieht bloss zufällig aus. Etwas genauer ist ein Pseudozufallszahlengenerator (engl. pseudorandom number generator KAPITEL 2. WAHRSCHEINLICHKEITSTHEORIE 108 oder kurz PRNG) für Zahlen mit n Bits ein Algorithmus, der eine Funk- tion f : {0, 1}m → {0, 1}m → {0, 1}n implementiert, wobei m einen natürliche Zahl ist (die Zustandslänge). Ausgehend von einem Startwert s0 2 {0, 1}m (dem sogenannten seed) erzeugt der Algorithmus eine Folge von Tupeln (s1, a1), (s2, a2), (s3, a3), . . . , wobei immer (si, ai) = f(si−1) ist. Hierbei ist si der ‘interne Zustand’ des PRNG, den man als Anwender nicht zu Ge- sicht bekommt, und a1, a2, a3, . . . ist die eigentliche Folge von generierten Pseudozufallszahlen. Für jeden Startwert s0 kriegt man also eine eigene Folge. Hierbei ist es natürlich essentiell, dass die Folge a1, a2, a3, . . . annä- hernd so aussieht, wie eine Folge von echten unabhängigen Zufallszahlen in {0, 1}n. Üblicherweise meint man damit, dass die Folge verschiedene sta- tistische Tests erfüllt, die von unabhängigen Zufallszahlen ebenfalls erfüllt werden. So soll zum Beispiel jede fixe Zahl in einer genügend langen Teil- folge a1, a2, a3, . . . , ak etwa k/|{0, 1}|n mal vorkommen. In weiterführenden Vorlesungen wird darauf genauer eingegangen. In dieser Vorlesung werden wir zur Einfachheit immer annehmen, dass wir in einem Algorithmus echte Zufallszahlen benutzen können. Diese An- nahme ist nicht ganz ungerechtfertigt, denn wenn der Algorithmus we- sentlich schlechter mit Pseudozufallszahlen als mit echten Zufallszahlen funktionieren würde, so hätten wir einen effizienten Test gefunden, der die Pseudozufallszahlen von echten Zufallszahlen unterscheiden kann. 2.4 Zufallsvariablen Bislang haben wir uns bei der Untersuchung eines Zufallsexperiments dar- auf beschränkt, die Wahrscheinlichkeiten bestimmter Ereignisse zu berech- nen. Oftmals sind wir aber gar nicht an den Wahrscheinlichkeiten der ein- zelnen Ereignisse interessiert, sondern wir beobachten eine „Auswirkung“ oder ein „Merkmal“ des Experiments. Wir werden im Folgenden nur nu- merische Merkmale betrachten, das heisst, wir ordnen jedem Ausgang des Experiments eine bestimmte Zahl zu. Dabei kann es sich zum Beispiel um das bei einem Glückspiel gewonnene bzw. verlorene Geld handeln oder um die Anzahl korrekt übertragener Bytes auf einem unsicheren Kanal. So eine Zuordnung stellt mathematisch gesehen nichts anderes dar als eine Abbil- dung. Damit erhalten wir die folgende Definition. KAPITEL 2. WAHRSCHEINLICHKEITSTHEORIE 109 Definition 2.25. Eine Zufallsvariable ist ein Abbildung X : Ω → R, wobei Ω die Ergebnismenge eines Wahrscheinlichkeitsraumes ist. Bei diskreten Wahrscheinlichkeitsräumen ist der Wertebereich einer Zu- fallsvariablen WX := X(Ω) = {x 2 R | 9 ω 2 Ω mit X(ω) = x} immer endlich oder abzählbar unendlich, je nach dem, ob Ω endlich oder abzählbar unendlich ist. Die Bezeichnung abzählbar steht hierbei für die Tatsache, dass wir sämtliche Elemente des Wertebereichs in der Form WX = {x1, x2, . . .} auflisten können. Formal definiert man: Eine Menge S heisst abzählbar unendlich genau dann, wenn es eine bijektive Abbildung von N nach S gibt. Die einzigen Mengen, die unendlich, aber nicht abzählbar unendlich sind, und mit denen wir es im Rahmen dieser Vorlesung zu tun haben werden, sind Teilmengen von R. Beispiel 2.26. Wir werfen eine ideale Münze dreimal. Als Ergebnismenge erhalten wir Ω := {K, Z} 3. Die Zufallsvariable Y bezeichne die Gesamtanzahl der Würfe mit Ergebnis „Kopf“. Beispielsweise gilt also Y(KZK) = 2 und Y(KKK) = 3. Y hat den Wertebereich WY = {0, 1, 2, 3}. Wenn man eine Zufallsvariable X untersucht, so interessiert man sich für die Wahrscheinlichkeiten, mit denen X bestimmte Werte annimmt. Für WX = {x1, . . . , xn} bzw. WX = {x1, x2, . . .} betrachten wir (für ein beliebiges 1 \u0014 i \u0014 n bzw. xi 2 N) das Ereignis {ω 2 Ω | X(ω) = xi}, das wir auch kurz durch X −1(xi) schreiben können. Anstelle von X −1(xi) verwendet man häufig auch die (intuitivere) Schreibweise “X = xi”. Analog setzt man Pr[“X \u0014 xi”] = ∑ x2 WX : x\u0014 xi Pr[“X = x”] = Pr[{ω 2 Ω | X(ω) \u0014 xi}]. In Zukunft werden wir zur weiteren Vereinfachung zusätzlich auf die An- führungszeichen verzichten und schreiben somit statt Pr[“X \u0014 xi”] einfach Pr[X \u0014 xi]. Analog definiert man Pr[X \u0015 xi], Pr[2 < Xi \u0014 7], Pr[X 2 \u0015 2] . Mit Hilfe dieser Notation können wir jeder Zufallsvariablen auf natürli- che Weise zwei reelle Funktionen zuordnen. Die Funktion fX : R → [0, 1], x 7→ Pr[X = x] (2.4) KAPITEL 2. WAHRSCHEINLICHKEITSTHEORIE 110 nennt man Dichte(funktion) von X. Die Funktion FX : R → [0, 1], x 7→ Pr[X \u0014 x] = ∑ x 0 2 WX : x 0 \u0014 x Pr[X = x 0 ] (2.5) heisst Verteilung(sfunktion) von X. Dichte bzw. Verteilungsfunktion be- schreiben eine Zufallsvariable eindeutig. Oft genügt es daher, lediglich die Dichte einer Zufallsvariablen anzugeben. Wir werden dies in Abschnitt 2.5 genauer ausführen. Beispiel 2.26 (Fortsetzung) Für die Zufallsvariable Y erhalten wir Pr[Y = 0] = Pr[ZZZ] = 1 8 , Pr[Y = 1] = Pr[KZZ] + Pr[ZKZ] + Pr[ZZK] = 3 8 , Pr[Y = 2] = Pr[KKZ] + Pr[KZK] + Pr[ZKK] = 3 8 , Pr[Y = 3] = Pr[KKK] = 1 8 . Abbildung 2.3 zeigt die Dichte und die Verteilung von Y. Bei der Darstellung der Dichte haben wir die Stellen, an denen fY von Null verschiedene Werte annimmt, durch breite Balken hervorgehoben. Formal gesehen befindet sich an diesen Stellen jedoch jeweils nur ein einzelner Punkt. 0 1 2 3 0 0.1 0.2 0.3 0.4 yfY(y) 0 1 2 3 0 0.5 1 yFY(y) Abbildung 2.3: Dichte- und Verteilungsfunktion von Y. 2.4.1 Erwartungswert Bei der Untersuchung einer Zufallsvariablen ist es interessant zu wissen, welches Ergebnis man „im Mittel“ erwarten kann. Wenn wir beispielswei- se beim Würfeln für jede Sechs einen Euro gewinnen, so erwarten wir KAPITEL 2. WAHRSCHEINLICHKEITSTHEORIE 111 bei n Würfen einen Gewinn von etwa n/6 Euro, da voraussichtlich bei ungefähr einem Sechstel der Würfe eine Sechs fallen wird. Man kann also sagen, dass wir bei jedem Spiel im Mittel 1/6 Euro gewinnen. Nun modifizieren wir das Spiel und gehen davon aus, dass wir für je- de gerade Augenzahl zehn Euro erhalten. Mit derselben Argumentation wie zuvor folgt, dass unser Gewinn pro Spiel im Mittel 0,5 \u0001 10 = 5 Euro beträgt. Diese Überlegungen lassen es sinnvoll erscheinen, den Wert der Zufallsvariable mit der Wahrscheinlichkeit für das Auftreten dieses Wertes zu gewichten. Definition 2.27. Zu einer Zufallsvariablen X definieren wir den Erwar- tungswert E[X] durch E[X] := ∑ x2 WX x \u0001 Pr[X = x], sofern die Summe absolut konvergiert. Ansonsten sagen wir, dass der Erwartungswert undefiniert ist. Beispiel 2.4 (Fortsetzung) Der Erwartungswert E[Y] für die Anzahl „Kopf“ bei dreimaligen Werfen einer idealen Münze ist E[Y] = 3∑ i=0 i \u0001 Pr[Y = i] = 1 \u0001 Pr[Y = 1] + 2 \u0001 Pr[Y = 2] + 3 \u0001 Pr[Y = 3] = 1 \u0001 3 8 + 2 \u0001 3 8 + 3 \u0001 1 8 = 3 2 , wie wir auch intuitiv vermutet hätten. Der Zusatz in Definition 2.27 über die Konvergenz der Summe mag auf den ersten Blick ein wenig merkwürdig erscheinen. In der Tat ist diese Bedingung bei endlichen Wahrscheinlichkeitsräumen trivialerweise erfüllt. Bei unendlichen Wahrscheinlichkeitsräumen ist jedoch Vorsicht geboten. In diesem Fall besitzen die Summen über x 2 WX unendlich viele Glieder und ihr Wert kann deshalb unter Umständen nicht definiert sein. Wenn der Er- wartungswert einer Zufallsvariablen definiert ist, so sagen wir auch, dass der Erwartungswert „existiert“. Unser nächstes Beispiel zeigt, welche Pro- bleme auftreten können, wenn der Erwartungswert einer Zufallsvariablen nicht definiert ist. Beispiel 2.28. In einem Casino wird folgendes Spiel angeboten: Eine Münze wird so lange KAPITEL 2. WAHRSCHEINLICHKEITSTHEORIE 112 geworfen, bis sie zum ersten Mal „Kopf“ zeigt. Sei k die Anzahl durchgeführter Würfe. Wenn k ungerade ist, zahlt der Spieler an die Bank 2k Euro. Andernfalls (k gerade) muss die Bank 2k Euro an den Spieler auszahlen. Wir definieren die Zufallsvariable G für den Gewinn der Bank deshalb wie folgt: G := { 2k falls k ungerade, −2k falls k gerade. Offenbar tritt das Ereignis „Anzahl Würfe = k“ genau dann ein, wenn die ersten k Münzwürfe zu der Ergebnisfolge Z . . . Z︸ ︷︷ ︸ k − 1 Mal K führen. Da das Ergebnis eines einzelnen Münzwurfes mit Wahrscheinlichkeit 1/2 jeweils Kopf oder Zahl ist und die einzelnen Münzwürfe unabhängig sind, erhalten wir: Pr[„Anzahl Würfe = k“] = (1/2)k. Damit erhalten wir für die Summe in Definition 2.27 den folgenden Ausdruck: ∞∑ k=1(−1)k−1 \u0001 2k \u0001 \u0012 1 2 \u0013 k = +1 − 1 + 1 − 1 + \u0001 \u0001 \u0001 . Da diese Summe offensichtlich nicht konvergiert, ist der Erwartungswert E[G] in diesem Fall nicht definiert. Man überlege sich, dass ähnliches gilt, wenn uns die Bank anbietet, in jedem Fall 2k Euro auszuzahlen, unabhängig von der Parität von k: dann ist jeder Summand gleich Eins und die Summe konvergiert daher ebenfalls nicht. Auch in diesem Fall ist der Erwartungswert daher nicht definiert. In dieser Vorlesung werden wir nur Zufallsvariablen betrachten, für die der Erwartungswert existiert. Um die Formulierungen der Beispiele und Sätze im Folgenden nicht unnötig unübersichtlich zu gestalten, werden wir darauf nicht immer gesondert hinweisen, sondern dies ab jetzt immer still- schweigend annehmen. In obiger Definition haben wir den Erwartungswert mit einer Summe über die Elemente im Wertebereich der Zufallsvariablen definiert. Alterna- tiv können wir aber auch eine Summe über die Elemente des Wahrschein- lichkeitsraums verwenden. Lemma 2.29. Ist X eine Zufallsvariable, so gilt: E[X] = ∑ ω2 Ω X(ω) \u0001 Pr[ω]. Sehr oft wird der Wertebereich unserer Zufallsvariablen aus nichtnega- tiven ganzen Zahlen bestehen. Für solche Zufallsvariablen kann man den Erwartungswert sehr elegant mit folgender Formel ausrechnen. KAPITEL 2. WAHRSCHEINLICHKEITSTHEORIE 113 Satz 2.30. Sei X eine Zufallsvariable mit WX \u0012 N0. Dann gilt E[X] = ∞∑ i=1 Pr[X \u0015 i]. Beweis. Nach Definition gilt E[X] = ∞∑ i=0 i \u0001 Pr[X = i] = ∞∑ i=0 i∑ j=1 Pr[X = i] = ∞∑ j=1 ∞∑ i=j Pr[X = i] = ∞∑ j=1 Pr[X \u0015 j]. Beispiel 2.31. Wir werfen eine Münze, von der wir wissen, dass die Wahrscheinlichkeit von „Kopf“ gleich p ist, wobei 0 < p < 1, so lange, bis wir das erste Mal Kopf sehen. X sei die Zufallsvariable, die zählt, wie oft wir die Münze werfen mussten. Wir verwenden Satz 2.30 um den Erwartungswert von X auszurechnen. Offenbar gilt X \u0015 j dann und nur dann, wenn die ersten j − 1 Versuche jeweils „Zahl“ geliefert haben. Dies geschieht mit Wahrscheinlichkeit (1 − p)j−1 Somit gilt: E[X] = ∑ j\u0015 1(1 − p)j−1 = ∑ j\u0015 0(1 − p)j = 1/p, wobei wir verwendet haben, dass für alle 0 < x < 1 gilt ∑ n\u0015 0 x n = 1/(1 − x). Aus Satz 2.30 ergibt sich sehr einfach (Übungsaufgabe!), dass für alle Zufallsvariablen X mit Wertebereich WX \u0012 N0 und jedes t > 0 gilt: Pr[X \u0015 t] \u0014 E[X]/t. Diese Ungleichung nennt man Markov-Ungleichung, benannt nach dem russischen Mathematiker Andrei Markov (1856–1922). Sie ist von zen- traler Bedeutung für viele Anwendungen in der Informatik. Wir werden sie in etwas allgemeinerer Form in Abschnitt 2.7.1 beweisen. Bedingte Zufallsvariablen In Beispiel 2.14 haben wir gesehen, dass der Satz von der totalen Wahr- scheinlichkeit (Satz 2.13) es ermöglicht, die Wahrscheinlichkeit eines Er- eignisses auszurechnen, indem wir auf verschiedene Spezialfälle bedingen. Für den Erwartungswert gilt dieses Prinzip analog. Um es zu formulieren, führen wir zunächst noch die Schreibweise einer bedingten Zufallsvariable KAPITEL 2. WAHRSCHEINLICHKEITSTHEORIE 114 ein. Sei X eine Zufallsvariable und A ein Ereignis mit Pr[A] > 0. Mit der Schreibweise X|A deuten wir an, dass wir die Wahrscheinlichkeiten, mit de- nen die Zufallsvariable X bestimmte Werte annimmt bezüglich der auf A bedingten Wahrscheinlichkeiten berechnen. Es gilt also: Pr[(X|A) \u0014 x] = Pr[X \u0014 x | A] = Pr[{ω 2 A : X(ω) \u0014 x}] Pr[A] Hiermit ergibt sich dann folgendes Analogon zum Satz von der totalen Wahrscheinlichkeit für die Berechnung von Erwartungswerten. Satz 2.32. Sei X eine Zufallsvariable. Für paarweise disjunkte Ereig- nisse A1, . . . , An mit A1 [ \u0001 \u0001 \u0001 [ An = Ω und Pr[A1], . . . , Pr[An] > 0 gilt E[X] = n∑ i=1 E[X|Ai] \u0001 Pr[Ai]. Für paarweise disjunkte Ereignisse A1, A2, . . . mit S ∞ i=1 Ak = Ω und Pr[A1], Pr[A2], . . . > 0 gilt analog E[X] = ∞∑ i=1 E[X|Ai] \u0001 Pr[Ai]. Beweis. Mit Hilfe des Satzes von der totalen Wahrscheinlichkeit rechnen wir nach, dass E[X] = ∑ x2 WX x \u0001 Pr[X = x] = ∑ x2 WX x \u0001 n∑ i=1 Pr[X = x|Ai] \u0001 Pr[Ai] = n∑ i=1 Pr[Ai] \u0001 ∑ x2 WX x \u0001 Pr[X = x|Ai] = n∑ i=1 Pr[Ai] \u0001 E[X|Ai]. Der Beweis für den unendlichen Fall verläuft analog. Beispiel 2.31 (Fortsetzung) Mit Hilfe von Satz 2.30 und der geometrischen Reihe haben wir in Beispiel 2.31 den Erwartungswert für die Anzahl Würfe bis zum ersten Mal „Kopf“ ausgerechnet (für eine Münze mit Wahrscheinlichkeit p für „Kopf“). Mit Hilfe von Satz 2.32 kann man dieses Ergebnis auf sehr elegante Weise auch ohne grosse „Rechnerei“ erhalten. Dazu definieren wir das Ereignis K1 := „im ersten Wurf fällt Kopf“. Offensichtlich gilt E[X|K1] = 1. Nehmen wir also an, dass im ersten Wurf nicht „Kopf“ gefallen ist. Dann wird das Experiment de facto neu gestartet, da der erste Wurf keine Auswirkungen auf KAPITEL 2. WAHRSCHEINLICHKEITSTHEORIE 115 die folgenden Würfe hat. Bezeichnen wir daher mit X 0 die Anzahl der Würfe bis zum ersten Auftreten von „Kopf“ im neu gestarteten Experiment, so gilt wegen der Gleichheit der Experimente E[X 0 ] = E[X]. Damit schliessen wir E[X|¯K1] = 1 + E[X 0 ] = 1 + E[X]. Nun können wir Satz 2.13 anwenden und erhalten E[X] = E[X|K1] \u0001 Pr[K1] + E[X|¯K1] \u0001 Pr[¯K1] = 1 \u0001 p + (1 + E[X]) \u0001 (1 − p). Diese Gleichung können wir nach E[X] auflösen und erhalten das bereits bekannte Ergebnis E[X] = 1/p. Linearität des Erwartungswertes Eine Zufallsvariable ist eine Funktion, die die Elementarereignisse eines Wahrscheinlichkeitsraumes Ω in die reellen Zahlen abbildet. Natürlich gibt es zu einem Wahrscheinlichkeitsraum Ω nicht nur eine Zufallsvariable, son- dern sehr viele. Nehmen wir einmal an, wir hätten n Zufallsvariablen defi- niert: X1, . . . , Xn : Ω → R. Für ein ω 2 Ω erhalten wir daher n reelle Zahlen X1(ω), . . . , Xn(ω). Wenn wir uns jetzt noch eine Funktion f : Rn → R vorgeben, die aus n reellen Zahlen wieder eine einzige reelle Zahl macht, so sehen wir, dass die Konka- tenation f(X1, . . . , Xn) wiederum eine Zufallsvariable ist, denn es gilt: f(X1, . . . , Xn) : Ω → R. Dies gilt für beliebige Funktionen f : R n → R. Insbesondere auch für affin lineare Funktionen: f : Rn → R (x1, . . . , xn) 7→ a1x1 + \u0001 \u0001 \u0001 + anxn + b, wobei a1, . . . , an, b 2 R beliebige reelle Zahlen sind. In diesem Fall schrei- ben wir die Zufallsvariable f(X1, . . . , Xn) üblicherweise explizit als X := a1X1 + . . . + anXn + b. Der folgende Satz zeigt, dass wir den Erwartungswert einer Summe von Zufallsvariablen sehr einfach berechnen können: Der Erwartungswert einer Summe von Zufallsvariablen ist die Summe der Erwartungswerte der Zufallsvariablen. KAPITEL 2. WAHRSCHEINLICHKEITSTHEORIE 116 Satz 2.33. (Linearität des Erwartungswerts) Für Zufallsvariablen X1, . . . , Xn und X := a1X1 + . . . + anXn + b mit a1, . . . , an, b 2 R gilt E[X] = a1E[X1] + . . . + anE[Xn] + b. Beweis. Aus dem Satz der totalen Wahrscheinlichkeit folgt E[X] = ∑ i2 WX i \u0001 Pr[X = i] = ∑ ω2 Ω ∑ i2 WX i \u0001 Pr[X = i \\ ω] = ∑ ω2 Ω X(ω) \u0001 Pr[ω]. Die Behauptung folgt mit Hilfe einiger elementarer Umformungen leicht aus dieser Darstellung des Erwartungswerts: E[X] = ∑ ω2 Ω(a1 \u0001 X1(ω) + . . . + an \u0001 Xn(ω) + b) \u0001 Pr[ω] = a1 \u0001 \u0012 ∑ ω2 Ω X1(ω) \u0001 Pr[ω]\u0013 + . . . + an \u0001 \u0012 ∑ ω2 Ω Xn(ω) \u0001 Pr[ω]\u0013 + b = a1 \u0001 E[X1] + . . . + an \u0001 E[Xn] + b. Hier haben wir ausserdem benutzt, dass ∑ ω2 Ω Pr[ω] = 1. Die Linearität des Erwartungswertes ermöglicht es oft, den Erwartungs- wert einer Zufallsvariablen sehr einfach zu berechnen, obwohl dies auf den ersten Blick nicht möglich scheint. Betrachten wir ein einfaches Beispiel: Beispiel 2.34. Wir werfen eine ideale Münze m-mal. Mit X bezeichnen wir die Anzahl Teilfolgen, die aus dreimal Kopf bestehen. Beispiel: für m = 6 könnte die Ergebnisfolge KKKKZK lauten. In diesem Fall hätte X den Wert 2, denn eine Folge KKK startet sowohl an Position 1, wie auch an Position 2. Da die Vorkommen von KKK überlappen können, ist es auf den ersten Blick nicht klar, wie man E[X] berechnet. Der Trick ist, X als Summe von vielen Zufallsvariablen zu schreiben, deren Erwartungswerte wir leicht berechnen können. Hier bietet sich das Folgende an. Zunächst überlegen wir uns, dass eine Teilfolge KKK an jeder der Positionen 1, . . . , m − 2 starten kann. (Die Positionen m − 1 und m kommen nicht in Frage, da hier die verbleibende Teilfolge ja nur noch Länge 2 bzw. 1 hat.) Für jede dieser Positionen definieren wir eine Variable, die angibt, ob an dieser Stelle eine Teilfolge KKK startet: Für jedes i = 1, . . . , m − 2 sei Xi := { 1, falls an Stelle i eine Teilfolge KKK beginnt 0, sonst. Für die gesuchte Zufallsvariable X gilt dann: X = X1 + . . . + Xm−2. Der Erwartungswert von Xi lässt sich einfach berechnen, da Xi ja nur zwei verschiedene Werte annehmen kann: E[Xi] = 0 \u0001 Pr[Xi = 0] + 1 \u0001 Pr[Xi = 1] = Pr[Xi = 1]. KAPITEL 2. WAHRSCHEINLICHKEITSTHEORIE 117 Nach Definition ist Xi = 1 genau dann, wenn an der Stelle i eine Teilfolge KKK beginnt, wenn also der ite und der (i+1)te und der (i+2)te Münzwurf jeweils Kopf ergeben haben. Die Wahrscheinlichkeit hierfür ist (1/2)3. Somit gilt E[Xi] = 1/8 für alle i = 1, . . . , m − 2 und daher E[X] = (m − 2)/8. In Beispiel 2.34 haben wir die gewünschte Zufallsvariable als Summe von Zufallsvariablen geschrieben, die jeweils nur die Werte 0 oder 1 annehmen können. Solche Variablen nennt man auch Indikatorvariablen. Wie wir in Beispiel 2.34 formal nachgerechnet haben, ist der Erwartungswert einer Indikatorvariablen gleich der Wahrscheinlichkeit, dass das entsprechende Ereignis eintritt: Beobachtung 2.35. Für ein Ereignis A \u0012 Ω ist die zugehörige Indika- torvariable XA definiert durch: XA(ω) := { 1, falls ω 2 A 0, sonst. Für den Erwartungswert von XA gilt: E[XA] = Pr[A]. Mit Hilfe von Indikatorvariablen können wir nun einen einfachen Beweis des Prinzips der Inklusion und Exklusion angeben, der keine Eigenschaf- ten der binomischen Summe erfordert, sondern nur mit der Linearität des Erwartungswertes auskommt. Beispiel 2.36 (Beweis von Satz 2.5). Zur Erinnerung: Zu Ereignissen A1, . . . , An wollen wir die Wahrscheinlichkeit Pr[B] des Ereignisses B := A1 [ . . . [ An ermitteln. Wir betrachten die Indikatorvariablen Ii := IAi der Ereignisse A1, . . . , An und die Indikatorvariable I ¯B des Ereignisses ¯B := Ω \\ B. Wir wissen bereits (siehe Beobachtung 2.35), dass der Er- wartungswert einer Indikatorvariablen eines Ereignisses gleich der Wahrscheinlichkeit ist, dass das dieses Ereignis eintrifft. Insbesondere gilt daher: E[I ¯B] = Pr[¯B] = 1 − Pr[B]. Das Produkt ∏n i=1(1 − IAi) ist genau dann gleich Eins, wenn alle Variablen IAi gleich Null sind, das heisst wenn B nicht eintritt. Somit gilt I ¯B = ∏n i=1(1 − Ii) und wir erhalten durch Ausmultiplizieren I ¯B = 1 − ∑ 1\u0014 i\u0014 n Ii + ∑ 1\u0014 i1<i2\u0014 n Ii1 Ii2 − + . . . + (−1)nI1 \u0001 . . . \u0001 In. Mit Hilfe der Linearität des Erwartungswertes (Satz 2.33) folgt daraus E[I ¯B] = 1 − ∑ 1\u0014 i\u0014 n E[IAi] + ∑ 1\u0014 i1<i2\u0014 n E[IAi1 IAi2 ] − + . . . + (−1)nE[IA1 \u0001 . . . \u0001 IAn ]. Wenn wir nun verwenden, dass das Produkt von Indikatorvariablen ebenfalls eine Indika- torvariable ist, nämlich der Indikator für den Schnitt der beteiligten Ereignisse, so erhalten KAPITEL 2. WAHRSCHEINLICHKEITSTHEORIE 118 wir E[Ii1 \u0001 . . . \u0001 Iik] = Pr[Ai1 \\ . . . \\ Aik ], für alle Tupel 1 \u0014 i1 < . . . < ik \u0014 n, und Satz 2.5 ist bewiesen. Oftmals werden wir das einer Indikatorvariable zugrunde liegende Er- eignis A nicht explizit definieren, sondern implizit durch eine textuelle Be- schreibung. Im Folgenden geben wir ein weiteres Beispiel für dieses Prinzip an. Diesmal in Form eines sogenannten verteilten Algorithmus. Beispiel 2.37. Ein verteilter Algorithmus ist ein Algorithmus, der von mehreren verschie- denen Prozessen gemeinsam ausgeführt wird, wobei die Prozesse untereinander ausschliess- lich durch Austausch von Nachrichten kommunizieren können. Solche verteilten Algorith- men kommen in der Regel in Netzwerken von Rechnern zum Einsatz, wenn ein einzelner Rechner nicht genügend Rechenleistung zur Lösung des Problems hat, oder wenn die Eingabe selbst in verteilter Form vorliegt. Letzteres ist zum Beispiel der Fall, wenn die einzelnen Rechner die Struktur des gesamten Netzwerkes nicht kennen, sie aber dennoch eine Teilstruktur des Netzes finden sollen, das eine vorgegebene Eigenschaft hat. Im Fol- genden betrachten wir eine einfache Form solche eines Problems. Gegeben sei ein Graph G = (V, E) mit |V| = n und |E| = m. Wir möchten eine möglichst grosse Teilmenge S \u0012 V bestimmen, so dass G[S] keine Kante enthält (man sagt auch: Die Menge S ist stabil oder unabhängig). Dies tun wir mit einem verteilten Algorithmus, wobei wir annehmen dass für jeden Knoten von v ein eigener Prozess Pv zuständig ist. Die verschiedenen Prozesse müssen nun untereinander ausmachen, welcher Knoten Teil der Menge S ist und welcher nicht. Genauer gesagt, soll jeder Prozess eine Zahl Sv 2 {0, 1} berechnen, so dass am Ende S = {v 2 V | Sv = 1} eine stabile Menge ist. Jeder Prozess Pv führt nun folgenden Algorithmus aus, wobei p 2 (0, 1) ein Wert ist, den wir später festlegen werden: Algorithmus für Pv: 1: Setze Sv ← 1 mit Wahrscheinlichkeit p und Sv ← 0 sonst; 2: for all u 2 V mit {u, v} 2 E do tausche Nachricht mit Pu aus: 3: if Su = Sv = 1 then 4: setze einen der Werte Sv und Su auf Null. 5: return Sv Wir wollen nun anschauen, wir gross die berechnete Menge S im Erwartungswert ist. Dafür definieren noch einige hilfreiche Zufallsvariabeln. Erstens bezeichnen wir mit Xv den Wert, der in Zeile 1 für Sv gewählt wird (es ist möglich, dass am Ende des Algorithmus Sv 6= Xv ist, denn der Wert von Sv kann sich ja noch ändern). Ausserdem setzen wir X := ∑ v2 V Xv. Für eine Kante e = {u, v} definieren wir die Indikatorvariable Ye, die genau dann 1 ist falls sowohl Pu als auch Pv ihre Werte Su bzw. Sv zunächst auf 1 gesetzt haben, falls also KAPITEL 2. WAHRSCHEINLICHKEITSTHEORIE 119 Xu = Xv = 1 ist. Ausserdem sei noch Y := ∑ e2 E Yv. Nun beobachten wir, dass S \u0015 X − Y gilt, denn wir konstruieren S ja dadurch, dass wir mit X Knoten anfangen, und dann noch für jede Kante e mit Ye = 1 höchstens einen Knoten löschen. Wegen der Linearität des Erwartungswertes gilt nun E[S] \u0015 E[X] − E[Y]. Beide Erwartungswerte rechnen wir leicht aus, indem wir wieder die Linearität des Er- wartungswertes benutzen. Zum Einen ist E[X] = ∑v2 V E[Xv] = np und zum Anderen E[Y] = ∑ e2 E E[Ye] = mp2. Daher gilt E[S] \u0015 np − mp2. Durch Ableiten sehen wir, dass dieser Erwartungswert maximiert wird, wenn 2mp = n ist, dass heisst p = n/(2m). Nehmen wir nun noch an, dass der Graph G d-regulär ist, so gilt 2m = dn und daher p = 1/d. Damit erhalten wir: E[S] \u0015 n/d − n/(2d) = n/(2d). Insbesondere hat daher jeder d-reguläre Graph eine stabile Menge der Grösse mindestens n/(2d). 2.4.2 Varianz Wenn zwei Zufallsvariablen denselben Erwartungswert besitzen, so kön- nen sie sich dennoch deutlich voneinander unterscheiden. Ein besonders wichtiges Merkmal einer Verteilung ist die Streuung um den Erwartungs- wert. Während bei manchen Zufallsvariablen nur Werte „in der Nähe“ des Erwartungswerts angenommen werden und das Verhalten der Variablen so- mit durch den Erwartungswert sehr gut charakterisiert wird, gibt es auch Zufallsvariablen, die niemals Werte in der Grössenordnung des Erwartungs- werts annehmen. Man betrachte hierzu beispielsweise die Variable X mit Pr[X = −106] = Pr[X = 106] = 1/2 und E[X] = 0. Bevor wir ein Mass für die Abweichung vom Erwartungswert einführen, betrachten wir zur Motivation ein Beispiel. Beispiel 2.38. Wir untersuchen ein faires Roulette-Spiel, das heisst wir verzichten auf die Einführung der Null und beschränken uns somit auf die Zahlen 1, . . . , 36. Wir nehmen an, dass wir hinreichend viel Kapital besitzen, um sehr viele Runden in Folge spielen zu können. Nun vergleichen wir zwei Strategien: Strategie 1: Setze immer auf Rot. Strategie 2: Setze immer auf die Eins. Wir setzen immer denselben Betrag, den wir der Einfachheit halber als Eins annehmen. Die Zufallsvariablen Gi geben den Gewinn pro Runde bei Strategie i (i = 1, 2) an. Es gilt KAPITEL 2. WAHRSCHEINLICHKEITSTHEORIE 120 Pr[G1 = 1] = Pr[G1 = −1] = 1 2 , da in der Hälfte der Fälle „Rot“ fällt und der doppelte Einsatz ausgezahlt wird. Ferner erhalten wir Pr[G2 = 35] = 1 36 und Pr[G2 = −1] = 35 36 , da die Eins nur mit Wahrscheinlichkeit 1/36 fällt, dafür jedoch der 36-fache Einsatz ausgezahlt wird. Damit folgt E[G1] = 1 \u0001 1 2 + (−1) \u0001 1 2 = 0 E[G2] = 35 \u0001 1 36 + (−1) \u0001 35 36 = 0. Welche Strategie ist nun vorzuziehen? Beim Roulette ist dies wohl eine Charakterfrage. Überträgt man das Szenario andererseits auf ein Problem aus der Informatik, so wird der Unterschied recht schnell deutlich. Dazu nehmen wir an, dass wir ein Datenbanksystem implementieren sollen. Die Bearbeitungsstrategie dieses Systems sei teilweise zufallsge- steuert. Die Zufallsvariable G 0 i := 100 + 50 \u0001 Gi sei die Anzahl der Anfragen, die pro Minute beantwortet werden können, wenn das System mit Strategie i arbeitet. Bei Strategie 1 werden jeweils in der Hälfte der Fälle 50 Anfragen bzw. 150 Anfragen bearbeitet. Bei Strategie 2 werden in seltenen Fällen 1850 Anfragen pro Minute beantwor- tet, in 35 36 der Fälle werden jedoch nur 50 Anfragen erledigt. Obwohl beide Systeme im Mittel pro Minute die selbe Anzahl von Anfragen beantworten, ist für ein reales System das Verhalten von Strategie 1 in der Regel vorzuziehen, da bei Strategie 2 Anwender meist ein deutlich geringe Performance beobachten. In anderen Worten: Strategie 1 verhält sich ausgeglichener und ist daher zu bevorzugen. Beispiel 2.38 zeigt, dass es bei vielen Zufallsvariablen sinnvoll ist, die zu erwartende Abweichung vom Erwartungswert zu untersuchen. Eine nahe liegende Lösung wäre, E[|X − µ|] zu berechnen, wobei µ = E[X] sei. Dies scheitert jedoch meist an der „unhandlichen“ Betragsfunktion. Aus diesem Grund betrachtet man stattdessen E[(X − µ)2], also die quadratische Ab- weichung vom Erwartungswert. Definition 2.39. Für eine Zufallsvariable X mit µ = E[X] definieren wir die Varianz Var[X] durch Var[X] := E[(X − µ)2] = ∑ x2 WX(x − µ)2 \u0001 Pr[X = x]. Die Grösse σ := q Var[X] heisst Standardabweichung von X. Bei Zufallsvariablen über unendlichen Wahrscheinlichkeitsräumen existiert die Varianz Var[X] = E[(X − µ)2] bei manchen Zufallsvariablen nicht. Dies ist genau dann der Fall, wenn der entsprechende Erwartungswert E[(X − µ)2] nicht existiert. In dieser Vorlesung werden wir nur Zufallsvariablen betrachten, bei der die Varianz definiert ist. Mit der folgenden Formel kann man die Varianz oft einfacher berechnen als durch direkte Anwendung der Definition. KAPITEL 2. WAHRSCHEINLICHKEITSTHEORIE 121 Satz 2.40. Für eine beliebige Zufallsvariable X gilt Var[X] = E[X 2] − E[X]2. Beweis. Sei µ := E[X]. Nach Definition gilt Var[X] = E[(X − µ)2] = E[X2 − 2µ \u0001 X + µ 2]. Aus der Linearität des Erwartungswertes (Satz 2.33) folgt E[X 2 − 2µ \u0001 X + µ2] = E[X2] − 2µ \u0001 E[X] + µ2. Damit erhalten wir Var[X] = E[X 2] − 2µ \u0001 E[X] + µ 2 = E[X 2] − E[X]2. Damit zeigen wir die folgende Rechenregel. Satz 2.41. Für eine beliebige Zufallsvariable X und a, b 2 R gilt Var[a \u0001 X + b] = a2 \u0001 Var[X]. Beweis. Aus der in Satz 2.33 gezeigten Linearität des Erwartungswerts folgt E[X + b] = E[X] + b. Zusammen mit der Definition der Varianz ergibt sich damit sofort Var[X + b] = E[(X + b − E[X + b])2] = E[(X − E[X])2] = Var[X]. Mit Hilfe von Satz 2.40 erhalten wir Var[a \u0001 X] = E[(aX)2] − E[aX]2 = a2E[X 2] − (aE[X])2 = a2 \u0001 Var[X]. Durch Kombination der beiden Aussagen folgt die Behauptung. Der Erwartungswert und die Varianz gehören zu den so genannten Mo- menten einer Zufallsvariablen, die wie folgt definiert sind: Definition 2.42. Für eine Zufallsvariable X nennen wir E[X k] das k-te Moment und E[(X − E[X])k] das k-te zentrale Moment . KAPITEL 2. WAHRSCHEINLICHKEITSTHEORIE 122 Der Erwartungswert ist also identisch zum ersten Moment, während die Varianz dem zweiten zentralen Moment entspricht. 2.5 Wichtige diskrete Verteilungen Erinnern wir uns: Ein Wahrscheinlichkeitsraum ist gegeben durch eine Er- gebnismenge Ω und eine Wahrscheinlichkeitsfunktion Pr : Ω → [0, 1], die jedem Elementarereignis ω 2 Ω eine Wahrscheinlichkeit Pr[ω] zuordnet, wobei wir verlangen, dass ∑ ω2 Ω Pr[ω] = 1 gilt. Eine Zufallsvariable X ist eine Funktion X : Ω → R von dem Ergebnisraum Ω in die reellen Zahlen. Die Wahrscheinlichkeitsfunktion Pr[\u0001 ] induziert die Dichte von X gemäss fX : R → [0, 1] x 7→ Pr[X = x] = Pr[{ω | X(ω) = x}]. und analog die Verteilungsfunktion FX : R → [0, 1] x 7→ Pr[X \u0014 x] = Pr[{ω | X(ω) \u0014 x}]. Oft ist es nicht wirklich wichtig, wie die Ergebnismenge Ω definiert ist. Was uns stattdessen interessiert, ist die Dichte oder die Verteilung einer Zufallsvariablen. Betrachten wir hierzu ein (übertriebenes) Beispiel: Beispiel 2.43. Werfen wir eine Münze, so bezeichnet man in der deutschsprachigen Lite- ratur die beiden möglichen Ergebnisse meist als Kopf und Zahl, abgekürzt durch K und Z. Unser Ergebnisraum ist daher Ω = {K, Z}. In der englischsprachigen Literatur verwen- det man statt dessen die beiden Begriffe head and tail, abgekürzt durch H und T . Dort würde man die Ergebnismenge daher mit Ω = {H, T } bezeichnen. Betrachten wir jetzt die Indikatorvariable X für Kopf (bzw X 0 für head), so gilt für beide Dichten: fX(x), fX 0 (x) =    p, wenn x = 1 1 − p, wenn x = 0 0, sonst, vorausgesetzt Pr[K] = Pr[H] = p. Das heisst, beide Ergebnismengen Ω = {K, Z} und Ω = {H, T } führen zur gleichen Dichtefunktion. In diesem Abschnitt stellen wir einige Dichten von Zufallsvariablen vor, die sehr häufig auftreten. Genauer, handelt es sich dabei um Klassen von Zufallsvariablen, die von einem oder mehreren Parametern abhängen. Ei- gentlich betrachten wir also immer eine ganze Familie von ähnlichen Zu- fallsvariablen. KAPITEL 2. WAHRSCHEINLICHKEITSTHEORIE 123 2.5.1 Bernoulli-Verteilung Eine Zufallsvariable X mit WX = {0, 1} und der Dichte fX(x) =    p für x = 1, 1 − p für x = 0, 0 sonst heisst Bernoulli-verteilt. Den Parameter p nennt man die Erfolgswahr- scheinlichkeit der Bernoulli-Verteilung. Wie wir im vorigen Beispiel gese- hen haben, erhält man eine solche Verteilung zum Beispiel für die Indika- torvariable für Kopf bei dem Wurf einer Münze mit Wahrscheinlichkeit p für Kopf. Ist eine Zufallsvariable X Bernoulli-verteilt mit Parameter p, so schreibt man dies auch als X ∼ Bernoulli(p). Für eine solche Bernoulli-verteilte Zufallsvariable X gilt E[X] = p und Var[X] = p(1 − p), wobei letzteres aus Satz 2.40 und E[X 2] = p folgt. Der Name der Bernoulli- Verteilung geht zurück auf den Schweizer Mathematiker Jakob Bernoulli (1654–1705). Sein Werk Ars Conjectandi stellt eine der ersten Arbeiten dar, die sich mit dem Teil der Mathematik beschäftigen, den wir heute als Wahrscheinlichkeitstheorie bezeichnen. 2.5.2 Binomialverteilung Eine Bernoulli-verteilte Zufallsvariable erhalten wir zum Beispiel als Indi- kator für ‘Kopf’, wenn wir ein Münze einmal werfen. Werfen wir die Münze statt dessen n-mal und fragen wie oft wir Kopf erhalten haben, so ist die entsprechende Zufallsvariable binomialverteilt. Beispiel 2.44. Wir werfen eine Münze mit Wahrscheinlichkeit p für Kopf n-mal. X sei die Zufallsvariable, die zählt, wie oft Kopf erscheint. Dann ist der Wertebereich offenbar WX = {0, 1, . . . , n} und es gilt: Pr[X = i] = ∑ ω2 {K,Z}n,X(ω)=i Pr[ω] = ∑ ω2 {K,Z}n,X(ω)=i p i(1 − p)n−i = pi(1 − p)n−i \u0001 |{ω 2 {K, Z}n, ω enthält genau i-mal Kopf}|, KAPITEL 2. WAHRSCHEINLICHKEITSTHEORIE 124 denn für ein ω 2 {K, Z} n ist Pr[ω] gleich p hoch Anzahl K in ω mal 1 − p hoch Anzahl Z in ω. Für die Dichte von X gilt daher: fX(x) = {\u0000 n x\u0001 px(1 − p)n−x, x 2 {0, 1, . . . , n} 0, sonst. Eine Zufallsvariable X mit WX = {0, 1, . . . , n} und der Dichte wie in Beispiel 2.44 heisst binomialverteilt mit Parameter n und p. Man schreibt dies auch als X ∼ Bin(n, p). Für eine solche binomialverteilte Zufallsvariable X gilt E[X] = np und Var[X] = np(1 − p), Dies kann man mit Hilfe der Definition von Erwartungswert und Varianz nachrechnen. Wir werden es aber im nächsten Abschnitt auch noch anders (und sehr viel eleganter) herleiten. 2.5.3 Geometrische Verteilung Wir haben bereits mehrere Male Experimente kennengelernt, bei denen eine Aktion so lange wiederholt wird, bis sie erfolgreich ist (siehe Beispiel 2.31 auf Seite 113 und die Fortsetzung auf Seite 114). Wenn ein einzelner Versuch mit Wahrscheinlichkeit p gelingt, so ist die Anzahl der Versuche bis zum Erfolg geometrisch verteilt. Wir schreiben hierfür auch X ∼ Geo(p). Den Parameter p nennt man auch die Erfolgswahrscheinlichkeit der geo- metrischen Verteilung. Für die Dichte einer geometrisch verteilten Zufalls- variable gilt fX(i) = { p(1 − p)i−1 für i 2 N, 0 sonst. Erwartungswert und Varianz sind E[X] = 1 p und Var[X] = 1 − p p2 . Für den Erwartungswert haben wir dies bereits in Beispiel 2.31 nachgerech- net, die Rechnung für die Varianz überlassen wir dem Leser als Übungs- aufgabe. Für die Verteilungsfunktion gilt für alle n 2 N: FX(n) = Pr[X \u0014 n] = n∑ i=1 Pr[X = i] = n∑ i=1 p(1 − p)i−1 = 1 − (1 − p)n. KAPITEL 2. WAHRSCHEINLICHKEITSTHEORIE 125 Gedächtnislosigkeit. Eine wichtige und oft sehr nützliche Eigenschaft der geometrischen Verteilung ist, dass sie gedächtnislos ist. Was damit gemeint ist, kann man sich leicht an dem Münzbeispiel erklären: Die Wahrschein- lichkeit, dass wir gleich im ersten Versuch ‘Kopf’ sehen, ist identisch zu der Wahrscheinlichkeit, dass wir nach 1000 Fehlversuchen beim 1001ten Wurf ‘Kopf’ erhalten. Die Tatsache, dass wir die Münze schon lange (aber erfolg- los) geworfen haben, hat also keinerlei Einfluss auf den Erfolg im nächsten Wurf. Formal gilt: Satz 2.45. Ist X ∼ Geo(p), so gilt für alle s, t 2 N: Pr[X \u0015 s + t | X > s] = Pr[X \u0015 t]. Beweis. Wir wissen bereits, dass für die Verteilungsfunktion gilt: FX(n) = 1 − (1 − p)n für alle n 2 N. Somit gilt Pr[X \u0015 n] = (1 − p)n−1 für alle n 2 N. Verwenden wir nun die Definition der bedingten Wahrscheinlichkeit, so erhalten wir daher Pr[X \u0015 s+t | X > s] = Pr[X \u0015 s + t] Pr[X > s] = (1 − p)s+t−1 (1 − p)s = (1−p)t−1 = Pr[X \u0015 t], wie behauptet. Warten auf den n-ten Erfolg. Bei der geometrischen Verteilung wird das Experiment so lange wiederholt, bis der erste Erfolg eingetreten ist. Dies kann man auf natürliche Weise dahingehend verallgemeinern, dass man auf den n-ten Erfolg wartet. Genauer sei Z die Zufallsvariable, die zählt, wie oft wir ein Experiment mit Erfolgswahrscheinlichkeit p wiederholen müssen, bis zum n-ten Mal Erfolg eintritt. Für n = 1 gilt offenbar Z ∼ Geo(p). Für n \u0015 2 nennt man Z negativ binomialverteilt mit Ordnung n. Die Dichte von Z kann man mit etwas Nachdenken leicht herleiten. Da- zu überlegen wir uns folgendes: Z bezeichnet die Anzahl der Versuche bis zum n-ten erfolgreichen Experiment. Wenn Z = z ist, so wurden also genau n erfolgreiche und z − n nicht erfolgreiche Experimente durchgeführt. Da nach Definition von Z das letzte Experiment erfolgreich sein muss, steht der Zeitpunkt des n-ten erfolgreichen Experimentes fest. Die übrigen n − 1 erfolgreichen Experimente können beliebig auf die restlichen z − 1 Expe- rimente verteilt werden. Hierfür gibt es genau \u0010 z−1 n−1 \u0011 Möglichkeiten. Jede KAPITEL 2. WAHRSCHEINLICHKEITSTHEORIE 126 dieser Möglichkeiten tritt mit Wahrscheinlichkeit pn(1 − p)z−n ein. Für die Dichte von Z gilt also fZ(z) = z − 1 n − 1 ! \u0001 pn(1 − p)z−n. Den Erwartungswert von Z kann man mit Hilfe der Definition des Erwar- tungswerts aus der Dichte herleiten. Einfacher geht es jedoch mit folgender Überlegung. Wir wissen, dass die Zeit bis zum ersten Erfolg geometrisch verteilt ist und daher Erwartungswert 1/p hat. Nach dem ersten Erfolg startet das Experiment jetzt gewissermassen neu, denn wir warten jetzt auf den zweiten Erfolg. Bezeichnen wir daher allgemein mit Xi die Anzahl Experimente nach dem (i − 1)-ten Erfolg und bis (und mit) dem i-ten Erfolg, so ist jede der Zufallsvariablen Xi geometrisch verteilt mit Parame- ter p. Wegen Z = ∑n i=1 Xi folgt aus der Linearität des Erwartungswertes (Satz 2.33) daher E[Z] = n∑ i=1 E[Xi] = n/p. Das Coupon-Collector-Problem. Zum Abschluss dieses Abschnittes betrach- ten wir noch ein klassisches Beispiel, das in dieser oder einer ähnlichen Form bereits so grosse Mathematiker wie de Moivre, Euler und La- place beschäftigt hat. Gelegentlich werden Produkten Bilder oder ähnliche Dinge beigelegt, um den Käufer zum Sammeln anzuregen. Wenn es insgesamt n verschiedene Bilder gibt, wie viele Produkte muss man im Mittel erwerben, bis man eine vollständige Sammlung besitzt? Hierbei nehmen wir an, dass bei jedem Kauf die Bilder unabhängig voneinander mit gleicher Wahrscheinlichkeit auftreten. Wir führen zunächst ein paar Bezeichnungen ein. X sei die Anzahl der Käufe bis zur Komplettierung der Sammlung. Ferner teilen wir die Zeit in Phasen ein: Phase i bezeichne die Schritte vom Erwerb des (i − 1)-ten Bildes (ausschliesslich) bis zum Erwerb des i-ten Bildes (einschliesslich). Wenn beispielsweise n = 4 gilt und wir die Bilder mit den Zahlen 1, 2, 3, 4 identifizieren, so könnte ein vollständiges Experiment beispiels- weise so aussehen: 2︸︷︷︸ 1 , 2, 1︸︷︷︸ 2 , 2, 2, 3︸ ︷︷ ︸ 3 , 1, 3, 2, 3, 1, 4︸ ︷︷ ︸ 4 , KAPITEL 2. WAHRSCHEINLICHKEITSTHEORIE 127 wobei die Phasen jeweils durch die geschweiften Klammern gekennzeichnet sind. Xi sei die Anzahl der Käufe in Phase i. Offensichtlich gilt X = ∑n i=1 Xi. Phase i wird beendet, wenn wir eines der n − i + 1 Bilder erhalten, die wir noch nicht besitzen. Somit ist Xi geometrisch verteilt mit Parameter p = n−i+1 n und es gilt E[Xi] = n n−i+1. Mit diesem Wissen können wir E[X] ausrechnen, denn es folgt wegen der Linearität des Erwartungswerts, dass E[X] = n∑ i=1 E[Xi] = n∑ i=1 n n − i + 1 = n \u0001 n∑ i=1 1 i = n \u0001 Hn, wobei Hn := ∑n i=1 1 i die n-te harmonische Zahl bezeichnet. Aus der Analysis wissen wir, dass Hn = ln n + O(1) ist und somit folgt, dass E[X] = n ln n + O(n). Diese Wartezeit ist erstaunlich kurz, wenn man be- denkt, dass man im optimalen Fall n Bilder erwerben muss. Durch völlig zufälliges Sammeln kommt also im Vergleich zum optimalen Vorgehen nur der Faktor ln n hinzu. 2.5.4 Poisson-Verteilung Die sogennante Poisson-Verteilung, benannt nach Siméon Denis Poisson (1781–1840), ist motiviert durch die Betrachtung von Ereignissen, von de- nen jedes einzelne zwar mit sehr geringer Wahrscheinlichkeit eintritt, wir aber auf Grund der Vielzahl möglicher Ereignisse dennoch erwarten, dass zumindest ein paar Ereignisse eintreten. Hier denke man zum Beispiel an die Möglichkeit, dass ein Bürger in der nächsten Stunde einen Herzinfarkt bekommt. Für den Einzelnen ist dies unwahrscheinlich, schweizweit gibt es aber dennoch etwa drei bis vier pro Stunde. Formal ist eine Poisson- Verteilung (mit Parameter λ) definiert durch die Dichtefunktion fX(i) = { e−λλi i! für i 2 N0 0 sonst. (Um nachzurechnen, dass fX ist eine zulässige Dichte, dass also ∑ i\u0015 0 fX(i) = 1 gilt, verwende man die aus der Analysis bekannte Reihenentwicklung ex = ∑∞ i=0 xi i! .) Für den Erwartungswert und die Varianz gilt E[X] = Var[X] = λ. KAPITEL 2. WAHRSCHEINLICHKEITSTHEORIE 128 Das Nachrechnen überlassen wir dem Leser als Übungsaufgabe. Um an- zugeben, dass eine Zufallsvariable X Poisson-verteilt ist mit Parameter λ schreibt man auch kurz X ∼ Po(λ). Poisson-Verteilung als Grenzwert der Binomialverteilung. Um zu erkennen, un- ter welchen Voraussetzungen die Poisson-Verteilung als sinnvolle Modellie- rung eines Zufallsexperiments verwendet werden kann, ist es hilfreich zu wissen, dass man die Poisson-Verteilung als Grenzwert einer Bionomialver- teilung erhält. Wir betrachten hierzu zunächst ein Beispiel. Beispiel 2.46. Wir werfen n Bälle unabhängig und gleichverteilt in n Körbe, vgl. Bei- spiel 2.11. Mit X bezeichnen wir die Anzahl Bälle, die im ersten Korb landen. Da jeder einzelne Ball mit Wahrscheinlichkeit 1/n im ersten Korb zu liegen kommt und wir n Bälle werfen, gilt X ∼ Bin(n, 1/n). Für die Dichtefunktion gilt daher fX(i) = \u0012 n i \u0013 \u0001 1 ni \u0001 \u0010 1 − 1 n \u0011 n−i für alle i 2 {0, 1, . . . , n}. Betrachten wir nun für ein festes i 2 N den Grenzwert für n → ∞, so erhalten wir lim n→∞ fX(i) = lim n→∞ n(n − 1) . . . (n − i + 1) i! \u0001 1 ni \u0001 \u0010 1 − 1 n \u0011 n−i = 1 i! \u0001 e−1, das heisst, für n → ∞ konvergiert X, bzw. die Binomialverteilung Bin(n, 1/n), gegen die Poisson-Verteilung Po(1). Ähnlich wie im vorigen Beispiel rechnet man allgemein nach, dass für jedes λ > 0 die Binomialverteilung Bin(n, λ/n) für n → ∞ gegen die Poisson-Verteilung mit Parameter λ konvergiert. Mit anderen Worten: gilt für eine Binomialverteilung, dass der erste Parameter n (die Anzahl Versuche) sehr gross ist und dass das Produkt der beiden Parameter np (also der Erwartungswert) eine (kleine) Konstan- te ist, so kann man die Binomialverteilung durch die Poisson-Verteilung approximieren, wobei der Parameter der Poisson-Verteilung durch den Er- wartungswert der Binomialverteilung gegeben ist. 2.6 Mehrere Zufallsvariablen Oftmals interessiert man sich bei einem Wahrscheinlichkeitsraum für meh- rere Zufallsvariablen zugleich. Wir betrachten dazu ein Beispiel: KAPITEL 2. WAHRSCHEINLICHKEITSTHEORIE 129 Beispiel 2.47. Aus einem Skatblatt mit 32 Karten ziehen wir zufällig eine Hand von zehn Karten sowie einen Skat von zwei Karten. Unter den Karten gibt es vier Buben. Die Zufallsvariable X zählt die Anzahl der Buben in der Hand, während Y die Anzahl der Buben im Skat angibt. Die Werte von X und Y hängen offensichtlich stark voneinander ab. Beispielsweise muss Y = 0 sein, wenn X = 4 gilt. Wir beschäftigen uns mit der Frage, wie man mit mehreren Zufallsva- riablen über demselben Wahrscheinlichkeitsraum rechnen kann, auch wenn sie sich wie in Beispiel 2.47 gegenseitig beeinflussen. Dazu untersuchen wir für zwei Zufallsvariablen X und Y Wahrscheinlichkeiten der Art Pr[X = x, Y = y] = Pr[{ω 2 Ω | X(ω) = x, Y(ω) = y}]. Die Schreibweise Pr[X = x, Y = y], bei der die über Zufallsvariablen defi- nierten Ereignisse „X = x“ und „Y = y“ durch Kommata getrennt aufgeli- stet werden, ist hier als Abkürzung von Pr[„X = x“ \\ „Y = y“] zu verstehen. Auch kompliziertere Ausdrücke wie beispielsweise Pr[X \u0014 x, Y \u0014 y1, p Y = y2] sind üblich. Beispiel 2.47 (Fortsetzung) Wenn wir nur die Zufallsvariable X betrachten, so gilt für 0 \u0014 x \u0014 4 Pr[X = x] = \u0000 4 x \u0001\u0000 28 10−x \u0001 \u0000 32 10\u0001 , da zehn der 32 insgesamt vorhandenen Karten für die Hand ausgewählt werden. Von diesen zehn Karten werden x aus den vier Buben gewählt und 10 − x aus den restlichen 28 Karten, die keine Buben sind. Für die Zufallsvariable Y erhält man analog für 0 \u0014 y \u0014 2 Pr[Y = y] = \u0000 4 y\u0001\u0000 28 2−y\u0001 /\u0000 32 2 \u0001 . Wenn wir jedoch X und Y gleichzeitig betrachten, so besteht ein enger Zusammenhang zwischen den Werten der beiden Variablen. Beispielsweise gilt Pr[X = 4, Y = 1] = 0, da insgesamt nur vier Buben vorhanden sind. Allgemein erhalten wir mit einer ähnlichen Argumentation wie zuvor Pr[X = x, Y = y] = \u0000 4 x\u0001\u0000 28 10−x\u0001\u0000 4−x y \u0001\u0000 28−(10−x) 2−y \u0001 \u0000 32 10\u0001\u0000 22 2 \u0001 , woraus auch formal folgt, dass zum Beispiel Pr[X = 3, Y = 1] 6= Pr[X = 3]Pr[Y = 1]. Die Funktion fX,Y(x, y) := Pr[X = x, Y = y] heisst gemeinsame Dichte der Zufallsvariablen X und Y. Wenn man die gemeinsame Dichte gegeben hat, kann man auch wieder zu den Dichten der einzelnen Zufallsvariablen übergehen, indem man fX(x) = ∑ y2 WY fX,Y(x, y) bzw. fY(y) = ∑ x2 WX fX,Y(x, y) KAPITEL 2. WAHRSCHEINLICHKEITSTHEORIE 130 setzt. Die Funktionen fX und fY nennt man Randdichten. Die Ereignisse „Y = y“ bilden eine disjunkte Zerlegung des Wahrscheinlichkeitsraumes und es gilt somit wegen Satz 2.3 Pr[X = x] Satz 2.3 = ∑ y2 WY Pr[X = x, Y = y] Def. = fX(x). Die Dichten der einzelnen Zufallsvariablen entsprechen also genau den Rand- dichten. Auch zur Verteilung gibt es ein Analogon: Für zwei Zufallsvaria- blen definiert man die gemeinsame Verteilung als FX,Y(x, y) := Pr[X \u0014 x, Y \u0014 y] = Pr[{ω 2 Ω | X(ω) \u0014 x, Y(ω) \u0014 y}] = ∑ x 0 \u0014 x ∑ y 0 \u0014 y fX,Y(x 0 , y 0 ) Auch hier kann man wieder zur Randverteilung übergehen, indem man FX(x) = ∑ x 0 \u0014 x fX(x 0 ) = ∑ x 0 \u0014 x ∑ y2 WY fX,Y(x 0 , y). ansetzt. Analog erhält man die Randverteilung von Y. Beispiel 2.48. Wir betrachten folgendes zweistufiges Experiment. Wir werfen zunächst einen Würfel. X bezeichne die geworfene Augenzahl. Danach werfen wir X-mal eine ideale Münze und bezeichnen mit Y die Anzahl Kopf. Wie gross ist der Erwartungswert für Y? – Intuitiv könnten wir folgende Rechnung anstellen: Die erwartete Augenzahl beim Würfel ist E[X] = 7/2. Und wenn wir eine ideale Münze 3.5 mal werfen so erwarten wir (auch wenn wir nicht genau wissen, wie das ‘ein-halb-mal’ Werfen geht), dass in der Hälfte der Fälle Kopf kommt. Das heisst, wir erwarten E[Y] = 7/4. Aber können wir dies auch formal begründen? Ja! Hierzu betrachten wir zunächst die gemeinsame Dichte von X und Y. Dies ist einfach: die Wahrscheinlichkeit für “X = x” ist 1/6 für alle x 2 {1, . . . , 6}. Und wenn wir die Münze x-mal werfen, so ist die Wahrscheinlichkeit für y-mal Kopf genau \u0000 x y\u0001 /2x für alle y 2 {0, 1, . . . , x}. Das heisst, wir haben fX,Y(x, y) =    1 6 \u0001 (x y) 2x falls x 2 {1, . . . , 6} und y 2 {0, 1, . . . , x} 0 sonst. Damit erhalten wir folgende Dichte für Y: fY(y) =    ∑6 x=max{1,y} 1 6 \u0001 (x y) 2x falls y 2 {0, 1, . . . , 6} 0 sonst. Für den Erwartungswert von Y gilt daher in der Tat E[Y] = 6∑ y=0 y \u0001 fY(y) = 6∑ y=1 y \u0001 6∑ x=y 1 6 \u0000 x y\u0001 2x = 1 6 6∑ x=1 1 2x x∑ y=1 y\u0012 x y \u0013 = . . . = 7 4 , wobei wir die elementaren Rechnungen in “. . .” dem Leser als Übung überlassen. KAPITEL 2. WAHRSCHEINLICHKEITSTHEORIE 131 Beispiel 2.49. Wir wählen eine zufällige Folge von n Nullen und Einsen, wobei jede Folge die gleiche Wahrscheinlichkeit 2−n hat. Wir bezeichnen mit X die Anzahl Einsen in der Folge. Ferner sei 0 \u0014 m \u0014 n und Y die Anzahl Einsen unter den ersten m Folgengliedern. Die gemeinsame Dichte von X und Y ist für 0 \u0014 y \u0014 m und y \u0014 x \u0014 n − m + y fX,Y(x, y) = Pr[X = x, Y = y] = \u0012 n − m x − y \u0013\u0012 m y \u0013 2−n, denn es gibt \u0000 m y \u0001 Möglichkeiten, y Einsen auf die ersten m Folgenglieder zu verteilen und \u0000 n−m x−y \u0001 Möglichkeiten, die verbleibenden x − y Einsen auf die restlichen n − m Glieder zu verteilen. Die Randdichte von X erhalten wir, indem wir über alle Möglichkeiten für Y summieren: fX(x) = Pr[X = x] = m∑ y=0 \u0012 n − m x − y \u0013\u0012 m y \u0013 2−n. Verwenden wir nun noch die sogenannte Vandermonde Identität für n \u0015 m \u0012 n x \u0013 = m∑ y=0 \u0012 n − m x − y \u0013\u0012 m y \u0013 , so erhalten wir Pr[X = x] = \u0000 n x\u0001 2−n, was wir natürlich auch direkt gewusst hätten. 2.6.1 Unabhängigkeit von Zufallsvariablen Bei Ereignissen haben wir den Begriff der Unabhängigkeit kennen gelernt, der intuitiv besagt, dass zwei Ereignisse sich gegenseitig „nicht beeinflus- sen“. Wie schon bei Ereignissen, so kann auch bei Zufallsvariablen dies „offensichtlich“ der Fall sein (weil die entsprechenden Zufallsvariablen „phy- sikalisch“ unabhängig sind) oder auch nur implizit (weil wir nachrechnen können, dass keine Abhängigkeit vorliegt). Die nächsten beiden Beispiele illustrieren beide Phänomene. Beispiel 2.50. Wir werfen eine Münze zweimal. Mit X1 bzw. X2 bezeichnen wir die Indika- torvariable für das Ereignis, dass der erste bzw. zweite Wurf „Kopf“ ist. Da der erste Wurf keinen Einfluss auf den zweiten Wurf hat, gilt für alle a, b 2 {0, 1}, dass Pr[X1 = a, X2 = b] = Pr[X1 = a] \u0001 Pr[X2 = b]. Es ist ebenfalls leicht einzusehen, dass dies immer der Fall sein wird, wenn die Variablen Xi Indikatorvariablen für unabhängige Ereignisse sind. Beispiel 2.51. Wir ziehen zufällig eine Karte aus einem Skatspiel mit 32 Karten und be- trachten die Indikatorvariablen X bzw. Y für die folgenden beiden Ereignisse: „die Karte ist eine Herz-Karte“ bzw. „die Karte ist ein Bube“. Dann sind die beiden Variablen offen- sichtlich nicht „physikalisch“ unabhängig, denn wir ziehen ja nur eine einzige Karte, es gilt aber: Pr[Y = 1 | X = 1] = 1 8 = 4 32 = Pr[Y = 1]. KAPITEL 2. WAHRSCHEINLICHKEITSTHEORIE 132 Das heisst, ob wir wissen, dass die Karte eine Herz-Karte ist, hat keinen Einfluss auf die Wahrscheinlichkeit, mit der die Karte ein Bube ist. Die Überlegungen aus Beispiel 2.51 motivieren die folgende, auf Zufalls- variablen erweiterte Definition von Unabhängigkeit. Definition 2.52. Zufallsvariablen X1, . . . , Xn heissen unabhängig genau dann, wenn für alle (x1, . . . , xn) 2 WX1 \u0002 . . . \u0002 WXn gilt Pr[X1 = x1, . . . , Xn = xn] = Pr[X1 = x1] \u0001 \u0001 \u0001 \u0001 \u0001 Pr[Xn = xn]. Alternativ kann man Definition 2.52 auch über die Dichten formulieren: X1, . . . , Xn sind genau dann unabhängig, wenn für alle (x1, . . . , xn) 2 WX1 \u0002 . . . \u0002 WXn gilt fX1,...,Xn(x1, . . . , xn) = fX1(x1) \u0001 \u0001 \u0001 \u0001 \u0001 fXn(xn). Bei unabhängigen Zufallsvariablen ist also die gemeinsame Dichte gleich dem Produkt der Randdichten. Die Gleichung in Definition 2.52 gilt im Übrigen auch für xi ausserhalb des Wertebereichs, sie ist dann nur nicht besonders interessant, da dann beide Seiten 0 sind. Das folgende Lemma zeigt, dass für unabhängigen Zufallsvariablen die Produkteigenschaft nicht nur für einzelne Werte xi gilt, sondern für belie- bige Mengen. Lemma 2.53. Sind X1, . . . , Xn unabhängige Zufallsvariablen und sind S1, . . . , Sn \u0012 R beliebige Mengen, dann gilt Pr[X1 2 S1, . . . , Xn 2 Sn] = Pr[X1 2 S1] \u0001 \u0001 \u0001 \u0001 \u0001 Pr[Xn 2 Sn]. Beweis. Es genügt, die Gleichung für Teilmengen des Wertebereichs nach- zurechnen, da sonstige Elemente die Wahrscheinlichkeiten nicht ändern. Insbesondere können wir annehmen, dass die Si endlich oder abzählbar KAPITEL 2. WAHRSCHEINLICHKEITSTHEORIE 133 sind. Dann rechnen wir direkt nach: Pr[X1 2 S1, . . . , Xn 2 Sn] = ∑ x12 S1 . . . ∑ xn2 Sn Pr[X1 = x1, . . . , Xn = xn] Unabh. = ∑ x12 S1 . . . ∑ xn2 Sn Pr[X1 = x1] \u0001 . . . \u0001 Pr[Xn = xn] = 0 @ ∑ x12 S1 Pr[X1 = x1] 1 A \u0001 . . . \u0001 0 @ ∑ xn2 Sn Pr[Xn = xn] 1 A = Pr[X1 2 S1] \u0001 \u0001 \u0001 \u0001 \u0001 Pr[Xn 2 Sn]. Mit Hilfe von Lemma 2.53 erhalten wir insbesondere auch einen for- malen Beweis für die intuitiv offensichtlich Tatsache, dass Teilmengen von unabhängigen Zufallsvariablen ebenfalls unabhängig sind. Korollar 2.54. Sind X1, . . . , Xn unabhängige Zufallsvariablen und ist I = {i1, . . . , ik} \u0012 [n], dann sind Xi1, . . . , Xik ebenfalls unabhängig. Beweis. Wir rechnen die Bedingung der Definition 2.52 nach. Für xij 2 WXij , 1 \u0014 j \u0014 k, setzen wir Si = { WXi falls i 62 I, {xi} falls i 2 I. Für i 62 I ist dann Xi 2 Si trivialerweise erfüllt und mit Lemma 2.53 folgt daher Pr[Xi1 = xi1, . . . , Xik = xik] = Pr[X1 2 S1, . . . , Xn 2 Sn] Lemma 2.53 = Pr[X1 2 S1] \u0001 \u0001 \u0001 \u0001 \u0001 Pr[Xn 2 Sn] = Pr[Xi1 = xi1] \u0001 \u0001 \u0001 \u0001 \u0001 Pr[Xik = xik]. Wir wissen bereits, dass die Anwendung einer Funktion f auf eine Zufalls- variable X wieder eine Zufallsvariable liefert, nämlich f(X) := f \u000e X. Damit KAPITEL 2. WAHRSCHEINLICHKEITSTHEORIE 134 können wir Zufallsvariablen der Form −X, 2X + 10, X2, (X − E[X])2 etc. be- trachten. Mit Hilfe von Lemma 2.53 werden wir nun zeigen, dass durch An- wendung von Funktionen auf Zufallsvariablen deren Unabhängigkeit nicht verloren geht. Satz 2.55. Seien f1, . . . , fn reellwertige Funktionen (fi : R → R für i = 1, . . . , n). Wenn die Zufallsvariablen X1, . . . , Xn unabhängig sind, dann gilt dies auch für f1(X1), . . . , fn(Xn). Beweis. Wir betrachten beliebige Werte z1, . . . , zn mit zi 2 Wf(Xi) für i = 1, . . . , n. Zu zi definieren wir die Menge Si = {x | f(x) = zi}. Es folgt mit Hilfe von Lemma 2.53 Pr[f1(X1) = z1, . . . , fn(Xn) = zn] = Pr[X1 2 S1, . . . , Xn 2 Sn] Unabh. = Pr[X1 2 S1] \u0001 \u0001 \u0001 \u0001 \u0001 Pr[Xn 2 Sn] = Pr[f1(X1) = z1] \u0001 \u0001 \u0001 \u0001 \u0001 Pr[fn(Xn) = zn]. Das folgende Beispiel zeigt, dass die Annahme von Satz 2.55, dass die Xi unabhängig sind, hinreichend aber nicht notwendig ist. Beispiel 2.56. Wählen wir die konstante Funktion f \u0011 1, so gilt für jede Zufallsvariable X: Y := f(X) ist eine Zufallsvariable mit Dichte fY(y) = { 1 y = 1 0 sonst. Insbesondere gilt daher: f(X1), . . . , f(Xn) sind auch dann unabhängig, wenn X1, . . . , Xn abhängig sind. 2.6.2 Zusammengesetzte Zufallsvariablen Mit Hilfe einer Funktion g können mehrere Zufallsvariablen auf einem Wahrscheinlichkeitsraum miteinander kombiniert werden. Man konstruiert also aus den Zufallsvariablen X1, . . . , Xn eine neue, zusammengesetzte Zu- fallsvariable Y durch Y := g(X1, . . . , Xn). Die Wahrscheinlichkeiten der zu Y gehörenden Ereignisse „Y = y“ für y 2 WY = {Y(ω) | ω 2 Ω} berechnen wir wie gewohnt: Pr[Y = y] = Pr[{ω 2 Ω | Y(ω) = y}] = Pr[{ω | g(X1(ω), . . . , Xn(ω)) = y}]. KAPITEL 2. WAHRSCHEINLICHKEITSTHEORIE 135 Beispiel 2.57. Ein Würfel werde zweimal geworfen. X bzw. Y bezeichne die Augenzahl im ersten bzw. zweiten Wurf. Daraus kann man zum Beispiel die Zufallsvariable Z := X + Y ableiten, die der Summe der gewürfelten Augenzahlen entspricht. Für Z gilt: Pr[Z = 1] = Pr[; ] = 0, Pr[Z = 4] = Pr[{(1, 3), (2, 2), (3, 1)}] = 3 36 usw. In diesem Beispiel haben wir die Dichte von Z berechnet, indem wir zu jedem möglichen Ergebnis für X den dazu passenden Wert von Y gewählt haben. Im Allgemeinen gilt ein ganz ähnliches Prinzip: Satz 2.58. Für zwei unabhängige Zufallsvariablen X und Y sei Z := X + Y. Es gilt fZ(z) = ∑ x2 WX fX(x) \u0001 fY(z − x). Beweis. Mit Hilfe des Satzes von der totalen Wahrscheinlichkeit folgt, dass fZ(z) = Pr[Z = z] = ∑ x2 WX Pr[X + Y = z | X = x] \u0001 Pr[X = x] = ∑ x2 WX Pr[Y = z − x] \u0001 Pr[X = x] = ∑ x2 WX fX(x) \u0001 fY(z − x). Den Ausdruck ∑ x2 WX fX(x) \u0001 fY(z − x) aus Satz 2.58 nennt man in Ana- logie zu den entsprechenden Begriffen bei Potenzreihen Faltung oder Kon- volution der Dichten fX und fY. Beispiel 2.59. Seien X und Y Poisson-verteilt mit Parametern λX bzw. λY und sei Z die Zufallsvariable X + Y. Dann gilt direkt nach dem Satz 2.58: fZ(z) = Pr[Z = z] = z∑ x=0 Pr[X = x]Pr[Y = z − x] = e−(λX+λY ) z∑ x=0 λx X x! λz−x Y (z − x)! = e−(λX+λY ) z∑ x=0 λx Xλz−x Y z! z! x!(z − x)! = e−(λX+λY ) 1 z! z∑ x=0 λx Xλ z−x Y \u0012 z x \u0013 = e−(λX+λY ) 1 z! (λX + λY)z. Entsprechend sehen wir, dass Z auch Poisson-verteilt ist mit Parameter λZ = λX + λY. KAPITEL 2. WAHRSCHEINLICHKEITSTHEORIE 136 2.6.3 Momente zusammengesetzter Zufallsvariablen Im Folgenden zeigen wir einige Rechenregeln für zusammengesetzte Zu- fallsvariablen. Die Linearität des Erwartungswertes kennen wir bereits aus Satz 2.33. Satz 2.60. (Linearität des Erwartungswerts) Für Zufallsvariablen X1, . . . , Xn und X := a1X1 + \u0001 \u0001 \u0001 + anXn mit a1, . . . , an 2 R gilt E[X] = a1E[X1] + \u0001 \u0001 \u0001 + anE[Xn]. Dieser Satz ist äusserst nützlich, da keine Voraussetzungen an die Unab- hängigkeit der beteiligten Zufallsvariablen gestellt werden. Bei Produkten von Zufallsvariablen können wir hingegen auf diese Voraussetzung nicht verzichten. Satz 2.61. (Multiplikativität des Erwartungswerts) Für unabhängi- ge Zufallsvariablen X1, . . . , Xn gilt E[X1 \u0001 \u0001 \u0001 \u0001 \u0001 Xn] = E[X1] \u0001 \u0001 \u0001 \u0001 \u0001 E[Xn]. Beweis. Wir beweisen den Fall n = 2. Der allgemeine Fall folgt daraus dann sofort per Induktion: E[X \u0001 Y] = ∑ x2 WX ∑ y2 WY xy \u0001 Pr[X = x, Y = y] Unabh. = ∑ x2 WX ∑ y2 WY xy \u0001 Pr[X = x] \u0001 Pr[Y = y] = ∑ x2 WX x \u0001 Pr[X = x] ∑ y2 WY y \u0001 Pr[Y = y] = E[X] \u0001 E[Y]. Um einzusehen, dass für die Gültigkeit von Satz 2.61 die Unabhängigkeit der Zufallsvariablen wirklich notwendig ist, betrachte man beispielsweise den Fall Y = X für eine Zufallsvariable X mit einer von Null verschiedenen Varianz. Dann gilt E[X \u0001 Y] = E[X 2] 6= (E[X])2 = E[X] \u0001 E[Y]. Nachdem wir nun Aussagen zum Erwartungswert von Summen und Produkten gesehen haben, wollen wir untersuchen, ob ähnliche Aussagen KAPITEL 2. WAHRSCHEINLICHKEITSTHEORIE 137 auch für die Varianz gelten. Der folgende Satz zeigt, dass bei unabhängigen Zufallsvariablen die Varianz der Summe auf die Varianzen der einzelnen Zufallsvariablen zurückgeführt werden kann. Satz 2.62. Für unabhängige Zufallsvariablen X1, . . . , Xn und X := X1 + . . . + Xn gilt Var[X] = Var[X1] + . . . + Var[Xn]. Beweis. Wir beschränken uns auf den Fall n = 2 und betrachten die Zu- fallsvariablen X und Y. Der allgemeine Fall folgt dann wieder per Induktion. Es gilt E[(X + Y)2] = E[X2 + 2XY + Y2] = E[X2] + 2E[X]E[Y] + E[Y2] E[X + Y]2 = (E[X] + E[Y])2 = E[X]2 + 2E[X]E[Y] + E[Y]2, wobei die erste Zeile die Unabhängigkeit von X und Y benutzt. Wir ziehen die zweite Gleichung von der ersten ab und erhalten E[(X + Y)2] − E[X + Y]2 = E[X 2] − E[X]2 + E[Y2] − E[Y]2. Mit Hilfe von Satz 2.40 folgt die Behauptung. Für abhängige Zufallsvariablen X1, . . . , Xn gilt Satz 2.62 im Allgemeinen nicht. Als Beispiel betrachte man den Fall einer Zufallsvariablen X mit von Null verschiedener Varianz. Für Y = −X nimmt die Zufallsvariable X + Y immer den Wert 0 an, also haben wir Var[X + Y] = 0 6= 2 \u0001 Var[X] = Var[X] + Var[Y]. Bei abhängigen Zufallsvariablen ist es daher meistens sehr schwer, Aussagen über die Varianz der Summe zu treffen. Für die Varianz des Produktes von Zufallsvariablen gilt ein Analogon zu Satz 2.62 im Allgemeinen nicht einmal für unabhängige Zufallsvariablen, wie das folgende Beispiel zeigt. Beispiel 2.63. Seinen X und Y zwei unabhängige Bernoulli-Variablen mit Parameter p. Dann ist XY eine Bernoulli-Variable mit Parameter p2. Daher gilt Var[XY] = p2(1 − p 2), was für 0 < p < 1 verschieden ist von Var[X] \u0001 Var[Y] = (p(1 − p))2. 2.6.4 Waldsche Identität Im vorherigen Abschnitt haben wir uns Summen und Produkte von Zufalls- variablen angesehen, bei denen die Anzahl der Summanden eine Konstante KAPITEL 2. WAHRSCHEINLICHKEITSTHEORIE 138 ist. In vielen Anwendungen ist die Anzahl der Summanden allerdings oft ebenfalls eine Zufallsvariable. Man denke hier beispielsweise an einen Al- gorithmus, der ein bestimmtes Unterprogramm solange aufruft, bis eine Haltebedingung erfüllt ist. Die Laufzeit eines solchen Algorithmus können wir abschätzen, indem wir den Algorithmus in Phasen zerlegen: Jede Phase entspricht einem Aufruf des Unterprogramms. Die Anzahl Phasen ist dann in der Regel allerdings nicht konstant, sondern durch eine Zufallsvariable gegeben. Solche algorithmischen Beispiele verschieben wir auf später, hier begnügen wir uns zunächst mit einem künstlichen Beispiel. Beispiel 2.64. Wir werfen eine Münze mit Wahrscheinlichkeit p für „Kopf“, bis wir zum er- sten Mal Kopf sehen. Die Zufallsvariable N bezeichne die entsprechende Anzahl an Würfen. Anschliessend werfen wir die Münze nochmals N-mal und bezeichnen mit Z die Anzahl „Kopf“ während diesen zweiten N Versuchen. Was können wir über den Erwartungswert von Z sagen? – Aus Abschnitt und Beispiel 2.31 wissen wir bereits, dass N geometrisch verteilt ist mit Parameter p, und dass daher E[N] = 1/p ist. Wir erwarten daher, dass wir die Münze in der zweiten Phase 1/p-mal werfen. Und da jeder dieser Würfe mit Wahr- scheinlichkeit p „Kopf“ ist, können wir vermuten, dass E[Z] = (1/p) \u0001 p = 1 gelten sollte. Anstatt diese Vermutung durch Nachrechnen zu Beweisen, werden wir zunächst die soge- nannte Waldsche Identität, benannt nach Abraham Wald (1902-1950), herleiten, die uns das vorhergesagte Ergebnis dann ohne weitere Rechnerei direkt liefert. Satz 2.65 (Waldsche Identität). N und X seien zwei unabhängige Zu- fallsvariable, wobei für den Wertebereich von N gilt: WN \u0012 N. Weiter sei Z := N∑ i=1 Xi, wobei X1, X2, . . . unabhängige Kopien von X seien. Dann gilt: E[Z] = E[N] \u0001 E[X]. Beweis. Wir verwenden Satz 2.32. Dann gilt offenbar E[Z] = ∑ n2 WN E[Z | N = n] \u0001 Pr[N = n]. Um E[Z | N = n] zu berechnen, stellen wir fest, dass hier die Anzahl Iterationen nicht mehr eine Zufallsvariable, sondern eine Konstante ist, da wir auf N = n bedingen. Mit der Linearität des Erwartungswertes folgt E[Z | N = n] = E[X1 + . . . + Xn] = n \u0001 E[X], KAPITEL 2. WAHRSCHEINLICHKEITSTHEORIE 139 und wir erhalten E[Z] = ∑ n2 WN n \u0001 E[X] \u0001 Pr[N = n] = E[X] ∑ n2 WN n \u0001 Pr[N = n] = E[X] \u0001 E[N]. 2.7 Abschätzen von Wahrscheinlichkeiten In Abschnitt 2.4.1 haben wir den Erwartungswert einer Zufallsvariablen eingeführt. Umgangssprachlich sprechen wir auch oft davon, dass wir ein bestimmtes Ergebnis eines Zufallsexperiments erwarten. Meinen beide Be- griffe dasselbe? Dies ist leider nicht so1. Der Erwartungswert entspricht dem Durchschnittswert bei sehr vielen Wiederholungen des Experimentes. Wenn wir hingegen anschaulich von unser Erwartung sprechen, so beziehen wir uns in der Regel nur auf ein einziges Experiment. Betrachten wir ein Beispiel. Beispiel 2.66. Wir betrachten eine Zufallsvariable X mit Dichte fX(x) =    1 − 1 n falls x = n, 1 n falls x = −n(n − 1), 0 sonst. Dann ist E[X] = n(1 − 1/n) − (n − 1) = 0. Dennoch nimmt aber X mit Wahrscheinlichkeit 1 − 1/n den Wert n an. Wenn wir das Experiment aus Beispiel 2.66 daher nur ein einziges Mal ausführen, so ‘erwarten’ wir den Wert n, denn dieser tritt ja mit Wahr- scheinlichkeit fast Eins ein. Wenn wir andererseits das Experiment N mal wiederholen, so wird der Durchschnitt der gesehenen Werte insbesondere für grosse Werte von N sehr nahe beim Erwartungswert sein, also nahe bei Null sein. Der Erwartungswert einer Zufallsvariablen kann also von dem erwarteten Ergebnis bei einer einzigen Wiederholung sehr stark abweichen. Für manche Zufallsvariablen kann man jedoch zeigen, dass der Erwar- tungswert und der erwartete Ausgang eines einzigen Experimentes sehr nahe beieinander liegen. Formal lässt sich so eine Aussage wir folgt be- schreiben: Nehmen wir an, für eine Zufallsvariable X, eine Konstante t > 0 1NB: wenn wir in Übungen von der ‘erwarteten Anzahl’ o.Ä. sprechen, meinen wir stets den Erwartungswert. KAPITEL 2. WAHRSCHEINLICHKEITSTHEORIE 140 und eine (kleine) Konstante δ > 0 gilt Pr[ |X − E[X]| \u0014 t] \u0015 1 − δ. Dann ‘erwarten’ wir also, dass wir bei einer einmaligen Durchführung des Experimentes X einen Wert erhalten, der sich um höchstens t vom Erwar- tungswert unterscheidet. Konkret könnte so eine Aussage beispielsweise wie folgt aussehen. Sei X die Zufallsvariable, die die Anzahl Käufe bei einem Coupon-Collector-Problem mit n Bildern angibt. Dann wissen wir (siehe Seite 126), dass E[X] = n ln n + O(n). In diesem Abschnitt werden wir zeigen, dass sogar gilt: Pr[ |X − E[X]| \u0014 n p ln n] \u0015 1 − π2 6 ln n. Für eine hinreichend grosse Bilderanzahl n ‘erwarten’ wir daher, dass wir bei der nächsten Bilder-Aktion von Migros oder Coop höchstens n ln n + n p ln n Bilder kaufen müssen, bis wir je ein Exemplar aller n Bilder besit- zen. 2.7.1 Die Ungleichungen von Markov und Chebyshev Bei der Konstruktion der Zufallsvariablen in Beispiel 2.66 haben wir den ‘wahrscheinlichen’ Wert n durch den negativen Wert −n(n − 1) ausgegli- chen. Viele in der Informatik auftretende Zufallsvariablen haben jedoch die Eigenschaft, dass sie nur nicht-negative Werte annehmen. Dann ist eine Konstruktion wie die in Beispiel 2.66 nicht möglich. Und wir können sogar zeigen, dass dann sehr grosse Werte der Zufallsvariable wenig wahrschein- lich sind. Der folgende Satz, benannt nach dem russischen Mathematiker Andrei Andrejewitsch Markov (1856–1922), formalisiert dies. Satz 2.67. (Ungleichung von Markov) Sei X eine Zufallsvariable, die nur nicht-negative Werte annimmt. Dann gilt für alle t 2 R mit t > 0, dass Pr[X \u0015 t] \u0014 E[X] t . Oder äquivalent dazu Pr[X \u0015 t \u0001 E[X]] \u0014 1/t. KAPITEL 2. WAHRSCHEINLICHKEITSTHEORIE 141 Beweis. Wir rechnen direkt nach, dass E[X] = ∑ x2 WX x \u0001 Pr[X = x] \u0015 ∑ x2 WX, x\u0015 t x \u0001 Pr[X = x] \u0015 t \u0001 ∑ x2 WX, x\u0015 t Pr[X = x] = t \u0001 Pr[X \u0015 t]. Man erkennt, dass die Markov-Ungleichung im Wesentlichen durch Weg- lassen einiger Summanden aus der Definition des Erwartungswerts ent- steht. Obwohl die Ungleichung von Markov sehr einfach zu beweisen ist, hat sie sich bei zahlreichen Anwendungen schon als sehr nützliches Hilfsmittel erwiesen. Für das Coupon-Collector-Problem erhalten wir zum Beispiel so- fort die Aussage, dass wir nur mit Wahrscheinlichkeit 1/100 viel mehr als 100n log n Käufe tätigen müssen. Noch nicht unser Wunschergebnis, aber ein Anfang. Erinnern wir uns an die Varianz. Sie misst die durchschnittliche Abwei- chung einer Zufallsvariablen von ihrem Erwartungswert. Definiert haben wir sie als Var[X] := E[(X − E[X])2]. Der Term (X − E[X])2 definiert eine nichtnegative Zufallsvariable. Und wir können daher auf diese Zufallsvaria- ble die Markov-Ungleichung anwenden. Tun wir dies, so erhalten wir die sogenannten Chebyshev-Ungleichung, benannt nach Pafnuti Lwowitsch Chebyshev2 (1821–1894). Satz 2.68. (Ungleichung von Chebyshev) Sei X eine Zufallsvariable und t 2 R mit t > 0. Dann gilt Pr[|X − E[X]| \u0015 t] \u0014 Var[X] t2 oder äquivalent dazu Pr[|X − E[X]| \u0015 tq Var[X]] \u0014 1/t2. Beweis. Es gilt Pr[|X − E[X]| \u0015 t] = Pr[(X − E[X])2 \u0015 t2]. 2In der deutschsprachigen Literatur meist Tschebyscheff; wir benutzen hier aber die im Englischen übliche Schreibweise. KAPITEL 2. WAHRSCHEINLICHKEITSTHEORIE 142 Die Zufallsvariable Y := (X − E[X])2 ist nicht-negativ und hat nach De- finition der Varianz den Erwartungswert E[Y] = Var[X]. Damit folgt die Behauptung durch Anwendung der Markov-Ungleichung: Pr[|X − E[X]| \u0015 t] = Pr[Y \u0015 t2] \u0014 E[Y] t2 = Var[X] t2 . Die Ungleichung von Chebyshev bestätigt die intuitive Bedeutung der Varianz: Je kleiner die Varianz ist, desto grösser ist die Wahrscheinlichkeit, mit der X nur Werte innerhalb eines Intervalls [E[X] − t, E[X] + t] um den Erwartungswert E[X] annimmt. Die Varianz ist also in der Tat ein gutes Mass dafür, mit welcher Sicherheit wir davon ausgehen können, dass die Werte einer Zufallsvariablen „nahe“ beim Erwartungswert liegen. Beispiel 2.69. Wir betrachten wieder das Coupon-Collector-Problem. Mit X bezeichnen wir die Anzahl Käufe, bis wir jedes Bild mindestens einmal besitzen. Auf Seite 126 haben wir den Erwartungswert von X ausgerechnet: E[X] = nHn = n(1 + 1/2 + 1/3 + \u0001 \u0001 \u0001 + 1/n). Um Chebyshev anzuwenden brauchen wir ausserdem die Varianz von X. Für deren Berechnung verwenden wiederum die Darstellung X = ∑n i=1 Xi, wobei Xi die Anzahl Käufe ist während, wir genau i − 1 verschiedene Bilder besitzen. Wegen der Unabhängigkeit der Xi wissen wir aus Satz 2.62, dass Var[X] = Var h n∑ i=1 Xii = n∑ i=1 Var[Xi]. Im Abschnitt auf Seite 126 haben wir uns schon überzeugt, dass Xi geometrisch verteilt ist mit dem Parameter pi = 1 − i−1 n . Daher gilt Var[Xi] = 1−pi p2 i (siehe Abschnitt 2.64), und somit Var[X] = n∑ i=1 1 − pi p2 i \u0014 n∑ i=1 1 p2 i = n∑ i=1 \u0012 n n − i + 1 \u0013 2 = n2 \u0001 n∑ i=1 1 i2 \u0014 n 2 \u0001 π 2 6 , wobei wir die Summe ∑∞ i=1 1 i2 = π2 6 verwendet haben. Mit Satz 2.68 gilt nun für eine beliebige Funktion f(n) Pr[|X − E[X]| \u0015 f(n)] \u0014 Var[X] (f(n))2 \u0014 π 2n 2 6 \u0001 (f(n))2 . Die rechte Seite geht für jede Funktion f(n), die schneller als n wächst, gegen Null. Die zuvor genannte Ungleichung Pr[ |X − E[X]| \u0014 np ln n] \u0015 1 − π 2 6 ln n folgt zum Beispiel für f(n) = np ln n. KAPITEL 2. WAHRSCHEINLICHKEITSTHEORIE 143 2.7.2 Die Ungleichung von Chernoff Wenn wir eine faire Münze n-mal werfen und mit X die Anzahl Kopf be- zeichnen, so ist X binomialverteilt mit Parameter 1/2. Insbesondere gilt daher E[X] = n/2. Mit der Ungleichung von Markov folgt daraus Pr[X \u0015 n] \u0014 1/2. Ein etwas schärferes Resultat liefert die Chebyshev-Ungleichung: sie ergibt (Übung) Pr[X \u0015 n] \u0014 1/n. Wir wissen aber andererseits bereits, dass Pr[X \u0015 n] = 2−n gilt. Die Markov- und Chebyshev-Ungleichungen liefern in diesem Beispiel also zwar korrekte, aber nicht sehr gute Abschätzungen. Dies liegt daran, dass die- se Ungleichungen für beliebige nicht-negative Zufallsvariablen gelten – sie sind daher leicht anzuwenden, geben aber nicht immer sehr gute Schranken. Wenn wir die Verteilung der Zufallsvariable kennen, können wir oft besse- re Schranken herleiten. Speziell für Summen von Bernoulli-Variabeln sind die sogenannten Chernoff-Schranken (benannt nach Herman Chernoff ( \u0003 1923)) sehr nützlich. Satz 2.70 (Chernoff-Schranken). Seien X1, . . . , Xn unabhängige Bernoulli- verteilte Zufallsvariablen mit Pr[Xi = 1] = pi and Pr[Xi = 0] = 1 − pi. Dann gilt für X := ∑n i=1 Xi: (i) Pr[X \u0015 (1 + δ)E[X]] \u0014 e− 1 3 δ2 E[X] für alle 0 < δ \u0014 1, (ii) Pr[X \u0014 (1 − δ)E[X]] \u0014 e− 1 2 δ2 E[X] für alle 0 < δ \u0014 1, (iii) Pr[X \u0015 t] \u0014 2−t für t \u0015 2eE[X]. Beweis. Wir betrachten zunächst (iii), weil der Beweis hier etwas über- sichtlicher ist. Die Idee ist, die Markov-Ungleichung auf die Zufallsvariable Y := 4X anzuwenden. Weil die Funktion 4x streng monoton wachsend ist, ist das Ereignis „X \u0015 t“ identisch mit dem Ereignis „4X \u0015 4t“. Insbesondere ist Pr[X \u0015 t] = Pr[4X \u0015 4t] \u0014 E[4X] 4t , wobei wir im zweiten Schritt die Markov-Ungleichung auf Y = 4X ange- wandt haben. Wir müssen also nur noch E[4X] ausrechnen. Dazu erinnern wir uns daran, dass die Zufallsvariablen Xi unabhängig sind, und daher die KAPITEL 2. WAHRSCHEINLICHKEITSTHEORIE 144 Zufallsvariablen eXi nach Satz 2.55 ebenfalls unabhängig sind. Nach der Multiplikativität des Erwartungswertes für unabhängige Zufallsvariablen (Satz 2.61) gilt deshalb: E[4X] = E h 4∑n i=1 Xi i = E 2 4 n∏ i=1 4Xi 3 5 Mult. = n∏ i=1 E[4Xi]. Da jedes Xi eine Bernoulli-Variable mit Parameter pi ist, nimmt der Aus- druck 4Xi nur die Werte 4 oder 1 an, und zwar mit Wahrscheinlichkeit pi bzw. 1 − pi. Deshalb ist E[4Xi] = 4pi + (1 − pi) = 1 + 3pi \u0014 e3pi, wobei der letzte Schritt eine Anwendung der aus der Analysis bekannten Ungleichung 1 + x \u0014 ex ist. Damit ist also E[4X] \u0014 n∏ i=1 e3pi = e3 ∑n i=1 pi = e3E[X] t\u0015 2eE[X] \u0014 e3t/(2e). Mit einem Taschenrechner sehen wir schnell, dass e3/(2e) ˇ 1.7364 \u0014 2 ist, und daher e3t/(2e) \u0014 2t. Setzen wir alles zusammen, so haben wir Pr[X \u0015 t] \u0014 E[4X] 4t \u0014 2t 4t = 2−t, wie behauptet. Die Ungleichungen (i) und (ii) beweist man ganz ähnlich, ausser dass wir statt Y := 4X die Zufallsvariable Y := (1 + δ)X bzw. Y := (1 − δ)X verwenden. Wir verzichten auf die Details. Beispiel 2.71. Wir betrachten wieder das Beispiel von vorher: Wir werfen n faire Münzen und bezeichnen mit X die Anzahl von „Kopf“-Ergebnissen. Dann gilt E[X] = n/2. Wie gross ist nun die Wahrscheinlichkeit Pr[|X − n/2| > 0.1 \u0001 n/2], dass die tatsächliche Anzahl um mindestens 10% vom Erwartungswert abweicht? Die folgende Tabelle vergleicht die Schranken, und die Chebyshev-Ungleichung und die Chernoff-Ungleichung liefern: Für n Chebyshev Chernoff 1000 0.1 0.270961 2000 0.05 0.0424119 5000 0.02 0.000244096 10000 0.01 5.77914 \u0001 10−8 100000 0.001 4.14559 \u0001 10−73 die Chernoff-Ungleichung haben wir hier die Werte angegeben, die sich aus der Summe der Formeln in (i) und (ii) in Satz 2.70 ergeben. KAPITEL 2. WAHRSCHEINLICHKEITSTHEORIE 145 2.8 Randomisierte Algorithmen Ziel eines Algorithmus ist es, für eine Eingabe I eine Ausgabe A (I) zu be- rechnen. Bislang haben wir nur Algorithmen gesehen, die die Eigenschaft haben, dass sie für identische Eingaben auch identische Ergebnisse berech- nen. Man nennt solche Algorithmen daher auch deterministische Algo- rithmen. In diesem Abschnitt wollen wir einen Schritt weiter gehen und sogenannte randomisierte Algorithmen betrachten. Die Idee eines rando- misierten Algorithmus ist, dass der Algorithmus zusätzlich zur Eingabe I auch noch Zugriff auf Zufallsvariablen hat. Das Ergebnis des Algorithmus hängt daher nicht nur von der Eingabe I ab, sondern auch noch von den Werten der Zufallsvariablen. Wir bezeichnen die Ausgabe des Algorithmus daher mit A (I, R ), wobei R für die Werte der Zufallsvariablen steht. Aus- serdem schreiben wir A (I) für die Zufallsvariable, die dem Wert von A (I, R ) bei einer zufälligen Wahl von R entspricht. Wichtig ist daher: bei randomi- sierten Algorithmen erhalten wir bei mehrmaligem Aufruf mit der gleichen Eingabe I im Allgemeinen verschiedene Ergebnisse. Für eine genaue Definition eines randomisierten Algorithmus müssen wir noch präzisieren, auf welche Zufallsvariablen ein randomisierter Al- gorithmus Zugriff hat. In der Komplexitätstheorie nimmt man üblicher- weise an, dass randomisierte Algorithmen lediglich Zugriff auf sogenannte Zufallsbits haben. Diese sind das Ergebnis von unabhängigen Bernoulli- verteilten Zufallsvariablen mit Parameter 1/2. Haben wir Zugriff auf sol- che Zufallsbits, so können wir daraus auch kompliziertere Zufallsvariablen konstruieren. Für die Binomialverteilung mit Parameter n und 1/2 ist das sofort einsichtig. Für eine Gleichverteilung auf der Menge {1, 2, 3} führt dies andererseits bereits zu einigen Schwierigkeiten: Wenn wir n Zufallsbits ver- wenden, so gibt es 2n verschiedene 0-1-Folgen, die alle gleich wahrscheinlich sind. Jeder Folge müssen wir als Ausgabe einen der drei Werte 1, 2, 3 zu- ordnen. Egal wir gross wir n wählen, so werden wir so nie eine exakte Gleichverteilung auf {1, 2, 3} hinbekommen. Um diese Probleme zu vermeiden, werden wir in dieser Vorlesung da- her davon ausgehen, dass wir Zugriff auf alle Arten von Zufallsvariablen haben, wie sie von modernen Programmiersprachen bereitgestellt werden. Wie auch bei den Zufallsbits gehen wir davon aus, dass diese Aufrufe unab- hängige Werte liefern. Realisiert wird dies in Programmiersprachen durch sogenannte Zufallszahlengeneratoren (siehe Seite 108). KAPITEL 2. WAHRSCHEINLICHKEITSTHEORIE 146 Bei randomisierten Algorithmen unterscheidet man zwei verschiedene Ansätze: Algorithmen, die immer schnell sind, aber zuweilen ein falsches Ergebnis liefern (sogenannte Monte-Carlo-Algorithmen) und Algorithmen, die nie ein falsches Ergebnis liefern, aber bei denen die Laufzeit eine Zufalls- variable ist (sogenannte Las-Vegas-Algorithmen). Wir können Las-Vegas- Algorithmen auch anders betrachten: Brechen wir den Algorithmus ab, wenn eine bestimme Laufzeit überschritten ist, so haben wir einen Algo- rithmus, der immer schnell ist, der aber zuweilen statt einer sinnvollen Antwort nur ‘ ???’ ausgibt (und umgekehrt können wir solch einen Algo- rithmus auch so lange wiederholen, bis wir einmal nicht ‘ ???’ als Antwort kriegen – dann ist aber wieder die Laufzeit eine Zufallsvariable). Wir be- nutzen hier die Definition eines Las-Vegas-Algorithmus als ein Algorithmus, der manchmal ‘ ???’ ausgeben kann. Wichtig ist hier natürlich, dass Fehler oder verweigerte Antworten nur sehr selten auftreten. Ein Algorithmus, der, statt die Eingabe überhaupt nur einzulesen, sofort eine Antwort rät, ist ein Monte-Carlo-Algorithmus im obigen Sinne: die Laufzeit ist immer konstant und er macht Fehler. Aber so ein Algorithmus ist natürlich komplett nutzlos. Was wir gerne hätten, sind Algorithmen, die zumindest „fast immer“ schnell sind und „fast nie“ Fehler machen. Wie sich gleich zeigen wird, ist dies oft gar nicht so schwer, da sich die Fehlerwahrscheinlichkeit oft mit einigen einfachen Tricks drastisch reduzieren lässt. 2.8.1 Reduktion der Fehlerwahrscheinlichkeit Ein Freund schlägt uns einen Münzentscheid vor für die Frage, wer die heutigen Kinokarten bezahlen soll. Auch eine Münze hat er gleich parat und sagt uns, dass wir „Zahl“ nehmen sollen. Wohl wissend, dass er als Hobby-Zauberer allerlei ungewöhnliche Dinge besitzt, wollen wir zunächst sicherstellen, dass die Münze keine Spezialanfertigung ist mit „Kopf“ auf beiden Seiten. Anfassen dürfen wir die Münze nicht und so bitten wir den Freund die Münze zumindest ein paar Mal zu werfen. Sobald wir „Zahl“ sehen, sind wir beruhigt – und bereit für den Kinokarten-Münzentscheid. Wenn die Münze allerdings jedes Mal „Kopf“ zeigt, so wird unser Misstrau- en schnell so gross werden, dass wir auf den Münzentscheid verzichten. Die Betonung hier liegt auf schnell. Schon bei nur 10 Münzwürfen ist die Wahr- scheinlichkeit bei einer fairen Münze für zehnmal Kopf kleiner als 1:1000, KAPITEL 2. WAHRSCHEINLICHKEITSTHEORIE 147 bei 20-mal ist es schon weniger als 1:106. Die Reduktion der Fehlerwahrscheinlichkeit bei Algorithmen beruht auf genau dieser Idee: Führen wir einen randomisierten Algorithmus mehrfach aus (jedes Mal natürlich mit „neuen“ Zufallsbits), so reduziert sich die Feh- lerwahrscheinlichkeit analog wie bei obigem Münzwurf. Ist die Fehlerwahr- scheinlichkeit bei einem Durchlauf 1/2, so ist die Wahrscheinlichkeit, dass 20 Durchläufe allesamt fehlerbehaftet sind kleiner als 10−6. Wir verwenden diesen Ansatz zunächst, um zu zeigen, dass es für Las- Vegas-Algorithmen genügt, dass der Algorithmus die richtige Antwort mit Wahrscheinlichkeit mindestens ε gibt, wobei ε > 0 beliebig klein sein darf. Durch eine genügend grosse Anzahl Wiederholungen kann man daraus dann jede beliebig kleine Fehlerwahrscheinlichkeit erzielen. Die Anzahl nötiger Wiederholungen hängt hierbei nur von der ursprünglichen Korrektheits- wahrscheinlichkeit ε und der gewünschten Fehlerwahrscheinlichkeit δ ab. Satz 2.72. Sei A ein randomisierter Algorithmus, der nie eine falsche Antwort gibt, aber zuweilen ‘ ???’ ausgibt, wobei Pr[A (I) korrekt] \u0015 ε. Dann gilt für alle δ > 0: bezeichnet man mit A δ den Algorithmus, der A solange aufruft, bis entweder ein Wert verschieden von ‘ ???’ ausgegeben wird (und A δ diesen Wert dann ebenfalls ausgibt) oder bis N = ε −1 ln δ−1-mal ‘ ???’ ausgegeben wurde (und A δ dann ebenfalls ‘ ???’ ausgibt), so gilt für den Algorithmus A δ, dass Pr[A δ(I) korrekt] \u0015 1 − δ. Beweis. Die Wahrscheinlichkeit, dass A bei N Aufrufen immer den Wert ‘ ???’ ausgibt, ist nach Annahme höchstens (1 − ε)N. Da 1 − x \u0014 e−x für alle x 2 R, folgt daher für N = ε −1 ln δ−1, dass die Wahrscheinlichkeit, dass A δ den Wert ‘ ???’ ausgibt, höchstens (1 − ε)N \u0014 e−εN = eln δ = δ ist. Mit Hilfe von Satz 2.72 können wir uns jetzt auch leicht ganz formal davon überzeugen, wie man aus 0-1-Zufallsbits einen Zufallsgenerator für eine Gleichverteilung auf den Zahlen {0, . . . , n} erzeugt. Beispiel 2.73. Wir betrachten der Einfachheit halber hier nur den Fall n = 2. Mit Hilfe von zwei Zufallsbits können wir einen exakt uniformen Sampler wie folgt konstruieren: Bei 00 gebe 0 aus, bei 01 gebe 1 aus, bei 10, gebe 2 aus, bei 11 gebe ‘ ???’ aus. Dieser KAPITEL 2. WAHRSCHEINLICHKEITSTHEORIE 148 Algorithmus gibt dann jede Zahl 0,1,2 mit der gleichen Wahrscheinlichkeit aus, und ‘ ???’ mit Wahrscheinlichkeit 1/4. Die Wahrscheinlichkeit, dass wir nach 30 Aufrufen dieses ein- fachen Samplers noch immer keine Zahl ausgegeben haben, ist 4 −30 \u0014 10−18. Wenn wir in diesem Fall dann zum Beispiel Null ausgeben, haben wir zwar keine genaue Gleichvertei- lung mehr, aber dies spielt für die Praxis keine Rolle. Alternativ kann man den einfachen Sampler auch so lange aufrufen, bis er eine Antwort liefert. Dann kann die Laufzeit des Algorithmus zwar im Prinzip beliebig gross werden, aber da die Wahrscheinlichkeit hierfür so gering ist, werden in der Praxis exorbitant grosse Laufzeiten nicht auftreten. Für Monte-Carlo-Algorithmen gilt ebenfalls, dass die Fehlerwahrschein- lichkeit sehr schnell abnimmt. Allerdings ist nicht immer offensichtlich, wie man das ausnutzen kann. Denn a priori ist nicht klar, wie man einer Ant- wort ansehen kann, ob sie korrekt ist oder nicht. In dem Spezialfall, dass ein Monte-Carlo-Algorithmus nur zwei Werte ausgibt und wir wissen, dass ei- ner dieser Werte immer korrekt ist, können wir jedoch ein ähnliches Prinzip anwenden. Satz 2.74. Sei A ein randomisierter Algorithmus, der immer eine der beiden Antworten Ja oder Nein ausgibt, wobei Pr[A (I) = Ja] = 1 falls I eine Ja-Instanz ist, und Pr[A (I) = Nein] \u0015 ε falls I eine Nein-Instanz ist. Dann gilt für alle δ > 0: bezeichnet man mit A δ den Algorithmus, der A solange aufruft, bis entweder der Wert Nein ausgegeben wird (und A δ dann ebenfalls Nein ausgibt) oder bis N = ε−1 ln δ −1-mal Ja ausgegeben wurde (und A δ dann ebenfalls Ja ausgibt), so gilt für alle Instanzen I Pr[A δ(I) korrekt] \u0015 1 − δ. Beweis. Falls I eine Ja-Instanz ist, wird A (I) = Ja mit Wahrscheinlichkeit 1 gelten, d.h. insbesondere Pr[Aδ(I) korrekt] = 1. Ist I eine Nein-Instanz, dann gibt jeder Aufruf von A mit Wahrscheinlichkeit mindestens ε die Ant- wort Nein. Die Wahrscheinlichkeit, dass unter N = ε −1 ln δ −1 unabhängigen Aufrufen kein einziges Nein ist, ist höchstens (1 − ε)N \u0014 e−εN = e− ln δ−1 = δ, das heisst Pr[Aδ(I) korrekt] \u0015 1 − δ. KAPITEL 2. WAHRSCHEINLICHKEITSTHEORIE 149 Monte-Carlo-Algorithmen, die die Bedingung aus Satz 2.74 erfüllen, nennt man Algorithmen mit einseitigem Fehler, denn sie machen ja nur bei einer der beiden Antworten einen Fehler. Bei Monte-Carlo-Algorithmen mit zweiseitigem Fehler, können wir den Fehler ebenfalls reduzieren, aber nur wenn die Fehlerwahrscheinlichkeit des Algorithmus von Anfang an strikt kleiner als 1/2 ist. Satz 2.75. Sei ε > 0 und A ein randomisierter Algorithmus, der immer eine der beiden Antworten Ja oder Nein ausgibt, wobei Pr[A (I) korrekt] \u0015 1/2 + ε. Dann gilt für alle δ > 0: bezeichnet man mit A δ den Algorithmus, der N = 4ε−2 ln δ −1 unabhängige Aufrufe von A macht und dann die Mehrheit der erhaltenen Antworten ausgibt, so gilt für den Algorith- mus A δ, dass Pr[A δ(I) korrekt] \u0015 1 − δ. Beweis. Wir können annehmen, dass ε \u0014 1/2 ist. Sei X die Anzahl kor- rekter Antworten unter N unabhängigen Aufrufen von A (I). Setzen wir p := Pr[A (I) ist korrekt], so ist X binomialverteilt mit Parametern N und p. Offenbar ist Pr[A δ(I) korrekt] \u0015 Pr[X > N/2] = 1 − Pr[X \u0014 N/2]. Zu beachten ist, dass N/2 viel kleiner ist als der Erwartungswert von X, nämlich ist E[X] = pN \u0015 N/2 + εN, und somit N/2 \u0014 (1 − ε)(N/2 + εN) \u0014 (1 − ε)E[X] (die erste Ungleichung gilt für alle 0 \u0014 ε \u0014 1/2). Daher können wir die Chernoff-Schranken anwenden. Aus E[X] \u0015 N/2 = 2ε−2 ln δ−1 und Satz 2.70 (ii) folgt Pr[X \u0014 N/2] \u0014 Pr[X \u0014 (1 − ε)E[X]] \u0014 e− 1 2 ε2E[X] \u0014 δ, und somit Pr[A δ(I) korrekt] \u0015 1 − δ. Bei randomisierten Algorithmen für Optimierungsprobleme (wie bei- spielsweise beim Berechnen einer möglichst grossen stabilen Menge wie in KAPITEL 2. WAHRSCHEINLICHKEITSTHEORIE 150 Beispiel 2.37) sprechen wir üblicherweise nicht von Fehlerwahrscheinlich- keiten, sondern davon, ob sie das gewünschte Ergebnis erzielen, also bei- spielsweise einen Wert ausgeben der mindestens so gross ist wie der Erwar- tungswert. Auch in diesem Fall funktioniert das Prinzip der unabhängigen Wiederholungen analog: Satz 2.76. Sei ε > 0 und A ein randomisierter Algorithmus für ein Maximierungsproblem, wobei gelte: Pr[A (I) \u0015 f(I)] \u0015 ε. Dann gilt für alle δ > 0: bezeichnet man mit A δ den Algorithmus, der N = ε −1 ln δ−1 unabhängige Aufrufe von A macht und die beste der erhaltenen Antworten ausgibt, so gilt für den Algorithmus A δ, dass Pr[A δ(I) \u0015 f(I)] \u0015 1 − δ. (Für Minimierungsprobleme gilt eine analoge Aussage wenn wir „\u0015 f(I)“ durch „\u0014 f(I)“ ersetzen.) Beweis. Die Wahrscheinlichkeit, dass bei N unabhängigen Aufrufen von A (I) kein einziges Mal ein Wert von mindestens f(I) erzielt wird, ist höch- stens (1 − ε)N \u0014 exp(−εN) = exp(− ln δ −1) = δ. Die Aussage für Minimierungsprobleme folgt analog. In den folgenden Abschnitten geben wir einige Anwendungsbeispiele für randomisierte Algorithmen. 2.8.2 Sortieren und Selektieren Ein klassisches Beispiel für einen Las-Vegas-Algorithmus ist der Quick- Sort Algorithmus, bei dem wir in jedem Schritt das Pivot-Element zu- fällig wählen. Dieser Algorithmus sortiert immer richtig, aber die konkrete Laufzeit hängt von der (zufälligen) Wahl der Pivot-Elemente ab. Wenn wir hierbei viel Pech haben, kann die Laufzeit quadratisch in der Anzahl zu sortierender Elemente sein. Wir wollen in diesem Abschnitt zeigen, dass die Laufzeit in der Regel aber durch O(n ln n) beschränkt sein wird. KAPITEL 2. WAHRSCHEINLICHKEITSTHEORIE 151 Wir wiederholen hier kurz den QuickSort-Algorithmus zur Sortierung einer Folge (A[1], . . . , A[n]). Mit Partition(A, ℓ, r, p) bezeichnen wir eine Prozedur, die für ein ℓ \u0014 p \u0014 r die Elemente A[ℓ], . . . , A[r] mit Hilfe von r − ℓ vielen Vergleichen so umsortiert, dass auf der linken Seite von A[p] die Elemente kleiner als A[p] stehen und auf der rechten Seite die Elemente grösser als A[p]. Das Element A[p] selbst wird dazwischen einsortiert und der Rückgabewert t gibt die entsprechende Position an. Zur Einfachheit nehmen wir hier an, dass die Elemente von A paarweise verschieden sind, sodass dieses t eindeutig definiert ist. QuickSort(A, ℓ, r) 1: if ℓ < r then 2: p ← Uniform({ℓ, ℓ + 1, . . . , r}) ▷ wähle Pivotelement zufällig 3: t ← Partition(A, ℓ, r, p) 4: QuickSort(A, ℓ, t − 1) 5: QuickSort(A, t + 1, r) Die Sortierung von (A[1], . . . , A[n]) erfolgt durch den Aufruf Quick- sort(A, 1, n). Für eine genauere Beschreibung des Algorithmus verweisen wir auf den ersten Teil der Vorlesung. Wir bezeichnen nun mit Tℓ,r die (zufällige) Anzahl an Vergleichen, die bei einem Aufruf QuickSort(A, ℓ, r) ausgeführt werden. Wir wollen zeigen, dass gilt: E[T1,n] \u0014 2(n + 1) ln n + O(n). (2.6) Für ℓ \u0015 r ist Tℓ,r = 0. Für ℓ < r gilt mit Satz 2.32 und der Linearität des Erwartungswerts E(Tℓ,r) = r∑ i=ℓ Pr[t = i] \u0001 (r − ℓ + E[Tℓ,i−1] + E[Ti+1,r]) = 1 r − ℓ + 1 \u0001 r−ℓ∑ i=0 (r − ℓ + E[Tℓ,ℓ+i−1] + E[Tℓ+i+1,r]). Hierbei haben wir benutzt, dass t gleichverteilt auf {ℓ, . . . , r} ist – dies folgt direkt aus der Annahme, dass die Elemente von A verschieden sind. Betrachten wir die eben gezeigte Rekursion nochmals etwas genauer, so sehen wir, dass der Erwartungswert E[Tℓ,r] gar nicht von r und ℓ abhängt, KAPITEL 2. WAHRSCHEINLICHKEITSTHEORIE 152 sondern nur von der Anzahl r − ℓ + 1 der zu sortierenden Elemente. Diese Beobachtung motiviert die folgende rekursive Definition von Zahlen tn: tn = { 0, falls n \u0014 1, und 1 n ∑n−1 i=0 (n − 1 + ti + tn−i−1), falls n \u0015 2. Durch Induktion über r − ℓ sieht man dann leicht, dass für alle ℓ, r die Gleichung E[Tℓ,r] = tr−ℓ+1 gilt. Im Folgenden leiten wir jetzt noch eine obere Schranke für tn her. Für alle n \u0015 3 gilt nach Definition: n \u0001 tn = n−1∑ i=0 (n − 1 + ti + tn−i−1) und ebenso (n − 1) \u0001 tn−1 = n−2∑ i=0 (n − 2 + ti + tn−i−2). Ziehen wir nun die zweite diese Gleichungen von der ersten ab, so erhalten wir: ntn − (n − 1) \u0001 tn−1 = 2(n − 1) + 2tn−1 und daher tn = n + 1 n \u0001 tn−1 + 2(n − 1) n \u0014 n + 1 n \u0001 tn−1 + 2. Nun verwenden wir nochmals Induktion (diesmal über n) um zu zeigen, dass für alle n \u0015 2 gilt: tn \u0014 2 n+1∑ i=3 n + 1 i . Für n = 2 folgt aus der Definition von tn, dass t2 = 1 \u0014 2 = ∑3 i=3 1. Für n \u0015 3 können wir die oben hergeleitete Ungleichung tn \u0014 n+1 n \u0001 tn−1+2 zusammen mit der Induktionsannahme verwenden, um die Gültigkeit der Ungleichung für alle n \u0015 3 nachzurechnen. Wegen ∑n i=1 1 i = Hn = ln n + O(1) gilt somit insbesondere E[T1,n] = tn \u0014 2(n + 1) ln n + O(n), wie in (2.6) behauptet. Zum Abschluss dieses Abschnitts betrachten wir nun noch das soge- nannte Selektionsproblem. Hierbei geht es darum, in einer Folge (A[1], . . . , KAPITEL 2. WAHRSCHEINLICHKEITSTHEORIE 153 A[n]) von paarweise verschiedenen Zahlen den k-te kleinsten Wert zu ermit- teln. Eine Möglichkeit dies zu erreichen, wäre die Folge zunächst zu sortie- ren und dann das k-te Element der sortierten Folge auszugeben. Da wir in Zeit O(n log n) sortieren können, können wir das Selektionsproblem also si- cherlich ebenfalls in Zeit O(n log n) lösen. Der QuickSelect-Algorithmus, den wir nun vorstellen werden, ist aber noch etwas schneller: mit ihm kön- nen wir das Problem in erwartet O(n) Schritten lösen. QuickSelect(A, ℓ, r, k) 1: p ← Uniform({ℓ, ℓ + 1, . . . , r}) ▷ wähle Pivotelement zufällig 2: t ← Partition(A, ℓ, r, p) 3: if t = ℓ + k − 1 then 4: return A[t] ▷ gesuchtes Element ist gefunden 5: else if t > ℓ + k − 1 then 6: return QuickSelect(A, ℓ, t − 1, k) ▷ gesuchtes Element ist links 7: else 8: return QuickSelect(A, t + 1, r, k − t) ▷ gesuchtes Element ist rechts Die Korrektheit des Algorithmus ist leicht einzusehen (Übung!). Wie aber steht es um die erwartete Laufzeit? Wenn wir QuickSelect(A, 1, n, k) ausführen, dann führt das zu einer zufälligen Zahl N an Aufrufen der Form Partition(A, ℓi, ri, p) für eine (ebenfalls zufällige) Folge (ℓ0, r0, k0), (ℓ2, r2, k2), . . . , (ℓN, rN, kN), mit (ℓ0, r0, k0) = (1, n, k). Hierbei ist immer entweder (ℓi+1, ri+1) = (ℓi, t−1) oder (ℓi+1, ri+1) = (t + 1, ri), wobei t eine auf {ℓi, . . . , ri} gleichverteilte Va- riable ist (weil die Element von A paarweise verschieden sind). Die Laufzeit bei einem Aufruf von QuickSelect(A, 1, n, k), gemessen an der Zahl an Vergleichen von Elementen in A, ist nun T = N∑ i=1 (ri − ℓi), weil jeder Aufruf Partition(A, ℓi, ri, p) genau ri − ℓi Vergleiche braucht. Wir definieren nun Nj als die Anzahl der Aufrufe von QuickSelect für die (3/4)jn < ri − ℓi + 1 \u0014 (3/4)j−1n gilt. Dann gilt sicherlich T \u0014 ∞∑ j=1 Nj \u0001 (3/4)j−1n KAPITEL 2. WAHRSCHEINLICHKEITSTHEORIE 154 und wegen der Linearität des Erwartungswertes somit E[T ] \u0014 n \u0001 ∞∑ j=1 E[Nj] \u0001 (3/4)j−1. Was können wir nun über E[Nj] sagen? Dazu überlegen wir uns, dass die Anzahl der zu betrachtenden Elemente sicherlich immer dann von ri −ℓi +1 auf höchstens 3 4 (ri − ℓi + 1) reduziert wird, wenn wir als Pivot-Element eines der mittleren 1 2 (ri − ℓi + 1) Elemente wählen. Mit anderen Worten: bei jeder Wahl eines Pivot-Elementes haben wir eine Wahrscheinlichkeit von mindestens 1/2, dass die Anzahl Elemente um mindestens einen Faktor 3/4 reduziert wird. Also gilt E[Nj] \u0014 2 für alle j \u0015 1 und somit E[T ] \u0014 2n ∞∑ j=1 (3/4)j−1 = 8n. Die erwartete Laufzeit von QuickSelect(A, 1, n, k) ist also in der Tat linear, wie oben behauptet. 2.8.3 Primzahltest In der Kryptographie benötigt man oft sehr grosse Primzahlen. So erfordert zum Beispiel die Generierung eines RSA-Schlüsselpaares die Wahl zweier Primzahlen mit mehreren Tausend Bits. Solche Primzahlen generiert man üblicherweise, indem man zufällig eine Zahl der gegebenen Länge auswählt, und dann überprüft, ob diese tatsächlich prim ist – und die Prozedur, wenn nötig, so lange wiederholt, bis eine Primzahl gefunden ist. Wir wenden uns nun also dem Problem zu, für eine gegebene Zahl n zu überprüfen, ob sie prim ist. Eine naheliegende Methode, dies zu überprüfen, ist alle möglichen Teiler bis p n durchzuprobieren. Dieser Algorithmus ist bei Zahlen mit mehreren Tausend Bits allerdings extrem ineffizient. Wir wollen stattdessen einen Algorithmus, dessen Laufzeit polynomiell in der Länge der Eingabe ist, also polynomiell in ln n. Es gibt mittlerweile deterministische Algorithmen, die in polynomiel- ler Zeit überprüfen, ob die Zahl n prim ist, so zum Beispiel den AKS- Primzahltest. In der Praxis verwendet man aber ausschliesslich rando- misierte Algorithmen, und zwar aus zwei Gründen: Einerseits sind diese Algorithmen immer noch weitaus effizienter, andererseits sind sie viel ein- facher zu implementieren. KAPITEL 2. WAHRSCHEINLICHKEITSTHEORIE 155 Im Folgenden wollen wir die wichtigsten Ideen hinter solch randomi- sierten Primzahltests vorstellen. Sei n die Zahl, von der wir wissen wollen, ob sie prim ist. Eine einfache Idee für einen randomisierten Primzahltest wäre, eine zufällige Zahl a 2 {2, . . . , p n} zu wählen, und zu schauen, ob a ein Teiler von n ist (oder, was ein bisschen cleverer ist, zu schauen, ob der ggT von a und n grösser als 1 ist, was mit dem Euklidschen Algorithmus ebenfalls leicht machbar ist). Ist dies der Fall, so ist n sicher nicht prim – wir können die Zahl a also als Zertifikat dafür ansehen, dass n zusammen- gesetzt ist. Leider ist die Erfolgswahrscheinlichkeit für diesen Algorithmus sehr klein, wenn n eine zusammengesetzte Zahl mit nur wenigen Primfak- toren ist. Ist zum Beispiel n = pq für zwei ähnlich grosse Primzahlen p und q, so erkennt der Algorithmus dies nur mit Wahrscheinlichkeit O(1/p n), und um die Fehlerwahrscheinlichkeit genügend zu reduzieren, wären etwa p n Wiederholungen nötig – das ist nicht besser als die deterministische Brute-Force-Lösung. Jeder randomisierte Primzahltest muss dieses Problem irgendwie um- gehen. Fast alle benutzen dafür folgendes Resultat der elementaren Zah- lentheorie (bekannt aus der Vorlesung Diskrete Mathematik). Satz 2.77 (Kleiner fermatscher Satz). Ist n 2 N prim, so gilt für alle Zahlen 0 < a < n an−1 \u0011 1 mod n. Falls wir für ein gegebenes n also eine Zahl 1 \u0014 a \u0014 n mit der Eigen- schaft an−1 6\u0011 1 (mod n) finden, so ist n sicher nicht prim – ein solches a ist also ebenfalls ein Zertifikat dafür, dass n zusammengesetzt ist. Hierbei ist es noch wichtig, dass wir an−1 mod n auch effizient berechnen können. Dies können wir mit der Methode der binären Exponentiation tun. Ge- nauer: hat die Zahl k Bits, so kann die Berechnung von an−1 mod n in Zeit O(k3) ausgeführt werden. Wie dies geht haben Sie in der Vorlesung Diskrete Mathematik im letzten Semester gesehen. Nun gibt es zusammengesetzte Zahlen n, die sogenannten Carmichael- Zahlen, die die Eigenschaft haben, dass an−1 \u0011 1 (mod n) für alle mit n teilerfremde Zahlen a gilt (die kleinste Carmichael-Zahl ist 561 = 3\u0001 11\u0001 17). Für solche Zahlen n liefert Satz 2.77 also keine Zertifikate, die wir nicht auch durch Ausrechnen des ggT von a und n finden würden. Solche Carmichael- Zahlen sind eher selten, aber es gibt davon unendlich viele, und um einen KAPITEL 2. WAHRSCHEINLICHKEITSTHEORIE 156 effizienten randomisierten Primzahltest zu erhalten, müssen wir unsere Idee eines Zertifikats daher noch ein bisschen verbessern. Die Idee, die wir dazu benutzen, ist folgende: Wenn n eine Primzahl ist, dann bilden die Zahlen 0 \u0014 a < n bezüglich der Addition und Multi- plikation Modulo n bekanntlich einen Körper (siehe die Vorlesung Diskrete Mathematik). Das heisst insbesondere, dass die Kongruenz x2 \u0011 1 (mod n) für 0 \u0014 x < n genau die zwei Lösungen x = 1 und x = n − 1 hat. Diese Idee können wir mit der vorherigen Idee kombinieren. Dazu schrei- ben wir zuerst n − 1 = d2k, wobei d ungerade ist. Ist n prim, dann muss nach Satz 2.77 für jedes beliebige a 2 {1, . . . , n − 1} gelten: an−1 = (ad)2k \u0011 1 (mod n). Dann ist aber wegen der vorhergehenden Beobach- tung entweder (ad)2k−1 \u0011 1 (mod n) oder (ad)2k−1 \u0011 n − 1 (mod n). Durch Iterieren sieht man leicht: entweder gilt für alle 0 \u0014 i \u0014 k die Kon- gruenz (ad)2i \u0011 1 (mod n), oder aber es gibt ein 0 \u0014 i \u0014 k − 1 mit (ad)2i \u0011 n − 1 (mod n). Sind beide Bedingungen verletzt, so sagen wir, dass a ein Zertifikat für die Zusammengesetztheit von n ist. Der folgende Algorithmus folgt genau dieser Idee: er wählt eine zufällige Zahl a 2 {2, 3, . . . , n − 1} und schaut, ob a ein Zertifikat für die Zusammen- gesetztheit von n ist. Miller-Rabin-Primzahltest(n) 1: if n = 2 then 2: return ‘Primzahl’ 3: else if n gerade oder n = 1 then 4: return ‘keine Primzahl’ 5: Wähle a 2 {2, 3, . . . , n − 1} zufällig und 6: berechne k, d 2 Z mit n − 1 = d2k und d ungerade. 7: x ← ad (mod n) 8: if x = 1 or x = n − 1 then 9: return ‘Primzahl’ 10: repeat k − 1 mal 11: x ← x 2 (mod n) 12: if x = 1 then 13: return ‘keine Primzahl’ 14: if x = n − 1 then 15: return ‘Primzahl’ 16: return ‘keine Primzahl’ KAPITEL 2. WAHRSCHEINLICHKEITSTHEORIE 157 Die Laufzeit dieses Algorithmus ist in O(ln n). Ist n prim, so gibt der Algorithmus immer die Antwort ‘Primzahl’. Falls n zusammengesetzt ist, so gibt der Algorithmus die Antwort ‘keine Primzahl’ mit Wahrscheinlichkeit mindestens 3/4. 3 Wir können die Fehlerwahrscheinlichkeit mit Satz 2.74 beliebig klein machen. 2.8.4 Target-Shooting In diesem Abschnitt betrachten wir folgendes Problem: Gegeben eine Men- ge U und eine Untermenge S \u0012 U unbekannter Grösse, wie gross ist der Quotient |S|/|U|? Wir nehmen an, dass wir für S die Indikatorfunktion IS : U → {0, 1} haben, sodass IS(u) = 1 genau dann gilt, wenn u 2 S. Wir betrachten nun folgenden Algorithmus zur Schätzung von |S|/|U|: Für eine geeignete Wahl von N > 0, wähle N Elemente aus U zufällig (d.h. unabhängig und gleichverteilt), und gebe das Verhältnis der gefundenen Elemente in S zu N aus. Man bezeichnet dieses Prinzip auch als Target- Shooting. Target-Shooting 1: Wähle u1, . . . , uN 2 U zufällig, gleichverteilt und unabhängig 2: return N −1 \u0001 ∑N i=1 IS(ui) Dieser Algorithmus beruht auf zwei Annahmen: Erstens muss die In- dikatorfunktion IS effizient berechenbar sein, das heisst, für ein Element u 2 U müssen wir schnell entscheiden können, ob u 2 S ist oder nicht. Zweitens brauchen wir eine effiziente Prozedur, die uns ein uniform zufäl- liges Element aus U gibt. Beispiel 2.78. Sei U = [−1, 1]2 und sei S = {(x, y) 2 R2 | x2 + y2 \u0014 1}. Dann ist bekanntlich π = 4|S|/|U|. Es ist möglich, effizient ein zufälliges Paar (x, y) 2 [−1, 1]2 zu wählen und darauf zu überprüfen, ob es in S liegt (wobei wir vernachlässigen, dass wir uns wegen der endlichen Präzision auf Fliesskommazahlen beschränken müssen). Wir können also versuchen, die Zahl π mittels Target-Shooting zu approximieren. 3Rabin, Michael O., Probabilistic algorithm for testing primality, Journal of Number Theory, 12 (1) (1980) 128–138. KAPITEL 2. WAHRSCHEINLICHKEITSTHEORIE 158 Wir wollen den Target-Shooting-Algorithmus genauer analysieren. Sei dazu für i 2 [N] Yi := IS(ui). Nun sind wegen der unabhängigen und uniformen Wahl der ui die Variablen Y1, . . . , YN unabhängige Bernoulli-Variablen mit Pr[Yi = 1] = |S|/|U| für jedes i = 1, . . . , N. Für die Zufallsvariable Y := 1 N N∑ i=1 Yi = 1 N N∑ i=1 IS(ui) erhalten wir demnach E[Y] = |S|/|U|, unabhängig von der Wahl von N. Die Varianz Var[Y] = 1 N 0 @ |S| |U| − |S| |U| ! 21 A ist ihrerseits durchaus abhängig von N: Sie ist streng monoton fallend in N. Wir erwarten also für grosse N, dass die Ausgabe des Algorithmus mit grosser Wahrscheinlichkeit sehr nah an |S|/|U| ist. Im Folgenden wollen wir dies genauer untersuchen. Sei ε > 0 beliebig klein. Wie gross muss N sein, damit der Algo- rithmus mit Wahrscheinlichkeit mindestens 1/2 eine Antwort im Intervall [(1 − ε)|S|/|U|, (1 + ε)|S|/|U|] ausgibt? Sicherlich muss N von ε abhängen. Andererseits hängt N auch von |S| und |U| ab. Wir betrachten dazu zwei extreme Fälle. Ist U eine sehr grosse endliche Menge und |S| = 1, dann suchen wir sozusagen die Nadel im Heuhaufen: Die Abweichung |Y − E[Y]| kann nur kleiner als εE[Y] sein, wenn Y > 0 ist, d.h. wenn wir mindestens einmal das Element in S auswählen. Damit dies mit Wahrscheinlichkeit mindestens 1/2 geschieht, müssen wir augenscheinlich etwa N = Ω(|U|) Versuche machen. Ein anderer extremer Fall tritt ein, wenn |S| = |U| − 1 ist. In diesem Fall besteht unser Heuhaufen fast nur aus Nadeln, und es gilt Pr[|Y − E[Y]| \u0014 εE[Y]] \u0015 1/2 schon nach einer konstanten Anzahl an Versuchen. Es scheint also, dass N nur von dem Quotienten |S|/|U| abhängt, und zwar müssen wir N grösser wählen, je kleiner dieser Quotient ist. Dies zeigen wir in folgendem Satz: Satz 2.79. Seien δ, ε > 0. Falls N \u0015 3 |U| |S| \u0001 ε−2 \u0001 ln(2/δ), so ist die Ausgabe des Algorithmus Target-Shooting mit Wahrscheinlichkeit KAPITEL 2. WAHRSCHEINLICHKEITSTHEORIE 159 mindestens 1 − δ im Intervall h (1 − ε) |S| |U|, (1 + ε) |S| |U| i . Beweis. Wegen E[Y] = |S|/|U| reicht es zu zeigen, dass Pr h |Y − E[Y]| \u0015 ε \u0001 E[Y]i \u0014 δ gilt. Schreiben wir Z := ∑N i=1 Yi = NY, ist dies äquivalent zu Pr h |Z − E[Z]| \u0015 ε \u0001 E[Z]i \u0014 δ. Da die Yi unabhängige Bernoulli-Variablen sind, können wir die Chernoff- Schranken benutzen. Mit Satz 2.70 (i) und (ii) folgt Pr h |Z − E[Z]| \u0015 ε \u0001 E[Z]i \u0014 2e−ε2E[Z]/3 = 2e−ε2N|S|/(3|U|). Nun ist wegen der Wahl N = 3 |U| |S| \u0001 ε −2 \u0001 ln(2/δ) diese Wahrscheinlichkeit höchstens δ. Beispiel 2.78 (Fortsetzung) Wir wollen π mit 99%iger Wahrscheinlichkeit bis auf die 10te Nachkommastelle genau bestimmen. Wir wählen dazu also δ = 0.01 und ε = 10−10 und sehen, dass wir nach Satz 2.79 mindestens N = 3π−1 \u0001 1020 \u0001 ln 200 viele Versuche machen sollen! Es gibt durchaus bessere Methoden, π zu approximieren. 2.8.5 Finden von Duplikaten In diesem Abschnitt betrachten wir verschiedene Lösungsverfahren für folgendes Problem: Gegeben ein Datensatz S := {s1, . . . sn}, finde Duplikate, d.h. finde ein bzw. alle Paare 1 \u0014 i < j \u0014 n mit si = sj. Wenn die Datensät- ze zum Beispiel in einem Array gespeichert sind und wir dieses verändern dürfen, so könnten wir das Problem dadurch lösen, dass wir das Array sor- tieren und dann aufeinanderfolgende Elemente auf Gleichheit vergleichen. In diesem Abschnitt gehen wir jedoch davon aus, dass wir zwar Zugriff auf den Datensatz haben, wir diesen aber nicht verändern dürfen. Solch eine Annahme ist beispielsweise dann sinnvoll, wenn jeder einzelne Datensatz si sehr gross ist und ein Umsortieren daher mit sehr vielen zeitaufwändigen Speicherzugriffen verbunden wäre. Wir lösen dieses Problem auf zwei Arten, jeweils unter Verwendung von Hashfunktionen. Dafür erinnern wir uns zunächst, was eine Hashfunktion ist. Gilt S \u0012 U, d.h. unser Datensatz ist eine Teilmenge eines sogenannten KAPITEL 2. WAHRSCHEINLICHKEITSTHEORIE 160 Universums U, so ist eine Hashfunktion eine Abbildung h : U → [m], wobei [m] = {1, . . . , m} und m die Anzahl der zusätzlich verfügbaren Spei- cherzellen ist. Wie üblich gehen wir dabei davon aus, dass die Hashfunkti- on h zum einen effizient berechenbar ist und zum anderen die Elemente zufällig verteilt, also für jedes Element u 2 U gilt: Pr[h(u) = i] = 1/m, für alle i 2 [m], wie dies beispielsweise der Fall ist, wenn wir h zufällig aus einer universellen Hashfamilie wählen. Mit solch einer Hashfunktion können wir unser Problem dann zum Beispiel mit einer Hashmap lösen. In dieser speichern wir die Elemente (h(si), i) für alle i 2 {1, . . . , n} und sortieren die Elemente dann bezüglich der ersten Koordinate. Anschliessend müssen wir dann nur noch diejenigen Datensätze auf Gleichheit vergleichen, die identische Einträge in der ersten Koordinate haben. Um die Güte dieses Verfahrens abzuschätzen, müssen wir die erwartete Anzahl Kollisionen bestimmen. Dieser Erwartungswert setzt sich zusammen aus der Anzahl tatsächlicher Duplikate zuzüglich der Anzahl der unbeabsichtigten Kollisionen. Um letztere abzuschätzen, defi- nieren wir für jeden Datensatz si eine Indikatorvariable Xi, die genau dann Eins ist, wenn es eine Kollision mit einem Datensatz sj mit sj 6= si gibt. Um Pr[Xi = 1] abzuschätzen, gehen wir wie folgt vor. Nach Annahme an die Hashfunktion wird jeder Datensatz sj 6= si auf einen zufälligen Wert aus [m] abgebildet. Daher gilt: Pr[Xi = 1] = 1 − (1 − 1 m )n−1 und somit E[Anzahl Kollisionen] \u0014 Anzahl Duplikate + n∑ i=1 E[Xi] \u0014 Anzahl Duplikate + n \u0001 (1 − (1 − 1 m )n−1). Wenn wir daher m so wählen, dass 1 − (1 − 1 m)n−1 = O(1/n) gilt, so er- warten wir nur konstant viele zusätzliche Kollisionen. Dies ist zum Beispiel dann der Fall, wenn wir m = n 2 setzen. In diesem Fall können wir daher alle Kollisionen nach Sortieren der Hashmap durch O(Anzahl Duplikate) Vergleiche der Datensätze bestimmen. Diese Lösung unseres Problems be- nötigt Θ(n(log n + log m)) = Θ(n log n) zusätzlichen Speicher (für das Ab- speichern der Hashmap) und Laufzeit Θ(n log n) (für das Sortieren der Hashmap). KAPITEL 2. WAHRSCHEINLICHKEITSTHEORIE 161 Eine Alternative zur Hashmap sind sogenannte Bloomfilter, die immer dann zum Einsatz kommen, wenn n sehr gross ist und man sich daher die zusätzlichen logarithmischen Faktoren bei Speicher und Laufzeit einsparen möchte. Grundlegende Idee ist hier, nicht nur eine, sondern k viele Hash- funktionen h1, . . . , hk : U → [m] zu verwenden. Als Speicher M verwenden wir m Bits, die wir zu Beginn alle auf Null setzen. Zusätzlich initialisie- ren wir eine Liste L von möglichen Wiederholungen mit L := ; : i 2 [n] heisst Wiederholung in S falls si 2 {s1, . . . , si−1}. Für jeden Datensatz si, 1 \u0014 i \u0014 n, gehen wir dann wie folgt vor: (1) Berechne (x1, . . . , xk) := (h1(si), . . . , hk(si)), (2) gilt (M[x1], . . . , M[xk]) = (1, . . . , 1), so fügen wir i zu L hinzu, anson- sten setzen wir (M[x1], . . . , M[xk]) := (1, . . . , 1). Man kann sich leicht überlegen, dass tatsächlich jede Wiederholung in L landet, wir aber auch falsche Einträge machen. Nachdem wir alle Datensät- ze si auf diese Weise behandelt haben, gehen wir nochmals alle Datensätze si durch und prüfen, ob si = sj für ein j 2 L , j 6= i, gilt. Unser Ziel ist es m und k so zu wählen, dass L mit hoher Wahrscheinlichkeit nur wenige Elemente enthält, sodass sich dann auch dieser zweite Durchlauf effizient durchführen lässt. Um die Güte dieses Verfahrens abzuschätzen, müssen wir ähnlich zu vorhin die erwartete Länge der Liste L bestimmen. Dieser Erwartungs- wert setzt sich zusammen aus der Anzahl tatsächlicher Wiederholungen zuzüglich der sogenannten “false positives ”, nennen wir sie falsche L - Einträge. Dies sind Elemente i 2 L , für die beim Abarbeiten von si bereits M[hj(si)] = 1 für alle 1 \u0014 j \u0014 k gilt, obwohl si noch nicht in (s1, . . . , si−1) aufgetreten ist. Um die Anzahl der falschen L -Einträge abzuschätzen, defi- nieren wir wieder für jeden Datensatz si eine Indikatorvariable Xi, die genau dann Eins ist, wenn M[hj(si)] = 1 für alle 1 \u0014 j \u0014 k gilt. Um Pr[Xi = 1] abzuschätzen, überlegen wir uns zunächst, was die Wahrscheinlichkeit ist, dass ein Bit M[x] noch Null ist, nachdem wir alle von si verschiedenen n−1 Datensätze sj eingefügt haben. Hierfür müssen wir genau n − 1 mal k viele Hashfunktionen auswerten – und jede von ihnen schreibt mit Wahrschein- lichkeit 1/m eine Eins an die Stelle M[x]. Daher gilt: Pr[M[x] = 0] \u0014 (1 − 1 m )k(n−1) KAPITEL 2. WAHRSCHEINLICHKEITSTHEORIE 162 und wir erhalten Pr[Xi = 1] = Pr[M[hj(si)] = 1 für alle 1 \u0014 j \u0014 k] \u0014 (1 − (1 − 1 m )k(n−1))k. Obige Ungleichung gilt streng genommen nur, wenn die einzelnen Bits M[x] unabhängig voneinander Eins wären. Dies sind sie aber nicht. Denn wenn eine Hashfunktion für einen Datensatz sj an der Stelle x eine Eins schreibt, dann kann diese Hashfunktion nicht auch noch an der Stelle x 0 6= x eine Eins schreiben. Man kann zeigen, dass aus dieser Eigenschaft (man sagt hierzu auch: die Bits M[x] sind negativ korreliert) folgt, dass die Ungleichheit in obiger Abschätzung trotz fehlender Unabhängigkeit dennoch gilt. Somit erhalten wir dann: E[#falsche L -Einträge] \u0014 n∑ i=1 E[Xi] \u0014 n \u0001 (1 − (1 − 1 m )k(n−1))k. Wenn wir daher k und m so wählen, dass (1 − (1 − 1 m )k(n−1))k = O(1/n) gilt, so erwarten wir nur konstant viele “false positives”. Etwas Rechnung zeigt, dass wir für k = ln n bereits für m = n ln n nur konstant viele “false positives ” erwarten. Das folgende Beispiel verdeutlicht den Vorteil der Bloomfilter gegenüber der Hashmap für eine konkrete Anwendung. Beispiel 2.80. Wir nehmen an, dass unser Datensatz aus n = 107 Einträgen besteht und nur ein einziges Duplikat enthält. Dieses möchten wir effizient bestimmen. Verwenden wir eine Hashmap, so können wir die erwartete Anzahl Kollisionen durch n \u0001 (1 − 1/m)n−1 abschätzen. Um diesen Wert für n = 107 auf Eins zu reduzieren müssen wir m ˇ 1014 wählen. Da jeder Eintrag in der Hashmap aus d log2 ne + d log2 me vielen Bits besteht, benötigen wir daher etwa 7.1 \u0001 108 viele Bits. Wählen wir stattdessen einen Bloomfilter mit k = d ln ne , so benötigen wir lediglich m = 3.5 \u0001 108 viele Bits an Speicher, um die erwartete Anzahl Kollisionen ebenfalls auf 1 zu reduzieren. Beachte: die Laufzeit ist beim Bloomfilter dann, wie auch wie auch bei der Hashmap, θ(n log n), da wir pro Datensatz k = Θ(log n) viele Hashfunktionen auswerten müssen. Wollen wir die Laufzeit auf O(n) reduzieren, können wir beispielsweise k = 3 wählen. Der Speicherbedarf ist dann mit etwa 6.4 \u0001 109 jedoch deutlich grösser. Wir beenden diesen Abschnitt mit einer Variante des Problems, die zwar in dieser Form keine unmittelbare praktische Bedeutung hat – aber zeigt, was für überraschende Dinge man mit einer guten algorithmischen Herangehensweise erzielen kann. Der Algorithmus den wir hier vorstellen werden, ein nach Robert Floyd benannter Algorithmus für das Auffinden von Kreisen in gerichteten Graphen, kommt in verschiedenen Varianten in KAPITEL 2. WAHRSCHEINLICHKEITSTHEORIE 163 ganz unterschiedlichen Bereichen der Informatik zum Einsatz. Wir schauen uns hier eine idealisierte Version an: Gegeben ein Array a[1, . . . , n], wobei a[i] 2 {1, . . . , n − 1}. Entwerfe Sie einen Algorithmus, der in Laufzeit O(n) zwei Indizes i 6= j findet mit a[i] = a[j]. Der Algorithmus darf dabei das Array a nicht verändern, er kann aber beliebig oft auf die Elemente a[i] zugreifen. Weiterhin darf der Algorithmus nur O(1) zusätzliche Speicherzellen benutzen. Wir empfehlen dem Leser an dieser Stelle erst einmal nicht weiter zu lesen, sondern zu versuchen selbst eine Lösung zu finden. – Für diejenigen, die jetzt neugierig geworden sind, kommt hier nun die Lösung. Zunächst formulieren wir die Aufgabenstellung etwas um. Dazu definieren wir uns einen gerichteten Graphen D = (V, A) wie folgt. Als Knotenmenge wählen wir V = [n] und als Kantenmenge A = {(i, a[i]) | 1 \u0014 i \u0014 n}. Was können wir über diesen Graphen sagen? Aus der Definition folgt unmittelbar, dass jeder Knoten genau eine ausgehende Kante hat. Aus der Aufgabenstellung folgt zusätzlich, dass der Knoten n keine eingehende Kante hat. Wir be- trachten jetzt den Subgraphen, den wir erhalten in dem wir ausgehend von Knoten n immer die ausgehende Kante weiterverfolgen. Da n keine einge- hende Kante besitzt, besteht dieser Subgraph aus einem Pfad und einem anschliessenden Kreis. Nehmen wir an, der Pfad besteht aus k \u0015 1 Kanten und der Kreis aus ℓ \u0015 3 Kanten. Wobei sicherlich k+ℓ \u0014 n gilt. Wir wählen nun ein 0 \u0014 r < ℓ und s \u0015 1 mit k + r = sℓ. (Beachte: für k \u0014 ℓ können wir s = 1 wählen, für k > ℓ nehmen wir s = d k/ℓe .) Definieren wir jetzt eine Folge von Knoten wie folgt: x0 := n und xi := a[xi−1] für alle i \u0015 1, so überlegt man sich schnell, dass xk+r = x2(k+r) gelten muss. Insbesondere gibt es also ein i \u0014 n mit xi = x2i. Ein solches können wir mit einem soge- nannten Hase-und-Igel Ansatz in linearer Zeit unter Verwendung von nur KAPITEL 2. WAHRSCHEINLICHKEITSTHEORIE 164 drei Variablen berechnen: igel = a[n]; hase := a[a[n]]; i := 1 while (igel 6= hase) igel = a[igel]; hase := a[a[hase]]; i := i + 1 Jetzt haben wir also ein 1 \u0014 i < n mit xi = x2i. Es ist auch nicht schwer, sich zu überlegen, dass i = k + r gelten muss, mit r wie oben definiert. Daraus folgt dann sehr einfach, dass xk = xi+k gelten muss. Wir können also das k bestimmen in dem wir den Igel weiterlaufen lassen und den Hasen zurück auf den Ausgangspunkt n setzen und ihn dieses Mal nur mit der Geschwindigkeit des Igels laufen lassen. Wenn wir uns dabei noch die jeweiligen Vorgängerknoten merken, so haben wir die gesuchten Indizes i 6= j mit a[i] = a[j] gefunden, sobald Hase und Igel wieder auf dem gleichen Knoten stehen: hase = n; while (igel 6= hase) i := igel; j := hase; igel = a[igel]; hase := a[hase]; return i, j Wir können also in der Tat die gesuchten Indizes in linearer Zeit unter Verwendung von nur vier zusätzlichen Speicherplätzen bestimmen. Kapitel 3 Algorithmen - Highlights 3.1 Graphenalgorithmen 3.1.1 Lange Pfade Neben kürzesten Wegen (oder Pfaden) ist es natürlich, auch nach einem längsten Pfad zwischen zwei Knoten in einem Graph zu fragen, oder ein- fach nach einem längsten Pfad in einem Graph. Wir betrachten hier die Entscheidungsvariante des Problems. Das Problem. Gegeben (G, B), G ein Graph und B 2 N0, stelle fest ob es einen Pfad der Länge B in G gibt. Wir nennen das das LONG-PATH Problem. Zur Erinnerung: Ein Pfad der Länge ℓ in einem Graph G = (V, E) ist eine Folge h v0, v1, . . . , vℓi von paarweise verschiedenen Knoten, mit {vi−1, vi} 2 E für i = 1, 2, . . . ℓ. Beachte, dass ℓ + 1 Knoten auf einem Pfad der Länge ℓ liegen. Das Problem ist vermutlich schwer Wir haben schon von einer Theorie (N P -Vollständigkeit) gehört, die ver- muten lässt, dass es keinen Polynomialzeit-Algorithmus gibt, der entschei- det, ob in einem gegebenen Graph ein Hamiltonkreis existiert. Wir wollen nun folgende Aussage zeigen: wenn das Hamiltonkreisproblem schwer ist (was zumindest plausibel ist), dann ist auch das LONG-PATH Problem schwer. 165 KAPITEL 3. ALGORITHMEN - HIGHLIGHTS 166 Dazu zeigen wir, dass wir für jeden Graph G mit n Knoten effizient einen Graph G 0 mit n 0 \u0014 2n − 2 Knoten konstruieren können, sodass G einen Hamiltonkreis hat gdw.1 G 0 einen Pfad der Länge n hat. Wähle dazu in G einen beliebigen Knoten v aus, entferne erst v und ersetze die zu v inzidenten Kanten {v, w1}, {v, w2}, . . . {v, wdeg(v)} durch Kan- ten { cw1, w1}, { cw2, w2}, . . . { ̂wdeg(v), wdeg(v)}, wobei cw1, cw2, . . . , ̂wdeg(v) neue Knoten sind. Das ist nun der obengenannte Graph G 0 , offensichtlich mit (n − 1) + deg(v) \u0014 2n − 2 Knoten; die Knoten cw1, cw2, . . . , ̂wdeg(v) haben alle Grad 1 in G 0 . Die Behauptung ist nun, dass G einen Hamiltonkreis hat gdw. G 0 einen Pfad der Länge n hat. (i) Sei h v1, v2, v3, . . . , vn, v1i ein Hamiltonkreis in G. O.B.d.A.2 sei v1 = v, der in unserer Konstruktion entfernte Knoten („O.B.d.A.“, weil wir jeden Kreis beim Knoten unserer Wahl in der Darstellung beginnen lassen kön- nen). Dann ist aber h cv2, v2, v3, . . . , vn, cvni ein Pfad der Länge n in G 0 . (ii) Sei nun h u0, u1, . . . , uni ein Pfad der Länge n in G 0 . Man beachte, dass alle Knoten u1, u2, . . . , un−1 Grad mindestens Grad 2 in G 0 haben, das müssen also genau die n − 1 überlebenden Knoten von G sein, und folglich sind u0 = cwi und un = cwj zwei verschiedene der neuen Knoten mit Grad 1 in G 0 . Daher muss u1 = wi und un−1 = wj sein und h v, u1, . . . , un−1, vi ist ein Hamiltonkreis in G. Wir können G 0 aus G sicherlich in O(n 2) Schritten erzeugen. Es gilt daher: Satz 3.1. Falls wir LONG-PATH für Graphen mit n Knoten in t(n) Zeit entscheiden können, dann können wir in t(2n − 2) + O(n 2) Zeit entscheiden, ob ein Graph mit n Knoten einen Hamiltonkreis hat. Mit anderen Worten: Können wir LONG-PATH in polynomieller Zeit lösen ist, ein Brief an das Clay Mathematics Institute3 fällig. 1genau dann wenn 2Ohne Beschränkung der Allgemeinheit 3Das Clay Mathematics Institute bietet eine Million US$ für einen polynomiellen Al- KAPITEL 3. ALGORITHMEN - HIGHLIGHTS 167 Kurze lange Pfade In einer biologischen Anwendung geht es genau darum, in einem Graph lange Pfade zu finden (Knoten sind Proteine und Kanten stellen Wechsel- wirkungen dar 4). Dabei gibt es aber typischerweise im Vergleich zur Grösse des Graphs keine wirklich langen Pfade. Wir könnten uns also fragen, ob das LONG-PATH Problem bei Eingabe (G, B), mit B klein im Vergleich zu n, immer noch schwer ist oder eventuell in polynomieller Zeit lösbar ist. Diese Frage war für B = log n einige Zeit offen, bis tatsächlich ein poly- nomieller Algorithmus mit einer sehr eleganten randomisierten Methode – Color Coding – gefunden wurde 5. Wir wollen dieses Verfahren jetzt ken- nenlernen. Hilfsmittel. Als erstes werden wir aber ein paar Notationen und einfache Hilfsmittel rekapitulieren, damit wir sie später griffbereit haben, wenn an- deres unsere Aufmerksamkeit erfordert. • [n] := {1, 2, . . . , n}; [n]k ist die Menge der Folgen über [n] der Länge k, es gilt \f \f \f [n]k\f \f \f = n k; \u0010 [n] k \u0011 ist die Menge der k-elementigen Teilmengen von [n] und es gilt \f \f \f \u0010 [n] k \u0011 \f \f \f = \u0010 n k \u0011 . • Für jeden Graph G = (V, E) gilt ∑ v2 V deg(v) = 2|E|. • Die k Knoten auf einem Pfad der Länge k − 1 kann man mit [k] auf genau kk Arten färben6, k! dieser Färbungen nutzen jede Farbe genau einmal; (das ist natürlich für jede Menge von k Knoten so, unabhängig davon, ob sie einen Pfad bilden). • Für c, n 2 R +, gilt c log n = n log c. Also, z.B. 2log n = n log 2 = n und 2O(log n) = n O(1) ist immer polynomiell in n. gorithmus für das Hamiltonkreis Problem, oder für einen Beweis, dass dies nicht möglich ist („P vs NP Problem“). 4J. Scott, T. Ideker, R.M. Karp, R. Sharan, Efficient algorithms for detecting signaling pathways in protein interaction networks Proceedings of RECOMB (2005) 1-13; B. Kelley, R. Sharan, R. Karp, et al.: Conserved pathways within bacteria and yeast as revealed by global protein network alignment. Proc. Natl. Acad. Sci. USA 100 (2003) 11394-11399. 5N. Alon, R. Yuster, U. Zwick, Color-coding, Journal of the ACM, 42 (4) (1995) 844- 856. 6Wir sprechen hier von beliebigen Färbungen (nicht nur in irgendeiner Weise zulässi- gen), z.B. können alle Knoten gleich gefärbt werden! KAPITEL 3. ALGORITHMEN - HIGHLIGHTS 168 • Für n 2 N0 gilt ∑n i=0 \u0010 n i \u0011 = 2n, eine Anwendung des Binomialsatzes: ∑n i=0 \u0010 n i \u0011 xiyn−i = (x + y)n. • Für n 2 N0 gilt n! nn \u0015 e−n, was man leicht der Potenzreihenentwick- lung der Exponentialfunktion ablesen kann: en = ∞∑ i=0 n i i! \u0015 n n n! (der Term in der Summe für i = n) • Wiederholt man ein Experiment mit Erfolgswahrscheinlichkeit p so- lange, bis man Erfolg hat, dann ist der Erwartungswert der Anzahl der Versuche 1 p (geometrische Verteilung Geo(p)). Das haben wir u.a. gerade bei der Diskussion von Monte Carlo Algorithmen wieder gese- hen. Bunte Pfade Wir gehen einen Umweg 7 und untersuchen erst eine Variante des Problems. Dazu betrachten wir einen mit k Farben gefärbten Graphen, d.h. G = (V, E) mit einer Abbildung γ : V → [k]. Ein Pfad in G heisst nun bunt, wenn alle Knoten auf dem Pfad verschiedene Farben haben. Wir beschreiben nun einen Algorithmus, der entscheidet, ob es in G einen bunten Pfad der Länge k−1 gibt (es müssen auf dem Pfad also alle k Farben genau einmal zu finden sein). Dazu definieren wir für v 2 V und i 2 N0 die Menge Pi(v) := { S 2 [k] i + 1 ! \f \f \f \f \f 9 in v endender genau mit S gefärbter bunter Pfad } ; Pi(v) enthält also eine Menge S von i + 1 Farben gdw. es einen bunten Pfad mit Endknoten v gibt, dessen Farben genau die Farben in S sind. Beachte, ein solcher Pfad muss immer die Länge genau i haben. Auch muss jedes S 2 Pi(v) natürlich die Farbe γ(v) von v enthalten. Können wir die Menge Pk−1(v) für jedes v 2 V berechnen, so ist unser Problem gelöst weil 9 bunter Pfad der Länge k − 1 ⇐⇒ [ v2 V Pk−1(v) 6= ; . 7Sehr passend beim Thema lange Pfade. KAPITEL 3. ALGORITHMEN - HIGHLIGHTS 169 Offensichtlich gilt P0(v) = {{γ(v)}} und P1(v) = {{γ(x), γ(v)} | x 2 N(v) und γ(x) 6= γ(v)}. Allgemein bekommen wir eine Menge S = R . [ {γ(v)} in Pi(v) gdw. wir einen genau mit R gefärbten bunten Pfad (der Länge |R| − 1) zu einem Nachbarn x von v finden. Das können wir als Formel schreiben: Pi(v) = [ x2 N(v) {R [ {γ(v)} | R 2 Pi−1(x) und γ(v) 62 R} Als Algorithmus liest sich diese Relation wie folgt: Bunt(G, i) 1: for all v 2 V do 2: Pi(v) ← ; 3: for all x 2 N(v) do 4: for all R 2 Pi−1(x) mit γ(v) 62 R do 5: Pi(v) ← Pi(v) [ {R [ {γ(v)}} Wir berechnen also, ausgehend von den Mengen P0(v) (für alle v 2 V), sukzessive in k − 1 Runden die Mengen P1(v), v 2 V, bis zu den Mengen Pk−1(v), v 2 V. Jede Menge in Pi−1(v) hat genau i Elemente und wegen Pi−1(v) \u0012 \u0010 [k] i \u0011 gilt sicherlich |Pi−1(v)| \u0014 \u0010 k i \u0011 . Folglich können wir die i-te Runde (d.h. Bunt(G, i), wo wir die Pi’s aus den Pi−1’s berechnen) in Zeit O 0 B B @ 2m ︷ ︸︸ ︷∑ v2 V deg(v) \u0001 k i ! \u0001 i 1 C C A = O k i ! \u0001 i \u0001 m ! bewältigen (wobei m die Anzahl der Kanten in G ist; der Faktor „i“ be- rücksichtigt, dass wir für jedes R 2 Pi−1(x) prüfen müssen, ob γ(v) 62 R gilt). Insgesamt, über alle k − 1 Runden, ergibt das O 0 @ k−1∑ i=1 k i ! im 1 A = O(2kkm). Hier haben wir erst den Faktor i durch k abgeschätzt, dann den Faktor km herausgehoben, und schliesslich ∑k−1 i=1 \u0010 k i \u0011 \u0014 ∑k i=0 \u0010 k i \u0011 = 2k abgeschätzt. KAPITEL 3. ALGORITHMEN - HIGHLIGHTS 170 Wir haben es tatsächlich geschafft für k = O(log n) einen polynomiel- len Algorithmus zu entwerfen und zu analysieren, allerdings nur für bunte Pfade. Wie wenden wir das aber jetzt für unser ursprüngliches farbloses LONG-PATH Problem an? Auf gut Glück – Zufallsfärbungen Wir haben also jetzt einen Graph G mit B 2 N0 gegeben und wollen ent- scheiden, ob es in G einen Pfad der Länge B gibt. Dazu färben wir die Knoten zufällig mit den Farben [k], wobei k := B + 1, und prüfen, ob es einen bunten Pfad der Länge k − 1 gibt. Natürlich, wenn es dann einen bunten Pfad der Länge k − 1 gibt, dann haben wir definitiv einen Pfad der Länge B = k − 1 und wir können das so behaupten. Andererseits, wenn es in G einen Pfad der Länge k − 1 gibt, dann können wir Glück haben, ein solcher Pfad wird bunt gefärbt und unser Algorithmus wird diesen dann auch finden. Oder wir können Pech haben, und kein Pfad der Länge k − 1 wird bunt gefärbt. Was ist die Wahrscheinlichkeit, dass wir Glück haben? Zum Zwecke der Analyse nehmen wir an, G enthält einen Pfad der Länge k − 1. Sei P ein solcher Pfad. Dann gibt es kk mögliche Färbungen von P mit k Farben, in k! davon ist der Pfad bunt. Folglich gilt für die Erfolgswahrscheinlichkeit pErfolg := Pr[9 bunter Pfad der Länge k − 1] \u0015 Pr[P ist bunt] = k! kk \u0015 e−k; hier setzen wir ein weiteres der bereit gestellten Hilfsmittel ein. Wir erhalten nun leicht (mit Blick auf die geometrische Verteilung): Satz 3.2. Sei G ein Graph mit einem Pfad der Länge k − 1. (1) Eine zufällige Färbung mit k Farben erzeugt einen bunten Pfad der Länge k − 1 mit Wahrscheinlichkeit pErfolg \u0015 e−k. (2) Bei wiederholten Färbungen mit k Farben ist der Erwartungs- wert der Anzahl Versuche, bis man einen bunten Pfad der Länge k − 1 erhält 1 pErfolg \u0014 ek. Wir können jetzt leicht einen Monte Carlo Algorithmus bauen, der unser Problem in polynomieller Zeit löst. Dazu wählen wir ein λ 2 R, λ > 1, und KAPITEL 3. ALGORITHMEN - HIGHLIGHTS 171 wiederholen unseren Test höchstens l λe km mal, bis wir eine Bestätigung haben, dass es einen Pfad der Länge k − 1 gibt. Gelingt dies, antworten wir Ja; scheitern wir in allen Versuchen, antworten wir Nein. Satz 3.3. (1) Der Algorithmus hat eine Laufzeit von O(λ(2e)kkm). (2) Antwortet der Algorithmus mit Ja, dann hat der Graph einen Pfad der Länge k − 1. (3) Hat der Graph einen Pfad der Länge k − 1, dann ist die Wahr- scheinlichkeit, dass der Algorithmus mit Nein antwortet, höch- stens e−λ. Teil (3) folgt dabei aus der uns bekannten Ungleichung 8 x 2 R : 1 + x \u0014 ex, denn die Wahrscheinlichkeit, dass der Algorithmus mit Nein antwortet, ist (mit x = e−k) höchstens \u0010 1 − e−k\u0011 d λeke \u0014 \u0010 e−e−k \u0011 d λeke \u0014 e−λ. Es handelt sich also um einen Monte Carlo Algorithmus, der mit Wahr- scheinlichkeit von mindestens 1 − e−λ die korrekte Antwort liefert (mit ein- seitigem Fehler). Man beachte, dass wir hier das Argument von Satz 2.74 wiederholt haben, bzw. diesen Satz mit ε = e−k und δ = e−λ hätten ver- wenden können. Anmerkungen. (1) Es gibt eine deterministische Variante, die das Problem für B = O(log n) in Polynomialzeit löst. (2) Es gibt eine randomisierte Verbesserung,8 die in Zeit O(2kpoly(n)) läuft (statt O((2e)kpoly(n)). (3) Wenn man neben der Existenz eines Pfades der Länge k − 1 einen solchen Pfad tatsächlich finden will, so kann man den Algorithmus oben leicht in die Richtung adaptieren. Man merkt sich dazu einfach zu jedem S 2 Pi(v) eine 8R. Williams, Finding paths of length k in O\u0003 (2k) time, Information Processing Letters 109:6 (2009) 315-318. KAPITEL 3. ALGORITHMEN - HIGHLIGHTS 172 Realisierung, d.h. einen genau mit S gefärbten bunten Pfad h u0, u1, . . . , uii , ui = v, der Länge i nach v. (4) Das Problem wird einfach in gerichteten azyklischen Graphen: Man gewich- tet alle Kanten einfach mit -1 und berechnet kürzeste Pfade (siehe z.B. die Algorithmen und Datenstruktur-Vorlesung im Herbst). 3.1.2 Flüsse in Netzwerken Maximale Flüsse in Netzwerken sind ein klassisches Beispiel der Algorith- mik und Diskreten Mathematik mit zahlreichen Anwendungen in Wissen- schaft und Praxis, z.B. in der Verkehrsplanung, beim data mining, in der Bildverarbeitung, etc. Die Berechnung eines maximalen Flusses in einem Netzwerk ist eines der schwierigsten Probleme, die „noch“ effizient (in po- lynomieller Zeit) lösbar sind. In diesem Abschnitt konzentrieren wir uns auf die Modellierung des Problems, den Zusammenhang mit dem Problem minimaler Schnitte sowie zwei Beispielen, wie man andere Probleme mit Hilfe von Netzwerkflüssen lösen kann. Modellierung Wir stellen uns ein verzweigtes Netzwerk von Röhren unterschiedlicher Dicke vor, in das man an einer Stelle Flüssigkeit zuführen kann, die an ei- ner anderen Stelle entweichen kann. Der Elektrotechniker denkt vielleicht eher an ein System von Leitungen unterschiedlichen Widerstands, durch die Strom fliesst. Und der Verkehrsplaner denkt an ein System von Stras- sen verschiedener Breite, über die Verkehr fliesst (es kann auch so etwas wie Einbahnen geben). Uns interessiert, wie viel Wasser (Strom, Verkehr) pro Zeiteinheit von einem gegebenen Startpunkt zu einem gegebenen Endpunkt fliessen kann. Ein solches System abstrahieren (bzw. modellieren)9 wir wie folgt. Definition 3.4. Ein Netzwerk ist ein Tupel N = (V, A, c, s, t), wobei gilt: 9Wir abstrahieren, um das Problem des Elektrotechnikers, Verkehrsplaners, etc. in einem Modell lösen zu können, wir modellieren, um die Probleme exakt (und in einem falsifizierbaren Kontext) lösen zu können. KAPITEL 3. ALGORITHMEN - HIGHLIGHTS 173 (V, A) ist ein gerichteter Graph, s 2 V, die Quelle (engl.: source), t 2 V \\ {s}, die Senke (engl.: target), und c : A → R+ 0 , die Kapazitätsfunktion (engl.: capacity function). Die Kapazitätsfunktion beschränkt, wie viel durch eine Kante fliessen kann (und wir sehen, dass wir schon Fluss nur in eine Richtung vorgesehen haben). Für einen Fluss gibt es eine einfache allgemeine Bedingung, die sich aus der Tatsache ergibt, dass das System abgesehen von Quelle und Senke abgeschlossen ist und deswegen in einem inneren Knoten weder Fluss entstehen noch verschwinden kann. In der Elektrotechnik kennt man diese Eigenschaft als erstes Kirchhoff’sches Gesetz (Gustav Robert Kirch- hoff, 1824, Königsberg, –1887, Berlin): „Die Summe der zufliessenden Ströme in einem elektrischen Knotenpunkt ist gleich der Summe der abfliessenden Ströme.“ Diese Eigenschaft lassen wir in die Definition des Flusses in einem Netz- werk eingehen. Definition 3.5. Gegeben sei ein Netzwerk N = (V, A, c, s, t). Ein Fluss in N ist eine Funktion f : A → R mit den Bedingungen 0 \u0014 f(e) \u0014 c(e) für alle e 2 A, die Zulässigkeit, und für alle v 2 V \\ {s, t} gilt ∑ u2 V: (u,v)2 A f(u, v) = ∑ u2 V: (v,u)2 A f(v, u) die Flusserhaltung. Der Wert (engl.: value) eines Flusses f ist durch val(f) := netoutflow(s) := ∑ u2 V: (s,u)2 A f(s, u) − ∑ u2 V: (u,s)2 A f(u, s) definiert. Wir nennen f ganzzahlig, wenn f(e) 2 Z 8 e 2 A. In unserem Modell besagt der Wert eines Flusses also, wie viel Flüssig- KAPITEL 3. ALGORITHMEN - HIGHLIGHTS 174 s t a b c 5 6 1 7 2 2 6 1 s t a b c 3 5 1 7 1 2 6 1 Abbildung 3.1: Ein Netzwerk und ein Fluss mit Wert 3 − 1 + 5 = 7. keit „netto“ von der Quelle in das System fliesst. Wenn unsere Modellierung vernünftig ist, sollte folglich dieselbe Menge an Flüssigkeit an der Senke an- kommen und das System verlassen. Das lässt sich nun auch mathematisch beweisen (was unsere Modellierung bekräftigt). Lemma 3.6. Der Nettozufluss der Senke gleicht dem Wert des Flusses, d.h. netinflow(t) := ∑ u2 V: (u,t)2 A f(u, t) − ∑ u2 V: (t,u)2 A f(t, u) = val(f) . Beweis. Es gilt 0 = ∑ (v,u)2 A f(v, u) − ∑ (u,v)2 A f(u, v) (3.1) = ∑ v2 V 0 B @ ∑ u2 V: (v,u)2 A f(v, u) − ∑ u2 V: (u,v)2 A f(u, v) 1 C A ︸ ︷︷ ︸ =0 für v62 {s,t} (3.2) = 0 B @ ∑ u2 V: (s,u)2 A f(s, u) − ∑ u2 V: (u,s)2 A f(u, s) 1 C A ︸ ︷︷ ︸ =val(f) + 0 B @ ∑ u2 V: (t,u)2 A f(t, u) − ∑ u2 V: (u,t)2 A f(u, t) 1 C A ︸ ︷︷ ︸ = −netinflow(t) . KAPITEL 3. ALGORITHMEN - HIGHLIGHTS 175 woraus die Aussage unmittelbar folgt. (Die Summe in (3.2) ist nur eine Umordnung der Terme in (3.1).) Das algorithmische Problem ist nun, für ein Netzwerk effizient einen maximalen Fluss zu berechnen, d.h. einen Fluss grösstmöglichen Werts. Schon bei der Problemstellung ist Vorsicht geboten, da es nicht klar ist, dass ein solcher maximaler Fluss existiert: Ähnlich wie das offene Intervall (0, 1) keine grösste Zahl hat, könnte es eine steigende Folge von Werten von Flüssen geben, deren Grenzwert aber nicht dem Wert eines Flusses entspricht. Offensichtlich gibt es im Allgemeinen unendlich viele Flüsse und so ist selbst bei Existenz eines maximalen Flusses dessen Berechenbarkeit nicht offensichtlich. Und schliesslich ist es nicht klar mit welchem Argument man belegen sollte, dass ein Fluss maximal ist, selbst wenn man einen solchen in der Hand haben sollte. Etwas Licht auf diese Fragen wirft die Betrachtung minimaler Schnitte in Netzwerken. Schnitte Teilt man die Knotenmenge eines Netzwerks in zwei Teile S (mit der Quelle) und T (mit der Senke), so muss jeder Fluss von s nach t durch Kanten aus S \u0002 T fliessen. Die Kapazität dieser Kanten sollte also eine Beschränkung für einen Fluss im Netzwerk darstellen. Diese Intuition wollen wir nun modellieren und beweisen. Definition 3.7. Ein s-t-Schnitt für ein Netzwerk (V, A, c, s, t) ist eine Partition (S, T ) von V (d.h. S [ T = V und S \\ T = ; ) mit s 2 S und t 2 T . Die Kapazität eines s-t-Schnitts (S, T ) ist durch cap(S, T ) := ∑ (u,w)2 (S\u0002 T )\\ A c(u, w) definiert (siehe Abbildung 3.2). Lemma 3.8. Ist f ein Fluss und (S, T ) ein s-t-Schnitt in einem Netzwerk KAPITEL 3. ALGORITHMEN - HIGHLIGHTS 176 s t a b c 5 6 1 7 2 2 6 1 S T Abbildung 3.2: Schnitt mit Kapaziät 6 + 2 + 2 = 10. (V, A, c, s, t), so gilt val(f) \u0014 cap(S, T ) . Beweis. Für eine Partition (U, W) von V setzen wir f(U, W) := ∑ (u,w)2 (U\u0002 W)\\ A f(u, w) . Nun behaupten wir val(f) (i) = f(S, T ) − f(T, S) (ii) \u0014 f(S, T ) (iii) \u0014 cap(S, T ), was ja genau die Aussage des Lemmas ergibt. Die Relation (ii) folgt aus der Nichtnegativität des Flusses auf jeder Kante, die Relation (iii) ergibt sich aus der Beschränkung „f(u, w) \u0014 c(u, w)“ für Flüsse. Für den Beweis von (i) kommt uns die Erfahrung aus dem Beweis zu Lemma 3.6 zugute: val(f) = ∑ u2 V: (s,u)2 A f(s, u) − ∑ u2 V: (u,s)2 A f(u, s) = ∑ v2 S 0 B @ ∑ u2 V: (v,u)2 A f(v, u) − ∑ u2 V: (u,v)2 A f(u, v) 1 C A ︸ ︷︷ ︸ =0 für v6=s KAPITEL 3. ALGORITHMEN - HIGHLIGHTS 177 In dieser Summe heben sich die Beiträge aller Kanten (u, w) auf, die beide Endpunkte in S haben. Es bleiben nur die Kanten, die nur ihren Anfangs- punkt in S haben (und die ihren Fluss positiv beitragen) und die Kanten, die ihren Endpunkt in S haben (und ihren Fluss negativ beitragen). Daher können wir wie folgt fortsetzen: = ∑ (u,w)2 (S\u0002 T )\\ A f(u, w) − ∑ (u,w)2 (T \u0002 S)\\ A f(u, w) = f(S, T ) − f(T, S) Das Problem der Berechnung eines minimalen Schnitts scheint fürs er- ste einfacher, als maximale Flüsse zu bestimmen. Jedes Netzwerk hat nur endlich viele s-t-Schnitte (wenn auch exponentiell viele: 2|V|−2), aber so ist auf jeden Fall die Existenz eines minimalen Schnitts gesichert und wir können diesen prinzipiell auch berechnen (wenn auch noch nicht klar ist, wie man das effizient machen sollte). Überraschenderweise sind die beiden betrachteten Probleme äquivalent, wie folgende klassische Dualität zeigt. Satz 3.9 („Maxflow-Mincut Theorem“). Jedes Netzwerk N = (V, A, c, s, t) erfüllt max f Fluss in N val(f) = min (S,T ) s-t-Schnitt in N cap(S, T ) Den Beweis dieses Satzes können wir später nur in abgeschwächter Form liefern. Er geht Hand in Hand mit der algorithmischen Erschliessung des Problems. Augmentierende Pfade Die Grundidee fast aller Algorithmen ist, mit einem beliebigen Fluss zu beginnen (f konstant 0 eignet sich immer), und diesen sukzessive zu verbes- sern. Dazu ein erster Ansatz. Angenommen, wir finden einen gerichteten Pfad P von Quelle zu Senke, wo der Fluss auf allen Kanten die Kapazi- tät noch nicht erschöpft hat, d.h. f(e) < c(e) für alle e auf P. Sei nun δ := mine2 P c(e) − f(e). Wenn wir nun auf allen Kanten auf P den Fluss um δ erhöhen, verletzen wir an keiner Stelle die Flusseigenschaft, und der Wert des Flusses hat sich um δ erhöht. KAPITEL 3. ALGORITHMEN - HIGHLIGHTS 178 So weit, so gut. Allerdings gibt es Flüsse, die sich nach diesem Schema nicht verbessern lassen, obwohl sie nicht optimal sind. Man kann näm- lich die Erhöhung eines Flusses an einer eingehenden Kante eines Knotens nicht nur durch Erhöhung des Flusses an einer ausgehenden Kante kom- pensieren, sondern auch durch Verringerung des Flusses an einer anderen eingehenden Kante. In diesem Sinne kann man nun Pfade von Quelle zu Senke betrachten, auf denen Kanten vorwärts und rückwärts gerichtet sein können. Nehmen wir an, dass wir auf jeder vorwärts gerichteten Kante den Fluss um δ erhöhen können, ohne die Zulässigkeit zu verletzen, und auf je- der rückwärts gerichteten Kante den Fluss um δ verkleinern können, ohne dass dieser negativ wird. Dann können wir entlang dieses Pfades den Fluss entsprechend modifizieren, ohne die Flusserhaltung zu verletzen. Verbessert man einen Fluss sukzessive mittels solcher sogenannter augmentierender Pfade, so kann man nur in maximalen Flüssen stecken bleiben (was man beweisen muss). Das heisst aber nicht, dass man so einen maximalen Fluss in endlich vielen Schritten erreicht (dies gilt interessanterweise nur, wenn die Kapa- zitäten rational sind). Das Restnetzwerk Unser nächstes Ziel ist es nun, die Idee der augmentierenden Pfade algo- rithmisch konkreter zu fassen und einen ersten einfachen Algorithmus zur Berechnung eines maximalen Flusses zu beschreiben. Dazu machen wir eine vereinfachende Annahme: Wir beschränken uns auf Netzwerke ohne ent- gegen gerichtete Kanten, d.h. zwischen zwei Knoten gibt es nie zugleich die beiden Kanten beider Richtungen. Dies dient hier nur zur Vereinfa- chung der Darstellung, man kann das auf verschiedene Arten umgehen, ohne schlechtere Ergebnisse zu bekommen. Die folgende Definition beschreibt für ein Netzwerk mit Fluss f, was relativ zu f der verbleibende Spielraum an einer Kante e ist, d.h. wie viel mehr oder weniger (als f(e)) Fluss man durch diese Kante schicken kann. Dabei bezeichnen wir für eine Kante e = (u, v) die entgegen gerichtete Kante (v, u) mit eopp. Definition 3.10. Sei N = (V, A, c, s, t) ein Netzwerk ohne entgegen ge- KAPITEL 3. ALGORITHMEN - HIGHLIGHTS 179 s t a b c 3 → 4 5 1 7 1 → 2 2 6 1 s t a b c 4 5 → 6 1 7 2 2 6 1 → 0 s t a b c 5 6 1 7 2 2 6 1 Abbildung 3.3: Augmentierende Pfade, der rechte mit rückwärts gerichteter Kante. KAPITEL 3. ALGORITHMEN - HIGHLIGHTS 180 richtete Kanten und sei f ein Fluss in N. Das Restnetzwerk Nf := (V, Af, rf, s, t) ist wie folgt definiert: (1) Ist e 2 A mit f(e) < c(e), dann ist e auch eine Kante in Af, mit rf(e) := c(e) − f(e). (2) Ist e 2 A mit f(e) > 0, dann ist eopp in Af, mit rf(eopp) = f(e). (3) Nur Kanten wie in (1) und (2) beschrieben finden sich in Af. rf(e), e 2 Af, nennen wir die Restkapazität der Kante e. Wir bemerken, dass wir zwar annehmen, dass es in N keine entgegen gerich- teten Kanten gibt, diese dann im Restnetzwerk typischerweise sehr wohl auftreten werden; konkret existiert für eine Kante e 2 A sowohl e als auch eopp in Af, ausser f(e) 2 {0, c(e)}, und dann gilt rf(e) + rf(eopp) = c(e). Die Restkapazitäten aller Kanten in Af sind strikt positiv. Satz 3.11. Ein Fluss f in einem Netzwerk N ist ein maximaler Fluss gdw. es im Restnetzwerk Nf keinen gerichteten Pfad von der Quelle s zur Senke t gibt. Für jeden solchen maximalen Fluss gibt es einen s-t-Schnitt (S, T ) mit val(f) = cap(S, T ). Beweis. Sei N = (V, A, c, s, t). Angenommen, es gibt einen s-t-Pfad P in Nf mit ε der kleinsten auf diesem Pfad auftretenden Restkapazität (es gilt also ε > 0). Dann können wir den Fluss f zu einem Fluss f 0 wie folgt erhöhen. f 0 (e) :=    f(e) + ε e auf P, f(e) − ε eopp auf P, und f(e) sonst. Auf diese Weise kann f 0 nie negativ werden und respektiert immer die Kapazitätsgrenzen. Auch addieren oder substrahieren wir an jedem inneren Knoten den gleichen Wert ε vom Fluss f, so gilt auch die Flusserhaltung weiter. Wir haben so einen neuen Fluss f 0 mit val(f 0 ) = val(f) + ε und f kann also kein maximaler Fluss gewesen sein. Nun gehen wir davon aus, dass Nf keinen Pfad von s nach t erlaubt; wir zeigen, dass es dann einen s-t-Schnitt (S, T ) mit cap(S, T ) = val(f) gibt. Da wir schon wissen (Lemma 3.8), dass kein Fluss die Kapazität eines Schnitts übersteigen kann, muss dann der Fluss f maximal sein. KAPITEL 3. ALGORITHMEN - HIGHLIGHTS 181 Sei S die Menge der in (V, Af) von s aus auf gerichteten Pfaden erreich- baren Knoten und sei T := V \\ S. Es gilt s 2 S, und nach Annahme t 62 S, d.h. (S, T ) ist ein s-t-Schnitt. Ist e = (u, v) 2 A, mit u 2 S und v 62 S, dann gibt es keine Kante in Af von u nach v, was ja heisst, dass f(e) = c(e). Ist e = (v, u) 2 A, mit u 2 S und v 62 S, dann gibt es keine Kante in Af von u nach v, was ja heisst, dass f(e) = 0, sonst wäre (u, v) eine Kante im Rest- netzwerk und wir könnten über u 2 S auch v erreichen. Zusammenfassend, es gilt f(S, T ) = cap(S) und f(T, S) = 0. Es folgt (siehe (i) im Beweis von Lemma 3.8) val(f) = f(S, T ) − f(T, S) = cap(S, T ) − 0 = cap(S, T ) . Algorithmen Wie bereits besprochen, liegt nun ein algorithmischer Ansatz auf der Hand: Suche mit Hilfe des Restnetzwerks augmentierende Pfade, solange es solche gibt. Ford-Fulkerson(V, A, c, s, t) 1: f ← 0 ▷ Fluss konstant 0 2: while 9 s-t-Pfad P in (V, Af) do ▷ augmentierender Pfad 3: Erhöhe den Fluss entlang P ▷ wie in Beweis zu Satz 3.11 4: return f ▷ maximaler Fluss Man ist versucht, zu behaupten, dass der Algorithmus nun laut Satz 3.11 unser Problem löst. Allerdings haben wir nicht sichergestellt, dass der Al- gorithmus jemals zum Ende kommt. Es ist tatsächlich möglich, dass der Algorithmus bei irrationalen Kapazitäten nicht terminiert. Andererseits ist das bei ganzzahligen Kapazitäten nicht möglich: In jedem Schritt erhöhen wir in diesem Fall den Wert des Flusses um einen ganzzahligen Wert, und da der Wert des Flusses nach oben beschränkt ist (z.B. durch cap({s}, V \\ {s})), ist eine Ende sichergestellt. In einem ganzzahligen Netzwerk (ohne entgegen gerichtete Kanten) sei U 2 N eine obere Schranke für die auftretenden Kapazitäten, sei n die Anzahl der Knoten und m die Anzahl der Kanten. Dann sieht man leicht, dass kein Fluss Wert gösser als nU haben kann (val(f) \u0014 cap({s}, V \\ {s}) \u0014 KAPITEL 3. ALGORITHMEN - HIGHLIGHTS 182 nU) , d.h. der Ford-Fulkerson terminiert nach höchstens nU Runden. In einer Runde müssen wir das Restnetzwerk 10 konstruieren und einen Pfad von Quelle zu Senke suchen, das können wir in O(m) Zeit erledigen. Satz 3.12. Sind in einem Netzwerk ohne entgegen gerichtete Kanten alle Kapazitäten ganzzahlig und höchstens U, so gibt es einen ganz- zahligen maximalen Fluss, der in Zeit O(mnU) berechnet werden kann (m ist die Anzahl Kanten, n die Anzahl Knoten im Netzwerk). Man beachte, dass wir jetzt tatsächlich (und erst jetzt!) das Maxflow- Mincut Theorem (Satz 3.9) max f Fluss in N val(f) = min (S,T ) s-t-Schnitt in N cap(S, T ) für Netzwerke ohne entgegen gesetzte Kanten und ganzzahligen Kapazitä- ten bewiesen haben. • Lemma 3.8 zeigt, dass val(f) \u0014 cap(S, T ) für jeden Fluss f und jeden Schnitt (S, T ) gilt. • Lemma 3.11 zeigt, dass, wenn f ein maximaler Fluss ist, dann gibt es einen Schnitt (S, T ) mit cap(S, T ) = val(f). • Der Ford-Fulkerson Algorithmus zeigt, dass es unter den gegebenen Umständen (Ganzzahligkeit, keine entgegen gerichtete Kanten) einen maximalen Fluss gibt. Weiterführende Algorithmen. Es gibt eine reichhaltige Literatur, aus der wir zwei Ergebnisse zitieren: Einerseits kann der U-Faktor bei ganzzahligen Schnitten durch einen Faktor logarithmisch in U ersetzt werden. Ande- rerseits kann man im Einheitskostenmodell einen maximalen Fluss auch unabhängig von der Grösse der Zahlen, selbst bei reelen Zahlen, schnell berechnen. 10Tatsaächlich werden wir das Restnetzwerk nicht immer neu konstruieren, sondern schrittweise entlang des gewählten augmentierenden Pfades ändern. KAPITEL 3. ALGORITHMEN - HIGHLIGHTS 183 Proposition 3.13 (Capacity-Scaling, Dinitz-Gabow, 1973). Sind in ei- nem Netzwerk alle Kapazitäten ganzzahlig und höchstens U, so gibt es einen ganzzahligen maximalen Fluss, der in Zeit O(mn(1 + log U)) berechnet werden kann (m Anzahl Kanten, n Anzahl Knoten). Proposition 3.14 (Dynamic Trees, Sleator-Tarjan, 1983). Der maxima- le Fluss eines Netzwerks kann in Zeit O(mn log n) berechnet werden (m Anzahl Kanten, n Anzahl Knoten). Offensichtlich ist die erste Schranke besser, wenn U klein ist (U = o(n)). Wir werden gleich eine Anwendung sehen, in der alle Kapazitäten 1 sind (also U = 1). Man beachte, dass nach Satz 3.9 die entsprechenden Schran- ken auch für die Berechnung eines minimalen s-t-Schnitts gelten. Bipartites Matching als Flussproblem Sei G = (V, E) ein bipartiter Graph, d.h. es gibt eine Partition (U, W) von V, sodass E \u0012 {{u, w} | u 2 U, w 2 W}. Wir interessieren uns für ein Matching maximaler Grösse in G. Dazu definieren wir ein Netzwerk N = (V . [ {s, t}, A, c, s, t). Die Kno- tenmenge besteht also aus den Knoten V von G und zwei neuen Knoten s und t, die die Rolle von Quelle bzw. Senke in N spielen. Die Kapazitäts- funktion c ist konstant 1. Die Kanten aus E werden übernommen, immer von U nach W gerichtet. Ausserdem hat s Kanten zu allen Knoten in U; zu t fügen wir Kanten von allen Knoten in W ein. Formal setzen wir A := ({s} \u0002 U) [ {(u, w) 2 U \u0002 W | {u, w} 2 E} [ (W \u0002 {t}) . Wir betrachten nun einen ganzzahligen Fluss f auf diesem Netzwerk und beachten, dass alle Kapazitäten 1 sind. Für jeden Knoten u aus U gibt es nur eine eingehende Kante, also fliesst höchstens Fluss 1 in diesen Knoten und folglich kann aus u auch höchstens Fluss 1 zu Knoten aus W fliessen, d.h. höchstens eine ausgehende Kante kann positiven Fluss haben. Ähnlich kann in jeden Knoten aus W höchstens Fluss 1 fliessen, weil es nur eine ausgehende Kante (nach t) gibt. Wir haben uns gerade überzeugt, dass die Kanten mit Fluss 1 zwischen U und W ein Matching auf U [ W KAPITEL 3. ALGORITHMEN - HIGHLIGHTS 184 U W s t bilden müssen. Die Grösse dieses Matchings ist genau der Wert val(f) des Flusses. s t Analog kann man aus einem Matching zwischen U und W mit k Kanten einen Fluss mit Wert k konstruieren. Es gilt also, da es in einem ganzzah- ligen Netzwerk immer einen ganzzahligen maximalen Fluss gibt: KAPITEL 3. ALGORITHMEN - HIGHLIGHTS 185 Lemma 3.15. Die maximale Grösse eines Matchings im bipartiten Graph G ist gleich dem Wert eines maximalen Flusses im Netzwerk N. Kanten- und knotendisjunkte Pfade Im Abschnitt 1.4 haben wir gesehen, dass wir den Grad des Zusammen- hangs eines Graphen (wieviele Knoten bzw Kanten wir entfernen müssen, bis wir einen unzusammenhängenden Graphen erhalten) mit Hilfe des Sat- zes von Menger auch dadurch bestimmen können, dass wir bestimmen, wie viele knoten- bzw kantendisjunkte Pfade es zwischen je zwei Knoten gibt. Damals hatten wir offen gelassen wie man diese Anzahl algorithmisch bestimmen kann. Jetzt, wo wir wissen, wie man maximale Flüsse in Netz- werken bestimmt, scheint das ein viel einfacheres Problem. Betrachten wir einen (ungerichteten) Graphen G = (V, E) und zwei Kno- ten u, v 2 V, u 6= v. Wir wollen bestimmen wieviele intern kanten- (oder knoten-)disjunkte u-v-Pfade es in G gibt. Um dieses Problem mit einem Flussalgorithmus zu lösen, müssen wir zunächst aus dem Graphen G ein Netzwerk N machen. Und hier ergibt sich schon ein erstes Problem: unser Graph G ist ungerichtet, ein Netzwerk N enthält aber gerichteten Kanten. Die Lösung dieses Problems ist aber einfach: Wir ersetzen jede ungerichtete Kante {x, y} 2 E durch zwei gerichtete Kanten (x, y) und (y, x) und geben beiden Kanten eine Kapazität von Eins. Wie können wir sicherstellen, dass ein Fluss wirklich nur eine der beiden Kanten verwendet? Nun ja, a priori können wir das nicht. Aber das ist auch nicht schlimm: Stellen wir uns vor, für einen Fluss f würde gelten f(x, y) = f(y, x) = 1. Anschaulich gespro- chen fliesst dann das, was aus x in Richtung y fliesst, anschliessend wieder zurück zu x. Wir können daher den Fluss f so zu einem Fluss f 0 abändern, dass wir f 0 (x, y) = f 0 (y, x) = 0 setzen und ihn auf allen übrigen Kanten unverändert lassen. Dieser Ansatz funktioniert analog, wenn f(x, y) und f(y, x) beide einen positiven Wert annehmen, der nicht unbedingt Eins ist: Erniedrigen wir den Fluss auf beiden Kanten um das Minimum aus f(x, y) und f(y, x) so ist danach einer der beiden Werte Null. Wir sehen daher: wir dürfen immer annehmen, dass ein Fluss höchstens auf einer der beiden Kanten einen positiven Wert annimmt. 11 11Wir haben hier einfach den Fluss entlang eines (gerichteten) Kreises der Länge zwei reduziert. Dies funktioniert analog auch für gerichtete Kreise beliebiger Länge, in der KAPITEL 3. ALGORITHMEN - HIGHLIGHTS 186 Als letztes fügen wir zu unserem Netzwerk noch zwei neue Knoten s und t hinzu – und verbinden s mit u und v mit t, d.h., wir fügen die beiden gerichteten Kanten (s, u) und (v, t) zu unserem Netzwerk hinzu. Diesen beiden Kanten geben wir eine Kapazität von n = |V|. Abbildung 3.4 zeigt diese Konstruktion an einem einfachen Beispiel. u v a b c u v a b c s t 5/3 5/3 1/1 1/01/01/11/01/1 1/11/11/01/11/0 1/1 1/0 1/0 1/1 Abbildung 3.4: Links ein Graph G = (V, E) mit drei intern kantendisjunkten u-v Pfaden (farbig). Rechts das daraus konstruierte Netzwerk N = (V . [ {s, t}, A, c, s, t); die Zahlen an den Kanten beschreiben wie üblich Kapazität (erste Zahl) und Fluss (zweite Zahl). Der Fluss entspricht genau den drei u-v-Pfaden und entsprechend ist der Wert des Flusses drei. Aus der Konstruktion unseres Netzwerkes folgt unmittelbar, dass die Anzahl intern kantendisjunkter u-v-Pfade genau dem Wert eines maxima- len Flusses entspricht, vgl. Abbildung 3.4. Wie aber sieht es aus, wenn wir nicht kantendisjunkte, sondern knotendisjunkte Pfade finden wollen? Hier- für ist unser Netzwerk in der jetzigen Form noch nicht geeignet. Aber auch hier hilft wieder ein einfacher Trick: Wir ersetzen jeden Knoten x 2 V \\{u, v} im Netzwerk durch zwei Knoten xin und xout und verbinden alle Eingangs- kanten von x mit xin, alle Ausgangskanten von x mit xout und fügen eine zusätzliche Kante von xin zu xout mit Kapazität Eins zum Netzwerk hinzu. Abbildung 3.5 zeigt das resultierende Netzwerk für obiges Beispiel. Wie- der überzeugt man sich leicht davon, dass der maximale Fluss in diesem Netzwerk genau der Anzahl intern knotendisjunkter u-v-Pfade entspricht. Bildsegmentierung als Schnittproblem Wir wollen ein Bild bestehend aus Pixeln (typischerweise in einem Gitter angeordnet) in Vordergrund und Hintergrund unterteilen—diese Operation englischsprachigen Literatur nennt man diesen Ansatz ganz anschaulich cycle canceling. Cycle Canceling ist ein wichtiges Hilfsmittel, wenn man einen maximalen Fluss mit mini- malen Kosten bestimmen wird, aber dies überlassen wir weiterführenden Vorlesungen. KAPITEL 3. ALGORITHMEN - HIGHLIGHTS 187 u v ain aout bin bout cin cout s t 5/2 5/2 1/1 1/01/0 1/1 1/01/0 1/0 1/01/11/0 1/1 1/0 1/0 1/01/1 1/1 1/0 Abbildung 3.5: Das Netzwerk, um für den Graphen aus der vorigen Abbil- dung die maximale Anzahl knotendisjunkter u-v Pfade zu bestimmen. Der Fluss ist maximal und entspricht den beiden Pfaden u-v und u-a-b-v. nennt man auch Segmentierung. Für unsere Betrachtungen ist es wichtig, dass die Pixelmenge P mit einer Nachbarschaftsrelation assoziiert ist. In einem Gitter etwa ist jedes Pixel (ausser am Rand) zu vier anderen Pixeln benachbart (darüber, darunter, links und rechts). Dies ergibt eine Kantenmenge E und somit bildet (P, E) einen ungerichteten Graph. Für uns ist es hier nicht wesentlich, ob die Pixel Graustufen oder Farb- werte darstellen. Was auch immer diese Werte sind, wir nehmen an, dass wir daraus für jedes Pixel p zwei nichtnegative Zahlen αp und βp extrahie- ren: Je grösser αp ist, desto mehr erwarten wir, dass p zum Vordergrund gehört; analog drückt βp unsere Erwartung aus, dass p im Hintergrund liegt. Mit diesen Zahlen scheint die Partition von P in Vordergrund A und Hintergrund B einfach: A := {p 2 P | αp > βp} und B := P \\ A . Allerdings wollen wir tendenziell keine zu feinkörnige Unterteilung, d.h. liegen viele Nachbarn eines Pixels p im Vordergrund, so sollte p eher auch im Vordergrund liegen. Diese Präferenz modellieren wir, indem wir jeder Kante e in E eine nichtnegative Zahl γe zuordnen, mit der Interpretation, dass je grösser γe ist, wir umso mehr erwarten, dass die beiden beteiligten Pixel im gleichen Teil der Segementierung landen (γe kann man als Strafzoll betrachten, wenn man in der Unterteilung die Endpunkte trennt). Mit diesen Zahlen bewerten wir nun eine Partition (A, B) mittels der KAPITEL 3. ALGORITHMEN - HIGHLIGHTS 188 Qualitätsfunktion12 q(A, B) := ∑ p2 A αp + ∑ p2 B βp − ∑ e2 E, |e\\ A|=1 γe . Uns interessiert hier nicht so sehr, wie man die Parameter α, β, und γ günstig wählt, so dass man gute Ergebnisse bekommt. Stattdessen fragen wir uns, wie wir eine Unterteilung von P in A und B finden, sodass q(A, B) maximal ist. Wir merken, dass die Fragestellung zumindest in einigen Aspekten ei- nem Schnittproblem gleicht. Tatsächlich gelingt es uns wieder, wie beim Matchingproblem, die Fragestellung in ein Netzwerkproblem (hier mini- maler Schnitt) überzuführen. Zuerst ändern wir die Qualitätsfunktion, sodass wir es—wie bei s-t- Schnitten gewohnt—mit einem Minimierungsproblem zu tun haben. Dazu definieren wir Q := ∑ p2 P(αp + βp) womit wir q(A, B) in q(A, B) = Q − ∑ p2 A βp − ∑ p2 B αp − ∑ e2 E,|e\\ A|=1 γe umschreiben können. Daraus wird klar, dass q(A, B) zu maximieren äqui- valent zur Minimierung von q 0 (A, B) := ∑ p2 A βp + ∑ p2 B αp + ∑ e2 E,|e\\ A|=1 γe ist. In einem nächsten Schritt erzeugen wir ein Netzwerk wie folgt. Wieder führen wir neue Knoten s und t ein, die für die Quelle und Senke im Netzwerk stehen. s hat gerichtete Kanten zu allen Pixeln in P, die Kapazität der Kante zu p sei αp. Analog hat dann jedes Pixel p eine gerichtete Kante zu t mit Kapazität βp. Schliesslich ersetzen wir jede ungerichtete Kante e = {p, p 0 } in E durch zwei gerichtete Kanten (p, p 0 ) und (p 0 , p), je mit Kapazität γe. Ein Netzwerk N mit Knotenmenge P [ {s, t} ist geschaffen. Was ist nun die Kapazität eines s-t-Schnitts (S, T ) in N? Dazu sehen wir uns an, welche Kanten des Netzwerks in S \u0002 T liegen, wobei wir A := S \\ {s} und B := T \\ {t} verwenden. 12Nochmals, wir kümmern uns hier nicht um berechtigten Fragen, wo die Werte αp, βp, und γe herkommen, und auch nicht darum, ob die Qualitätsfunktion gut ist und den Zweck erfüllt. Tatsächlich ist das aber ein Ansatz, der in der Praxis so zum Einsatz kommt. KAPITEL 3. ALGORITHMEN - HIGHLIGHTS 189 • Kanten (s, p) mit p 2 B. Ihr Beitrag zur Kapazität cap(S, T ) ist ∑ p2 B αp. • Kanten (p, t) mit p 2 A, die ∑ p2 A βp zur Kapazität des Schnitts beitragen. • Kanten (p, p 0 ) des Netzwerks in A\u0002 B mit Beitrag ∑ (p,p 0 ) γ(p,p 0 ), wobei die Summe über alle Kanten des Netzwerks aus A \u0002 B geht. Wir sehen, dass für die aus (S, T ) abgeleitete Unterteilung (A, B) von P tatsächlich q 0 (A, B) = cap(S, T ) gilt. Eine optimale Segmentierung entspricht somit einem minimalen s-t- Schnitt im generierten Netzwerk N und kann so mit einem Fluss- oder Schnittalgorithmus für Netzwerke berechnet werden. Eine Auswahl weiterer Anwendungen findet man unter anderem in Al- gorithm Design von Jon Kleinberg und Éva Tardos (Pearson – Addison Wesley). Flüsse und konvexe Mengen Wir schliessen diesen Abschnitt ab, indem wir versuchen die Menge aller Flüsse in einem Netzwerk besser zu verstehen, und einen Bezug zu einem zentralen Begriff der Geometrie herstellen: konvexe Mengen. So wie wir Netzwerke und Flüsse eingeführt haben, hat jedes Netzwerk mindestens einen Fluss: die Funktion konstant 0; bezeichnen wir diesen Fluss mit 0. Nehmen wir an, es gibt mindestens einen zweiten Fluss (un- gleich 0), nennen wir den f1. Aber nun gibt es sofort einen weiteren Fluss f \u0003 1 indem wir den Fluss f1 einfach halbieren, d.h. 8 e 2 A : f \u0003 1(e) := 1 2 f1(e) . Dazu müssen wir sicherstellen, dass die Bedingungen für einen Fluss erfüllt sind: 0 \u0014 f \u0003 1(e) \u0014 c(e) für alle Kanten e 2 A und die Flusserhaltung – beides lässt sich leicht zeigen. Allgemeiner gilt KAPITEL 3. ALGORITHMEN - HIGHLIGHTS 190 Lemma 3.16. Sind f0 und f1 Flüsse in einem Netzwerk N und λ 2 R, 0 < λ < 1, dann ist der Fluss fλ, definiert durch 8 e 2 A : fλ(e) := (1 − λ)f0(e) + λf1(e) , ebenfalls ein Fluss in N. Es gilt val(fλ) = (1 − λ) \u0001 val(f0) + λ \u0001 val(f1) . Beweis. Wir können aus der Zulässigkeit von f0 und f1 leicht die Zulässig- keit von fλ herleiten (man beachte, dass λ \u0015 0 und 1 − λ \u0015 0): fλ(e) = (1 − λ) \u0015 0 ︷ ︸︸ ︷ f0(e) +λ \u0015 0 ︷ ︸︸ ︷ f1(e) \u0015 (1 − λ) \u0001 0 + λ \u0001 0 = 0 fλ(e) = (1 − λ) f0(e) ︸ ︷︷ ︸ \u0014 c(e) +λ f1(e) ︸ ︷︷ ︸ \u0014 c(e) \u0014 (1 − λ) \u0001 c(e) + λ \u0001 c(e) = c(e) Ähnlich einfach lassen sich Flusserhaltung und die Behauptung zum Wert des Flusses verifizieren. Korollar 3.17. Es gilt: (i) Ein Netzwerk N hat entweder genau einen Fluss (den Fluss 0) oder unendlich viele Flüsse. (ii) Ein Netzwerk hat entweder genau einen maximalen Fluss, oder unendlich viele maximale Flüsse. Konvexe Mengen. Für eine geometrische Interpretation wählen wir eine Nu- merierung (Ordnung) (e1, e2, . . . , em), m := |A|, der Kanten in A. Jede Funktion f : A → R induziert so einen Vektor vf := (f(e1), f(e2), . . . , f(em)) in R m. Das heisst, die Menge der Flüsse (oder die Menge der maximalen Flüsse) kann man so als Teilmengen des R m interpretieren. Definition 3.18. Sei m 2 N. (i) Für v0, v1 2 R m sei v0v1 := {(1 − λ)v0 + λv1 | λ 2 R, 0 \u0014 λ \u0014 1}, KAPITEL 3. ALGORITHMEN - HIGHLIGHTS 191 das v0 und v1 verbindende Liniensegment. (ii) Eine Menge C \u0012 R m heisst konvex, falls für alle v0, v1 2 C das ganze Liniensegement v0v1 in C enthalten ist. Beispiele konvexer Mengen sind Kugeln oder konvexe Polytope (z.B. Tetraeder oder Würfel im R 3). Konvexe Polygone (im R2) wurden in der Vorlesung Diskrete Mathematik erwähnt, konvexe Mengen in der Analysis (oder auch kurz in der Linearen Algebra). Aus Lemma 3.16 folgt jetzt unmittelbar folgende Eigenschaft. Satz 3.19. Die Menge der Flüsse eines Netzwerks mit m Kanten, in- terpretiert als Vektoren, ist eine konvexe Teilmenge des R m. Ebenso bildet die Menge der maximalen Flüsse eine konvexe Teilmenge des R m. Man kann zeigen, dass diese Flüssen entsprechenden Mengen konvexe Polytope sind, wir gehen darauf nicht weiter ein. Die Tatsache, dass es immer einen maximalen Fluss gibt, folgt leicht aus der Theorie konvexer Mengen (dazu muss man zeigen, dass die Menge der Flüsse eine konvexe kompakte Menge bildet). Der Bezug (oder besser die Äquivalenz) von Funktionen und Vektoren ist wichtig, und erlaubt die Anwendung von Konzepten und Ergebnissen aus der Geometrie und Linearen Algebra auf Mengen von Funktionen. Als Illustration ist empfohlen sich die Menge der Flüsse für das einfache Netzwerk N = ({s, t, q), {e1, e2}, c, s, t) mit e1 = (s, q), e2 = (q, t), c(e1) = 1 und c(e2) = 2 im R 2 zu veranschaulichen (jede Funktion f : {e1, e2} → R wird als Vektor (f(e1), f(e2)) 2 R2 interpretiert). Dazu zeichne man erst das Rechteck aller zulässigen Funktionen/Vektoren f mit 0 \u0014 f(e1) \u0014 1 und 0 \u0014 f(e2) \u0014 2, und schneide dieses Rechteck mit der Geraden f(e1) = f(e2) (die in diesem einfachen Beispiel einzige Flusserhaltungsbedingung). Man sieht dann leicht, dass die Menge der Flüsse ein Liniensegment ist. 3.1.3 Minimale Schnitte in Graphen In diesem Abschnitt betrachten wir ungerichtete ungewichtete Graphen G = (V, E) ohne Schleifen, wobei wir mehrere Kanten zwischen demsel- ben Knotenpaar erlauben – sogenannte Multigraphen. Wir könnten statt KAPITEL 3. ALGORITHMEN - HIGHLIGHTS 192 Mehrfachkanten auch ganzzahlige Kantengewichte erlauben, aber die Ab- handlung wird mit Mehrfachkanten einfacher. Wir interessieren uns in einem solchen Multigraph G = (V, E) für eine kleinste Menge C von Kanten, deren Entfernung einen unzusammenhän- genden Multigraph erzeugt. Ist G selber nicht zusammenhängend, so kann man hier offensichtlich C = ; wählen. Eine Menge C \u0012 E für die (V, E \\ C) unzusammenhängend ist, nennen wir Kantenschnitt in G. Mit µ(G) be- zeichnen wir die Kardinalität eines kleinstmöglichen Kantenschnitts in G. Das Problem. Gegeben ein Multigraph G, bestimme µ(G) (die Kardinalität eines minimalen Schnitts). Wir nennen das das MIN-CUT Problem. Ein ähnliches Problem hatten wir ja gerade bei den Flüssen kennen- gelernt. Wo liegt der Unterschied oder haben wir das Problem schon ge- löst? Wir skizzieren den Zusammenhang: Statt Mehrfachkanten könnten wir, wie erwähnt, einfach Kantengewichte verwenden. Ungerichtete Kan- ten {u, v} können wir durch Paare gerichteter Kanten (u, v), (v, u) ersetzen. Und dann hatten wir es im letzten Kapitel mit s-t-Schnitten zu tun, hier jetzt sind s und t nicht spezifiziert. Um jetzt MIN-CUT für einen Multi- graph G = (V, E) zu lösen, transformieren wir ihn wie beschrieben zu einem gerichteten Graph (V, A) (mit Kanten-Gewichtsfunktion w), fixieren einen Knoten s 2 V und berechnen minimale s-t-Schnitte, für alle t 2 V \\ {s}, im Netzwerk (V, A, w, s, t). Der kleinste dieser s-t-Schnitte zeigt uns den minimalen Schnitt im Ausgangs-Multigraph G. Wir hatten erwähnt, dass man minimale s-t-Schnitte in O(nm log n) = O(n 3 log n) Zeit berechnen kann. Das macht dann insgesamt O(n 4 log n) für unser MIN-CUT Problem (weil wir n − 1 s-t-Schnitte berechnen müssen). Kantenkontraktion Sei G ein Multigraph und e = {u, v} eine Kante in G. Die Kontraktion von e verschmilzt die beiden Knoten u und v zu einem neuen Knoten xu,v, der nun zu allen Kanten inzident ist, zu denen u oder v inzident war, ausser den Kanten zwischen u und v – diese Kanten verschwinden. Den entstehenden Graph bezeichnen wir mit G/e. Ist k die Anzahl der Kanten zwischen u und v, dann gilt degG/exu,v = degG(u) + degG(v) − 2k . KAPITEL 3. ALGORITHMEN - HIGHLIGHTS 193 u v e G xu,v (Wichtig ist hier, dass wir in einem Multigraphen G mit degG(u) die Anzahl der zu u inzidenten Kanten bezeichnen und nicht die Anzahl der Nachbarn.) Es gibt eine natürliche Bijektion {Kanten in G ausser denen zwischen u und v} ←→ {Kanten in G/e} : Entweder bleibt eine Kante in G bei der Kontraktion gleich, oder {w, u} oder {w, v} wird zu einer Kante {w, xu,v}. Man beachte, dass es so für je- den Kantenschnitt C in G/e einen entsprechenden Kantenschnitt in G mit gleicher Kardinalität gibt. Umgekehrt gibt es für jeden Kantenschnitt ohne e in G einen entsprechenden in G/e, wieder mit gleicher Kardinalität. Es ergibt sich folgendes Lemma. Lemma 3.20. Sei G ein Graph und e eine Kante in G. Dann gilt µ(G/e) \u0015 µ(G) und falls es in G einen minimalen Schnitt C mit e 62 C gibt, dann gilt µ(G/e) = µ(G). Auf gut Glück – zufällige Kantenkontraktionen Wir können nun den einfachen randomisierten Algorithmus dieses Ab- schnitts beschreiben. KAPITEL 3. ALGORITHMEN - HIGHLIGHTS 194 Cut(G) G zusammenhängender Multigraph 1: while |V(G)| > 2 do 2: e ← gleichverteilt zufällige Kante in G 3: G ← G/e 4: return Grösse des eindeutigen Schnitts in G Sei n Anzahl der Konten in G. Für die Implementierung setzen wir folgendes voraus: • Eine Kantenkontraktion kann in O(n) Zeit durchgeführt werden. • Eine gleichverteilt zufällige Kante in G kann in O(n) gewählt werden. (Das ist nicht ganz offensichtlich, und erfordert u.a., dass Mehrfachkan- ten mittels Kantengewichten dargestellt werden.) Mit dieser Voraussetzung können wir Cut(G) mit einer Laufzeit von O(n 2) implementieren. Als nächstes stellen wir sicher, dass eine zufällige Wahl von e mit guter Wahrscheinlichkeit die Grösse des minimalen Schnitts nicht verändert. Lemma 3.21. Sei G = (V, E) ein Multigraph mit n Knoten. Falls e gleichverteilt zufällig unter den Kanten in G gewählt wird, dann gilt Pr [µ(G) = µ(G/e)] \u0015 1 − 2 n . Beweis. Sei C ein minimaler Schnitt in G und sei k := |C| = µ(G). Sicherlich ist der Grad jedes Knotens in G mindestens k, da die zu ei- nem Knoten inzidenten Kanten immer einen Schnitt bilden. Es gilt daher |E| = 1 2 ∑ v2 V deg(v) \u0015 kn 2 . Wir erinnern uns an e 62 C ⇒ µ(G/e) = µ(G) und somit Pr [µ(G) = µ(G/e)] \u0015 Pr[e 62 C] = 1 − |C| |E| \u0015 1 − k kn/2 = 1 − 2 n, was zu zeigen war. Nun interessieren wir uns dafür, dass der Algorithmus Cut(G) insge- samt den richtigen Wert ausgibt, d.h. ^p(G) := Wahrscheinlichkeit, dass Cut(G) den Wert µ(G) ausgibt KAPITEL 3. ALGORITHMEN - HIGHLIGHTS 195 und ^p(n) := inf G=(V,E), |V|=n ^p(G) . Man beachte, dass ^p(2) = 1. Lemma 3.22. Es gilt für alle n \u0015 3 ^p(n) \u0015 (1 − 2/n) \u0001 ^p(n − 1). Beweis. Sei G ein Multigraph mit n Knoten. Damit Cut(G) tatsächlich µ(G) ausgibt, müssen die beiden folgenden Ereignisse eintreten: • E1 := Ereignis µ(G) = µ(G/e). • E2 := Ereignis, dass Cut(G/e) den Wert µ(G/e) ausgibt. Es gilt nun ^p(G) = Pr[E1 ∧ E2] = Pr[E1] \u0001 Pr[E2 | E1] \u0015 (1 − 2/n) \u0001 ^p(n − 1) und da dies für jeden Multigraph G mit n Knoten gilt, folgt auch die Aussage ^p(n) \u0015 (1 − 2/n) \u0001 ^p(n − 1). Wir erhalten so ^p(n) \u0015 n − 2 n \u0001 n − 3 n − 1 \u0001 n − 4 n − 2 \u0001 \u0001 \u0001 3 5 \u0001 2 4 \u0001 1 3 \u0001 ^p(2) ︸︷︷︸ =1 = 2 n(n − 1) Lemma 3.23. Es gilt ^p(n) \u0015 2 n(n−1) = 1/\u0010 n 2 \u0011 für alle n \u0015 2. Wir wiederholen nun den Algorithmus Cut(G) λ\u0010 n 2 \u0011 mal, für ein λ > 0, und geben dann den kleinsten je erhaltenen Wert aus. Dann erhalten wir folgendes Ergebnis (wir erinnern uns, dass ein Aufruf von Cut(G) Zeit O(n 2) benötigt). Satz 3.24. Für den Algorithmus der λ \u0010 n 2 \u0011 -maligen Wiederholung von Cut(G) gilt: (1) Der Algorithmus hat eine Laufzeit von O(λn 4). KAPITEL 3. ALGORITHMEN - HIGHLIGHTS 196 (2) Der kleinste angetroffene Wert ist mit einer Wahrscheinlichkeit von mindestens 1 − e−λ gleich µ(G). Für die Fehlerabschätzung gehen wir nach dem bekannten Muster vor: Die Wahrscheinlichkeit, dass wir λ \u0010 n 2 \u0011 Mal nicht einen minimalen Schnitt finden ist höchstens (1 − ^p(n))λ(n 2) \u0014 1 − 1/ n 2 !! λ(n 2) \u0014 e−λ (mit der bewährten Ungleichung 8 x 2 R : 1 + x \u0014 ex). Wählen wir λ = ln n, gibt das eine Laufzeit von O(n 4 log n) mit Feh- lerwahrscheinlichkeit höchstens 1/n. Diese Laufzeit haben wir aber mit- tels Flussalgorithmen auch schon deterministisch und ohne Fehler erreicht. Aber der Ansatz hat noch Potential, wie wir gleich sehen werden. Bootstrapping Sollte man den Algorithmus implementieren, wird man schnell folgende Beobachtung machen. Hat unser Multigraph (im Zuge der Rekursi- on) nur mehr 3 Knoten und machen wir eine zufällige Kantenkontraktion, dann haben wir nur mehr eine Erfolgswahrscheinlichkeit von 1/3. Dabei können wir doch ganz einfach den minimalen Schnitt schnell bestimmen, es besteht gar kein Grund mehr im letzten Schritt noch dieses Risiko ein- zugehen. Das könnten wir eigentlich schon bei 4 Knoten machen, etc. Was passiert, wenn wir die Rekursion in Cut(G) abbrechen, sobald wir bei einem Multigraph mit t Knoten angelangt sind (für einen Parame- ter t, den wir noch bestimmen), um dann das Problem für diesen kleine- ren Multigraph mit einem anderen Algorithmus in Zeit z(t) und Erfolgs- wahrscheinlichkeit \u0015 p \u0003 (t) zu lösen: z.B. deterministisch mittels Flüssen in z(t) = O(t4 log t) Zeit mit p\u0003 (t) = 1, oder nach Satz 3.24 (mit λ = 1) in z(t) = O(t4) Zeit mit p \u0003 (t) = 1 − e−1). Cut1(G) G zusammenhängender Multigraph 1: while |V(G)| > t do 2: e ← gleichverteilt zufällige Kante in G 3: G ← G/e 4: return Grösse des eindeutigen Schnitts in G ▷ in Zeit O(z(t)) KAPITEL 3. ALGORITHMEN - HIGHLIGHTS 197 Dieser Algorithmus benötigt nun Zeit O(n(n − t) + z(t)), er macht Fehler in den ersten n − t Schritten, und schliesslich noch einen Fehler mit Wahrscheinlichkeit \u0014 1 − p\u0003 (t) im letzten Schritt (auf dem Multigraph der Grösse t), d.h. die Erfolgswahrscheinlichkeit ist \u0015 n − 2 n \u0001 n − 3 n − 1 \u0001 n − 4 n − 2 \u0001 \u0001 \u0001 t + 1 t + 3 \u0001 t t + 2 \u0001 t − 1 t + 1 \u0001 p \u0003 (t) = t(t − 1) n(n − 1) \u0001 p\u0003 (t) . Legen wir uns (vorerst) auf z(t) = O(t4) und p \u0003 (t) = 1 − e−1 = e−1 e fest. Wir müssen den revidierten Algorithmus Cut1(G) nun λ n(n−1) t(t−1) e e−1 Mal wie- derholen, um eine Erfolgswahrscheinlichkeit von 1 − e−λ zu erreichen. Die Laufzeit ist dann λn(n − 1) t(t − 1) e e − 1 \u0001 O(n(n − t) + t4) = O λ n 4 t2 + n 2t2!! . Wählen wir t klein, dann dominiert n4 t2 , bei t gross, dominiert n 2t2. Wir entscheiden uns für t = n 1/2 (sodass sich die beiden Terme ausbalancieren) und erhalten so eine Laufzeit von O(λn 3), was nun eine Verbesserung ge- genüber dem ursprünglichen Flussansatz ergibt. Das würde an dieser Stelle einen Satz rechtfertigen, könnten wir diesen schnelleren Algorithmus nicht gleich wieder verwenden (uns steht jetzt z(t) = O(t3) zur Verfügung), um das Problem für den Multigraphen mit t Knoten zu lösen. Das führt dann zu einer anderen Wahl von t und einem noch schnelleren Algorithmus,13 den wir natürlich gleich verwenden, um den Algorithmus wieder schneller zu machen, . . . Dieses in sich selbst einsetzen eines Algorithmus, um diesen immer schneller zu machen, nennt man Bootstrapping. Wo führt das hin? Es konvergiert zu einem Verfahren mit einer Laufzeit von O(n 2poly(log n)), man kann sich das wie einen „Grenzwertalgorithmus“ vorstellen. Natürlich muss man eine sorgfältige Buchhaltung über die Feh- lerwahrscheinlichkeit machen. Wir verweisen für diese weiteren Schritte auf die Literatur. 3.2 Geometrische Algorithmen 3.2.1 Kleinster umschliessender Kreis In diesem Abschnitt betrachten wir folgendes Problem. Zu einer gegebenen Menge P von n Punkten in der Ebene möchten wir einen Kreis C(P) be- 13Bestimmen Sie als Übung einen guten Parameter t und die resultierende Laufzeit. KAPITEL 3. ALGORITHMEN - HIGHLIGHTS 198 stimmen, sodass C(P) alle Punkte aus P umschliesst und der Radius von C(P) so klein wie möglich ist. Für einen Kreis C verwenden wir C\u000f für die von C umschlossene Kreisscheibe (abgeschlossen, also inklusive C). Hierbei erlauben wir, dass die Punkte in P auch auf C(P) liegen dürfen – die Punkte müssen also nicht strikt innerhalb des Kreises liegen. Dann ist es möglich zu zeigen, dass es immer einen kleinsten Kreis gibt, der al- le Punkte enthält. Bevor wir uns der Entwicklung eines Algorithmus für dieses Problem zuwenden, leiten wir zunächst zwei Eigenschaften eines sol- chen kleinsten umschliessenden Kreises her. Zunächst zeigen wir, dass der kleinste umschliessende Kreis eindeutig bestimmt ist, es also insbesondere Sinn macht von dem Kreis C(P) zu sprechen. Lemma 3.25. Für jede (endliche) Punktemenge P im R 2 gibt es einen eindeutigen kleinsten umschliessenden Kreis C(P). Beweis. Den Beweis für die Existenz überspringen wir. Wir zeigen die Ein- deutigkeit durch einen Widerspruchsbeweis. Nehmen wir also an, es gäbe eine Menge P, für die es (mindestens) zwei verschiedene kleinste umschlies- sende Kreise C1 und C2 gibt. Da C1 und C2 beides kleinste Kreise sind, haben sie den gleichen Radius, sagen wir r. Und da C1 und C2 verschie- den sind, müssen sie verschiedene Mittelpunkte z1 und z2 haben. Da beide Kreise die Punktemenge P enthalten, gilt auch: P \u0012 C \u000f 1 \\ C\u000f 2. Wir konstru- ieren nun einen neuen Kreis C wie folgt: als Mittelpunkt nehmen wir den Mittelpunkt z der Strecke von z1 zu z2 (z = 1 2 (z1 +z2)). Als Radius ^r wählen wir den Abstand von z zu einem (der beiden) Schnittpunkte von C1 und C1. (Man überlegt sich leicht, dass z zu beiden Schnittpunkten den glei- chen Abstand hat.) Dann gilt P \u0012 C\u000f 1 \\ C\u000f 2 \u0012 C\u000f und ^r = q r2 − ( 1 2|z1z2|)2, wobei |z1z2| die Länge der Strecke von z1 nach z2 ist. Insbesondere gilt al- so ^r < r, im Widerspruch zu unserer Annahme, dass C1 und C2 kleinste umschliessende Kreise sind. Das nächste Lemma wird die Basis unseres Algorithmus werden. Es zeigt, dass es immer drei Punkte aus P gibt, die den kleinsten umschlies- senden Kreis bereits eindeutig bestimmen. KAPITEL 3. ALGORITHMEN - HIGHLIGHTS 199 Lemma 3.26. Für jede (endliche) Punktemenge P im R 2 mit |P| \u0015 3 gibt es eine Teilmenge Q \u0012 P, so dass |Q| = 3 und C(Q) = C(P). Beweis. Sei P eine beliebige Punktemenge mit mindestens drei Punkten. Aus Lemma 3.25 wissen wir, dass C := C(P) eindeutig ist. Mit B bezeichnen wir die Menge derjenigen Punkte aus P, die auf dem Rand von C liegen. Wir zeigen zunächst folgende Hilfseigenschaft: (⋆) Ist g eine beliebige Gerade durch den Mittelpunkt von C, so kann es nicht sein, dass alle Punkte von B (strikt) auf einer der beiden Seiten von g liegen. Dies gilt, da wir ansonsten den Mittelpunkt von C ganz leicht senkrecht zu g weg von der Seite ohne Punkte auf dem Rand verschieben könnten und gleichzeitig den Radius etwas verkleinern, so dass dennoch noch immer alle Punkte aus P innerhalb des nun kleineren Kreises liegen, im Widerspruch zu unserer Annahme. Aus dieser Beobachtung folgt bereits, dass |B| \u0015 2 gelten muss, und dass im Falle |B| \u0014 3 der Kreis C durch C(B) gegeben ist. Falls |B| \u0015 4 so wählen wir zwei beliebige Punkte p und q von B, die bei Durchlaufen der Kreislinie von C nicht unmittelbar aufeinander folgen. Wenn sie auf einer Geraden durch den Mittelpunkt liegen, so gilt C = C({p, q}) und das Lemma ist bewiesen. Falls nicht, so wählen wir einen beliebigen Punkt r aus B aus dem kürzeren der beiden durch p und q gegebenen Kreissegmente. Dann gilt die Eigenschaft (⋆) auch noch für die Menge B \\ {r} – und das Lemma folgt damit durch Induktion über |B|. Aus Lemma 3.26 können wir sofort einen O(n 4) Algorithmus für die Berechnung von C(P) ableiten: CompleteEnumeration(P) 1: for all Q \u0012 P mit |Q| = 3 do 2: bestimme C(Q) 3: if P \u0012 C\u000f (Q) then 4: return C(Q) Die Laufzeit sieht man wie folgt ein: wir müssen höchstens \u0010 n 3 \u0011 viele Mengen Q testen. Für jede solche Menge können wir C(Q) in konstanter KAPITEL 3. ALGORITHMEN - HIGHLIGHTS 200 Zeit bestimmen (da Q ja nur drei Punkte enthält) und müssen dann für jeden Punkt in P testen, ob er in C \u000f (Q) enthalten ist. Für jeden Punkt geht dies in konstanter Zeit, jede Iteration der for-Schleife benötigt daher O(n) Zeit. Unser Ziel ist ein randomisierter Algorithmus mit (erwarteter) Laufzeit O(n ln n). Dazu betrachten wir als erstes eine randomisierte Version von obigem Algorithmus: Randomised_PrimitiveVersion(P) 1: repeat forever 2: wähle Q \u0012 P mit |Q| = 3 zufällig und gleichverteilt 3: bestimme C(Q) 4: if P \u0012 C\u000f (Q) then 5: return C(Q) Kurzes Nachdenken zeigt uns, dass das noch keine sehr clevere Idee ist: Für Punktemengen P, in denen der kleinste einschliessende Kreis durch ge- nau drei Punkte gegeben ist, müssen wir die repeat-Schleife ausführen, bis wir genau diese dreielementige Menge ziehen. Dies geschieht in jeder Itera- tion mit Wahrscheinlichkeit 1/\u0010 n 3 \u0011 . Die Anzahl Iterationen ist daher geome- trisch verteilt mit Parameter 1/\u0010 n 3 \u0011 – und die erwartete Anzahl Iterationen ist somit \u0010 n 3 \u0011 . Die erwartete Laufzeit unseres randomisierten Algorithmus ist daher ebenfalls O(n 4). Was können wir tun, um den Algorithmus zu beschleunigen? Eine erste Idee ist, in jeder Runde mehr als 3 Punkte zu ziehen. Wir könnten beispiels- weise 11 Punkte ziehen. Dann können wir C(Q) noch immer in konstanter Zeit berechnen, aber wir haben eine höhere Chance, dass die Menge Q die drei definierenden Punkte von C(P) enthält. Eine kurze Rechnung zeigt dann allerdings schnell, dass dies an der asymptotischen Laufzeit von O(n 4) nichts ändert. Um die Laufzeit wirklich zu verbessern, müssen wir noch eine zusätzli- che Idee hinzufügen: wir verdoppeln in jeder Iteration die Punkte ausser- halb von C(Q): KAPITEL 3. ALGORITHMEN - HIGHLIGHTS 201 Randomised_CleverVersion(P) 1: repeat forever 2: wähle Q \u0012 P mit |Q| = 11 zufällig und gleichverteilt 3: bestimme C(Q) 4: if P \u0012 C\u000f (Q) then 5: return C(Q) 6: verdoppele alle Punkte von P ausserhalb von C(Q) Für die Implementierung dieses Algorithmus müssen wir uns zunächst überlegen, wie wir die “Verdopplung” der Punkte realisieren. Dies ist recht einfach: Wir initialisieren ein Array num der Länge n mit konstant Eins. Die Idee ist, dass num[i] die Anzahl Kopien des i-ten Punktes angibt. Liegt der i-te Punkt dann ausserhalb von C(Q), so können wir die Verdopplung aller Kopien dieses Punktes einfach dadurch realisieren, indem wir num[i] durch 2 \u0001 num[i] ersetzen. Als nächstes müssen wir uns noch überlegen, wie wir in Zeit O(n) die 11 Punkte q1, . . . , q11 2 P zufällig und gleichverteilt wählen können. Hierfür zeigen wir folgendes Lemma: Lemma 3.27. Seien n1, . . . , nt natürliche Zahlen und N := ∑t i=1 ni. Wir erzeugen X 2 {1, . . . , t} zufällig wie folgt: k ← UniformInt(1, N) x ← 1 while ∑x i=1 ni < k do x ← x + 1 return x Dann gilt Pr[X = i] = ni/N für alle i = 1, . . . , t. Beweis. Der Beweis folgt sofort aus der Tatsache, dass x = i genau für k 2 {1 + ∑x−1 i=1 ni, . . . , ∑x i=1 ni} ausgegeben wird, also für ni der möglichen N Werte für k. Mit Hilfe dieses Lemmas und des Arrays num[\u0001 ] können wir somit Punk- te der Menge P so ziehen, dass die Wahrscheinlichkeit eines jeden Punktes proportional zu der Anzahl seiner Kopien ist. Wählen wir dann den näch- sten Punkt bezüglich eines leicht korrigierten Arrays num[\u0001 ] (in dem wir berücksichtigen, dass wir einen Punkt schon gezogen haben), so erhalten KAPITEL 3. ALGORITHMEN - HIGHLIGHTS 202 wir auf diese Weise in Zeit O(n) die gewünschte Teilmenge Q, die aus genau 11 Punkten besteht. Für die Analyse des Algorithmus benötigen wir jetzt noch das folgende Lemma: Lemma 3.28. Sei P eine Menge von n (nicht unbedingt verschiedenen) Punkten und für r 2 N, R zufällig gleichverteilt aus \u0010 P r \u0011 . Dann ist die erwartete Anzahl Punkte von P, die ausserhalb von C(R) liegen, höchstens 3 n−r r+1 \u0014 3 n r+1 . Beweis. Für den Beweis definieren wir uns zwei Hilfsfunktionen, für p 2 P, R, Q \u0012 P: out(p, R) := { 1 falls p 62 C \u000f (R) 0 sonst (beachte, dass ∑ p2 P\\R out(p, R) die Anzahl der Punkte ausserhalb C(R) ist) und essential(p, Q) := { 1 falls C(Q \\ {p}) 6= C(Q) 0 sonst. Leicht überzeugt man sich davon, dass beide Funktionen in folgender Be- ziehung stehen. Für p 62 R, out(p, R) = 1 ⇐⇒ essential(p, R [ {p}) = 1. Damit erhalten wir für die Anzahl X der Punkte ausserhalb von C(R): E[X] = 1 \u0010 n r \u0011 ∑ R2 (P r) ∑ s2 P\\R out(s, R) = 1 \u0010 n r \u0011 ∑ R2 (P r) ∑ s2 P\\R essential(s, R [ {s}) = 1 \u0010 n r \u0011 ∑ Q2 ( P r+1) ∑ p2 Q essential(p, Q) ︸ ︷︷ ︸ \u0014 3 \u0014 1 \u0010 n r \u0011 ∑ Q2 ( P r+1) 3 = 3 \u0001 \u0010 n r+1 \u0011 \u0010 n r \u0011 = 3 n − r r + 1 , wobei die erste Ungleichung in der letzten Zeile aus Lemma 3.26 folgt. KAPITEL 3. ALGORITHMEN - HIGHLIGHTS 203 Mit diesem Lemma können wir nun die Laufzeit und Korrektheit unseres Algorithmus beweisen. Satz 3.29. Algorithmus Randomized_CleverVersion berechnet den kleinsten umschliessenden Kreis von P in erwarteter Zeit O(n log n). Beweis. Wir führen zunächst einige Zufallsvariablen ein: mit T bezeichnen wir die Anzahl Iterationen des Algorithmus und mit Xk die Anzahl Punkte nach k Iterationen; X0 = n. Den Erwartungswert von Xk können wir mit Hilfe von Lemma 3.28 leicht abschätzen. Es gilt: E[Xk] = ∞∑ t=0 E[Xk | Xk−1 = t] \u0001 Pr[Xk−1 = t] Lemma 3.28 \u0014 ∞∑ t=0 1 + 3 r + 1 ! t \u0001 Pr[Xk−1 = t] = 1 + 3 r + 1 ! \u0001 ∞∑ t=0 t \u0001 Pr[Xk−1 = t] = 1 + 3 r + 1 ! \u0001 E[Xk−1]. Per Induktion folgt somit (da X0 \u0011 n), dass E[Xk] \u0014 (1 + 3 r+1 )k \u0001 n. Aus Lemma 3.26 wissen wir, dass es eine Menge Q0 \u0012 P der Grösse 3 gibt, mit C(Q0) = C(P). Sobald daher Q0 in der Menge Q, die der Algorith- mus in einer Iteration wählt, enthalten ist, wird der Algorithmus stoppen. Falls der Algorithmus daher nach k Runden noch nicht terminiert hat, muss mindestens einer der Punkte in Q0 in k/3 der Runden ausserhalb von C(Q) gelegen haben – was zu eine Verdopplung seiner Punkte geführt hat. Mit anderen Worten: wenn der Algorithmus nach k Runden noch nicht termi- niert hat, so gibt es von mindestens einem der Punkte in Q0 mindestens 2k/3 viele Kopien. Insbesondere gilt daher: E[Xk] = E[Xk | T \u0015 k] ︸ ︷︷ ︸ \u0015 2k/3 \u0001 Pr[T \u0015 k] + E[Xk | T < k] ︸ ︷︷ ︸ \u0015 0 \u0001 Pr[T < k] \u0015 2k/3 \u0001 Pr[T \u0015 k]. Vergleichen wir beide Ungleichungen, die wir für E[Xk] erhalten haben, so folgt 2k/3 \u0001 Pr[T \u0015 k] \u0014 E[Xk] \u0014 (1 + 3 r + 1 )k \u0001 n KAPITEL 3. ALGORITHMEN - HIGHLIGHTS 204 bzw. für r = 11 gilt Pr[T \u0015 k] \u0014 min{1, [(1+3/12)/21/3]kn} \u0014 min{1, 0.995 kn} und somit für k0 = − log0.995 n: E[T ] = ∑ k\u0015 1 Pr[T \u0015 k] \u0014 k0∑ k=1 1 + ∑ k>k0 0.995kn k=k0+k 0 = k0∑ k=1 1 ︸ ︷︷ ︸ =k0 + ∑ k 0 \u0015 1 0.995k 0 \u0001 0.995k0n︸ ︷︷ ︸ =1 = k0 + O(1) \u0014 200 ln n + O(1). Dies ist die erwartete Anzahl Runden; für die Laufzeit müssen wir noch mit n multiplizieren. Der Algorithmus, den wir in diesem Abschnitt vorgestellt haben, ist eine Variation eines Algorithmus von Clarkson, siehe Beitrag im Taschenbuch der Algorithmen14. Man sollte hier auch erwähnen, dass es randomisierte Algorithmen gibt, die C(P) in optimal linearer Zeit berechnen. Das Sampling Lemma Hinter dem Lemma 3.28 steckt ein einfaches allgemeines Prinzip, welches wir noch ergründen wollen. Dazu beginnen wir mit einer sehr allgemeinen Definition. Definition 3.30. Gegeben sei eine endliche Menge S, n := |S|, und ϕ eine beliebige Funktion auf 2S in einen beliebigen Wertebereich. Wir definieren V(R) = Vϕ(R) := {s 2 S | ϕ(R [ {s}) 6= ϕ(R)} X(R) = Xϕ(R) := {s 2 R | ϕ(R \\ {s}) 6= ϕ(R)} 14E. Welzl, Kleinster umschliessender Kreis (Ein Demokratiebeitrag aus der Schweiz?), Taschenbuch der Algorithmen, (B. Vöcking et al., Eds.), Springer-Verlag Berlin Heidel- berg, eXamen.press, (2008) 385-388 KAPITEL 3. ALGORITHMEN - HIGHLIGHTS 205 Elemente in V(R) nennen wir Verletzer von R, Elemente in X(R) nennen wir extrem in R. Wir sehen, dass s 2 V(R) ⇔ s 2 X(R [ {s}), eine Beziehung die im nächsten Beweis wesentlich sein wird. Unser Ziel ist zu verstehen, wie gross V(R) ist, wenn R zufällig mit gegebener Grösse r gewählt wird. Beispiel Kleinste Zahl. Sei A \u0012 N, endlich, und für R \u0012 A sei ϕ(R) := min(R), mit min(; ) := ∞. Es gilt X(R) = {min(R)} (für R 6= ; ) und V(R) = {a 2 A | a < min(R)}. Offensichtlich gilt für R 6= ; , dass |X(R)| = 1 und |V(R)| ist die Anzahl der Zahlen in A, die kleiner als min(R) sind, d.h. |V(R)| + 1 ist der Rang von min(R) in A (der Rang von a 2 A ist der Index von a in der aufsteigend sortierten Reihenfolge von A). Beispiel kleinster umschliessender Kreis. Sei P eine endliche Punktemenge und für R \u0012 P sei ϕ(R) := C(R) der kleinste umschliessende Kreis von R (mit ϕ(; ) := ; ). V(R) ist genau die Menge der Punkte ausserhalb C(R) und wir haben gesehen, dass |X(R)| \u0014 3. Das Sampling Lemma setzt die erwartete Anzahl verletzender Elemente in Bezug zur Anzahl extremer Elemente. Wir verwenden im Beweis folgende einfache Tatsache: Sei G = (A . [ B, E) ein bipartiter Graph mit E \u0012 {{a, b} | a 2 A, b 2 B}. Dann ist der Durchschnittsgrad 15 der Knoten in A mal |A| genau |E|. Lemma 3.31 (Sampling Lemma). Sei k 2 N, 0 \u0014 k \u0014 n. Wir setzen vk := E[|V(R)|] und xk := E[|X(R)|], wobei R eine k-elementige Teil- menge von S ist, zufällig gleichverteilt aus \u0010 S k \u0011 . Dann gilt für r 2 N, 0 \u0014 r < n, vr n − r = xr+1 r + 1 . Beweis. Wir definieren einen bipartiten Graph wie folgt: Die Knoten sind\u0010 S r \u0011 . [ \u0010 S r+1 \u0011 mit den Kanten {R, R [ {s}}, R 2 \u0010 S r \u0011 , s verletzt R (d.h. ϕ(R) 6= ϕ(R [ {s})). Folglich ist der Grad des Knoten R 2 \u0010 S r \u0011 in dem Graph genau |V(R)| und die Anzahl der Kanten des Graphen ist genau \u0010 n r \u0011 vr. 15Das ist 1 |A| ∑ a2 A deg(a). KAPITEL 3. ALGORITHMEN - HIGHLIGHTS 206 Beachte nun, dass die Kanten dieses Graphen genau die Paare {Q\\{s}, Q} sind mit Q 2 \u0010 S r+1 \u0011 und s extrem in Q (d.h. ϕ(Q \\ {s}) 6= ϕ(Q)). Der Grad von Q 2 \u0010 S r+1 \u0011 ist folglich |X(Q)| und die Anzahl der Kanten des Graphen ist genau \u0010 n r+1 \u0011 xr+1. Wir haben \u0010 n r \u0011 vr = \u0010 n r+1 \u0011 xr gezeigt und das Lemma folgt aus der einfa- chen Identiät \u0010 n r+1 \u0011 / \u0010 n r \u0011 = n−r r+1 . Korollar 3.32. Wählen wir r Elemente R aus einer Menge A von n Zahlen zufällig, dann ist der erwartete Rang des Minimums von R in A genau n−r r+1 + 1 = n+1 r+1 . Wählen wir r Punkte R aus einer Menge P von n Punkten in der Ebene zufällig, dann ist die erwartete Anzahl von Punkten aus P ausserhalb von C(R) höchstens 3 n−r r+1 . 3.2.2 Konvexe Hülle Wir haben bereits bei den Flüssen konvexe Mengen kennengelernt. Ähn- lich wie beim kleinsten umschliessenden Kreis kann man auch nach der kleinsten konvexen Menge fragen, die eine gegebene Teilmenge S des R d enthält. Definition 3.33. Sei S \u0012 R d, d 2 N. Die konvexe Hülle, conv(S), von S ist der Schnitt aller konvexen Mengen, die S enthalten, d.h. conv(S) := \\ S\u0012 C\u0012 Rd, C konvex C . Man kann sich leicht davon überzeugen, dass die konvexe Hülle immer selbst wieder konvex ist, also tatsächlich die kleinste konvexe Menge ist, die S enthält. Wir beschränken uns auf die Ebene (R 2) und die Berechnung der kon- vexen Hülle einer endlichen Menge P, n := |P| \u0015 3. Der Einfachheit halber nehmen wir an, dass P in allgemeiner Lage ist, d.h. keine drei Punkte auf einer Geraden liegen und dass keine zwei Punkte die gleiche x-Koordinate haben. Wir gehen später noch auf diese wesentliche Einschränkung ein, KAPITEL 3. ALGORITHMEN - HIGHLIGHTS 207 vorerst wollen wir uns aber nicht von Spezialfällen ablenken lassen und uns auf die algorithmischen Gesichtspunkte konzentrieren. Für eine endliche Punktemenge P in der Ebene wird die konvexe Hülle durch ein Polygon, der Rand von conv(P), bestimmt, dessen Ecken Punkte aus P sind. Wenn wir von der Berechnung von conv(P) sprechen, so meinen wir die Bestimmung der Folge (q0, q1, . . . , qh−1), h \u0014 n, (3.3) der Ecken dieses Polygons, beginnend bei einer beliebiger Ecke q0 und dann entgegen dem Uhrzeigersinn entlang dieses Polygons. p7p5p1p3p6p2p4 Abbildung 3.6: Punktemenge P = {p1, p2, p3, p4, p5, p6, p7} mit dem Polygon (p4, p1, p5, p7), welches conv(P) umrandet. Sei ein geordnetes Paar qr, q, r 2 P mit q 6= r, Randkante von P, falls alle Punkte in P\\{q, r} links von qr, d.h. auf der linken Seite der gerichteten Geraden durch q und r, gerichtet von q nach r, liegen.16 Offensichtlich müssen in der Folge (3.3) oben alle Paare qi−1qi, i = 1, 2, . . . , h, Randkanten von P sein (wir verstehen Indizes modh). Tatsächlich charakterisiert das schon die gültigen Ergebnisse für unser Problem. Lemma 3.34. (q0, q1, . . . , qh−1) ist die Eckenfolge des conv(P) umschlies- senden Polygons gegen den Uhrzeigersinn genau dann, wenn alle Paa- re (qi−1, qi), i = 1, 2, . . . , h, Randkanten von P sind. 16Falls ein Punkt s links (rechts) von qr liegt, so nennen wir (q, r, s) einen leftturn (rightturn). KAPITEL 3. ALGORITHMEN - HIGHLIGHTS 208 Offensichtlich ist die Frage, ob ein Punkt p links (oder rechts) von qr liegt für uns wichtig. Mit Hilfe der linearen Algebra und insbesondere Determi- nanten ist diese Frage algorithmisch aus den Koordinaten der Punkte leicht zu beantworten (hier ohne Beweis). Lemma 3.35. Seien p = (px, py), q = (qx, qy), und r = (rx, ry) Punkte in R 2. Es gilt q 6= r und p liegt links von qr genau dann, wenn det(p, q, r) := \f \f \f \f \f \f \f \f px py 1 qx qy 1 rx ry 1 \f \f \f \f \f \f \f \f = \f \f \f \f \f qx − px qy − py rx − px ry − py \f \f \f \f \f > 0 ⇔ (qx − px)(ry − py) > (qy − py)(rx − px) Genauer gesagt, ist 1 2 | det(p, q, r)| die Fläche des Dreiecks pqr, wobei das Vorzeichen bestimmt, wie die Punkte p, q, r den Rand dieses Dreiecks durchlaufen. Falls det(p, q, r) > 0, dann passiert das gegen den Uhrzei- gersinn17 und p ist links von qr. det(p, q, r) = 0 zeigt an, dass die drei Punkte auf einer gemeinsamen Gerade liegen18. Basierend auf Lemma 3.34 können wir einen ersten Algorithmus zur Bestimmung der konvexen Hülle angeben: Gehe durch jedes der n(n − 1) geordneten Paare qr, und prüfe, ob dies eine Randkante ist, indem man für alle n − 2 Punkte p in P \\ {q, r} feststellt, ob p links von qr liegt. So haben wir die Randkanten in O(n 3) gefunden, die wir nur mehr richtig aneinanderreihen müssen. Einwickeln Den ersten Ansatz wollen wir nun verbessern. Sei q0 der Punkt mit klein- ster x-Koordinate in P (der ist eindeutig auf Grund unserer Annahme zur allgemeinen Lage von P). q0 ist sicher eine Ecke der konvexen Hülle, also Teil der gesuchten Folge und wir können insbesondere die Folge auch mit q0 beginnen. Was ist nun der Punkt q1, der mit q0 eine Randkante q0q1 bil- det? Dazu rufen wir die Funktion FindNext(q0) auf, die uns genau dieses q1 liefert. 17Gegen den Uhrzeigersinn gilt in der Mathematik als die positive, bzw. “normale” Orientierung, man denke etwa an die Nummerierung der Quadranten in der Ebene. 18Das beinhaltet den Fall, dass zwei der Punkte, oder alle drei gleich sind. KAPITEL 3. ALGORITHMEN - HIGHLIGHTS 209 FindNext(q) 1: Wähle p0 2 P \\ {q} beliebig 2: qnext ← p0 3: for all p 2 P \\ {q, p0} do 4: if p rechts von qqnext then qnext ← p 5: return qnext Wir sollten uns bewusst machen, warum das funktioniert. Der Algorith- mus erinnert uns an das Finden des Minimums einer Menge von Zahlen. Tatsächlich können wir, gegeben q 2 P, eine Relation ˚ q auf P \\ {q} mittels p1 ˚ q p2 :⇔ p1 rechts von qp2 definieren und es gilt: Lemma 3.36. Ist q eine Ecke der konvexen Hülle von P, so ist die Relation ˚ q eine totale Ordnung auf P \\ {q}. Für das Minimum pmin dieser Ordnung gilt, dass qpmin eine Randkante ist. qp5p1p3p6p2p4 Abbildung 3.7: Totale Ordnung p4 ˚ q p2 ˚ q p6 ˚ q p1 ˚ q p3 ˚ q p5. qp4 ist Randkante. Die wesentliche Eigenschaft, die sich aus “q eine Ecke der konvexen Hülle von P” ergibt, ist, dass es eine Gerade gibt, die q von P \\ {q} trennt. Ist dies nicht möglich, so ist die Relation ˚ q zyklisch, also definitiv keine totale Ordnung und der Algorithmus FindNext liefert einen beliebigen Punkt in P \\ {q}. Nun können wir mittels FindNext(q1) den Punkt q2 finden, der die Randkante q1q2 bildet, usw., bis wir wieder bei q0 angelangt sind. Wir KAPITEL 3. ALGORITHMEN - HIGHLIGHTS 210 haben den sogenannten Jarvis’ Wrap Algorithmus (Einwickelalgorithmus) gefunden. JarvisWrap(P) 1: h ← 0 2: pnow ← Punkt in P mit kleinster x-Koordinate 3: repeat 4: qh ← pnow 5: pnow ← FindNext(qh) 6: h ← h + 1 7: until pnow = q0 8: return (q0, q1, . . . , qh−1) Jeder Aufruf der Funktion FindNext benötigt O(n) Zeit, und wir rufen diese genau h-mal auf. Daraus ergibt sich sofort folgendes Ergebnis. Satz 3.37. Gegeben eine Menge P von n Punkten in allgemeiner Lage in R 2, berechnet der Algorithmus JarvisWrap die konvexe Hülle in Zeit O(nh), wobei h die Anzahl der Ecken der konvexen Hülle von P ist. Dieser Algorithmus ist sehr schnell für h klein (z.B. wenn die konvexe Hülle ein Dreieck ist, ist der Algorithmus linear), und im schlimmsten Fall h = n haben wir immerhin die erste O(n 3) Schranke auf O(n 2) verbessert. Bevor wir diese quadratische Schranke verbessern, widmen wir uns kurz den Spezialfällen und Fragen der Implementierung. Spezialfälle und Implementierung. Geometrie ist anschaulich, der Jarvis- Wrap Algorithmus ist wirklich einfach und man ist vielleicht versucht, den Algorithmus sofort zu implementieren. Dabei tritt sofort die Frage nach der “allgemeine Lage” Annahme auf. Haben wir es mit einer beliebigen Menge P zu tun, also mit Kollinearitäten (mehr als zwei Punkte auf einer gemeinsa- men Geraden) oder mehreren Punkten gleicher x-Koordinate, ist folgendes zu beachten. 1. Der Anfangspunkt q0: Wir wählen q0 als den Punkt mit kleinster x-Koordinate, und wenn es mehrere Punkte mit gleicher kleinster x- Koordinate gibt, den unter denen mit kleinster y-Koordinate, d.h. KAPITEL 3. ALGORITHMEN - HIGHLIGHTS 211 qp1p3p6p2p4p5p7p8 Abbildung 3.8: Totale Ordnung bei möglichen Kollinearitäten: p4 ˚ q p7 ˚ q p2 ˚ q p6 ˚ q p1 ˚ q p5 ˚ q p8 ˚ q p3. qp4 ist Randkante. den lexikographisch kleinsten Punkt in P. Dieser Punkt ist immer Ecke der konvexen Hülle. 2. Der Test “p rechts von qqnext” muss ersetzt werden durch (p rechts von qqnext) oder (p auf der Geraden durch qqnext und |qp| > |qqnext|); kompakt: (det(p, q, qnext) < 0) ∨ (det(p, q, qnext) = 0 ∧ |qp| > |qqnext|) . 3. Wie bekommen wir P gegeben? In der Regel als Array, wobei wir kei- ne Garantie haben, dass alle Punkte verschieden sind. Wir könnten natürlich in einem ersten Schritt Doubletten entfernen. Dazu brau- chen wir aber Θ(n log n) Zeit (indem wir die Folge lexikographisch sortieren und dann die sortierte Folge auf Wiederholungen prüfen). Dann verlieren wir aber die Linearzeit des JarvisWrap bei h = O(1). Es genügt aber in der Funktion FindNext bei der Wahl von p0 auf p0 6= q zu achten. Und beim Test “pnow = q0” muss man achten, dass man nicht die Array-Indizes von pnow und q0 vergleicht, son- dern tatsächlich die Punkte19. Sonst läuft man möglicherweise in eine unendliche Schleife. Neben den gerade diskutierten Spezialfällen treten auch numerische Pro- bleme auf. Der Test “(qx − px)(ry − py) > (qy − py)(rx − px)” ist in einer Implementierung mit floating point nicht exakt, insbesondere auch, wenn 19Alternativ kann man am Anfang einmal das Array nach Doubletten von q0 durchsu- chen und entfernen. KAPITEL 3. ALGORITHMEN - HIGHLIGHTS 212 man auf Gleichheit abfragt. Der Gleichheitstest macht in floating point nach arithmetischen Operationen eigentlich schlichtweg keinen Sinn. Da- bei geht es weniger darum, dass unser Ergebnis absolut exakt ist. Oft ist die Eingabe schon mit numerischen Ungenauigkeiten behaftet, weshalb wir auch in der Ausgabe mit kleinen Ungenauigkeiten leben können. Aber das Problem ist, dass wir wegen dieser Ungenauigkeiten beim JarvisWrap am Startpunkt “vorbeilaufen” können. Es empfiehlt sich daher, einen exakten Datentyp zu verwenden, wie er in verschiedenen Programmbibliotheken angeboten wird. Lokal Verbessern Wir kehren zurück zu unserer Annahme, dass unsere Punktemenge in all- gemeiner Lage ist. Unser nächster Ansatz ist mit einem Polygon (r0, r1, . . . , rk−1) mit Ecken aus P zu beginnen und dieses Polygon sukzessive zu “korrigie- ren”, wann immer wir ein Problem sehen. Sollte diese Folge tatsächlich eine konvexe Menge gegen den Uhrzeigersinn umranden, dann muss sicher gel- ten, dass ri rechts von ri−1ri+1 liegt, für alle i = 0, 1, . . . , k − 1 (Indizes modk). Ist ri links von ri−1ri+1, entfernen wir ri einfach aus der Folge, bis wir keinen solchen Defekt mehr entdecken. p7p5p1p3p6p2p4 Abbildung 3.9: Eine lokal konvexes Polygon durch alle Punkte von P. Als kleine Warnung: Ist in der Folge kein solcher Defekt zu entdecken, heisst das noch lange nicht, dass wir das richtige Polygon gefunden haben. Offensichtlich wissen wir nicht, dass das Polygon die Menge P umschliesst. Aber selbst wenn etwa jeder Punkt in P in der Folge auftritt, können wir KAPITEL 3. ALGORITHMEN - HIGHLIGHTS 213 nicht sicher sein. Es kann sein, dass wir einen geschlossenen lokal konve- xen Polygonzug haben, der sich selbst schneidet, siehe Abb. 3.9. Richtig eingesetzt wird uns die Grundidee aber gute Dienste leisten. Als erstes sortieren wir P aufsteigend nach x-Koordinate; sei (p1, p2, . . . , pn) die sich ergebende Reihenfolge. Betrachten wir das Polygon (p1, p2, . . . , pn−1, pn, pn−1, . . . , p2) , d.h. wir durchlaufen P einmal von links nach rechts und dann wieder zurück von rechts nach links. Das Polygon hat 2(n − 1) gerichtete Kanten. Nun beginnen wir mit dem lokalen Verbessern dieses Polygons, siehe Abb. 3.10. Dabei wird sowohl p1 wie auch pn sicher nie entfernt, und zu jedem Zeit- punkt teilt sich die Folge in einen Teil der x-monoton von p1 nach pn läuft, und einen zweiten Teil der dann von pn zurück nach p1 läuft (man erinnere sich, dass wir implizit immer das erste Element der Folge auch am Ende der Folge sehen, so dass sich das Polygon schliesst). →→↓←← . . . ←p1pn Abbildung 3.10: Das links-rechts-links Polygon durch P, und lokale Verbes- serungsschritte (in unorganisierter Reihenfolge) bis zum Polygon, welches conv(P) umrandet. Kümmern wir uns vorerst nicht um die konkrete Implementierung un- seres Algorithmus, z.B. in welcher Reihenfolge wir die Tests durchfüh- ren, sondern sehen wir das sukzessive lokale Verbessern einfach als nicht- deterministischen Prozess. Ein Verbesserungsschritt sei definiert als die Operation, bei der wir für drei aufeinanderfolgende Punkte p, p 0 , p 00 fest- stellen, dass p 0 links von pp 00 liegt und wir p 0 deshalb aus der Folge entfer- nen. Dabei vergrössert sich das vom Polygonzug umrandete Gebiet genau KAPITEL 3. ALGORITHMEN - HIGHLIGHTS 214 um das Dreieck pp 0 p 00 . Behalten wir alte Kanten in der Zeichung, wie in Abb. 3.10, bekommen wir am Ende eine sogenannte Triangulierung20 der Punktemenge P. Bevor wir eine konkrete Organisation der Verbesserungsschritte präsen- tieren, widmen wir uns diesen Triangulierungen. Ebene Graphen und Triangulierungen Definition 3.38. Ein Graph G = (P, E) auf P heisst eben, wenn sich die Segmente pq := conv({p, q}) der Kanten {p, q} 2 E höchstens in ihren jeweils gemeinsamen Endpunkten schneiden. Entfernen wir die Segmente pq, {p, q} 2 E, aus R 2, so nennen wir die entstehenden zusammenhängenden Gebiete die Gebiete von G. Die beschränkten Gebiete nennen wir innere Gebiete, das unbeschränkte (unendliche) Gebiet das äussere Gebiet. Ein Graph T = (P, E) auf P heisst Triangulierung von P, falls T eben ist und maximal mit dieser Eigenschaft ist, d.h. das Hinzufügen jeder Kante \u0010 P 2 \u0011 \\ E zu T verletzt die Eigenschaft “eben”. Wir beobachten, dass die Gebiete eines ebenen Graphen G auf P bis auf genau eines beschränkt sind, siehe Abb. 3.11. Die inneren Gebiete einer Triangulierung sind alle Dreiecke 21; das einzige äussere Gebiet ist das Kom- plement von conv(P) in R 2 und liegt genau an den Randkanten von P an. Lemma 3.39. Sei h die Anzahl der Ecken der konvexen Hülle von P. Der lokale Verbesserungsprozess macht genau 2n − 2 − h Verbesse- rungsschritte und erzeugt eine Triangulierung mit 2n − 2 − h inneren Dreiecken und 3n − 3 − h Kanten. 20Triangulierungen spielen eine wichtige Rolle in Computergraphik, geographischen Informationssystemen, Numerik, Mathematik, etc. Will man etwa ein Gelände aus Mes- spunkten (x, y, z) 2 R3 rekonstruieren, so projiziert man die Punkte in die x-y-Ebene ((x, y, z) 7→ (x, y)), bestimmt eine Triangulierung der Punkte in der Ebene, und “liftet” die entstandenen Dreiecke wieder in den R3. 21Jedes andere Gebiet kann man durch Segmente weiter unterteilen, was der Maxima- litätseigenschaft widerspricht. KAPITEL 3. ALGORITHMEN - HIGHLIGHTS 215 GT1T2e1e2 Abbildung 3.11: Ein ebener Graph G und zwei Triangulierungen T1 und T2 einer Punktemenge, wobei T1 die sich aus dem Prozess in Abb. 3.10 ergebende Triangulierung ist. Der ebene Graph G hat zwei innere Gebie- te (schattiert) und ein äusseres Gebiet (der nicht schattierte Rest). Beide Triangulierungen haben 6 innere Gebiete, alles Dreiecke. Beweis. (i) Anzahl Schritte: Wir beginnen mit einem Polygon mit 2n − 2 gerichteten Kanten. In jedem Verbesserungsschritt werden zwei alte ge- richtete Kanten durch eine neue ersetzt, d.h. es gibt genau eine gerichtete Kante weniger. Da wir am Ende h gerichtete Kanten haben, sind wir genau 2n − 2 − h Schritte durchlaufen. (ii) Anzahl Dreiecke der Triangulierung: Wir beginnen mit 0 Dreiecken, jeder Verbesserungsschritt erzeugt ein neues Dreieck. Da wir 2n − 2 − h Schritte durchlaufen, haben wir am Schluss genau 2n − 2 − h Dreiecke. (iii) Anzahl ungerichteter Kanten der Triangulierung: Wir beginnen für die Triangulierung mit n − 1 ungerichteten Kanten (hier zählen wir die Kanten nicht doppelt für die beiden Richtungen) und fügen in jedem Schritt eine Kante hinzu, also haben wir am Ende (n−1)+(2n−2−h) = 3n−3−h Kanten. (iii’) Für die Anzahl der Kanten können wir uns alternativ überlegen, dass jedes der 2n − 2 − h Dreiecke drei Kanten hat, die – abgesehen von den h Randkanten – an jeweils zwei Dreiecken anliegen. Berücksichtigen wir noch das äussere Gebiet R 2 \\ conv(P) mit seinen h Kanten, haben wir jede Kante genau zweimal gezählt. Folglich ist die Anzahl der Kanten 1 2 (3 (2n − 2 − h) ︸ ︷︷ ︸ Anzahl Dreiecke + h︸︷︷︸ unendl. Gebiet) = 3n − 3 − h . An der Stelle fragen wir uns, ob jede Triangulierung T von P genau 2n−2−h innere Dreiecke und genau 3n − 3 − h Kanten hat, oder ob man dies nur KAPITEL 3. ALGORITHMEN - HIGHLIGHTS 216 für Triangulierungen behaupten kann, die aus unserem lokalen Verbesse- rungsprozess entstehen. Dazu zeigen wir erst eine wichtige Identität für alle ebenen Graphen. Lemma 3.40. (Euler Relation) Sei G = (P, E) ein ebener Graph auf P mit v := |P| Knoten, e := |E| Kanten, f Gebieten (inkl. des äusseren Gebiets), und c Zusammenhangskomponenten. Dann gilt v − e + f = 1 + c . (3.4) Beweis. Die Aussage gilt sicher, wenn E = ; , da es dann v Zusammen- hangskomponenten und genau ein Gebiet gibt, es gilt also v−e+f = v−0+1 und 1 + c = 1 + v. Nehmen wir an, dass E 6= ; und entfernen wir eine Kante g 2 E, was einen Graph G 0 := (P, E \\ {g}) ergibt, der sicher wieder eben ist. Unser Ziel ist zu zeigen, dass die Gültigkeit der Gleichheit (3.4) durch diese Operation nicht betroffen ist. Seien v 0 , e 0 , f 0 , c 0 die den v, e, f, c entsprechenden Werte für G 0 . Wir wollen also v 0 − e 0 + f 0 − (1 + c 0 ) = v − e + f − (1 + c) (3.5) beweisen. Sicher gilt v 0 = v und e 0 = e − 1. Was passiert mit f 0 und c 0 ? Wir wählen die Kante g nicht beliebig. Wenn möglich, sei g Teil eines Kreises in G. Ist dies nicht möglich, sind alle Zusammenhangskomponenten Bäume und wir wählen g so, dass es zu einem Knoten vom Grad 1 (ein Blatt) inzident ist22 (was möglich 23 ist, weil wir E 6= ; voraussetzen). Fall 1. g ist Kante auf einem Kreis in G. Dann ändert sich die Anzahl der Zusammenhangskomponenten nicht, d.h. c 0 = c. Und der Kreis trennt die beiden Seiten von g, daher liegt g an seinen beiden Seiten 24 zwei ver- schiedenen Gebieten von G an, die in G 0 zu einem Gebiet verschmelzen, d.h. f 0 = f−1. Es folgt (3.5), weil v 0 −e 0 +f 0 −(1+c 0 ) = v−(e−1)+(f−1)−(1+c). 22Diese Einschränkung auf zu Blättern inzidenten Kanten ist nicht wesentlich, macht aber unsere Argument einfacher. 23Zur Erinnerung: Jeder nichtleere Baum hat mindestens zwei Blätter. 24Wir identifizieren hier die kombinatorische Kante {p, q} 2 \u0000 P 2\u0001 bisweilen mit dem geometrischen Liniensegment pq. KAPITEL 3. ALGORITHMEN - HIGHLIGHTS 217 Fall 2. g ist zu einem Knoten p vom Grad 1 in G inzident. Dann gilt sicher c 0 = c + 1. Und die beiden Seiten von g liegen den gleichen Gebieten von G an, weil wir von der einen Seite des Segments g entlang von g und dann um p herum auf die andere Seite gelangen, ohne eines der Kanten von G zu kreuzen. Das heisst, es gilt f 0 = f. (3.5) folgt leicht. Durch sukzessives Entfernen von Kanten folgt nun, dass (3.4) für G gilt gdw. es für den leeren Graph (P, ; ) gilt, wovon wir uns schon überzeugt haben. Korollar 3.41. Sei P eine Menge von n \u0015 3 Punkten in allgemeiner Lage in R2 und sei h die Anzahl der Kanten von conv(P). (i) Jede Triangulierung T von P hat genau 3n − 3 − h Kanten und genau 2n−2−h innere Gebiete. (ii) Jeder ebene Graph G auf P hat höchstens 3n − 3 − h \u0014 3n − 6 Kanten und höchstens 2n − 2 − h \u0014 2n − 5 innere Gebiete. Beweis. (i) Sei f die Anzahl der Gebiete von T . f − 1 der Gebiete sind innere Gebiete, Dreiecke. Das äussere Gebiet liegt an h Kanten an. Die Anzahl der Kanten ist folglich 1 2(3(f − 1) + h). Da T zusammenhängend ist, gilt wegen (3.4), dass n − 1 2(3(f − 1) + h) + f = 2 ⇔ f = 2n − 1 − h und die Anzahl der inneren Gebiete ist 2n − 2 − h. Daraus ergibt sich auch die Anzahl der Kanten mit 1 2 (3(f − 1) + h) = 1 2 (3(2n − 1 − h − 1) + h) = 3n − 3 − h . Ausserdem gilt wegen n \u0015 3 und allgemeiner Lage, dass h \u0015 3. (ii) Die Schranken für G ergeben sich, weil Triangulierungen maximale ebene Graphen sind, und durch Hinzufügen von Kanten in einem ebenen Graph nicht nur die Anzahl der Kanten steigt, sondern auch die Anzahl der Gebiete nicht reduziert werden kann. Triangulierungen (und ebene Graphen im Allgemeinen) sind also dünne Graphen mit O(n) Kanten. KAPITEL 3. ALGORITHMEN - HIGHLIGHTS 218 Planare Graphen. Die Definitionen wie oben werden in der Graphentheorie allgemeiner betrachtet: Ein Graph heisst planar, wenn man ihn in der Ebene so zeichnen 25 kann (wobei Kanten als ihre Endpunkte verbindende Kurven realisiert werden können), dass sich keine zwei Kanten kreuzen. Ein ebener Graph ist ein planarer Graph zusammen mit einer Zeichnung ohne Kreuzung. Unsere Ergebnisse oben (obere Schranken von 3n−6 für die Anzahl von Kanten bzw. Euler Relation) gelten für planare bzw. ebene Graphen genau so. Eine wichtige Familie planarer Graphen erhält man aus den Kantengra- phen konvexer Polytope in R 3 (Tetraeder, Würfel, Oktaeder, etc.). Deshalb heisst die Euler Relation auch Eulersche Polyederformel: In einem kon- vexen Polytop in R 3 gilt immer: #Ecken minus #Kanten plus #Seiten ist immer 2; z.B. 4 − 6 + 4 = 2 für den Tetraeder oder 8 − 12 + 6 = 2 für den Würfel. Tatsächlich sind Begriffe wie z.B. “Kanten” in der Graphentheorie aus der Geometrie motiviert. Lokales Verbessern – Organisiert Wir kehren nun zum lokalen Verbessern zurück und beschreiben eine kon- krete Realisierung, wobei wir die Verwendung verketterter Listen vermei- den wollen, wie auch die anfängliche doppelte Speicherung der Punkte. Betrachten wir die nach x-Koordinate sortierte Folge (p1, p2, . . . , pn) (gespeichert in einem Array) und unser Ziel ist die Berechnung der kon- vexen Hülle (q0, q1, . . . , qh−1) (wieder in einem Array). Für i = 2, 3, . . . , n bestimmen wir die untere konvexe Hülle von {p1, p2, . . . , pi} und speichern sie in (q0, q1, . . . , qh), wobei qh = pi gelten muss. Dann erweitern wir diese Folge um pi+1 und verbessern sie lokal, indem wir die Folge (q0, q1, . . . , qh) beginnend mit qh zurücklaufen, bis wir die Tangente von pi+1 an diese Folge gefunden haben; jeder Schritt zurück ist eines unserer Verbesserungsschrit- te. Sind wir bei i = n angelangt, wiederholen wir das ganze von rechts nach links für die obere konvexe Hülle. Wir fassen das Vorgehen im Algorithmus LocalRepair zusammen, siehe auch Abb. 3.12. 25Man sagt auch: “in der Ebene einbetten”. KAPITEL 3. ALGORITHMEN - HIGHLIGHTS 219 LocalRepair(p1, p2, . . . , pn) ▷ setzt (p1, p2, . . . , pn), n \u0015 3, nach x-Koordinate sortiert, voraus 1: q0 ← p1 2: h ← 0 3: for i ← 2 to n do ▷ untere konvexe Hülle, links nach rechts 4: while h > 0 und qh links von qh−1pi do 5: h ← h − 1 6: h ← h + 1 7: qh ← pi ▷ (q0, . . . , qh) untere konvexe Hülle von {p1, . . . , pi} 8: h 0 ← h 9: for i ← n − 1 downto 1 do ▷ obere konvexe Hülle, rechts nach links 10: while h > h 0 und qh links von qh−1pi do 11: h ← h − 1 12: h ← h + 1 13: qh ← pi 14: return (q0, q1, . . . , qh−1) ▷ Ecken der konvexen Hülle, gg. Uhrzeigersinn Jeder erfolgreiche Test “h > 0 und qh links von qh−1pi” erzeugt ein neues Dreieck, d.h. wir wissen, dass es genau 2n − 2 − h davon gibt. Dazu gibt es genau einen erfolglosen Test für jedes neue pi, i = 2, 3, . . . , n, bei der unteren konvexen Hülle, und jedes neue neue pi, i = n − 1, n − 2, . . . , 1, bei der oberen konvexen Hülle. Das macht zusätzliche 2(n−1) solche Tests. Insgesamt also 4n−4−h Tests. Wir erhalten so also eine sehr genau lineare Schranke für den LocalRepair Algorithmus. Satz 3.42. Gegeben eine Folge p1, p2, . . . , pn nach x-Koordinate sor- tierter Punkte in allgemeiner Lage in R2, berechnet der Algorithmus LocalRepair die konvexe Hülle von {p1, p2, . . . , pn} in Zeit O(n). Das heisst, inklusive vorbereitendes Sortieren haben wir einen O(n log n) Algorithmus, der asymptotisch schneller als JarvisWrap ist, es sei denn h = o(log n). Auch ist es relativ leicht, Punkte gleicher x-Koordinate (sor- tiere lexikographisch) und Kollinearitäten miteinzubeziehen. Wiederholun- gen von Punkten kann man nach dem Sortieren entfernen. Numerische Probleme können Ungenauigkeiten hervorrufen, aber man kann deswegen nicht in eine unendliche Schleife zu laufen. KAPITEL 3. ALGORITHMEN - HIGHLIGHTS 220 p2p3p5 = q2p6p7p8p9p10p2p3p4p5p6 = q1p7p8p9p10p1 = q0p4 = q1p1p2p3p4p5p6 = q1 = q5p7 = q2p8p9 = q4p10 = q3p1 = q0p2 = q6p3p4p5p6 = q1p7 = q2p8p9 = q4p10p1 = q0 = q7= q3= q5= q0(1)(2)(3)(4) Abbildung 3.12: Illustration des LocalRepair Algorithmus. (1) (q0, q1, q2) nach i = 5 bei links nach rechts. (2) (q0, q1) nach Erweiterung auf i = 6. (3) (q0, . . . , q5) nach i = 6 bei rechts nach links. (4) (q0, . . . , q7) nach Beendigung des Algorithmus, mit Ausgabe (q0, . . . , q6). Geht es besser? Konvexe Hülle kann nicht schneller als Sortieren gelöst wer- den. Dazu betrachte man eine Folge (x1, x2, . . . , xn) von Zahlen in R. Wir setzen pi = (xi, x 2 i ), i = 1, 2, . . . , n. Das heisst, wir betten die xi’s auf der x-Achse im R2 ein und projizieren diese Punkte vertikal auf die Einheitspa- rabel y = x2. Berechnen wir jetzt die konvexe Hülle von P := {p1, p2, . . . , pn} in unserem Sinn, d.h. als sortierte Folge der Ecken der konvexen Hülle so er- gibt sich daraus (in linearer Zeit) auch die aufsteigend sortierte Reihenfolge der xi’s. Wir haben eine sogenannte Reduktion gezeigt: Kann man konvexe Hülle in t(n) berechnen, so kann man in t(n) + O(n) Zeit sortieren. Trotz- x1x5x4x2x3p1p5p4p2p3 Abbildung 3.13: Vertikale Projektion auf die Einheitsparabel y = x2. dem haben wir gesehen, dass es für spezielle Eingaben (z.B. Punktemengen mit konvexen Hüllen mit wenig Ecken) schnellere Algorithmen geben kann.","libVersion":"0.3.2","langs":""}
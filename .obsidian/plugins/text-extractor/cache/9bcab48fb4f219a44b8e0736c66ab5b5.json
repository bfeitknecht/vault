{"path":"sem4/W&S/UE/s/W&S-s-u13.pdf","text":"Probability and Statistics (D-INFK) Lecturer: Prof. Dr. Dylan Possamaï Coordinator: Daniel Kršek Probability and Statistics Exercise sheet 13 - Solutions MC 13.1. Which of the following statements are true? (The number of correct answers is between 0 and 4.) (a) If we reject the null hypothesis, the realized p-value must be less than or equal to the significance level α. (b) If the realized p-value is less than or equal to the level α, we reject the null hypothesis. (c) The realized p-value tells us the probability that H0 is true. (d) If the realized p-value is very low, it indicates that our data do not fit the null hypothesis well. Solution: (a) True. (b) True. (c) Not true. We cannot assign a probability to the event “H0 is true,” as it is not a random event. (d) True. Exercise 13.2. Compute the realized p-values for the tests from Exercises 12.3, 12.4, 12.6, and 12.7. Remark: You should write down an explicit formula (e.g., involving the standard normal CDF), but you do not need to compute its numerical value. Remark: To compute the numerical value, you can use Wolfram Alpha to find values of the standard normal distribution function or Python: from scipy.stats import norm value = norm.cdf(x=1.96) # Replace x with the value you’re interested in print(value) You can find values of other distribution functions analogously. Solution: (12.3) We have that S(ω) = ∑1000 i=1 xi = 80.2, which gives using that σ2 = 1: S(ω) √1000σ2 ≈ 2.54. We compute p-value(ω) = P0[|S| ≥ 2.54] = 2(1 − Φ(2.54)) ≈ 0.011. As p-value = 0.011 < 0.05 = α, we reject the null hypothesis, which agrees with the result from Exercise 12.3. 1 Probability and Statistics (D-INFK) Lecturer: Prof. Dr. Dylan Possamaï Coordinator: Daniel Kršek (12.4) We have S(ω) = 650, and so S(ω) − 1000 × 0.6 √1000 × 0.24 = 650 − 1000 × 0.6 √1000 × 0.24 ≈ 3.23. Thus, p-value(ω) = P0.6[S ≥ 3.23] = 1 − Φ(3.23) ≈ 6.2 × 10−4. For comparison, using the distribution function of the Binom(1000,0.6)-distribution instead of the approximation gives p-value(ω) = P0.6[S ≥ 650] = 1 − P0.6[S ≤ 649] = 1 − FBinom(1000,0.6)(649) ≈ 6.5 × 10−4, where we computed: from scipy.stats import binom value = 1 - binom.cdf(649, 1000, 0.6) print(value) >> 0.0006454991535237431 (12.6) We have that T (ω) = 4, which gives p-value(ω) = P 1 6 [T ≥ 4] = 1 − P 1 6 [T ≤ 3] = 1 − FBinom(10,1/6)(3) ≈ 0.0697. (12.7) We have that T (ω) = −0.00598, which gives p-value(ω) = Pµ0 [|T | ≥ 0.00598] = 2(1 − Φ(0.00598)) ≈ 0.9952. Exercise 13.3. The average travel time from Zurich to Bellinzona by Intercity train is 146 minutes. The following times are recorded for the Cisalpino: x1 x2 x3 x4 x5 x6 x7 x8 x9 152 145 141 137 145 146 139 147 138 We assume that these values are realizations of an i.i.d. sample X1, . . . , Xn with Xi ∼ N (µ, σ2), where µ is an unknown parameter and σ2 = 9 is known. (a) Perform an appropriate test at the 5% level to determine whether the mean travel time of the Cisalpino differs from that of the Intercity. (b) Compute the realized p-value. (c) What is the lowest level α at which you would still reject the null hypothesis? Solution: (a) Since the variance σ2 = 9 is known, it is appropriate to conduct a (two-sided) z-test in this case. We want to test the null hypothesis H0 : µ = µ0 := 146 against the alternative H1 : µ ̸= µ0, 2 Probability and Statistics (D-INFK) Lecturer: Prof. Dr. Dylan Possamaï Coordinator: Daniel Kršek using the test statistic T = X 9 − µ0 σ/ √9 . Under Pµ0 , we have T ∼ N (0, 1), and we choose the critical region to be of the form K̸= = (−∞, −c̸=) ∪ (c̸=, ∞). So we reject H0 if |T | > c̸=, where c̸= is to be determined. Since we are testing at the 5% level, we choose c̸= such that 0.05 = α = Pµ0 [T ∈ K̸=] = 2(1 − Φ(c̸=)). This gives c̸= = Φ −1(1 − α/2) = z0.975 = 1.96. The realized value of the test statistic is T (ω) = t(x1, . . . , xn) = −2.67. Since |T (ω)| = 2.67 > 1.96, we reject the null hypothesis. (b) We have that p-value(ω) = Pµ0[|T | ≥ 2.67] = 2(1 − Φ(2.67)) ≈ 0.0076. (c) The lowest level alpha at which we would still reject the null hypothesis is exactly the p-value. The answer is thus α = 0.0076. For comparison, if instead we were testing the one-sided alternative H′ 1 : µ < µ0, then the critical region would be K< = (−∞, c<) with c< = z0.05 = −z0.95 = −1.645. Since −2.67 < −1.645, and so T (ω) ∈ K<, we of course also reject the null hypothesis in this case; the data thus suggest that the Cisalpino has a shorter average travel time. The p-value in this case is p-value(ω) = Pµ0 [T ≤ −2.67] = Φ(−2.67) ≈ 0.0038. Exercise 13.4. Let {Pθ : θ ∈ Θ}, where Θ ⊆ R, be a family of models, and let X1, . . . , Xn be i.i.d. random variables from the distribution Pθ. Assume that we have a confidence interval for θ of the form [A = a(X1, . . . , Xn), B = b(X1, . . . , Xn)] with coverage probability 1 − α. Further, consider the hypotheses H0 : θ = θ0, H1 : θ ̸= θ0, (1) where θ0 ∈ Θ is fixed. (a) Show that the test procedure “We reject H0 if and only if θ0 /∈ [A, B]” defines a test at level α. (b) Conversely, for every θ0 ∈ Θ, let (Tθ0 , Kθ0) be a test for (1) at level α. Show that the random set S(ω) := {θ0 ∈ Θ : Tθ0(ω) /∈ Kθ0} is a confidence set for θ with coverage probability at least 1 − α. That is, show that Pθ0 [θ0 ∈ S] ≥ 1 − α, θ0 ∈ Θ. 3 Probability and Statistics (D-INFK) Lecturer: Prof. Dr. Dylan Possamaï Coordinator: Daniel Kršek (c) How would you modify the confidence interval in (a) for the one-sided alternative H0 : θ = θ0, H′ 1 : θ > θ0? Solution: (a) We want to verify that the probability of a type I error is at most α, i.e., Pθ0 [“H0 is rejected”] ≤ α. We have Pθ0[“H0 is rejected”] = Pθ0 [θ0 /∈ [A, B]] = 1 − Pθ0 [θ0 ∈ [A, B]] ≤ 1 − (1 − α) = α, where we have used that [A, B] is a confidence interval with coverage probability 1 − α, which means that Pθ[θ ∈ [A, B]] ≥ 1 − α, θ ∈ Θ. (b) By similar reasoning as in part (a), we have for every θ0 ∈ Θ Pθ0 [θ0 ∈ S] = Pθ0[Tθ0 /∈ Kθ0 ] = 1 − Pθ0[Tθ0 ∈ Kθ0 ] ≥ 1 − α, where we have used that (Tθ0 , Kθ0) is a test at level α, meaning that Pθ0[Tθ0 ∈ Kθ0 ] ≤ α, θ0 ∈ Θ. Thus, S is a confidence set for θ with coverage probability at least 1 − α. (c) To modify the test for the one-sided alternative, we can consider a one-sided interval of the form [C = c(X1, . . . , Xn), ∞). We require that the probability of coverage is at least 1 − α, i.e., Pθ[θ ∈ [C, ∞)] = Pθ[θ ≥ C] ≥ 1 − α, θ ∈ Θ. As in part (a), we can then show that the test procedure “We reject H0 if and only if θ0 /∈ [C, ∞)” defines a test at level α. This test generally has greater power in this case, as it explicitly accounts for the direction of the alternative hypothesis. Exercise 13.5. Find the p-values for the tests from Exercise 12.5. Solution: (a) Let t(a) denote the observed value of T(a), i.e., t(a) = T(a)(ω). Then, the p-value is given by p-value(ω) = PH0 [|T(a)| ≥ |t(a)|] = 2(1 − Φ(|t(a)|)) = 2(1 − Φ(|T(a)(ω|))). (b) Let t(b) denote the observed value of T(b), i.e., t(b) = T(b)(ω). Then, the p-value is given by p-value(ω) = PH0[|T(b)| ≥ |t(b)|] = 2(1 − Ftn−1 (|t(b)|)) = 2(1 − Ftn−1 (|T(b)(ω|))), 4 Probability and Statistics (D-INFK) Lecturer: Prof. Dr. Dylan Possamaï Coordinator: Daniel Kršek where Ftn−1 denotes the distribution function of the t-distribution with n − 1 degrees of freedom. (c) Let t(c) denote the observed value of T(c), i.e., t(c) = T(c)(ω). Then, the p-value is given by p-value(ω) = PH0 [T(c) ≥ t(c)] = 1 − Fχ2 n−1(t(c)) = 1 − Fχ2 n−1(T(c)(ω)), where Fχ2 n−1 denotes the distribution function of the chi-squared distribution with n − 1 degrees of freedom. (d) Let t(d) denote the observed value of T(d), i.e., t(d) = T(d)(ω). Then, the p-value is given by p-value(ω) = PH0 [T(d) ≤ t(d)] = Φ(t(d)) = Φ(T(d)(ω)). (e) Let t(e) denote the observed value of T(e), i.e., t(e) = T(e)(ω). Then, the p-value is given by p-value(ω) = PH0 [T(e) ≤ t(e)] = Φ(t(e)) = Φ(T(e)(ω)). 5 Probability and Statistics (D-INFK) Lecturer: Prof. Dr. Dylan Possamaï Coordinator: Daniel Kršek Rewind These are some additional exercises to review some of the material we covered during the semester. MC 13.6. Let X1, X2, . . . be a sequence of independent, identically distributed random variables with E[X 2 1 ] < ∞. Let Z be a standard normally distributed random variable. We define µ := E[X1] and σ2 := Var[X1]. Which of the following statements is correct? (Exactly one answer is correct.) (a) lim n→∞ P [ 1 σ2n n∑ i=1 Xi ≤ a ] = P[Z ≤ a], a ∈ R. (b) lim n→∞ P [ 1 σ2n n∑ i=1(Xi − µ) ≤ a ] = P[Z ≤ a], a ∈ R. (c) lim n→∞ P [ 1 √σ2n n∑ i=1(Xi − µ) ≤ a ] = P[Z ≤ a], a ∈ R. (d) lim n→∞ P [ 1 √σ2n n∑ i=1 Xi ≤ a ] = P[Z ≤ a], a ∈ R. Solution: (c) is the correct form of the Central Limit Theorem. MC 13.7. Does the correct answer to MC 13.6 also hold exactly for finite n (i.e., if we omit limn→∞)? (The number of correct answers is between 0 and 4.) (a) The correct answer to MC 13.6 also holds without the limit for all distributions satisfying E[X 2 1 ] < ∞. (b) The correct answer to MC 13.6 also holds without the limit if the Xi’s are normally distributed. (c) The correct answer to MC 13.6 also holds without the limit if µ = 0 and σ = 1. (d) The correct answer to MC 13.6 never holds exactly for finite n if the limit is omitted. Solution: (b) is correct. If Xi ∼ N (µ, σ2), then by independence, ∑n i=1 Xi ∼ N (nµ, nσ2). It follows that 1 √nσ2 ( n∑ i=1 Xi − nµ ) = 1 √nσ2 n∑ i=1(Xi − µ) ∼ N (0, 1). None of the other options is correct. Exercise 13.8. It costs $1 to play a particular slot machine in Las Vegas. The machine is programmed so that it pays out $2 with probability 0.45 (the player wins), and nothing with probability 0.55 (the casino wins). Let Xi be the net gain of the casino on the i-th round of the game. Let Sn := ∑n i=1 Xi be the casino’s total gain after n rounds. Assuming that the outcomes of the games are independent, determine: 6 Probability and Statistics (D-INFK) Lecturer: Prof. Dr. Dylan Possamaï Coordinator: Daniel Kršek (a) E[Sn] and Var[Sn]; (b) the approximate probability that after 10 ′000 rounds, the casino’s gain lies between $800 and $1100. Assume that we know the casino’s gain after 10′000 rounds is $1200. (c) Based on this observation, can we conclude that the probability the casino wins is greater than the stated value 0.55? Use significance level α = 0.05. Solution: (a) The casino’s gain in each round is an independent random variable with Xi = {1 with probability p = 0.55, −1 with probability 1 − p = 0.45. This gives E[Xi] = 1×0.55+(−1)×0.45 = 0.1 and Var[Xi] = E[X 2 i ]−(E[Xi]) 2 = 1−0.12 = 0.99. Thus, E[Sn] = n × E[Xi] = 0.1n, Var[Sn] = n × Var[Xi] = 0.99n. Alternatively, observe that Bi := Xi + 1 2 , i = 1, . . . , n, are i.i.d. Bernoulli(0.55) variables. Then Sn = n∑ i=1 Xi = n∑ i=1(2Bi − 1) = 2 n∑ i=1 Bi − n = 2 ˜Sn − n, where ˜Sn ∼ Bin(n, 0.55). Hence, E[Sn] = 2 × 0.55n − n = 0.1n, Var[Sn] = 4 × 0.55 × 0.45n = 0.99n. (b) Since the Xi are i.i.d., we apply the Central Limit Theorem. For large n, we have approximately Sn − 0.1n √0.99n ∼ N (0, 1). For n = 10 ′000, we have approximately S10′000 − 1000 √9900 ∼ N (0, 1), and therefore 7 Probability and Statistics (D-INFK) Lecturer: Prof. Dr. Dylan Possamaï Coordinator: Daniel Kršek P[800 ≤ S10′000 ≤ 1100] = P [ − 200 √9900 ≤ S10′000 − 1000 √9900 ≤ 100 √9900 ] ≈ Φ ( 100 √9900 ) − Φ (− 200 √9900 ) = Φ(1.005) − Φ(−2.010) ≈ 0.82. (c) We test the hypotheses H′ 0 : p ≤ 0.55, H1 : p > 0.55. Alternatively, we can take H0: p = 0.55. Under H0 (which also works for H′ 0 as in Exercise 12.4), we have approximately S10′000 − 1000 √9900 ∼ N (0, 1). Then, P0.55[S10′000 ≥ c] = P0.55 [ S10′000 − 1000 √9900 ≥ c − 1000 √9900 ] ≈ 1 − Φ ( c − 1000 √9900 ) . We solve 1 − Φ ( c − 1000 √9900 ) = 0.05 ⇐⇒ c − 1000 √9900 = Φ −1(0.95) ⇐⇒ c − 1000 √9900 = 1.6449 ⇐⇒ c = 1000 + 1.6449 × √9900 ≈ 1163.67. Thus, the approximate critical region for the test statistic S10′000 is [1164, ∞). Since 1200 ∈ [1164, ∞), we reject H0 and can state that the probability the casino wins is greater than 0.55. Exercise 13.9. A team of three people is randomly selected from a group of six people. Among the six are three women (Anna, Elsa, and Helga) and three men (Franz, Mario, and Tobias). Let X be the number of women and Y the number of men in the selected team. (a) What is the conditional probability that the team consists only of women, given that the team includes at least one woman? (b) What is the conditional probability that the team consists only of women, given that Helga is in the team? (c) Find the joint distribution of (X, Y ). Compute E[X] and E[Y ]. (d) Compute Var[X], Var[X + Y ], Cov(X, Y ), and Corr(X, Y ). 8 Probability and Statistics (D-INFK) Lecturer: Prof. Dr. Dylan Possamaï Coordinator: Daniel Kršek Solution: (a) For x ∈ {0, 1, 2, 3}, the number of teams with x women and 3 − x men is (3 x )( 3 3 − x ). There are 3∑ x=1 (3 x )( 3 3 − x ) = 3 × 3 + 3 × 3 + 1 = 19 teams with at least one woman. Exactly one of these consists only of women. Hence, the conditional probability is 1 19 . Alternatively, there are (6 3) = 20 possible teams. Thus, P[“only women” | “at least one woman”] = P[“only women” and “at least one woman”] P[“at least one woman”] = P[“only women”] P[“at least one woman”] = 1/20 19/20 = 1 19 . (b) For x ∈ {0, 1, 2}, the number of teams including Helga and x additional women and 2 − x men is (2 x )( 3 2 − x ). This gives 2∑ x=0 (2 x )( 3 2 − x ) = 1 + 2 × 3 + 3 = 10 teams that include Helga. Exactly one of these consists only of women. Hence, the conditional probability is 1 10 . Alternatively, P[“only women” | “Helga in team”] = P[“only women” and “Helga in team”] P[“Helga in team”] = P[“only women”] P[“Helga in team”] = 1/20 10/20 = 1 10 . (c) Clearly, P[X = x, Y = y] = 0 if x + y ̸= 3. For y = 3 − x, we have P[X = x, Y = y] = (3 x)(3 y) (6 3) = (3 x)(3 y) 20 . So, P[X = 0, Y = 3] = 1 20 , P[X = 1, Y = 2] = 9 20 , P[X = 2, Y = 1] = 9 20 , P[X = 3, Y = 0] = 1 20 . 9 Probability and Statistics (D-INFK) Lecturer: Prof. Dr. Dylan Possamaï Coordinator: Daniel Kršek We compute E[X] = 1 × 9 20 + 2 × 9 20 + 3 × 1 20 = 30 20 = 3 2 . By symmetry, E[Y ] = 3 2 . Alternatively, Y = 3 − X, so E[Y ] = 3 − E[X] = 3 2 . (d) We compute E[X 2] = 12 × 9 20 + 22 × 9 20 + 32 × 1 20 = 54 20 , so Var[X] = E[X 2] − (E[X]) 2 = 54 20 − ( 3 2 )2 = 9 20 . Since X + Y = 3, we have Var[X + Y ] = Var[3] = 0. Using the formula Var[X + Y ] = Var[X] + 2Cov(X, Y ) + Var[Y ], and noting that Var[X] = Var[Y ], we find Cov(X, Y ) = −Var[X] = − 9 20 . Alternatively, from the joint distribution: E[XY ] = 1 × 2 × 9 20 + 2 × 1 × 9 20 = 36 20 = 9 5 , so Cov(X, Y ) = E[XY ] − E[X]E[Y ] = 9 5 − 9 4 = − 9 20 . Finally, Corr(X, Y ) = Cov(X, Y ) √ Var[X] × Var[Y ] = −1. That is, X and Y are perfectly negatively correlated, which can be directly seen from the identity X = 3 − Y . Exercise 13.10. Let X and Y be independent random variables where X is uniformly distributed on [0, 1] and Y is exponentially distributed with parameter 1. Define U = X + Y and V = XY . (a) Compute E [ V X 2 + 1 ] . (b) Determine the distribution function and the density function of U . 10 Probability and Statistics (D-INFK) Lecturer: Prof. Dr. Dylan Possamaï Coordinator: Daniel Kršek Solution: (a) Since X and Y are independent, so are Y and X/(X 2 + 1). Therefore, we have using that E[Y ] = 1: E [ V X 2 + 1 ] = E [ Y × X X 2 + 1 ] = E[Y ] × E [ X X 2 + 1 ] = ∫ 1 0 x x2 + 1 dx. Using the substitution formula: ∫ 1 0 x x2 + 1 dx = 1 2 log(x2 + 1)∣ ∣ ∣1 x=0 = 1 2 log 2. So, the value is log 2 2 . (b) Since X and Y are independent, the joint density is fX,Y (x, y) = 1[0,1](x) × e−y × 1[0,∞)(y). We compute P[U ≤ u] for different values of u. For u < 0, clearly P[U ≤ u] = 0. For u ≥ 0: P[U ≤ u] = ∫ min{u,1} 0 ∫ u−x 0 e−ydydx = ∫ min{u,1} 0 (1 − e−(u−x)) dx. We simplify: ∫ min{u,1} 0 (1 − ex−u) dx = min{u, 1} − e−u ∫ min{u,1} 0 e xdx. • For 0 ≤ u ≤ 1, the distribution function is: P[U ≤ u] = u − e−u(eu − 1) = u + e−u − 1. • For u > 1, we get: P[U ≤ u] = 1 − e−u(e − 1). The distribution function is thus FU (u) = P[U ≤ u] =    0 if u < 0, u + e−u − 1 if 0 ≤ u ≤ 1, 1 − e−u(e − 1) if u > 1. To find the density, we differentiate the distribution function: fU (u) =    0 if u < 0, 1 − e−u if 0 ≤ u < 1, e−u(e − 1) if u > 1. 11 Probability and Statistics (D-INFK) Lecturer: Prof. Dr. Dylan Possamaï Coordinator: Daniel Kršek Quantile table for the standard normal distribution 0.5 0.75 0.9 0.95 0.975 0.99 0.995 0.999 0 0.6745 1.2816 1.6449 1.9600 2.3263 2.5758 3.0902 . For instance, Φ−1(0.9) = 1.2816, where Φ is the distribution function of N (0, 1). Table of standard normal distribution 0.00 0.01 0.02 0.03 0.04 0.05 0.06 0.07 0.08 0.09 0.0 0.5000 0.5040 0.5080 0.5120 0.5160 0.5199 0.5239 0.5279 0.5319 0.5359 0.1 0.5398 0.5438 0.5478 0.5517 0.5557 0.5596 0.5636 0.5675 0.5714 0.5753 0.2 0.5793 0.5832 0.5871 0.5910 0.5948 0.5987 0.6026 0.6064 0.6103 0.6141 0.3 0.6179 0.6217 0.6255 0.6293 0.6331 0.6368 0.6406 0.6443 0.6480 0.6517 0.4 0.6554 0.6591 0.6628 0.6664 0.6700 0.6736 0.6772 0.6808 0.6844 0.6879 0.5 0.6915 0.6950 0.6985 0.7019 0.7054 0.7088 0.7123 0.7157 0.7190 0.7224 0.6 0.7257 0.7291 0.7324 0.7357 0.7389 0.7422 0.7454 0.7486 0.7517 0.7549 0.7 0.7580 0.7611 0.7642 0.7673 0.7704 0.7734 0.7764 0.7794 0.7823 0.7852 0.8 0.7881 0.7910 0.7939 0.7967 0.7995 0.8023 0.8051 0.8078 0.8106 0.8133 0.9 0.8159 0.8186 0.8212 0.8238 0.8264 0.8289 0.8315 0.8340 0.8365 0.8389 1.0 0.8413 0.8438 0.8461 0.8485 0.8508 0.8531 0.8554 0.8577 0.8599 0.8621 1.1 0.8643 0.8665 0.8686 0.8708 0.8729 0.8749 0.8770 0.8790 0.8810 0.8830 1.2 0.8849 0.8869 0.8888 0.8907 0.8925 0.8944 0.8962 0.8980 0.8997 0.9015 1.3 0.9032 0.9049 0.9066 0.9082 0.9099 0.9115 0.9131 0.9147 0.9162 0.9177 1.4 0.9192 0.9207 0.9222 0.9236 0.9251 0.9265 0.9279 0.9292 0.9306 0.9319 1.5 0.9332 0.9345 0.9357 0.9370 0.9382 0.9394 0.9406 0.9418 0.9429 0.9441 1.6 0.9452 0.9463 0.9474 0.9484 0.9495 0.9505 0.9515 0.9525 0.9535 0.9545 1.7 0.9554 0.9564 0.9573 0.9582 0.9591 0.9599 0.9608 0.9616 0.9625 0.9633 1.8 0.9641 0.9649 0.9656 0.9664 0.9671 0.9678 0.9686 0.9693 0.9699 0.9706 1.9 0.9713 0.9719 0.9726 0.9732 0.9738 0.9744 0.9750 0.9756 0.9761 0.9767 2.0 0.9772 0.9778 0.9783 0.9788 0.9793 0.9798 0.9803 0.9808 0.9812 0.9817 2.1 0.9821 0.9826 0.9830 0.9834 0.9838 0.9842 0.9846 0.9850 0.9854 0.9857 2.2 0.9861 0.9864 0.9868 0.9871 0.9875 0.9878 0.9881 0.9884 0.9887 0.9890 2.3 0.9893 0.9896 0.9898 0.9901 0.9904 0.9906 0.9909 0.9911 0.9913 0.9916 2.4 0.9918 0.9920 0.9922 0.9925 0.9927 0.9929 0.9931 0.9932 0.9934 0.9936 2.5 0.9938 0.9940 0.9941 0.9943 0.9945 0.9946 0.9948 0.9949 0.9951 0.9952 2.6 0.9953 0.9955 0.9956 0.9957 0.9959 0.9960 0.9961 0.9962 0.9963 0.9964 2.7 0.9965 0.9966 0.9967 0.9968 0.9969 0.9970 0.9971 0.9972 0.9973 0.9974 2.8 0.9974 0.9975 0.9976 0.9977 0.9977 0.9978 0.9979 0.9979 0.9980 0.9981 2.9 0.9981 0.9982 0.9982 0.9983 0.9984 0.9984 0.9985 0.9985 0.9986 0.9986 3.0 0.9987 0.9987 0.9987 0.9988 0.9988 0.9989 0.9989 0.9989 0.9990 0.9990 For instance, P[Z ≤ 1.96] = 0.975. 12","libVersion":"0.5.0","langs":""}
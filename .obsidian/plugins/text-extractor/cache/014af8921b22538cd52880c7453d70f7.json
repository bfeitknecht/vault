{"path":"sem2/A1/PV/summaries/A1-HS18-mmathys.pdf","text":"Analysis II Patrick Eigensatz, Max Mathys https://github.com/mmathys/analysis-ii-summary Fixes und Verbesserungen: Issue/PR w¨aren appreciated! 1 Allgemein x y 0◦ 90◦ 180◦ 270◦ 30◦ 60◦120◦ 150◦ 210◦ 240◦ 300◦ 330◦ 45◦135◦ 225◦ 315◦ π 2 π 3π 2 2π π 6 π 3 2π 3 5π 6 7π 6 4π 3 5π 3 11π 6 π 4 3π 4 5π 4 7π 4 ( √2 2 , √2 2 )(− √2 2 , √2 2 ) (− √2 2 , − √2 2 ) ( √2 2 , − √2 2 ) ( √3 2 , 1 2 ) ( 1 2 , √3 2 ) (− √3 2 , 1 2 ) (− 1 2 , √3 2 ) (− √3 2 , − 1 2 ) (− 1 2 , − √3 2 ) ( √3 2 , − 1 2 ) ( 1 2 , − √3 2 ) (−1, 0) (1, 0) (cos, sin) (0, −1) (0, 1) Rechenregeln: Sinus und Cosinus • eix = cos(x) + i · sin(x) • cos(x) = Re(eix) • sin(x) = Im(eix) • sin(x ± y) = sin(x) cos(y) ± cos(x) sin(y) • cos(x ± y) = cos(x) cos(y) ∓ sin(x) sin(y) • sin(x + y) sin(x − y) = cos2(y) − cos2(x) = sin 2(x) − sin 2(y) • cos(x + y) cos(x − y) = cos2(y) − sin 2(x) = cos2(x) − sin 2(y) • sin x cos x = 1 2 (sin(x + y) + sin(x − y)) • cos x cos y = 1 2 (cos(x + y) + cos(x − y)) • sin x sin y = 1 2 (cos(x − y) − cos(x + y)) • cos(x)2 + sin(x) 2 = 1 • cos(π − x) = − cos(x), sin(π − x) = sin(x) • cos(x + π) = − cos(x), sin(x + π) = − sin(x) • cos(2x) = cos2(x) − sin 2(x) = 1 − 2 sin 2(x) = 2 cos2(x) − 1 • sin(2x) = 2 sin(x) cos(x) • tan(2x) = 2 tan(x) 1−tan2(x) • sin ( x 2 ) = √ 1−cos(x) 2 • cos( x 2 ) = √ 1+cos(x) 2 • tan ( x 2 ) = 1−cos(x) sin(x) = sin(x) 1+cos(x) 1 • cot ( x 2 ) = 1+cos(x) sin(x) = sin(x) 1−cos(x) • sin 2(x) = 1−cos(2x) 2 • cos2(x) = 1+cos(2x) 2 • tan(π + x) = tan(x) • sin(−x) = sin(x), cos(−x) = cos(x), tan(−x) = − tan(x) • F¨ur alle (a, b) ∈ R2, sodass a2+b2 = 1, gibt es x ∈ R, sodass a = cos(x), b = sin(x). • sin(x) = 2 tan(x/2) 1+tan2(x/2) • cos(x) = 1−tan2(x/2) 1+tan2(x/2) • sin(x) = eix−e−ix 2i • cos(x) = eix+e−ix 2 • ∫ 2π 0 sin(t) · cos(t)dt = ∫ 2π 0 sin(t)dt = ∫ 2π 0 cos(t)dt = 0 • ∫ sin 2(x)dx = 1 2 (x − sin(x) cos(x)) • ∫ cos2(x)dx = 1 2 (x + sin(x) cos(x)) • ∫ x sin(x)dx = sin(x) − x cos(x) • ∫ x cos(x)dx = x sin(x) + cos(x) Rechenregeln: Ableitung • Summenregel (f (x) + g(x))′ = f ′(x) + g′(x) • Faktorregel (c · f (x))′ = c · f ′(x) • Produktregel (f (x) · g(x))′ = f ′(x)g(x) + f (x)g′(x) • Quotientenregel ( f (x) g(x) )′ = f ′(x)g(x)−f (x)g′(x) g2(x) (g ̸= 0) • Kettenregel (f (g(x)))′ = (f ◦ g)′ = f ′(g(x))g′(x) Rechenregeln: Integration • Summe/Diﬀerenz: ∫ b a (f (x) + / − g(x))xd = ∫ b a f (x) + / − ∫ b a g(x) • Konstanter Faktor: ∫ b a c · f (x)dx = c · ∫ b a f (x)dx • Partielle Integration: ∫ b a f ′(x) · g(x)dx = [f (x)g(x)] b a − ∫ b a f (x)g′(x) • Substitution: ∫ φ(b) φ(a) f (x)dx = ∫ b a f (φ(t))φ′(t)dt • a + c, b + c ∈ I ∫ b a f (t + c)dt = ∫ b+c a+c f (x)dx • ca, cb ∈ I: ∫ b a f (ct)dt = 1 c f (x)dx • Logarithmus: (f stetig diﬀbar) ∫ f ′(t) f (t) dt = log(|f (x)|), bzw. ∫ b a f ′(t) f (t) dt = log(f (|b|)) − log(f (|a|)) Rechenregeln: Limes von Sinus und Cosinus • limx→0 arctan(x) = 0, limx→∞ arctan(x) = π 2 • limx→0 tan(x) = 0, limx→∞ tan(x) = ∞, limx→ π 2 tan(x) = ∞ • limx→∞ cos(x) = [−1, 1] • limx→∞ sin(x) = [−1, 1] 2 N¨utzliches • Kreisgleichung (x − x0)2 + (y − y0)2 = r2 • Ellipsengleichung (x−x0)2 a2 + (y−y0)2 b2 = 1 • Mitternachtsformel x1,2 = −b±√b2−4ac 2a • Matrix Determinante ∣ ∣ ∣ ∣ ∣ a b c d ∣ ∣ ∣ ∣ ∣ = ad − bc • Matrix Invertierbarkeit: Eine quadratische Matrix ist genau dann in- vertierbar, falls die Determinante ̸= 0. • Skalarprodukt x · y = ∑n i=1 xiyi • Kreuzprodukt a × b = (a2b3 − a3b2, a3b1 − a1b3, a1b2 − a2b1)⊤ Rechenregeln: Stammfunktionen, Ableitungen diﬀerenzierbar =⇒ stetig =⇒ integrierbar f ′(x) f (x) F(x) 0 c (c ∈ R) cx c cx c 2 x2 r · xr−1 xr(r ∈ R\\{−1} xr+1 r+1 −1 x2 = −x−2 1 x = x−1 log |x| 1 2 √x √x 2 3 x 3 2 cos x sin x − cos x − sin x cos x sin x 1 + tan2 x = 1 cos2 x tan x − log | cos x| − 1 sin2(x) cot x log | sin x| ex ex ex c · ecx ecx 1 c ecx log a · ax ax ax log a 1 x log |x| x(log |x| − 1) 1 log a·x loga |x| x log a (log |x| − 1) = x(loga |x| − loga e) 1√1−x2 arcsin x x arcsin x + √1 − x2 − 1√1−x2 arccos x x arccos x − √1 − x2 1 1+x2 arctan x x arctan x − 1 2 log(1 + x2) sinh(x) cosh(x) - cosh(x) sinh(x) - tanh(x) 1 cosh2(x) - 2 sin(x) cos(x) sin 2(x) 1 2 (x − sin(x) cos(x)) −2 sin(x) cos(x) cos2(x) 1 2 (x + sin(x) cos(x)) 2 sin(x) cos3(x) tan2(x) tan(x) − x 3 2 Diﬀerentialgleichungen Deﬁnition 1: Diﬀerentialgleichung Eine Diﬀerentialgleichung ist eine Gleichung, in welcher eine unbekannte Funktion y(x) einer oder mehreren Variablen und ihre Ableitung vorkommnt. Im Falle, dass y eine auf dem Intervall I ⊂ R deﬁnierte Funktion ist y : I ⊂ R → R, spricht man von einer gew¨ohnlichen Diﬀerentialgleichung. Deﬁnition 2: Ordnung, linear, homogen Die Ordnung einer Gleichung ist die h¨ochste vorkommende Ableitung. Bsp: y′′ =⇒ 2. Eine Diﬀerentialgleichung heisst linear, falls jeder Term y, y′, y′′ usw. nur linear vorkommt. Wichtig: Falls y1(x) und y2(x) L¨osungen der selben Diﬀe- rentialgleichung sind, dass ist auch die Linearkombination ay1(x) + by2(x). Eine Diﬀerentialgleichung heisst homogen, falls keine Terme vorkommen, die rein von den Funktionsvariablen abh¨angen (also kein y, y′′, ... enthalten). Sonst heisst die Gleichung inhomogen. Deﬁnition 3: Anfangswertproblem Ein Anfangswertproblem n-ter Ordnung ist eine gew¨ohnliche Diﬀerenti- algleichung n-ter Ordnung zusammen mit n Anfangsbedingungen. Satz 1: Grundprinzip f¨ur lineare, inhomogene Diﬀerenzialgleichungen Die allgemeine L¨osung einer linearen, inhomogenen Diﬀerentialgleichung hat die Form y(x) ︸︷︷︸ Gesamtl¨osung = yhom(x) ︸ ︷︷ ︸ allg. homogene L¨osung + yp(x) ︸ ︷︷ ︸ partikul¨are L¨osung Rezept 1: Separation der Variablen Diese Methode eignet sich f¨ur Diﬀerentialgleichungen erster Ordnung und ist die einfachste Methode. F¨ur eine Diﬀerentialgleichung der Form y′ = dy dx = h(x) · g(y), mit g(y) ̸= 0 gehen wir folgendermassen vor: 1. Wir nehmen alle Teile mit x und alle mit y auf verschiedene Seiten. 1 g(y) dy = h(x)dx 2. Nun integrieren wir direkt ∫ 1 g(y) dy = ∫ h(x)dx 4 3. Durch die Unbestimmtheit der Integrale f¨uhren wir eine Konstante C ein. Durch Anfangsbedingungen y(x0) = y0 (in einem Anfangswertpro- blem) kann diese bestimmt werden. Rezept 2: Variation der Konstanten (1. Ordnung) Diese Methode eignet sich f¨ur inhomogene Diﬀerentialgleichungen ers- ter Ordnung, der Form y′ = h(x)y + b(x). Wir benutzen den Grundsatz f¨ur inhomogene Diﬀerentialgleichungen. D.h. wir suchen die allgemeine homogene L¨osung und eine partikul¨are L¨osung und addieren diese f¨ur die gesamte L¨osung. Eine partikul¨are L¨osung kann manchmal erraten werden, ansonsten nutzen wir folgendes Rezept: 1. Die homogene L¨osung yhom(x) suchen wir mit der Methode Separation der Variablen. 2. Die Integrationskonstante aus Schritt I fassen wir als eine von x abh¨angige Funktion auf C → C(x) 3. Die entstandene Funktion yp(x) (homogene L¨osung mit C(x) anstelle von C) setzen wir als Ansatz in die Diﬀerentialgleichung ein und l¨osen nach C(x) auf. Dies gibt uns die partikul¨are L¨osung. 4. Wir nutzen den Grundsatz f¨ur die gesamte L¨osung y(x) = yh(x) + yp(x). . Rezept 3: Euler-Ansatz F¨ur lineare, homogene Diﬀerentialgleichung n − ter Ordnung mit konstanten Koeﬃzienten, k¨onnen wir den Euler-Ansatz verwenden. Wir haben eine Gleichung der Form any(n) + an−1y(n−1) + · · · + a0y = 0, wobei a0, . . . , an ∈ R und an ̸= 0 sind. Wir wenden folgendes Rezept an: 1. Setze den Euler-Ansatz y(x) = eλx, λ ∈ C in die Diﬀerentialgleichung ein und berechne das charakteristische Polynom. 2. Finde die Nullstellen λk mit Vielfachheiten mk des charakteristischen Polynoms und konstruiere daraus die linear unabh¨angigen L¨osungen gem¨ass e λx, x · eλx, x 2 · eλx, . . . , xm−1 · e λx. 3. Diese L¨osungen bilden ein Fundamentalsystem der Diﬀerentialglei- chung. 4. Die allgemeinste L¨osung ist eine Linearkombination aller L¨osungen im Fundamentalsystem. Die Koeﬃzienten sind durch die Anfangsbedin- gungen zu bestimmen. 5 Rezept 4: Euler-Ansatz mit vielfachen/komplexen Nullstellen Richtung: L¨osungen der Charakteristischen Gleichung λi → Ansatz der homogenen L¨osung yh. L¨osung f¨ur λ Linearkombinationen f¨ur yh(x) α c1 · eαx α1 = α2 = . . . = αk c1 · eαx + x · eαx + .. + ck · xk−1 · eαx α + βi, β > 0 c1 · eαx · sin(βx) α + βi, β < 0 c1 · eαx · cos(βx) α1 + β1i = .. = αk + βki β > 0 c1eαx · sin(βx) + .. + ckxk−1 · eαx · sin(βx) α1 + β1i = .. = αk + βki β < 0 c1eαx · cos(βx) + .. + ckxk−1 · eαx · cos(βx) N¨utzliches Manchmal sind die Terme in y(x) = Aeix + Be−ix nicht die geeignetste Form und man m¨ochte lieber reelle Funktionen. Dann nutzt man die Formel sin x = eix − e−ix 2i cos x = eix + e−ix 2 Damit lassen sich zwei neue Integrationskonstanten deﬁnieren: ̃A sin x + ̃B cos x Rezept: F¨ur kompliziertere Ausdr¨ucke funktioniert: y(x) = Ae2ix + Be−2ix = ̃A sin(2x) + ̃B cos(2x) Rezept 5: Variation der Konstanten (2. Ordnung) Wir suchen die L¨osung f¨ur eine Diﬀerentialgleichung der Form y′′ + a1y′ + a0y = g(x) 1. Die homogene L¨osung yh(x) ﬁnden wir mittels Euler-Ansatz. 2. Wir suchen nun eine L¨osung der Form yp(x) = C1(x)y1(x) + C2(x)y2(x), wobei y1(x) und y2(x) aus dem Euler-Ansatz stammen und das System { C′ 1(x)y1(x) + C′ 2(x)y2(x) = 0 C′ 1(x)y′ 1(x) + C′ 2(x)y′ 2(x) = g(x) d.h. ( y1(x) y2(x) y′ 1(x) y′ 2(x) ) ︸ ︷︷ ︸ =:A · ( C′ 1(x) C′ 2(x) ) = ( 0 g(x) ) erf¨ullt sein muss. Wir pr¨ufen also, ob die Determinante det A = y1(x)y′ 2(x) − y2(x)y′ 1(x) nicht verschwindet, denn aus LinAlg wissen wir, dass genau dann eine eindeutige L¨osung existiert. 3. Wir ﬁnden nun C1 und C2 und somit yp(x) entweder durch (a) Inversion der Matrix ( C′ 1(x) C′ 2(x) ) = 1 y1(x)y′ 2(x) − y2(x)y′ 1(x) ( y′ 2(x) −y2(x) −y′ 1(x) y1(x) ) · ( 0 g(x) ) und anschliessender Integration C1 = ∫ C′ 1(x)dx, C2 = ∫ C′ 2(x)dx 6 (b) oder mit der direkten Formel yp(x) = − y1(x) ∫ y2(x)g(x) y1(x)y′ 2(x) − y2(x)y′ 1(x) dx + y2(x) ∫ y1(x)g(x) y1(x)y′ 2(x) − y2(x)y′ 1(x) dx. 4. Die gesamte L¨osung erhalten wir aus y(x) = yh(x) + yp(x). N¨utzliches: Bei unchilligen Formeln kann x ↦→ et, x2 ↦→ e2t, ... substituiert werden und anschliessend durch ein Gleichungssystem aufgel¨ost werden. Rezept 6: Substitution Gleichungen der Form y′ = h ( y x ) Substitution z(x) = y(x) x ⇔ y(x) = xz(x), dann wird y′ durch y′ = z + xz′ ersetzt. Gleichungen der Form y′ = h(ax + by + c) Substitution z(x) = ax + by(x) + c ⇔ y = z − ax − c b , dann wird y′ durch y′ = z′ − a b ersetzt. Gleichungen der Form y′ = h ( ax + by + c dx + ey + f ) Wir wollen y(x) und x ersetzen. Wir l¨osen das Gleichungssystem { ax + by + c = 0 dx + ey + f = 0 und wollen eine eindeutige L¨osung (x0, y0), d.h. wir fordern det (a b d e ) ̸= 0. Jetzt setzen wir z = y − y0 und t = x − x0. Dann werden y′ und z′ zu y′ = dy dx = d(z + y0) d(t + x0) = dz dt = z′. Gleichungen der Form y′ = y x h(xy) Substitution z(x) = xy(x) ⇔ y = z(x) x , dann wird y′ durch y′ = xz′ − z x2 ersetzt. 7 Beispiel 1: Substitution: Funktion Sei xy′ = y + x2 die DGL. Sei v die neue Variable und die Substitution v = y x oder y = vx. L¨osungsschritt I: L¨ose nach y auf: y = v · x. L¨osungsschritt II: Berechne dy dx = y′: y′ = v + xv′ L¨osungsschritt III: Setze y und y′ in die DGL ein: x(v′x + v) = vx + x2 und l¨ose die DGL normal nach v auf (hier Separation der Variablen). Man bekommt v = x + c. L¨osungsschritt IV: Setze v zur¨uck in die Substution y = vx ein. Man bekommt y = (x + c)x. Beispiel 2: Substitution: Variable Sei x2y′′ − 3xy′ + 5y = 0 die DGL. Sei x = et bzw. t = log(x) die Variablensubstitution. L¨osungsschritt I: Deﬁniere h(t) = y(et) und berechne h′ und h′′: h(t) = y(et) = y(x) h ′(t) = y′(et)et = xy(e t) h ′′(t) = y′′(et)e2t + y′(e t)e t = x2y′′(x) + xy′(x) L¨osungsschritt II: L¨ose auf, sodass alle Terme in der DGL (x2y′′, xy′, y) durch counterparts in t und h(t) ersetzt werden k¨onnen. Setze in Diﬀglei- chung ein. Man bekommt h ′′ − 4h ′ + 5h = 0 L¨osungsschritt III: L¨ose die Gleichung normal mit h(t). Anschliessend, ersetze t = log(x) Rezept 7: Methode des direkten Ansatzes Der Ansatz ist geeignet f¨ur lineare, inhomogene DGLs n-ter Ordnung mit konstanten Koeﬃzienten. Also eine DGL der Form any(n) + an−1y(n−1) + · · · + a0y = b(x). Die homogene L¨osung ﬁnden wir mit dem Euler-Ansatz. F¨ur die partikul¨are L¨osung nutzen wir folgende Idee: Der Ansatz f¨ur yp(x)hat dieselbe Form wie der inhomogene Term b(x). 8 Inhomogener Term b(x) Ansatz f¨ur yp(x) a (const.) b (const.) a0 + a1x + . . . + amxm b0 + b1x + . . . + bmxm aeλx beλx P (x)eλx Q(x)eλx P (x) sin(mx) Q(x) sin(mx) + R(x) cos(mx) P (x) cos(mx) Q(x) sin(mx) + R(x) cos(mx) a sin(mx) c sin(mx) + d cos(mx) a cos(mx) c sin(mx) + d cos(mx) a sin(mx) + b cos(mx) c sin(mx) + d cos(mx) ∑m i=0 bixi ∑m i=0 Aixi eαx ∑m i=0 bixi eαx ∑m i=0 Aixi sin(ωx) ∑m i=0 bixi + cos(ωx) ∑m i=0 cixi sin(ωx) ∑m i=0 Aixi + cos(ωx) ∑m i=0 Bixi sinh(ωx) ∑m i=0 bixi + cosh(ωx) ∑m i=0 cixi sinh(ωx) ∑m i=0 Aixi + cosh(ωx) ∑m i=0 Bixi eαx sin(ωx) ∑m i=0 bixi +eαx cos(ωx) ∑m i=0 cixi eαx sin(ωx) ∑m i=0 Aixi +eαx cos(ωx) ∑m i=0 Bixi Bemerkung I: Verschiedene Ans¨atze k¨onnen additiv kombiniert werden. So w¨ahlt man f¨ur b(x) = 5x + sin(x)e3x als Ansatz yp(x) = Ax + B︸ ︷︷ ︸ Teil I + (C + sin x + D cos x)e3x ︸ ︷︷ ︸ Teil II . Bemerkung II: Wenn ein Teil der f¨ur yp(x) zu w¨ahlende Funktion be- reits in der L¨osung des homogenen Problems vorhanden ist, wird der Ansatz zus¨atzlich mit x multipliziert. Wenn z.B. die homogene L¨osung die Form yh(x) = Ax + B hat, w¨ahlt man anstelle des Ansatzes yp(x) = ax + b ⇒ yp(x) = x · (ax + b). Rezept 8: Inhomogene AWP Wie im Beispiel (y′ + y = 2 sin(x) mit y(0) = 0) vorgehen: 1. Homogene L¨osung ﬁnden: (λ + 1)(eλx) = 0 ⇒ λ = −1 ⇒ yh = c1 · e−x 2. Gem¨ass St¨orfunktion den Ansatz f¨ur yp w¨ahlen und dessen Ableitungen ﬁnden: yp = c · sin(x) + d · cos(x) y′ p = c · cos(x) − d · sin(x) 3. Dies in die urspr¨ungliche DGL einsetzen, um die Koeﬃzienten des An- satzes und damit die partikul¨are L¨osung zu ﬁnden: c · cos(x) − d · sin(x) + c · sin(x) + d · cos(x) ! = 2 sin(x) ⇔ (c + d) cos(x) + (c − d) sin(x) ! = 2 sin(x) ⇐⇒ c = 1, d = −1 4. Anfangswertbedingungen nutzen um ck aus der homogenen L¨osung zu ﬁnden y(0) = c1 · e−x ︸ ︷︷ ︸ yh(0) + sin(x) − cos(x) ︸ ︷︷ ︸ yp(0) = c1 · 1 + 0 − 1 ! = 0 ⇔ c1 = 1 5. y(x) = 1 + sin(x) − cos(x) 9 3 Diﬀerentialrechnung in Rd 3.1 Allgemein Beschr¨ankt (bounded) Falls ||x|| beschr¨ankt f¨ur alle x ∈ M . Geschlossen (closed) Jede Folge (xn) mit xn ∈ M ist lim(xn) ∈ M . Kompakt (compact) Falls beschr¨ankt und geschlossen. 3.2 Stetigkeit Deﬁnition 4: Stetigkeit (Continuity) Normale Deﬁnition: lim x→x0 f (x) = f (x0) Deﬁnition Stetigkeit mit Folgen: F¨ur jede Folge (xn) sodass xn → x f¨ur x → ∞: (f (xn)) → f (x) Sei f, g stetig: f + g, f · g, f g , f ◦ g stetig. Falls f stetig, gilt lim x→a f (x) = f ( lim x→a x) f diﬀbar ⇒ f stetig ⇒ f integrierbar f nicht integrierbar ⇒ f nicht stetig ⇒ f nicht diﬀbar. Rezept 9: Polarkoordinatentrick (Change of Variable, Coordinates) Ziel: Zeige oder widerlege Stetigkeit. Seien x = r cos ϕ, y = r sin ϕ. Berechne lim (x,y)→(0,0) f (x, y) = lim r→0 f (x, y) H¨angt das Resultat von ϕ ab ⇒ der Grenzwert existiert nicht ⇒ nicht stetig an dieser Stelle. Rezept 10: Linientrick Ziel: Stetigkeit widerlegen. Suche zwei Linien, die einen unterschied- lichen lim haben. Zeigt, dass ein lim nicht existieren kann. Sei f (x, y) = y x+1 und {(x, y) ∈ R | x ̸= 1} f¨ur (x, y) → (−1, 0). Linie {(x, y) ∈ R | y = 0 ∩ x ̸= 1} = 0 und {(x, y) ∈ R | y = x + 1} = 1. Bemerkung: Meistens `a la: f (x, y) verschwindet auf der Linie {x = ...}, dann m¨usste lim(x,y)→(0,0) f (x, y) = 0, aber f¨ur x = ...y... sehen wir, dass f (x, y) = fancy Expression = 1 ̸= 0. Da x = ... auf der Linie liegt, folgt der Widerspruch. Todo: Quasi Ausnahme ﬁnden! intuitiv erl¨autern! Beispiel 3: Linientrick Gegeben f (x, y) = y x − 1 existiert lim (x,y)→(1,0) f (x, y) ? L¨osung: Wir sehen f auf der Linie {(x, y)|y = 0, x ̸= 1} verschwindet. H¨atte also f einen Grenzwert f¨ur (x, y) → (1, 0) w¨are dieser gleich 0. Aber die Linie y = x − 1 geht durch (1, 0) und auf dieser Linie ist f gleich 1. Also existiert lim(x,y)→(1,0) f (x, y) nicht. 10 Beispiel 4: Vergleichstrick / Sandwich Gegeben f (x, y) = (x − 1)2 ln(x) (x − 1)2 + y2 existiert lim (x,y)→(1,0) f (x, y) ? L¨osung: |f (x, y)| = |(x − 1)2| |(x − 1)2 + y2| |ln(x)| ≤ |ln(x)| Wegen limx→1 ln(x) = 0 sehen wir, dass 0 ≤ lim (x,y)→(1,0) |f (x, y) ≤ | lim x→1 | ln(x)| = 0 und damit ist auch der gesuchte Grenzwert = 0. Rezept 11: Stetigkeit pr¨ufen Sei f die zu pr¨ufende Funktion. 1) f muss ¨uberall deﬁniert sein. 2) limx→a f (x) existiert. 3) limx→a f (x) = f (a). 3.3 Diﬀerenzierbarkeit Deﬁnition 5: Diﬀerenzierbarkeit Sei Ω ⊂ R oﬀen, f : Ω → R, x0 ∈ Ω. f heisst diﬀerenzierbar an Stelle x0, falls der Grenzwert lim x tox0 f (x) − f (x0) x − x0 =: f ′(x0) =: df dx existiert. Wir nennen f ′(x0) die Ableitung (das Diﬀerential) von f an der Stelle x0. Eine solche Funktion heisst dann diﬀerenzierbar auf Ω, wenn sie an jeder Stelle x0 ∈ Ω diﬀerenzierbar ist. f diﬀbar ⇔ alle Teil-f sind diﬀbar. f, g diﬀbar ⇒ f + g, f · g, f g , g ◦ f diﬀbar Satz 2: Kettenregel Seien X, Y ⊂ Rn oﬀen und f : X → Y , g : Y → Rp diﬀerenzierbar. Dann ist g ◦ f diﬀerenzierbar und die Ableitung ist d(g ◦ f )(x0) = dg(f (x0)) ◦ df (x0) und die Jakobi-Matrix ist Jg◦f (x0) = Jg(f (x0))Jf (x0) Deﬁnition 6: Partielle Diﬀerenzierbarkeit f : Rn → Rm, falls: lim h→0 f (x0 + hei) − f (x0) h =: ∂f ∂xi (x0) oder generell f¨ur alle Einheitsvektoren ei zusammengefasst in Richtung v ∈ Rn 11 lim h→0 f (x0 + hv) − f (x0) h =: Dvf (x0) Dieser lim existiert ⇔ in Richtung ei an Stelle x0 partiell diﬀerenzierbar. Deﬁnition 7: Totale Diﬀerenzierbarkeit Sei f : Ω ⊂ Rm → Rn. f heisst diﬀerenzierbar an der Stelle x0 ∈ Ω, falls eine lineare Abbildung A : Rn → Rm existiert (also eine m × n Matrix), sodass lim x→x0 |f (x) − f (x0) − A(x − x0)| |x − x0| = 0 Dann heisst df (x0) := A das Diﬀerenzial von f in Punkt x0. Diese Matrix A = Df (x0) ist gegeben durch Df (x0) =    ∂f1 ∂x1 (x0) . . . ∂f1 ∂xn (x0) ... . . . ... ∂fm ∂x1 (x0) . . . ∂fn ∂xm (x0)    3.4 Stetigkeit vs Diﬀerenzierbarkeit Rezept 12: Pr¨ufen, ob f diﬀerenzierbar an x0 f stetig an x0? Nein ⇒ f nicht diﬀbar. ⇓ Ja Ist f in x0 partiell diﬀbar, existiert ∂f ∂xi (x0)? Nein ⇒ f nicht diﬀbar. ⇓ Ja Ist ∂f ∂xi (x0) stetig? Ja ⇒ f ist diﬀbar! ⇓ Nein Existiert eine lineare Abbildung A: Rn → Rm sodass A = ∇f (x0), also existert: lim x→x0 |f (x) − f (x0) − ∇f (x0) − (x − x0)| ||x − x0|| ? Ja ⇒ f ist diﬀbar! Nein ⇒ f ist nicht diﬀbar. 3.5 Partielle Ableitung (Partial Derivative) f : Rn → R an Stelle a nach xi lim h→0 f (a1, ..., ai + h, ..., an) − f (a1, ..., ai, ..., an) h =: ∂f ∂xi (a) Wichtig: Alle anderen xi werden als konstante behandelt bei Ableitung. 12 3.5.1 Satz von Schwarz (Higher derivatives) f ∈ C2. Gilt nur f¨ur zwei und drei verschiedene Variablen. Beliebige Potenzen von xi und xj m¨oglich. ∂2f ∂xixj = ∂2f ∂xjxi ∀i, j ∈ {1, ..., n} 3.5.2 Gradient ∇f =    ∂f ∂x1 ... ∂f ∂xn    Gradient eines Skalarfeldes: Richtung: Richtung des steilten Anstiegs; Betrag: St¨arke des Anstiegs. Regeln (n ∈ N, c konstant, u, v Vektoren): grad(c) = 0, grad(c · u) = c · grad(u) (Linearit¨at), grad(u + v) = grad(u) + grad(u) (Addition), grad(u · v) = grad(u) · grad(u) (Produktregel), TODO andere gradienten regeln von der ¨ubungsstunde 5 TODO Serie 5 2.1 senkrecht satz grad(un) = n · un−1 · grad(u) (n ̸= 0). 3.5.3 Richtungsableitung (Directional Derivative) f heisst an der Stelle a in Richtung u diﬀerenzierbar, falls der Grenzwert lim h→0 f (a + hu) − f (a) h = d dh f (a + hu) ∣ ∣ ∣ ∣h=0 =: Dvf (a) existiert. Ist ||u|| = 1 (normiert), heisst dieser Grenzwert Richtungsableitung. Rezept 13: Richtungsableitung Duf (a) existiert: Falls t ↦→ f (a + tu) diﬀerenzierbar ist bei t = 0, dann existiert Duf (a). Die Richtungsableitung existiert f¨ur jede Richtung, falls d dh f (a + hu) ∣ ∣ h=0 NICHT von ϕ abh¨angt (wenn mal x = r cos(ϕ), y = r sin(ϕ) substituiert). Rezept 14: Richtungsableitung Duf (a) Falls f in a diﬀerenzierbar ist: F¨ur f in Richtung u in Punkt a: 1) u normie- ren: ˜u = u ||u|| 2) Gradient ∇f (x) berechnen, dann: Duf (a) = ˜u ·︸︷︷︸ SP. ∇f (a) Deﬁnition 8: Hessematrix Hess(f ) =     ∂2f ∂x2 1 . . . ∂2f ∂x1xn ... . . . ... ∂2f ∂xnx1 . . . ∂2f ∂x2 n     Deﬁnition 9: Jakobimatrix f (x, y) =    f1(x, y) ... fn(x, y)    Jf (x, y) =     ∂f1 ∂x ∂f1 ∂y ... ... ∂fn ∂x ∂fn ∂y     13 F¨ur die Kettenregel von Jakobimatrizen siehe ”generelle Kettenregel”. 3.6 Taylorpolynome f (x) = f (a) + f ′(a)(x − a) + 1 2 f ′′(a)(x − a)2 + 1 3! f (3)(a)(x − a)3 + ... In R2: ∆x = (x − x0), ∆y = (y − y0) f (x, y) = f (x0, y0) + ∂f ∂x (x0, y0)∆x + ∂f ∂y (x0, y0)∆y + 1 2 ( ∂2f ∂x2 (x0, y0)(∆x)2 + 2 ∂2f ∂x∂y (x0, y0)∆x∆y + ∂2f ∂y2 (x0, y0)(∆y)2) + 1 3! ( ∂3f ∂x3 (x0, y0)(∆x) 3 + 3 ∂3f ∂x2∂y (x0, y0)(∆x)2∆y + 3 ∂3f ∂x∂y2 (x0, y0)∆x(∆y)2 + ∂3f ∂y3 (x0, y0)(∆y) 3) + ... In Rn: ∆xi = xi − x0 i T f (x; x0) = ∞∑ n=0 1 n! ( ∆x1 ∂ ∂x1 + ... + ∆xn ∂ ∂xn )n f (x1, ..., xn) ∣ ∣ ∣ ∣ ∣(x0 1,...,x0 n) In Rn bis Grad 2: T2f (x) = f (x0) + ∇f (x0)(x − x0) + 1 2 (x − x0)⊤Hessf (x0)(x − x0) Rezept 15: Tangentialebene (Variante I) Tangentialebene der Fl¨ache f (x, y) ﬁnden in Punkt (x0, y0). L¨osungsschritt I: Erstelle F (x, y) = (x, y, f (x, y))⊤ und berechne die Ba- sisvektoren f¨ur die Tangentialebene dF (x0, y0) =    ∂F1 ∂x (x0, y0) ∂F1 ∂y (x0, y0) ∂F2 ∂x (x0, y0) ∂F2 ∂y (x0, y0) ∂F3 ∂x (x0, y0) ∂F3 ∂y (x0, y0)    =    u1 v1 u2 v2 u3 v3    (x0 und y0 einsetzen). L¨osungsschritt II: Berechne Normalvektor: n = u × v =    u1 u2 u3    ×   v1 v2 v3    =    a b c    Berechne d mit p = (x0, y0, f (x0, y0)): d = p · n L¨osungsschritt III: Konstruiere Gleichung, sodass: ax + by + cz = d 14 Rezept 16: Tangentialebene (Variante II) Idee: Ann¨aherung von f im Punkt (x0, y0) durch Taylorpolynom I. Grades z = f (x0, y0) + ∂f ∂x (x0, y0) · (x − x0) + ∂f ∂y (x0, y0) · (y − y0) kann direkt umgeformt werden in die Normalform der Ebenengleichung. 3.7 Extremstellen (Kritische Punkte) Deﬁnition 10: Kritische und regul¨are Punkte Fall f : Rn → R: Sei f : Ω ⊂ Rn → R diﬀerenzierbar. Ein Punkt p0 ∈ Ω heisst kritischer Punkt von f , falls df (p0) = 0. Ist der Punkt nicht kritisch, heisst er regul¨ar. Fall f : Rn → Rm: Sei f : Ω ⊂ Rn → Rm diﬀerenzierbar. Wir wissen, dass df (x0) eine lineare Abbildung ist. Diese l¨asst sich mit einer m × n-Matrix darstellen. Der Rang der Matrix beschreibt die Dimension des Bildes. F¨ur eine m × n Matrix A gilt Rang(A) ≤ min(m, n) Ein Punkt p0 ∈ Ω heisst regul¨ar, wenn die Matrix df (x0) einen maximalen Rang besitzt. Sonst heisst p0 kritisch. Ein kritischer Punkt heisst degene- riert, wenn an dieser Stelle f¨ur die Hesse-Matrix gilt: det(Hf (p0)) ̸= 0 Ansonsten heisst der Punkt nicht-degeneriert. Satz 3: Extremwerte in einer Variable Sei f : Ω ⊂ R → R, f ∈ C2 und x0 ∈ Ω ein kritischer Punkt (d. h. f ′(x0) = 0), dann gilt • x0 ist ein Minimum, falls f ′′(x0) > 0, • x0 ist ein Maximum, falls f ′′(x0) < 0, • x0 ist ein Sattelpunkt, falls f ′′(x0) = 0 Satz 4: Extremwerte in mehreren Variablen (Corollary 3.8.7) Sei X ⊂ Rn oﬀen und f : X → R ∈ C2. Sei x0 ein nicht-degenerierender kritischer Punkt von f . Sei p und q die Anzahl der positiven resp. negativen Eigenwerte von Hessf (x0). 1. Falls p = n, bzw. q = 0 (Hessf (x0) ist positiv deﬁnit), besitzt f ein lokales Minimum an x0 2. Falls q = n, bzw. p = 0 (Hessf (x0) ist negativ deﬁnit), besitzt f ein lokales Maximum an x0 3. Ansonsten, bzw. pq ̸= 0, besitzt f kein Extremum an x0. Man sagt deshalb, f besitzt einen Sattelpunkt an x0. 15 Rezept 17: Eigenwerte ﬁnden Charakteristisches Polynom mittels det(A − λI) berechnen. Nullstellen des Polynoms sind die Eigenwerte. Satz 5: Deﬁnitheit f¨ur symmetrische Hesse-Matrizen (Remark 3.8.8) F¨ur eine symmetrische Matrix gilt A = ( a b b d ) positiv deﬁnit ⇐⇒ a > 0, ad − b 2 > 0 negativ deﬁnit ⇐⇒ a < 0, ad − b 2 > 0 indeﬁnit ⇐⇒ ad − b 2 < 0 A =   a b c b e f c f i    positiv deﬁnit ⇐⇒ a > 0, ae − b 2 > 0, det A > 0 Satz 6: Eigenwert-Kriterium Seien λ1, ..., λn die Eigenwerte einer reellen, symmetrischen n × n Matrix A. Dann gilt A ist positiv deﬁnit ⇐⇒ Alle λi > 0, A ist positiv semi-deﬁnit ⇐⇒ Alle λi ≥ 0, A ist negativ deﬁnit ⇐⇒ Alle λi < 0, A ist negativ semi-deﬁnit ⇐⇒ Alle λi ≤ 0 Deﬁnition 11: Hauptminoren Die Hauptminor einer symmetrischen, reellen Matrix A sind die nordwestli- chen Unterdeterminanten der Matrix A. Sie werden mit Ai bezeichnet, wobei i die Gr¨osse der Teilmatrix Ai ist. Sei die Matrix A =       a11 a12 . . . a1n a21 a22 . . . a2n ... ... . . . ... an1 an2 . . . ann       16 dann sind die n Hauptminoren A1, ..., An gegeben durch A1 = det(a11) = a11, A2 = det ( a11 a12 a21 a22 ) , A3 = det    a11 a12 a13 a21 a22 a23 a31 a32 a33    , ... An = det(A) Satz 7: Sylvester-Kriterium NUR F ¨UR GROSSE MATRIZEN VERWENDEN. Sind A1, ..., An die Hauptminoren der reellen, symmetrischen n × n Matrix A, dann gilt: A ist positiv deﬁnit ⇐⇒ Alle Ai > 0, A ist negativ deﬁnit ⇐⇒ Wechselndes Vorzeichen: A1 < 0, A2 > 0, A3 < 0, ... A ist indeﬁnit ⇐⇒ Weder alle Ai ≤ 0 noch Ai ≥ 0 Rezept 18: Kritische Punkte ﬁnden in Skalarfeld (nicht abgegrenzt) L¨osungsschritt I: Gradient berechnen; Gradient = 0 setzen =⇒ kritische Punkte. L¨osungsschritt II: Hessematrix berechnen; f¨ur jeden kritischen Punkt: Falls die Hessematrix positiv deﬁnit ist =⇒ lokales Minimum; falls Hesse- matrix negativ deﬁnit ist =⇒ lokales Maximum; sonst Sattelpunkt. Rezept 19: Kritische Punkte ﬁnden in Skalarfeld (abgegrenzt) L¨osungsschritt I: Inneres Skalarfeld nach kritischen Punkten untersuchen nach Rezept 18. (∇f ! = 0) L¨osungsschritt II: Alle Begrenzungen des Skalarfeldes einzeln nach kri- tischen Punkten untersuchen. Beispiel Dreieck: alle Seiten parametrisie- ren und alle Eckpunkte einzeln untersuchen. Parametrisierungen ab- leiten und die Extrempunkte der St¨ucke untersuchen; Eckpunkte notieren. d dt (f ◦ γ1) ! = 0, also t, resp. die kritischen Punkte so ﬁnden. L¨osungsschritt III: Alle gefundenen Punkte miteinander vergleichen und herausﬁnden, welches die Extrema sind (jeweils die Funktionswerte der Ex- trempunkte berechnen). Rezept 20: Extremwertaufgaben ohne Nebenbedingungen Gegeben: f : Ω ⊂ Rn → R mit Ω oﬀen (d.h. ohne Rand) und f von der Klasse C2. Gesucht: Extremalstellen von f in Ω. L¨osungsschritt I: Finde die kritischen Punkte {x0} ∈ Ω. D.h. alle Punkte, f¨ur die gilt df (x0) = 0 und x0 ∈ Ω. 17 L¨osungsschritt II: Untersuche die Hesse-Matrix von f in den Punkten {x0} um ¨uber die Art der Extremum zu entscheiden. Hf (x0) ist positiv deﬁnit ⇒ x0 ist ein lokales Minimum vonf Hf (x0) ist negativ deﬁnit ⇒ x0 ist ein lokales Maximum vonf Hf (x0) ist indeﬁnit ⇒ x0 ist ein Sattelpunkt vonf Wenn die Hesse-Matrix keine klare Aussage ergibt (degenerierte kritische Punkte), muss man die Funktion in einer Umgebung absch¨atzen (um ein Max/Min zu zeigen) oder konkrete Gegenbeispiele ﬁnden. Rezept 21: Extremwerteaufgaben mit “einfachen” Nebenbedingungen Gegeben: f : Ω ⊂ Rn → R mit Rand ∂Ω und f von der Klasse C2. Gesucht: Extremalstellen von f in Ω. L¨osungsschritt I: Wir untersuchen das Innere ◦ Ω analog zu Rezept 20. L¨osungsschritt II: Wir parametrisieren den Rand ∂Ω durch γ(t). Die kritischen Punkte sind dann die Punkte γ(t) f¨ur die gilt d dt (f ◦ γ)(t) = 0. L¨osungsschritt III: Bestimme die Art der kritischen Punkte. • Variante 1 (nur kleinstes Min/ gr¨osstes Max): Werte alle kritischen Punkte auf dem Rand explizit aus. D.h. berechne f (γ(t)). • Variante 2 (Min/Max/Sattelpunkt): Die Funktion f (γ(t)) ist nur von einer Variable abh¨angig. Bestimme die Art der kritischen Punkte anhand der Kriterien f¨ur 1D-Funktionen. L¨osungsschritt IV: Ist der Rand st¨uckweise parametrisiert durch γ1, γ2, . . . , muss die Funktion zus¨atzlich an allen Anfangs- und Endpunkten der γi explizit ausgewertet werden. Bemerkung: Das Wort “einfach“ bedeutet hier, dass wir eine Parame- trisierung f¨ur den Rand ﬁnden k¨onnen. 3.8 Lagrange Multiplikatoren Sei f (x) ∈ Rn die zu maximierende Funktion, von der wir aber nur Punkte betrach- ten wollen, f¨ur welche gilt, dass g(x) = 0 mit g(x) ∈ Rl Deﬁnition der Lagrange- Funktion: L = f − λ · g = f − λ1g1 − . . . − λngn mit λ in R l Dieses λ existiert immer, wenn f, g ∈ C1. Die Kandidaten f¨ur Extrema von f unter der Nebenbedingung g = 0 sind genau die kritischen Punkte der Lagrange- Funktion L. Mittels der Hesse-Matrix von L kann die Art der Extrema gefunden werden. Jeder Kandidat wird in f eingesetzt um zu erkennen, wo f mit welchen Werten Extrema annimmt. 18 Rezept 22: Extremwertaufgaben mit Nebenbedingungen Gegeben: f : Ω ⊂ Rn → R und g : Ω → Rl der Klasse C1. Gesucht: ein Extremum der Funktion f unter der Nebenbedingung g = 0. L¨osungsschritt I: Bilde die Lagrange-Funktion L(x1, . . . , xn, λ) = f (x1, . . . , xn) − λ1g1(x1, . . . , xn) − · · · − λlgl(x1, . . . , xn), wobei g1, . . . , gl die l Komponenten von g sind. Oft ist l = 1. L¨osungsschritt II: Bestimme die kriischen Punkte von L, d.h. l¨ose ∂L ∂x1 = ∂f ∂x1 − λ1 ∂g1 ∂x1 − · · · − λl ∂gl ∂x1 = 0 ... ∂L ∂xn = ∂f ∂xn − λ1 ∂g1 ∂xn − · · · − λl ∂gl ∂xn = 0. L¨ose dieses Gleichungssystem mit den zus¨atzlichen Gleichungen von g = 0. L¨osungsschritt III: Die L¨osungen (x1, . . . , xn) sind die Kandidaten f¨ur Extremalstellen von f . Untersuche die Hesse-Matrix von L um den Typ zu bestimmen. Hess(L)(x0, λ) ist positiv deﬁnit → x0 ist ein lokales Minimum von f auf g−1(0), Hess(L)(x0, λ) ist negativ deﬁnit → x0 ist ein lokales Maximum von f auf g−1(0), Hess(L)(x0, λ) ist indeﬁnit → x0 ist ein Sattelpunkt von f auf g−1(0). Ist man nur an den globalen Extremwerten interessiert, spart man sich diesen Schritt und wertet stattdessen die Funktion f an den Kandidaten aus. L¨osungsschritt IV: Ist man auch an Extremalstellen im Innern ◦ Ω interessiert, sucht man diese mit dem bereits bekannten Rezept. 3.9 Satz der Impliziten Funktion Ziel: Existenz von lokalen Umkehrungen. ”Implizit”, weil die Form der Gleichung stets ein Gleichungssystem impliziert. Sei das Gleichungssystem der Form: f (x, y) = 0 x = (x1, ..., xk), y = (y1, ..., yl) df (x, y) = (dfx(x, y) | dfy(x, y)) =     ∂f1 ∂x1 . . . ∂f1 ∂xk ∂f1 ∂y1 . . . ∂f1 ∂yl ... . . . ... ... . . . ... ∂fl ∂x1 . . . ∂fl ∂xk ∂fl ∂y1 . . . ∂fl ∂yl     Satz 8: Implizite Funktionen Sei Ω ⊂ Rn = Rk × Rl oﬀen und sei f : Ω → Rl stetig diﬀerenzierbar. Ist der Punkt p0 = (a, b) ∈ Ω (mit a = erste k Koordinaten und b = letzte l Koordinaten von p0) regul¨ar mit f (p0) = 0 und det(dyf (p0)) ̸= 0 ( ⇐⇒ dyf (p0) ist invertierbar) wobei dyf (p0) die partiellen Ableitungen der Koordinaten y1, ..., yl enth¨alt, 19 so l¨asst sich das Gleichungssystem f (x, y) = 0 nach Koordinaten y auﬂ¨osen. Das heisst es existiert ein h : U → V sodass ∃h : f (x, h(x)) = 0 Beispiel 5: Zeigen, dass implizite Funktion existiert f → R F (x, y) = x4 + x 3y2 − y + y2 + y3 − 1 Zeigen Sie, dass oﬀene Intervalle U, V ⊂ R existieren, so dass 1 ∈ U , −1 ∈ V und eine C1-Abbildung f : V → U mit f (−1) = 1 existiert, s.d. f¨ur alle (x, y) ∈ U × V gilt: F (x, y) = 0 ⇐⇒ x = f (x) Berechnen Sie f ′(−1) L¨osung: Es gilt ∂yF (x, y) = 2x3y − 1 + 2y + 3y2 mit ∂yF (−1, 1) = 2 ̸= 0 Dann existiert dank dem Satz ¨uber implizite Funktionen eine Funktion f : V → U mit den vorherigen Eigenschaften und es gilt f ′(1) = − ∂xf (−1, 1) ∂yf (−1, 1) = 1 2 sowie x4 + x3f (x)2 − f (x) + f (x) 2 + f (x)3 = 1 4x3 + 3x2f (x) 2 + 2x3f ′(x)f (x) − f ′(x) + 2f ′(x)f (x) + 3f ′(x)f (x) 2 = 0 Da f (−1) = 1 gilt folglich: 0 = −4 + 3 − 2f ′(−1) − f ′(−1) + 2f ′(−1) + 3f ′(−1) = −1 + 2f ′(−1) also f ′(−1) = 1 2 Beispiel 6: Zeigen, dass implizite Funktion existiert f → R2 F (x, y, z) = x + y + z + sin(xyz) Zeigen Sie, dass ein oﬀener Bereich U ⊂ R2 und ein oﬀenes Intervall V ⊂ R existieren, so dass (0, 0) ∈ U , U ∈ V und eine C1-Abbildung f : U ← V mit f (0, 0) = 0 existiert, sodass f¨ur alle (x, y, z) ∈ U × V gilt: F (x, y, z) = 0 ⇐⇒ z = f (x, y) Berechnen Sie ∇f (0, 0). L¨osung: Es gilt ∂zF (x, y, z) = 1 + xy cos(xyz) mit ∂xF (0, 0, 0) = 1 ̸= 0 Daher existiert gem. Satz ¨uber implizite Funktionen die Funktion f und es gilt: ∇f (0, 0) = ( − ∂xF (0, 0, 0) ∂zF (0, 0, 0) , − ∂yF (0, 0, 0) ∂zF (0, 0, 0) ) = (−1, −1) 20 Rezept 23: Ableitung der Auﬂ¨osungsfunktion h: Bsp 2-dimensional (auﬂ¨osen nach y) oder 3-dimensional (auﬂ¨osen nach z) dh(x) = − dxf (x, h(x)) dyf (x, h(x)) ∇h(x, y) = (− ∂xf (x, y, h(x, y)) ∂zf (x, y, h(x, y)) , − ∂yf (x, y, h(x, y)) ∂zf (x, y, h(x, y)) ) Rezept 24: Typische Aufgabe 1. p0 bestimmen, sodass f (x, y) = 0 stimmt. 2. df (x, y) berechnen und dy kontrollieren, ob ̸= 0 3. Satz bewiesen, Ableiten der Auﬂ¨osungsfunktion. 4 Integration in Rd 4.1 Wegintegrale Sei f : [a, b] → Rn stetig, d.h. f¨ur f (t) = (f1(t), . . . , fn(t)) jedes fi stetig, dann ist ∫ b a f (t)dt = (∫ b a f1(t)dt, . . . , ∫ b a fn(t)dt) ∈ Rn F¨ur eine parametrisierte Kurve in Rn, d.h. γ : [a, b] → Rn, s.d. 1. γ stetig 2. 2. ∃t0, . . . , tk, s.d. t0 = a < ti < tk = b, s.d. γ | ]ti, ti−1[ ∈ C1 nennen wir γ einen Pfad zwischen γ(a) und γ(b). Satz 9: L¨ange einer Kurve Sei γ eine regul¨are Kurve t → γ(t) sei |.| die euklidische Norm: Die L¨ange ist L(γ) = ∫ b a |γ′|dt Rezept 25: Wegintegrale Gegeben: Vektorfeld f von der Klasse C1 und eine Kurve γ ∈ C1 pw. Gesucht: Wegintegral ∫ γ f · ds. L¨osungsschritt I: Parametrisiere γ, d.h. ﬁnde eine Abbildung γ(t) : [a, b] → Rn, t → γ(t). L¨osungsschritt II: Berechne γ′(t) = d dt γ(t). Dabei wird jede Komponente des Vektors γ einzeln nach t abgeleitet. L¨osungsschritt III: 21 Das Wegintegral von f entlang γ ist deﬁniert als ∫ γ f (s) · d⃗s = ∫ b a f (γ(t)) ︸ ︷︷ ︸ ∈Rn · γ′(t) ︸︷︷︸ ∈Rn ︸ ︷︷ ︸ Skalarprodukt in R dt ∈ R und ist unabh¨angig der gew¨ahlten Parametrisierung! 4.2 Potential Intuition: St¨arke der ¨Anderung der Richtung der Vektoren in einem Vektorfeld. Deﬁnition 12: Potentialfelder und Potentiale Ein Vektorfeld ⃗v : Ω ⊂ Rn → Rn heisst Potentialfeld, falls eine stetig diﬀerenzierbare Abbildung Φ : Ω ⊂ Rn → R existiert, sodass ⃗v = ∇Φ gilt. Das skalare Feld Φ heisst dann Potential von ⃗v. Wichtig: Es gibt sehr viele Vektorfelder, die sich nicht als Gradient eines skalaren Feldes schreiben lassen (also keine Potentialfelder sind)! Rezept 26: Potential ﬁnden Sei ⃗v =    f1 ... fn    ein Vektorfeld. Dann muss f¨ur das Potential Φ stimmen: ⃗v =    ∂Φ ∂x1 ... ∂Φ ∂xn    4.3 Konservative Vektorfelder (= Potentialfelder) Rezept 27: Konservativit¨at zeigen (mittels Integrabilit¨atsbedingungen) Ein Vektorfeld V : (x, y) ↦→ (f1(x), f2(y)) ist konservativ (= ein Potential- feld) wenn es ¨uberall deﬁniert und zusammenh¨angend (f¨ur 2D: keine ’L¨ocher’) ist und die Integrabilit¨atsbedingungen gelten: F¨ur R2: ∂f1 ∂x2 = ∂f2 ∂x1 F¨ur R3: ∂f1 ∂x2 = ∂f2 ∂x1 , ∂f1 ∂x3 = ∂f3 ∂x1 , ∂f2 ∂x3 = ∂f3 ∂x2 F¨ur Rn: ∂fi ∂xj = ∂fj ∂xi , ∀i ̸= j, i, j ∈ {1, ..., n} Satz 10: Wegintegrale f¨ur Potentialfelder Sei ⃗v : Ω ⊂ Rn → Rn ein Potentialfeld mit Potential Φ. Dann gilt f¨ur jedes Wegintegrale entlang γ, dass ∫ γ ⃗v · d⃗s = ∫ b a ⃗v(γ(t)) · γ′(t)dt = Φ(γ(b)) − Φ(γ(a)) 22 Wir m¨ussen also nur die Potentiale am Anfangs- und Endpunkt der Kurve auswerten! Damit sieht man auch gerade, dass f¨ur jede geschlossene Kurve das Wegintegrale eines Potentialfeldes gleich 0 ist. N¨utzliches: Zusammenfassung Sei ⃗v : Ω ⊂ Rn → Rn ein stetig diﬀerenzierbares Vektorfeld und Ω einfach zusammenh¨angend. Folgende Aussagen sind ¨aquivalent: • ⃗v ist konservatives Vektorfeld • ⃗v ist ein Potentialfeld • F¨ur alle geschlossene Kurven gilt ∮ ⃗v · d⃗s = 0 • Das Integral ∫ γ ⃗v · d⃗s ist unabh¨angig vom Weg • ⃗v erf¨ullt die Integrabilit¨atsbedingung auf Ω. F¨ur R3 gilt also ∇ ×⃗v = 0 4.4 Integrationsregeln Satz 11: Satz von Fubini Reduzierung von mehrdimensionalen Integralen auf eine Dimension. Sei f : [a, b] × [c, d] stetig, dann gilt ∫ b a dx ∫ d c f (x, y)dy = ∫ d c dy ∫ b a f (x, y)dx = ∫ [a,b]×[c,d] f (x, y)dµ(x, y) Es sei der Quader Q = [a1, a2]×[a2, b2]×· · ·×[an, bn] mit f ∈ C0(Q) gegeben. Dann gilt ∫ Q f (x)dµ(x) = ∫ b1 a1 dx1 ∫ b2 a2 dx2· · · ∫ bn an dxnf (x1, x2, ..., xn) Die Integrationsreihenfolge darf vertauscht werden. Alternative Schreibweise von dx dy: µ(x, y), µ(x + y). Satz 12: Substitutionsregeln in einer Dimension Sei f eine Riemann-integrierbare Funktion. F¨ur die Berechnung des Integrals ∫ b a f (x)dx f¨uhrt die Substitution x → g(u) zu dx = g′(u)du und damit wird das Integral ∫ b a f (x)dx = ∫ g−1(b) g−1(a) f (g(u))g′(u)du Das heisst wir haben das Integrationselement dx durch g′(u)du ersetzt und die Grenzen entsprechend angepasst. 23 Satz 13: Substitutionsregel in R2 ∫ Ω f (x, y) dxdy = ∫ ̃Ω f (g(u, v), h(u, v)) ∣ ∣ ∣ ∣ ∣ ∣ ∣ ∣ ∣ ∣ det ( ∂g ∂u ∂g ∂v ∂h ∂u ∂h ∂v ) ︸ ︷︷ ︸ dΦ=∇Φ ∣ ∣ ∣ ∣ ∣ ∣ ∣ ∣ ∣ ∣ dudv Satz 14: Substitutionsregeln in n Dimensionen Sei f eine Riemann-integrierbare Funktion auf dem Gebiet Ω ⊂ Rn und die Koordinatentransformation (Substitution) (x1, . . . , xn) = Φ(u1, . . . , un) oder in Komponenten    x1 ... xn    = Φ(u) =    g1(u1, . . . , un) ... gn(u1, . . . , un)    ist ein C1-Diﬀeomorphismus. Dann gilt ∫ Ω f (x1, . . . , xn)dx1 . . . dx1 = ∫ ̃Ω f (g1(u), . . . , gn(u)) · | det dΦ| du1 . . . dun wobei das Gebiet ̃Ω = Φ−1(Ω) ist. | det dΦ| ist die Funktionaldeterminan- te (Jakobi-Determinante). Rechenregeln: Koordinatentransformationen und Funktionaldet. Wichtige Koordinatentransformationen und Funktionaldeterminanten Polarkoordinaten in R2 x = r cos ϕ 0 ≤ r < ∞ dxdy = r · drdϕ y = r sin ϕ 0 ≤ ϕ < 2π Elliptische Koordinaten R2 x = r · a cos ϕ 0 ≤ r < ∞ dxdy = a · b · r · drdϕ y = r · b sin ϕ 0 ≤ ϕ < 2π Zylinderkoordinaten R3 x = r · a cos ϕ 0 ≤ r < ∞ dxdydz = r · drdϕdz y = r · b sin ϕ 0 ≤ ϕ < 2π z = z ∞ ≤ z < ∞ Kugelkoordinaten R3 x = r · sin θ cos ϕ 0 ≤ r < ∞ dxdydz = r2 sin θ · drdθdϕ y = r · sin θ sin ϕ 0 ≤ θ < π z = r cos θ 0 ≤ ϕ < 2π 24 4.5 Geometrische Anwendungen von Integralen Rezept 28: Area(D) - Vol(D) - Volumen eines Normalbereichs in Rn Analog zum Integrieren ¨uber Normalbereich: Vol(D) = ∫ D 1 dX = ∫ ∫ . . . ∫ ︸ ︷︷ ︸ n 1 dx1 . . . dxn−1dxn, D ⊆ R n 4.5.1 Normalbereiche in R2 Deﬁnition 13: Normalbereiche in zwei Dimensionen Sei Ω eine beschr¨ankte Teilmenge von R2. Ω heisst y-Normalbereich, falls sich Ω wie folgt darstellen l¨asst: Ω = {(x, y) ∈ R2 | a ≤ x ≤ b, f (x) ≤ y ≤ g(x)} wobei f , g stetige Funktionen der Variable x sind. Die Rolle von x und y darf vertauscht werden (es existiert also auch ein x-Normalbereich). (a): y-Normalbereich, (b): x-Normalbereich Satz 15: Integration auf Normalbereichen Sei Ω = {(x, y) ∈ R2 | a ≤ x ≤ b, f (x) ≤ y ≤ g(x)} ein y-Normalbereich mit stetigen Funktionen f , g und sei die zu integrie- rende Funktion F ∈ C0(Ω), dann gilt: ∫ Ω F dµ = ∫ b a dx ∫ g(x) f (x) dyF (x, y) Das innere Integral wird zuerst ausgewertet. Rezept 29: Integrieren ¨uber Normalbereichen Am folgenden Beispiel: ∫ D f (x, y) dxdy wobei D = R 2∩{(x, y) | y ≥ 0 ∧ x−y+1 ≥ 0 ∧ x+2y−4 ≤ 0} 1. Es hilft, sich den Normalbereich visuell vorzustellen, um die Grenzen zu ﬁnden. Bedingungen nutzen: y ≥ 0 ∧ (y − 1 ≤ x ≤ 4 − 2y) Damit x nicht leer ist, muss y − 1 ≤ 4 − 2y sein, resp. y ≤ 5 3 25 2. F¨ur das ¨aussere Integral sind die Integrationsgrenzen nun fest vorgege- ben. Die inneren Grenzen werden abh¨angig von der ¨ausseren Variable gew¨ahlt: ∫ D f (x, y) dxdy = ∫ 5 3 0 ∫ 4−2y y−1 f (x, y) dxdy 4.5.2 Satz von Green Dieser Satz erlaubt uns, eindimensionale Wegintegrale in zweidimensionale Ge- bietsintegrale umzuwandeln. D.h. wir rechnen dann jeweils die Variante aus, die einfacher geht. Idee: Beziehung Linienintegral und Fl¨achenintegral. Satz 16: Satz von Green in der Ebene Sei ⃗v = (v1, v2) ein stetig diﬀerenzierbares Vektorfeld auf einem Gebiet Ω ⊂ R2 und C ⊂ Ω ein beschr¨ankter Bereich mit C1 pw Rand ∂C, der sich nicht selbst schneidet. Dann gilt ∫ γ=∂C ⃗v · d⃗s = ∫ C ( ∂v2 ∂x − ∂v1 ∂y ) dxdy Bemerkung I: Der Rand ∂C muss im positiven mathematischen Sinn durchlaufen werden. D.h. das Gebiet C muss jeweils links vom Rand sein, f¨ur ein Beobachter, der auf dem Rand l¨auft. Bemerkung II: Der Satz von Green ist die zweidimensionale Version des Satzes von Stokes Bemerkung III: γ = ∂C muss den gesamten Rand abdecken. Evtl. Gebiets- additivit¨at nutzen und gewisse Bereiche (R¨ander) einzeln parametrisieren. Rezept 30: Fl¨achen berechnen mit Satz von Green Gegeben: Gebiet C ⊂ R2 beschr¨ankt mit C1 pw Rand ∂C. Gesucht: Fl¨ache F (C) L¨osungsschritt I: Parametrisiere den Rand von C mit einer Kurve γ : [a, b] → R2, t ↦→ γ(t) Beachte, dass die Parametrisierung in positiver mathematischer Richtung verl¨auft. D.h. das Gebiet muss jeweils links der Kurve sein. L¨osungsschritt II: Berechne γ′ L¨osungsschritt III: W¨ahle ein geeignetes Vektorfeld: ∂v2 ∂x − ∂v1 ∂y = 1 Zum Beispiel ⃗v = (0, x) oder ⃗v = (−y/2, x/2) oder ⃗v = (−y, 0). Wende daf¨ur den Satz von Green an, F (C) = ∫ γ=∂C ⃗v · d⃗s 26 Satz 17: Masse und Schwerpunkt Sei Ω ein zweidimensionales Gebiet mit Massendichte ρ(x, y), welche die Massenverteilung auf Ω beschreibt. Die Masse von Ω ist dann M (Ω) = ∫ Ω ρ(x, y)dxdy Der Schwerpunkt S = (xs, ys) von Ω ist gegeben durch xs = 1 M ∫ Ω xρ(x, y)dxdy ys = 1 M ∫ Ω yρ(x, y)dxdy Analog berechnen sich Masse, Schwerpunkt von dreidimensionalen Gebieten. Satz 18: Satz von Stokes Sei ⃗v = (v1, v2, v3) ein stetig diﬀerenzierbares Vektorfeld auf Ω ⊂ R3 und C ⊂ Ω eine oﬀene Fl¨ache durch die geschlossene C1 pw Kurve γ = ∂C berandet: ∫ γ=∂C ⃗v · d⃗s = ∫ C(⃗∇ × ⃗v) · ⃗n do wobei ⃗n der nach aussen gerichtete Normalenvektor entlang C und do das zweidimensionale Integrationselement ¨uber die Fl¨ache bezeichnen. Der Weg γ muss positiv orientiert sein. 4.5.3 Satz von Gauss Satz 19: Satz von Gauss Sei V ein beschr¨ankter r¨aumlicher Bereich mit Rand ∂V ∈ C1 pw gegeben. Sei das Vektorfeld ⃗v auf ganz V deﬁniert und stetig diﬀerenzierbar. Dann gilt ∫ ∂V ⃗v · ⃗n do = ∫ V ⃗∇ · ⃗v dµ wobei ⃗n der nach aussen gerichtete Normalenvektor entlang ∂V , do das zwei- dimensionale Integrationselement ¨uber die Fl¨ache und dµ das dreidimensio- nale Integrationselement ¨uber das Volumen bezeichnen. 5 Tricks und Umformungen Rezept 31: f (b) − f (a) Falls irgendwo die Diﬀerenz einer Funktion auftaucht, kann oft der Funda- mentalsatz genutzt werden f (b) − f (a) = ∫ b a ∂f ∂x dx Rezept 32: Beweise, dass z(t) konstant ist z(t) konstant ⇐⇒ z′(t) = 0 bzw ∇z(t) =    ∂z1 ∂t ... ∂zn ∂t    =    0 ... 0    also ∀i ∈ {1, . . . , n} : ∂zi ∂t = 0 27 6 Integrale 6.1 Spezielle unbestimmte Integrale ∫ 0 dx = C, ∫ a dx = ax + C ∫ xsdx = 1 s + 1 xs+1 + C, s ̸= −1 ∫ 1 x dx = log|x| + C ∫ (ax + b) s dx = 1 a(s + 1) (ax + b) s+1 + C, s ̸= −1 ∫ 1 ax + b dx = 1 a log|ax + b| + C ∫ (ax p + b)sxp−1 dx = (axp + b)s+1 ap(s + 1) + C, s ̸= −1, a ̸= 0 ∫ (ax p + b)−1xp−1 dx = 1 ap log|axp + b| + C, a ̸= 0, p ̸= 0 ∫ ax + b cx + d dx = ax c − ad − bc c2 log|cx + d| + C ∫ 1 x2 + a2 dx = 1 a arctan( x a ) + C ∫ 1 x2 − a2 dx = 1 2a log∣ ∣ ∣ x − a x + a ∣ ∣ ∣ ∫ √ a2 + x2 dx = x 2 √ a2 + x2 + a2 2 log(x + √ a2 + x2) + C ∫ √ a2 − x2 dx = x 2 √ a2 − x2 + a2 2 arcsin ( x |a| )+C ∫ √ x2 − a2 dx = x 2 √ x2 − a2 − a2 2 log|x + √ x2 − a2| + C ∫ 1 √x2 − a2 dx = log(x + √ a2 + x2) + C ∫ 1 √x2 − a2 dx = log|x + √ x2 − a2| + C ∫ 1 √a2 − x2 dx = arcsin ( x |a| )+C ∫ e kx dx = 1 k ekx + C ∫ a kx dx = 1 k ∗ log(a) a kx + C ∫ e axp(x) dx = eax(a−1p(x) − a−2p′(x) + a −3p′′(x) − . . . +(−1) na −n−1p(n)(x)) + C, a ̸= 0, p: Polynom n-ten Grades ∫ e kxsin(ax + b) dx = ekx a2 + k2 (k sin(ax + b)− a cos(ax + b) )+C ∫ e kxcos(ax + b) dx = ekx a2 + k2 (k cos(ax + b)... ... + a sin(ax + b))+C ∫ log|x| dx = x(log|x| − 1) + C ∫ xklog(x) dx = xk+1 k + 1 (log(x) − 1 k + 1 )+C, k ̸= −1 ∫ x−1log(x) dx = 1 2 (log(x)) 2 + C ∫ sin(x) dx = −cos(x) + C ∫ sin(ax + b) dx = − 1 a cos(ax + b) + C ∫ cos(x) dx = sin(x) + C ∫ cos(ax + b) dx = 1 a sin(ax + b) + C ∫ tan(x) dx = −log|cos(x)| + C 28 ∫ sin2(x) dx = 1 2 (x − sin(x)cos(x)) + C ∫ cos 2(x) dx = 1 2 (x + sin(x)cos(x)) + C ∫ tan2(x) dx = tan(x) − x + C ∫ 1 sin(x) dx = log∣ ∣ ∣tan x 2 ∣ ∣ ∣+C ∫ 1 cos(x) dx = log∣ ∣ ∣tan( x 2 + π 4 )∣ ∣ ∣+C ∫ 1 tan(x) dx = log|sin(x)| + C ∫ arcsin(x) dx = x arcsin(x) + √1 − x2 + C ∫ arccos(x) dx = x arccos(x) − √ 1 − x2 + C ∫ arctan(x) dx = x arctan(x) − 1 2 log(1 + x2) + C 6.2 Spezielle bestimmte Integrale ∫ 2π 0 sin(mx)cos(nx) dx = 0, m, n ∈ Z ∫ ∞ 0 sin(ax) x dx = π 2 , a > 0 ∫ ∞ 0 sin(x2) dx = ∫ ∞ 0 cos(x 2) dx = 1 2 √ π 2∫ ∞ 0 e−axxn dx = n! an+1 , a > 0 ∫ ∞ 0 e−ax2 dx = 1 2 √ π a , a > 0 29","libVersion":"0.3.2","langs":""}
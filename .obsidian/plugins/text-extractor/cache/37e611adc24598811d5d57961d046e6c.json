{"path":"sem2/PProg/VRL/extra/kuhn/PProg-w06-kuhn.pdf","text":"Parallel Programming Session 6 Spring 2024 Exam Preparation Session Monday, April 6, 10:15 – 12:00 HG F 7 Hosted by Julianne Orel and Finn Heckman Schedule Assignment 5 post-discussion (incl. last week theory recall) Theory Recap incl. exam task (fork/join) Assignment 6 pre-discussion Keywords (this& last week) Quiz Post-Discussion Ex.5 Recall: Amdahl& Gustafson Goal: Understand main difference and implications (i.e when do we use which formula) Know how to derive both speed up formulas (not just because you memorize them) Recall: Amdahl's vs Gustafson's Law p=1 p=4 Amdahl's Law Gustafson's Law Less Time for the parallel part More work in the same Time Time p=1 p1 p2 p3 p4p1 p2 p3 p4 p=4 p1p1 Recall: Amdahl& Gustafson Goal: Understand main difference and implications (i.e when do we use which formula) Know how to derive both speed up formulas (not just because you memorize them) Amdahl's Law Derivation T1 - sequential time f - sequential fraction Tp - parallel time on p processors Tp = T1f + T1(1-f)/p Sp - speedup Sp = T1/Tp Sp = 1/(f + (1-f)/p) p=1 Amdahl's Law p=4 Less Time for the parallel part T1 T1f T1(1-f)/p T1f Gustafson's Law Derivation Gustafson's Law T - sequential time of original work T1 - sequential time with work*p f - sequential fraction T1 = Tf + T(1-f)p Tp - parallel time on p processors Tp = Tf + T(1-f)p/p = T Sp - speedup Sp = T1/Tp Sp = f + (1-f)p More work in the same Time p=4 key take-aways Amdahl: % of non-parallelizable code fixed (even with infinite processors) speedup at most 1/f. Gustafson: Sequential part (not the fraction) stays fixed parallel part increases Speedup unbounded Speed Up Sub-linear: common case P processors -> speed up less than P why? Speed Up Sub-linear: common case P processors -> speed up less than P why? parallelization overhead, workload imbalance etc. Speed Up Sub-linear: common case P processors -> speed up less than P why? parallelization overhead, workload imbalance etc. perfect linear: perfect theory case P processors -> speed up exactly P Speed Up Sub-linear: common case P processors -> speed up less than P why? parallelization overhead, workload imbalance etc. perfect linear: perfect theory case P processors -> speed up exactly P super linear: in theory not possible but in real-life happening P processor -> speed up more than P how ? Speed Up Sub-linear: common case P processors -> speed up less than P why? parallelization overhead, workload imbalance etc. perfect linear: perfect theory case P processors -> speed up exactly P super linear: in theory not possible but in real-life happening P processor -> speed up more than P how ? hardware properties f eg. caching effects Task extract values from text and plug them into Amdahl or Gustafson formula if something unclear -> write me an email Task graphs Why? Modell execution of a program, visualize dependencies Task graphs Why? Modell execution of a program, visualize dependencies Characteristics: critical path: longest path through the graph (top to bottom) gives us longest dependency chain !!! Task graphs Why? Modell execution of a program, visualize dependencies Characteristics: critical path: longest path through the graph (top to bottom) gives us longest dependency chain !!! length of a path: we count visited nodes& their time (not edges) fib(4) task graph public class Fibonacci { public static long fib(int n) { if (n < 2) { return n; } spawn task for fib(n-1); spawn task for fib(n-2); wait for tasks to complete return addition of task results } } fib(4) task graph public class Fibonacci { public static long fib(int n) { if (n < 2) { return n; } spawn task for fib(n-1); spawn task for fib(n-2); wait for tasks to complete return addition of task results } } fib(4) fib(3) fib(2) fib(1) fib(0) fib(2) What is a task? spawn base case wait What is an edge? spawn same procedure wait fib(0) fib(1) fib(1) fib(4) task graph public class Fibonacci { public static long fib(int n) { if (n < 2) { return n; } spawn task for fib(n-1); spawn task for fib(n-2); wait for tasks to complete return addition of task results } } What is a task? spawn base case wait fib(4) fib(3) fib(2) fib(1) fib(0)fib(1) fib(1) fib(0) fib(2) What is an edge? spawn same procedure waitcritical path length is 8 tasks fib(4) simplified task graph public class Fibonacci { public static long fib(int n) { if (n < 2) { return n; } spawn task for fib(n-1); spawn task for fib(n-2); wait for tasks to complete return addition of task results } } What is a task? Call to Fibonacci What is an edge? spawn (no dependency within same procedure) 4 2 1 1 0 3 2 1 0 Simpler at the expense of not modelling joins and inter-process dependencies fib(4) simplified task graph public class Fibonacci { public static long fib(int n) { if (n < 2) { return n; } spawn task for fib(n-1); spawn task for fib(n-2); wait for tasks to complete return addition of task results } } What is a task? Call to Fibonacci What is an edge? spawn (no dependency within same procedure) 4 2 1 1 0 3 2 1 0 Simpler at the expense of not modelling joins and inter-process dependencies Caching results can speed-up computation Task Graphs Adding eight numbers: What is the corresponding task graph? Task Graphs Adding eight numbers: What is the corresponding task graph? +1 +3 +4 +5 +6 +7 +8 +2 Task Graphs Adding eight numbers: What is the corresponding task graph? +1 +3 +4 +5 +6 +7 +8 +2 Critical path n essentials Task Graphs Adding eight numbers: What is the corresponding task graph? Task Graphs Adding eight numbers: What is the corresponding task graph? Task Graphs Adding eight numbers: What is the corresponding task graph? Critical path log(n) Old Exam TaskOld Exam TaskSearch& Count Search an array of integers for a certain feature and count integers that have this feature We will study single threaded and multi-threaded implementations of the problem. Search& Count Search an array of integers for a certain feature and count integers that have this feature We will study single threaded and multi-threaded implementations of the problem. Light workload: count number of non-zero values. Heavy workload: count how many integers are prime numbers. Search And Count - Sequential public class SearchAndCountSingle { private int[] input; private Workload.Type type; private SearchAndCountSingle(int[] input, Workload.Type wt) { this.input = input; this.type = wt; } private int count() { int count = 0; for (int i = 0; i < input.length; i++) { if (Workload.doWork(input[i], type)) count++; } return count; } } Straightforward implementation. Simply iterate through the input array and count how many times given event occurs. Divide& Conquer Divide: Break into subproblems Conquer: Solve those subproblems Combine results Seems naturally perfect for parallelizing Divide& Conquer Divide: Break into subproblems Conquer: Solve those subproblems Combine results Seems naturally perfect for parallelizing How do we asses performance of those algorithms & how do we implement them ? Task Graphs Executor Service Fork/Join Executor Service Executor Service Limited thread pool, thus can run forever ->deadlock not well for deep recursive tasks ! Executor Service Executor Service Limited thread pool, thus can run forever ->deadlock not well for deep recursive tasks Divide and Conquer Parallelization ++++++++ ++++ ++ + thread 1 thread 2 thread 3 thread 4 thread 5 thread 6 thread 7 thread 8 ... Divide and Conquer Parallelization ++++++++ ++++ ++ + thread 1 thread 2 thread 3 thread 4 thread 5 thread 6 thread 7 thread 8 ... span a new thread or not Divide and Conquer Parallelization Performance optimization Same thread is reused instead of creating a new one ++++++++ ++++ ++ + thread 1 thread 2 thread 3 thread 4 thread 5 thread 6 thread 7 thread 8 ... similar thinking as run() vs start() Divide and Conquer Parallelization Performance optimization Same thread is reused instead of creating a new one ++++++++ ++++ ++ + thread 1 thread 2 thread 3 thread 4 thread 5 thread 6 thread 7 thread 8 ... Task B: Extend your implementation such that it creates only a fixed number of threads. Make sure that your solution is properly synchronized when checking whether to create a new thread How to achieve this? Divide and Conquer Parallelization ++++++++ ++++ ++ + Option 1: Shared counter with synchronized/atomic access Divide and Conquer Parallelization ++++++++ ++++ ++ + Option 1: Shared counter with synchronized/atomic access Option 2: Assign unique sequential id to each task. Spawn threads for first N tasks. 0 1 2 3 4 5 6 Divide and Conquer Parallelization ++++++++ ++++ ++ + Option 1: Shared counter with synchronized/atomic access Option 2: Assign unique sequential id to each task. Spawn threads for first N tasks. 0 1 2 3 4 5 6 n 2n + 1 2n + 2 Divide and Conquer Parallelization ++++++++ ++++ ++ + Option 1: Shared counter with synchronized/atomic access Option 2: Assign unique sequential id to each task. Spawn threads for first N tasks. 0 1 2 3 4 5 6 n 2n + 1 2n + 2 + no synchronization required - imbalanced amount of work Divide and Conquer vs Fork/Join Fork/Join ++++++++ ++++ ++ + a framework that supports Divide and Conquer style parallelism problems are solved in parallel thread 1 thread 2 thread 3 thread 4 thread 5 thread 6 thread 7 ... Divide and Conquer vs Fork/Join Fork/Join ++++++++ ++++ ++ + thread 1 thread 2 thread 3 thread 4 thread 5 thread 6 thread 7 ... Performance optimization Same thread is reused instead of creating a new one fork() vs compute() Search And Count - Task Parallel public class SearchAndCountMultiple extends RecursiveTask<Integer> { private int[] input; private int start; private int length; private int cutOff; private Workload.Type workloadType; } Define the task structure: Search And Count protected Integer compute() { if (// work is small) { // do the work directly else { // split work into pieces // invoke the pieces and wait for the results // combine the results } } Recall the template for divide and conquer task parallelism Search And Count protected Integer compute() { if (// work is small) { // do the work directly else { // split work into pieces // invoke the pieces and wait for the results // combine the results } } protected Integer compute() { if (// work is small) { // do the work directly else { // split work into pieces // invoke the pieces and wait for the results // combine the results } } public class SearchAndCountMultiple extends RecursiveTask<Integer> { private int[] input; private int start; private int length; private int cutOff; private Workload.Type type; } Search And Count protected Integer compute() { if (// work is small) // do the work directly else { // split work into pieces // invoke the pieces and wait for the results // combine the results } } protected Integer compute() { if (length <= cutOff) { // do the work directly else { // split work into pieces // invoke the pieces and wait for the results // combine the results } } public class SearchAndCountMultiple extends RecursiveTask<Integer> { private int[] input; private int start; private int length; private int cutOff; private Workload.Type type; } Search And Count protected Integer compute() { if (// work is small) // do the work directly else { // split work into pieces // invoke the pieces and wait for the results // combine the results } } protected Integer compute() { if (length <= cutOff) { // do the work directly else { // split work into pieces // invoke the pieces and wait for the results // combine the results } } public class SearchAndCountMultiple extends RecursiveTask<Integer> { private int[] input; private int start; private int length; private int cutOff; private Workload.Type type; } Search And Count protected Integer compute() { if (// work is small) // do the work directly else { // split work into pieces // invoke the pieces and wait for the results // combine the results } } protected Integer compute() { if (length <= cutOff) { int count = 0; for (int i = start; i < start + length; i++) { if (Workload.doWork(input[i], type)) count++; } return count; else { // split work into pieces // invoke the pieces and wait for the results // combine the results } } Same as sequential implementation public class SearchAndCountMultiple extends RecursiveTask<Integer> { private int[] input; private int start; private int length; private int cutOff; private Workload.Type type; } Search And Count protected Integer compute() { if (// work is small) // do the work directly else { // split work into pieces // invoke the pieces and wait for the results // combine the results } } protected Integer compute() { if (length <= cutOff) { int count = 0; for (int i = start; i < start + length; i++) { if (Workload.doWork(input[i], type)) count++; } return count; else { // split work into pieces // invoke the pieces and wait for the results // combine the results } } public class SearchAndCountMultiple extends RecursiveTask<Integer> { private int[] input; private int start; private int length; private int cutOff; private Workload.Type type; } Search And Count protected Integer compute() { if (// work is small) // do the work directly else { // split work into pieces // invoke the pieces and wait for the results // combine the results } } protected Integer compute() { if (length <= cutOff) { int count = 0; for (int i = start; i < start + length; i++) { if (Workload.doWork(input[i], type)) count++; } return count; else { int half = (length) / 2; SearchAndCountMultiple sc1 = new SearchAndCountMultiple(input, start, half, cutOff, type); SearchAndCountMultiple sc2 = new SearchAndCountMultiple(input, start + half, length - half, cutOff, type); // invoke the pieces and wait for the results // combine the results } } public class SearchAndCountMultiple extends RecursiveTask<Integer> { private int[] input; private int start; private int length; private int cutOff; private Workload.Type type; } Search And Count protected Integer compute() { if (// work is small) // do the work directly else { // split work into pieces // invoke the pieces and wait for the results // combine the results } } protected Integer compute() { if (length <= cutOff) { int count = 0; for (int i = start; i < start + length; i++) { if (Workload.doWork(input[i], type)) count++; } return count; else { int half = (length) / 2; SearchAndCountMultiple sc1 = new SearchAndCountMultiple(input, start, half, cutOff, type); SearchAndCountMultiple sc2 = new SearchAndCountMultiple(input, start + half, length - half, cutOff, type); // invoke the pieces and wait for the results // combine the results } } public class SearchAndCountMultiple extends RecursiveTask<Integer> { private int[] input; private int start; private int length; private int cutOff; private Workload.Type type; } Search And Count protected Integer compute() { if (// work is small) // do the work directly else { // split work into pieces // invoke the pieces and wait for the results // combine the results } } protected Integer compute() { if (length <= cutOff) { int count = 0; for (int i = start; i < start + length; i++) { if (Workload.doWork(input[i], type)) count++; } return count; else { int half = (length) / 2; SearchAndCountMultiple sc1 = new SearchAndCountMultiple(input, start, half, cutOff, type); SearchAndCountMultiple sc2 = new SearchAndCountMultiple(input, start + half, length - half, cutOff, type); sc1.fork(); sc2.fork(); int count1 = sc1.join(); int count2 = sc2.join(); // combine the results } } public class SearchAndCountMultiple extends RecursiveTask<Integer> { private int[] input; private int start; private int length; private int cutOff; private Workload.Type type; } Search And Count protected Integer compute() { if (// work is small) // do the work directly else { // split work into pieces // invoke the pieces and wait for the results // combine the results } } protected Integer compute() { if (length <= cutOff) { int count = 0; for (int i = start; i < start + length; i++) { if (Workload.doWork(input[i], type)) count++; } return count; else { int half = (length) / 2; SearchAndCountMultiple sc1 = new SearchAndCountMultiple(input, start, half, cutOff, type); SearchAndCountMultiple sc2 = new SearchAndCountMultiple(input, start + half, length - half, cutOff, type); sc1.fork(); sc2.fork(); int count1 = sc1.join(); int count2 = sc2.join(); // combine the results } } public class SearchAndCountMultiple extends RecursiveTask<Integer> { private int[] input; private int start; private int length; private int cutOff; private Workload.Type type; } Alternative ? Search And Count protected Integer compute() { if (// work is small) // do the work directly else { // split work into pieces // invoke the pieces and wait for the results // combine the results } } protected Integer compute() { if (length <= cutOff) { int count = 0; for (int i = start; i < start + length; i++) { if (Workload.doWork(input[i], type)) count++; } return count; else { int half = (length) / 2; SearchAndCountMultiple sc1 = new SearchAndCountMultiple(input, start, half, cutOff, type); SearchAndCountMultiple sc2 = new SearchAndCountMultiple(input, start + half, length - half, cutOff, type); sc1.fork(); sc2.fork(); int count1 = sc1.join(); int count2 = sc2.join(); // combine the results } } public class SearchAndCountMultiple extends RecursiveTask<Integer> { private int[] input; private int start; private int length; private int cutOff; private Workload.Type type; } Alternative ? 2nd compute() and not fork() Search And Count protected Integer compute() { if (// work is small) // do the work directly else { // split work into pieces // invoke the pieces and wait for the results // combine the results } } protected Integer compute() { if (length <= cutOff) { int count = 0; for (int i = start; i < start + length; i++) { if (Workload.doWork(input[i], type)) count++; } return count; else { int half = (length) / 2; SearchAndCountMultiple sc1 = new SearchAndCountMultiple(input, start, half, cutOff, type); SearchAndCountMultiple sc2 = new SearchAndCountMultiple(input, start + half, length - half, cutOff, type); sc1.fork(); sc2.fork(); int count1 = sc1.join(); int count2 = sc2.join(); // combine the results } } public class SearchAndCountMultiple extends RecursiveTask<Integer> { private int[] input; private int start; private int length; private int cutOff; private Workload.Type type; } Search And Count protected Integer compute() { if (// work is small) // do the work directly else { // split work into pieces // invoke the pieces and wait for the results // combine the results } } protected Integer compute() { if (length <= cutOff) { int count = 0; for (int i = start; i < start + length; i++) { if (Workload.doWork(input[i], type)) count++; } return count; else { int half = (length) / 2; SearchAndCountMultiple sc1 = new SearchAndCountMultiple(input, start, half, cutOff, type); SearchAndCountMultiple sc2 = new SearchAndCountMultiple(input, start + half, length - half, cutOff, type); sc1.fork(); sc2.fork(); int count1 = sc1.join(); int count2 = sc2.join(); return count1 + count2; } } public class SearchAndCountMultiple extends RecursiveTask<Integer> { private int[] input; private int start; private int length; private int cutOff; private Workload.Type type; } Search And Count public class SearchAndCountMultiple extends RecursiveTask<Integer> { private int[] input; private int start; private int length; private int cutOff; private Workload.Type type; } protected Integer compute() { if (// work is small) // do the work directly else { // split work into pieces // invoke the pieces and wait for the results // combine the results } } protected Integer compute() { if (length <= cutOff) { int count = 0; for (int i = start; i < start + length; i++) { if (Workload.doWork(input[i], type)) count++; } return count; else { int half = (length) / 2; SearchAndCountMultiple sc1 = new SearchAndCountMultiple(input, start, half, cutOff, type); SearchAndCountMultiple sc2 = new SearchAndCountMultiple(input, start + half, length - half, cutOff, type); sc1.fork(); sc2.fork(); int count1 = sc1.join(); int count2 = sc2.join(); return count1 + count2; } } Why all of this “fork/join”?Divide& Conquer with Java Threads log(n) What‘s the problem ? Why can‘t we do this? Theory Recap Fork/Join again :/ Library suited for divide& conquer algorithms Implemented like Java Threads but with different names and interfaces Java Threads vs. ForkJoin: Extend Thread à Extend RecursiveAction<T> (with return value) RecursiveTask<> (without return value) Override run à Override compute Calling start à call fork Main thread à create ForkJoinPool and call invoke Fork/Join again :/ Library suited for divide& conquer algorithms Implemented like Java Threads but with different names and interfaces Java Threads vs. ForkJoin: Extend Thread à Extend RecursiveAction<T> (with return value) RecursiveTask<> (without return value) Override run à Override compute Calling start à call fork Main thread à create ForkJoinPool and call invoke fork() vs invoke () ? Exam TaskParallel Patterns Now we have the skills to parallelize algorithms Parallel Patterns Now we have the skills to parallelize algorithms Look for recurring patterns, are important as they appear often Parallel Patterns Maps Reductions Reduction A reduction is an operation that produces a single answer from a collection (array etc) via an associative operator. Reduction “size reduction” : Input (array, list etc) à Output (single element) A reduction is an operation that produces a single answer from a collection (array etc) via an associative operator. Needs to be associative else divide and conquer wouldn’t work Examples: Search and Count from exercises find max element from last week etc. Map Operates on each element of the input data independently (each array element). Output is of the same size -> no size reduction Map Operates on each element of the input data independently (each array element). Output is of the same size -> no size reduction Doesn’t have to be the same operation on each element !! Map Operates on each element of the input data independently (each array element). Output is of the same size -> no size reduction Doesn’t have to be the same operation on each element !! example: image -> apply a certain filter on each pixel add two arrays Stencil like map but can take more than one element as input Generalization of map thus also no size reduction Stencil like map but can take more than one element as input Generalization of map thus also no size reduction example: image -> apply a averaging filter on each pixel update value based on its neighbours etc. Stencil like map but can take more than one element as input Generalization of map thus also no size reduction example: image -> apply a averaging filter on each pixel update value based on its neighbours etc. Never do it in-place because then take inputs that are actually already output values. Scan Collection of data X à return collection of data Y Y(i) = function Of ( Y(i-1) & X(i) ) Scan Collection of data X à return collection of data Y Y(i) = function Of ( Y(i-1) & X(i) ) Seems sequential because of dependencies Can parallelize if function is assosicative -> O (log(n)) span Scan Collection of data X à return collection of data Y Y(i) = function Of ( Y(i-1) & X(i) ) Seems sequential because of dependencies Can parallelize if function is assosicative -> O (log(n)) span Example: parallel prefix sum as seen in lecture Pack Collection of data X à return collection of data X if fulfill condition Pack Collection of data X à return collection of data X if fulfill condition first compute bit vector Then to find index in result array prefix sum on bit vector Exam TaskExam Task Pre-Discussion Ex.6 Task Parallelism Merge Sort Longest Sequence Merge Sort You will implement merge sort using task parallelism merge sort seen in AnD (you only have to parallelize, rest is given J) Merge Sort You will implement merge sort using task parallelism merge sort seen in AnD (you only have to parallelize, rest is given J) Initially cut off is at 1 or 2 elements I suggest you try different cut-off values and observe how performance changes. Merge Sort You will implement merge sort using task parallelism merge sort seen in AnD (you only have to parallelize, rest is given J) Initially cut off is at 1 or 2 elements I suggest you try different cut-off values and observe how performance changes. You can use the search&count structure for orientation if you are lost. Longest Sequence Given a sequence of numbers, look for longest sequence of consecutive numbers. [1, 9, 4, 3, 3, 8, 7, 7, 7, 0] Longest Sequence Given a sequence of numbers, look for longest sequence of consecutive numbers. [1, 9, 4, 3, 3, 8, 7, 7, 7, 0] if multiple have same length, return the first one. [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] Longest Sequence Implement task parallel version (“simple without edge cases”) Longest Sequence Implement task parallel version (“simple without edge cases”) Implement challenge where input cannot be partitioned arbitrarily Here combining the sub-results would give a wrong result (1, but solution is 2). Think about implementing extra case when sequence goes across the middle. [1, 2, 3, 3, 4, 1] [1, 2, 3] [3, 4, 1] Keywords (this & last week) speed up task graph: work task graph: span divide and conquer scheme Executor Service vs. Fork Join fork() vs. compute() fork() vs invoke() map, reduction stencil, scan, pack Amdahl, Gustafson finally https://quizizz.com/admin/quiz/622660d2679f87001de7eb18 See you next week J I really recommend doing the exercieses this week.","libVersion":"0.3.2","langs":""}
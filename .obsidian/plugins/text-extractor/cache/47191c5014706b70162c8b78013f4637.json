{"path":"sem4/W&S/UE/s/W&S-s-u12.pdf","text":"Probability and Statistics (D-INFK) Lecturer: Prof. Dr. Dylan Possamaï Coordinator: Daniel Kršek Probability and Statistics Exercise sheet 12 - Solutions MC 12.1. Let X ∼ N (1, 4) and Y ∼ N (−1, σ2), where σ2 > 0 is unknown. What is the value of σ2 if P[X ≤ −1] = P[Y ≥ 2]? (Exactly one answer is correct.) (a) σ2 = 9. (b) σ2 = 1. (c) σ2 = 4. (d) σ2 = 2. Solution: (a) is correct. Due to the symmetry of the normal distribution, we have P[X ≤ −1] = P [ X − 1 √4 ≤ −1 − 1 √4 ] = Φ(−1) = 1 − Φ(1), P[Y ≥ 2] = 1 − P[Y ≤ 2] = 1 − P [ Y + 1 σ ≤ 2 + 1 σ ] = 1 − Φ ( 3 σ ) . Furthermore, 1 − Φ(1) = 1 − Φ ( 3 σ ) ⇐⇒ 1 = 3 σ ⇐⇒ σ = 3 ⇐⇒ σ2 = 9. MC 12.2. Which of the following statements about statistical tests are true? (The number of correct answers is between 0 and 4.) (a) If the null hypothesis is not rejected, we conclude that it must be true. (b) The statistical test measures the probability that the null hypothesis is true. (c) It is possible that a test rejects the null hypothesis even though it is true. However, we control the probability of this event. (d) The result of the statistical test is random. Solution: (a) is not true. (b) is also not true. We cannot assign a probability to the event {“the null hypothesis is true”}. This is because the truth of the hypothesis is unknown, but not random. (c) is true. (d) is also true. Since the observed data are random, the result of the statistical test is also random. 1 Probability and Statistics (D-INFK) Lecturer: Prof. Dr. Dylan Possamaï Coordinator: Daniel Kršek Exercise 12.3. We suspect that the consumption of sodium-rich foods has certain effects on blood pressure. Therefore, we conduct a study in which we first measure the blood pressure of 1000 individuals. These individuals then adopt a diet that is very high in sodium. After doing so, we measure their blood pressure again. Let X1, . . . , X1000 denote the random variables representing the differences in blood pressure values (after minus before). We assume that the Xi are independent with Xi ∼ N (µ, σ2), where σ2 > 0 is known, but µ ∈ R is unknown. Design a test to determine whether sodium has an effect on blood pressure. (a) Formulate the null hypothesis and the alternative. (b) Find a test statistic and the critical region at the 5% level. (c) Suppose that σ2 = 1 and ∑1000 i=1 xi = 80.2. What is the result of the test? Solution: (a) We formulate the hypotheses as follows: H0 : µ = 0 and H1 : µ ̸= 0. (b) We know that under the null hypothesis, the random variable S := ∑1000 i=1 Xi follows the distri- bution N (0, 1000σ2). Therefore, under the null hypothesis: S √1000σ2 ∼ N (0, 1). We want to find c such that P0 [|S| ≥ c] = P0 [S /∈ (−c, c)] = 0.05. We have P0 [S /∈ (−c, c)] = 0.05 ⇐⇒ P0 [ S √1000σ2 /∈ (− c √1000σ2 , c √1000σ2 )] = 0.05. Due to the symmetry of the normal distribution, we further have P0 [ S √1000σ2 /∈ (− c √1000σ2 , c √1000σ2 )] = Φ ( − c √1000σ2 ) + (1 − Φ ( c √1000σ2 )) = 2 (1 − Φ ( c √1000σ2 )) . Thus, P0 [S /∈ [−c, c]] = 0.05 ⇐⇒ 2 (1 − Φ ( c √1000σ2 )) = 0.05 ⇐⇒ Φ ( c √1000σ2 ) = 0.975 ⇐⇒ c √1000σ2 = Φ −1(0.975) ⇐⇒ c √1000σ2 = 1.96 ⇐⇒ c = 1.96√1000σ2. 2 Probability and Statistics (D-INFK) Lecturer: Prof. Dr. Dylan Possamaï Coordinator: Daniel Kršek The critical region is therefore (−∞, −1.96√1000σ2] ∪ [1.96√1000σ2, ∞), and we reject the null hypothesis when ∑1000 i=1 xi ≤ −1.96√1000σ2 or ∑1000 i=1 xi ≥ 1.96√1000σ2. (c) We have ∑1000 i=1 xi = 80.2 > 1.96 √1000 ≈ 61.98. Therefore, we reject the null hypothesis and conclude that a sodium-rich diet has a significant effect on blood pressure. We also observe that blood pressure increased. Hence, we can claim that sodium tends to increase blood pressure. Exercise 12.4. A pharmaceutical company is introducing a new drug and wants to conduct a study to examine whether the effectiveness of this drug exceeds 60%. To do so, they administer the drug to 1000 individuals and collect the data. For simplicity, we assume that the drug either worked or did not work for each person. (a) Find a suitable class of distributions for the random sample X1, . . . , X1000 and formulate the null and alternative hypotheses to test whether the effectiveness exceeds 60%. (b) Consider the test statistic S := ∑1000 i=1 Xi. Use an appropriate approximation for the distribution of S under the null hypothesis. (c) Find the approximate critical region at the significance level α = 0.05. (d) In our study, the drug was effective for 650 individuals. What is the result of this test? Solution: (a) We model this situation by assuming that the Xi are independent and follow a Bernoulli distri- bution with parameter p ∈ [0, 1]. We want to test whether p > 0.6. Therefore, we formulate the hypotheses as follows: H0 : p ≤ 0.6, and H1 : p > 0.6. (b) We know that if the Xi, i ∈ {1, . . . , 100}, are independent Bernoulli variables with parameter p ∈ [0, 1], then S ∼ Binom(1000, p). Under the null hypothesis, we assume p ≤ 0.6. Since p0 = 0.6 is the closest value to the alternative, we choose S ∼ Binom(1000, 0.6). See (1) for more details. We can use the central limit theorem. With E0.6[Xi] = p0 = 0.6 and Var0.6[Xi] = p0(1 − p0) = 0.24, we have approximately under the null hypothesis: S − 1000 × 0.6 √1000 × 0.24 ∼ N (0, 1). (c) We want to find c such that P0.6[S ≥ c] = 0.05. Note that Pp[S ≥ c] ≤ P0.6[S ≥ c] = 0.05 (1) for every p ∈ [0, 0.6]. In other words, the test has the correct significance level even if the true value of p is less than 0.6. 3 Probability and Statistics (D-INFK) Lecturer: Prof. Dr. Dylan Possamaï Coordinator: Daniel Kršek We have P0.6[S ≥ c] = P0.6 [ S − 600 √240 ≥ c − 600 √240 ] ≈ 1 − Φ ( c − 600 √240 ) . Moreover 1 − Φ ( c − 600 √240 ) = 0.05 ⇐⇒ 0.95 = Φ ( c − 600 √240 ) ⇐⇒ Φ−1(0.95) = c − 600 √240 ⇐⇒ 1.6449 = c − 600 √240 ⇐⇒ c = 1.6449 √240 + 600. Since 1.6449√240 + 600 ≈ 625.5, we obtain an approximate critical region [626, ∞). For comparison: the exact 0.95-quantile of Binom(1000, 0.6) is 625, so the approximation is very accurate. (d) We see that s = 650 lies in the approximate critical region. Therefore, we reject the null hypothesis and are confident that the effectiveness exceeds 60%. Exercise 12.5. Assume that X1, . . . , Xn, n ∈ N, are i.i.d. random variables with E[X 2 1 ] < ∞. Let µ = E[X1] and σ2 = Var[X1]. Suggest suitable (exact or approximate) tests at level α ∈ (0, 1) for the following situations. (a) Test H0 : µ = 0 against H1 : µ ̸= 0, assuming that Xi ∼ N (µ, σ2) and the variance σ2 is known. (b) Test H0 : µ = 0 against H1 : µ ̸= 0, assuming that Xi ∼ N (µ, σ2) and the variance σ2 is unknown. (c) Test H0 : σ2 = 1 against H1 : σ2 > 1, assuming that Xi ∼ N (µ, σ2) and the mean µ ∈ R is unknown. (d) Test H0 : µ = 1 against H1 : µ < 1, assuming that the variance σ2 is known, but the distribution of Xi is unknown. (e) Test H0 : µ = 1 against H1 : µ < 1, assuming that both the variance σ2 and the distribution of Xi are unknown. Solution: We only provide the summaries for each test for the sake of brevity. The detailed steps of each test can be carried out analogously to the other exercises. (a) Under H0, the statistic T(a) := X n√ σ2 n follows the standard normal distribution. Since the alternative is two-sided, we reject the null 4 Probability and Statistics (D-INFK) Lecturer: Prof. Dr. Dylan Possamaï Coordinator: Daniel Kršek hypothesis if T(a) < zα/2 or T(a) > z1−α/2, which is equivalent to |T(a)| > z1−α/2. (b) As the variance is unknown, we replace it with an estimator. Under H0, the statistic T(b) := X n√ S2 n n , where S2 n := 1 n − 1 n∑ i=1(Xi − X n)2, follows the Student’s t-distribution with n − 1 degrees of freedom. Since the alternative is two-sided, we reject the null hypothesis if T(b) < tn−1,α/2 or T(b) > tn−1,1−α/2, which is equivalent to |T(b)| > tn−1,1−α/2, where tn−1,α denotes the α-quantile of the t-distribution with n − 1 degrees of freedom. (c) Under H0, i.e., assuming σ2 = σ2 0 := 1, the statistic T(c) := (n − 1)S2 n σ2 0 = (n − 1)S2 n follows the χ2 n−1 distribution. Since the alternative is one-sided, we must be careful about which quantile to use. For large values of σ2, both S2 n and the value of the statistic tend to be large, and so we reject the null hypothesis if T(c) > χ 2 n−1,1−α, where, as usual, χ2 n−1,α denotes the α-quantile of the χ 2 n−1 distribution. (d) As the distribution of the sample is unknown, we use the central limit theorem to construct an approximate test. Under H0, the statistic T(d) := X n − 1 √ σ2 n approximately follows the standard normal distribution. Since the alternative is one-sided and the value of the test statistic tends to be low when µ is small, we reject the null hypothesis if T(d) < zα. (e) As the variance is unknown, we once again replace it with an estimator. Under H0, the statistic T(e) := X n − 1 √ S2 n n still approximately follows the standard normal distribution. Since the alternative is one-sided and the value of the test statistic tends to be low when µ is small, we reject the null hypothesis if T(e) < zα. 5 Probability and Statistics (D-INFK) Lecturer: Prof. Dr. Dylan Possamaï Coordinator: Daniel Kršek Remark: It is clear that the test statistic T(e) could also be used in point (d). However, given our data, it is not clear what effect the estimate s 2 n = S2 n(ω) has on the value of the test statistic. For instance, if the estimate is higher than the true variance, it will make the value of the test statistic closer to zero, which may be undesirable since we are not testing the variance. Therefore, if we are truly confident that we know the variance (which is, however, usually not the case), it is better to use T(d). Exercise 12.6. A six-sided die is to be tested for whether it is loaded and more likely to land on six. For this purpose, an experiment is conducted in which the die is rolled ten times and the result of each roll is recorded. We assume all rolls are independent and that the probability of rolling a 1, 2, 3, 4, or 5 is the same. We model the outcomes of the rolls as a sample X1, . . . , X10, where Xi = 1 indicates that the i-th roll was a six, and Xi = 0 otherwise. We obtain the following results: x1 x2 x3 x4 x5 x6 x7 x8 x9 x10 0 0 1 0 1 1 0 1 0 0 (a) Determine a suitable model (Pθ)θ∈Θ, i.e., a parameter space and the distributions of X1, . . . , X10 under each Pθ. (b) Formulate a suitable null hypothesis H0 and alternative hypothesis H1. (c) Let T = ∑10 i=1 Xi be the test statistic. What distribution does T follow? (d) Let K = (4, 10] be the rejection region. Compute the probability of a Type I error. (e) Describe the test decision based on the observed results. Solution: (a) From the assumptions, it follows that X1, . . . , X10 are independent and each follows a Bernoulli distribution with success parameter θ := Pθ[X1 = 1] ∈ Θ = [0, 1] under Pθ. (b) Our null hypothesis is that the die is not loaded; i.e., H0 : θ = 1 6 , i.e., Θ0 = { 1 6 } . The alternative hypothesis, that the die is loaded, is then H1 : θ > 1 6 , i.e., Θ1 = ( 1 6 , 1] . (c) Since X1, . . . , X10 are independent and follow Bernoulli(θ) under Pθ, the test statistic T follows a binomial distribution: T ∼ Binom(10, θ) under Pθ. 6 Probability and Statistics (D-INFK) Lecturer: Prof. Dr. Dylan Possamaï Coordinator: Daniel Kršek (d) The probability of a Type I error is P 1 6 [T ∈ K] = P 1 6 [T ≥ 5] = 10∑ k=5 (10 k ) ( 1 6 )k ( 5 6 )10−k = 1 610 ((10 5 )5 5 + (10 6 )5 4 + (10 7 )5 3 + (10 8 ) 52 + ( 10 9 )5 1 + ( 10 10 )5 0) = 0.0155. (e) Since t(x1, . . . , x10) = t(X1(ω), . . . , X10(ω)) = T (ω) = 4 is not in the rejection region, we do not reject the null hypothesis. Exercise 12.7. Let X1, . . . , X12 be independent and identically distributed as N (µ, σ2) under Pθ, where θ = µ is an unknown parameter. The standard deviation σ = 0.0499 is known. The following sample data are given: x1 x2 x3 x4 x5 x6 1.00781 1.00646 1.00801 1.00833 1.00738 1.00687 x7 x8 x9 x10 x11 x12 1.00783 1.00936 1.00564 1.00543 1.00794 1.01060 We test the hypothesis H0 : µ = µ0 against the alternative H1 : µ ̸= µ0, where µ0 = 1.0085. (a) Determine a and b such that the test statistic T := 1 a ( ∑12 i=1 Xi + b) follows N (0, 1) under Pµ0. (b) Let K := (−∞, −c) ∪ (c, ∞) be the rejection region for some c ≥ 0. Test H0 against H1 at the 5% significance level. (c) Compute the power of the test at µ = 1.008. Solution: (a) Since ∑12 i=1 Xi ∼ N (12µ0, 12σ2) under Pµ0, it follows that T = ∑12 i=1 Xi − 12µ0 σ√12 ∼ N (0, 1) under Pµ0. Therefore, we choose a = σ√12 and b = −12µ0. (b) Let α = 0.05. We perform a test with test statistic T and rejection region K, i.e., we reject the hypothesis if |T | > c for some c to be determined. By definition of the significance level: α = Pµ0[T ∈ K] = Pµ0 [T /∈ [−c, c]] = Pµ0 [T < −c] + Pµ0[T > c] = Φ(−c) + 1 − Φ(c) = 2 − 2Φ(c), 7 Probability and Statistics (D-INFK) Lecturer: Prof. Dr. Dylan Possamaï Coordinator: Daniel Kršek since T ∼ N (0, 1) under Pµ0. Thus, Φ(c) = 1 − α 2 = 1 − 0.05 2 = 0.975, so c = Φ −1(0.975) = z0.975 = 1.96. The observed test statistic is T (ω) = t(x1, . . . , x12) = −0.00598. Thus, we do not reject the null hypothesis. (c) The power of the test at point µ = 1.008 is Pµ[T ∈ K] = Pµ[T /∈ [−c, c]] = Pµ [ ∑12 i=1 Xi − 12µ σ√12 < −c + √12 σ (µ0 − µ) ] + Pµ [ ∑12 i=1 Xi − 12µ σ√12 > c + √12 σ (µ0 − µ) ] = Φ (−c + √12 σ (µ0 − µ) ) + 1 − Φ ( c + √12 σ (µ0 − µ)) = Φ(−1.93) + 1 − Φ(1.99) = 0.0501. This is a low value, and the reason is that µ is very close to µ0. 8 Probability and Statistics (D-INFK) Lecturer: Prof. Dr. Dylan Possamaï Coordinator: Daniel Kršek Quantile table for the standard normal distribution 0.5 0.75 0.9 0.95 0.975 0.99 0.995 0.999 0 0.6745 1.2816 1.6449 1.9600 2.3263 2.5758 3.0902 . For instance, Φ−1(0.9) = 1.2816, where Φ is the distribution function of N (0, 1). Table of standard normal distribution 0.00 0.01 0.02 0.03 0.04 0.05 0.06 0.07 0.08 0.09 0.0 0.5000 0.5040 0.5080 0.5120 0.5160 0.5199 0.5239 0.5279 0.5319 0.5359 0.1 0.5398 0.5438 0.5478 0.5517 0.5557 0.5596 0.5636 0.5675 0.5714 0.5753 0.2 0.5793 0.5832 0.5871 0.5910 0.5948 0.5987 0.6026 0.6064 0.6103 0.6141 0.3 0.6179 0.6217 0.6255 0.6293 0.6331 0.6368 0.6406 0.6443 0.6480 0.6517 0.4 0.6554 0.6591 0.6628 0.6664 0.6700 0.6736 0.6772 0.6808 0.6844 0.6879 0.5 0.6915 0.6950 0.6985 0.7019 0.7054 0.7088 0.7123 0.7157 0.7190 0.7224 0.6 0.7257 0.7291 0.7324 0.7357 0.7389 0.7422 0.7454 0.7486 0.7517 0.7549 0.7 0.7580 0.7611 0.7642 0.7673 0.7704 0.7734 0.7764 0.7794 0.7823 0.7852 0.8 0.7881 0.7910 0.7939 0.7967 0.7995 0.8023 0.8051 0.8078 0.8106 0.8133 0.9 0.8159 0.8186 0.8212 0.8238 0.8264 0.8289 0.8315 0.8340 0.8365 0.8389 1.0 0.8413 0.8438 0.8461 0.8485 0.8508 0.8531 0.8554 0.8577 0.8599 0.8621 1.1 0.8643 0.8665 0.8686 0.8708 0.8729 0.8749 0.8770 0.8790 0.8810 0.8830 1.2 0.8849 0.8869 0.8888 0.8907 0.8925 0.8944 0.8962 0.8980 0.8997 0.9015 1.3 0.9032 0.9049 0.9066 0.9082 0.9099 0.9115 0.9131 0.9147 0.9162 0.9177 1.4 0.9192 0.9207 0.9222 0.9236 0.9251 0.9265 0.9279 0.9292 0.9306 0.9319 1.5 0.9332 0.9345 0.9357 0.9370 0.9382 0.9394 0.9406 0.9418 0.9429 0.9441 1.6 0.9452 0.9463 0.9474 0.9484 0.9495 0.9505 0.9515 0.9525 0.9535 0.9545 1.7 0.9554 0.9564 0.9573 0.9582 0.9591 0.9599 0.9608 0.9616 0.9625 0.9633 1.8 0.9641 0.9649 0.9656 0.9664 0.9671 0.9678 0.9686 0.9693 0.9699 0.9706 1.9 0.9713 0.9719 0.9726 0.9732 0.9738 0.9744 0.9750 0.9756 0.9761 0.9767 2.0 0.9772 0.9778 0.9783 0.9788 0.9793 0.9798 0.9803 0.9808 0.9812 0.9817 2.1 0.9821 0.9826 0.9830 0.9834 0.9838 0.9842 0.9846 0.9850 0.9854 0.9857 2.2 0.9861 0.9864 0.9868 0.9871 0.9875 0.9878 0.9881 0.9884 0.9887 0.9890 2.3 0.9893 0.9896 0.9898 0.9901 0.9904 0.9906 0.9909 0.9911 0.9913 0.9916 2.4 0.9918 0.9920 0.9922 0.9925 0.9927 0.9929 0.9931 0.9932 0.9934 0.9936 2.5 0.9938 0.9940 0.9941 0.9943 0.9945 0.9946 0.9948 0.9949 0.9951 0.9952 2.6 0.9953 0.9955 0.9956 0.9957 0.9959 0.9960 0.9961 0.9962 0.9963 0.9964 2.7 0.9965 0.9966 0.9967 0.9968 0.9969 0.9970 0.9971 0.9972 0.9973 0.9974 2.8 0.9974 0.9975 0.9976 0.9977 0.9977 0.9978 0.9979 0.9979 0.9980 0.9981 2.9 0.9981 0.9982 0.9982 0.9983 0.9984 0.9984 0.9985 0.9985 0.9986 0.9986 3.0 0.9987 0.9987 0.9987 0.9988 0.9988 0.9989 0.9989 0.9989 0.9990 0.9990 For instance, P[Z ≤ 1.96] = 0.975. 9","libVersion":"0.5.0","langs":""}
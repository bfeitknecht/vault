{"path":"sem3/A&D/VRL/script/A&D-script-w06-dp.pdf","text":"Skript zur Vorlesung Algorithmen und Datenstrukturen Dynamische Programmierung Herbstsemester 2024 Stand: 29. November 2024 Johannes Lengler David Steurer Inhaltsverzeichnis 1 Einleitung 1 1.1 Memoization und Bottom-up-Programmierung . . . . . . . . . . . . 1 1.1.1 Naiver rekursiver Algorithmus . . . . . . . . . . . . . . . . . 1 1.1.2 Memoization . . . . . . . . . . . . . . . . . . . . . . . . . . . 2 1.1.3 Bottom-up Berechnung . . . . . . . . . . . . . . . . . . . . . 3 1.1.4 Vergleich der Ans¨atze . . . . . . . . . . . . . . . . . . . . . . 4 1.2 Kernidee von DP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5 1.2.1 Beispiel: Maximum Subarray Sum . . . . . . . . . . . . . . . 6 2 Beispiele 9 2.1 Jump Game . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9 2.1.1 Erster Ansatz . . . . . . . . . . . . . . . . . . . . . . . . . . . 10 2.1.2 Zweiter Ansatz . . . . . . . . . . . . . . . . . . . . . . . . . . 11 2.1.3 Untere Schranke . . . . . . . . . . . . . . . . . . . . . . . . . 12 2.2 L¨angste gemeinsame Teilfolge . . . . . . . . . . . . . . . . . . . . . . 13 2.2.1 Versuch 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13 2.2.2 Versuch 2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14 2.3 Editierdistanz . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17 2.4 Das Teilsummenproblem . . . . . . . . . . . . . . . . . . . . . . . . . 23 2.5 Das Rucksackproblem . . . . . . . . . . . . . . . . . . . . . . . . . . 26 2.6 Geht es besser? P vs. NP . . . . . . . . . . . . . . . . . . . . . . . . 30 2.7 Approximationsalgorithmus f¨ur das Rucksackproblem . . . . . . . . 32 2.8 L¨angste aufsteigende Teilfolge . . . . . . . . . . . . . . . . . . . . . . 35 2.9 Matrixkettenmultiplikation . . . . . . . . . . . . . . . . . . . . . . . 40 i ii Kapitel 1 Einleitung Dynamische Programmierung (DP) ist eine m¨achtige Technik zur L¨osung von al- gorithmischen Problemen, insbesondere solcher, die sich rekursiv l¨osen lassen. DP ist eng verwandt mit dem Prinzip der mathematischen Induktion und der Idee der Invarianten, die wir bereits in der Vorlesung kennengelernt haben. Im Kontext von Sortieralgorithmen haben wir Invarianten genutzt, um den kor- rekten Ablauf und die Korrektheit der Algorithmen zu beweisen. Beispielsweise ha- ben wir bei Insertion-Sort die Invariante verwendet, dass die ersten j Elemente des Arrays nach j Durchl¨aufen der ¨ausseren Schleife sortiert sind. Diese Invariante hat uns geholfen zu verstehen, wie der Algorithmus funktioniert und warum er korrekt ist. Bei der dynamischen Programmierung nutzen wir eine ¨ahnliche Idee. Allerdings verwenden wir Invarianten nicht, um den Ablauf eines Algorithmus zu beschreiben, sondern um die L¨osung eines Problems zu berechnen. Genauer gesagt definieren wir eine Menge von Teilproblemen, deren L¨osungen wir iterativ oder rekursiv auseinan- der berechnen, und die schliesslich zur L¨osung des Gesamtproblems f¨uhren. Bevor wir uns Beispielen der Dynamischen Programmierung zuwenden, wollen wir erst noch gewisse Fallstricke von rekursiven Programmen an einem einfachen Beispiel diskutieren. 1.1 Memoization und Bottom-up-Programmierung Ein klassisches Beispiel f¨ur ein rekursives Problem sind die Fibonacci-Zahlen. Die Fibonacci-Zahlen sind rekursiv definiert durch F1 = 1, F2 = 1, Fn = Fn−1 + Fn−2 f¨ur n ≥ 3. Also sind die ersten Fibonacci-Zahlen: 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, . . . 1.1.1 Naiver rekursiver Algorithmus Ein naiver Ansatz zur Berechnung der Fibonacci-Zahlen besteht darin, die rekursive Definition direkt in ein rekursives Programm umzusetzen: Fibonacci(n) Fibonacci- Zahlen (naiv) 1 2 Einleitung 1 if n ≤ 2 then return 1 2 else return Fibonacci(n − 1) + Fibonacci(n − 2) Dieser Algorithmus ist zwar korrekt, aber sehr ineffizient. Um zu verstehen, warum, betrachten wir die Berechnung von Fibonacci(5): Fib(6) Fib(5) Fib(4) Fib(3) Fib(2) 1 Fib(1) 1 Fib(2) 1 Fib(3) Fib(2) 1 Fib(1) 1 Fib(4) Fib(3) Fib(2) 1 Fib(1) 1 Fib(2) 1 Wir sehen, dass der Algorithmus die Werte Fibonacci(3) und Fibonacci(4) mehrmals berechnet. Die naive rekursive Implementierung f¨uhrt hier zu einer exponentiellen Laufzeit!1 1.1.2 Memoization Eine M¨oglichkeit, die exponentielle Laufzeit der naiven Implementierung zu vermei- den, ist die Verwendung von Memoization.2 Die Idee dabei ist, die bereits berechne- ten Werte in einer Tabelle zu speichern und bei Bedarf wiederzuverwenden. Im Fall der Fibonacci-Zahlen k¨onnen wir ein Array memo[1..n] verwenden, um die Werte Fibonacci(1), . . . , Fibonacci(n) zu speichern. Zu Beginn initialisieren wir alle Werte in memo mit einem Platzhalterwert, z.B. −1. Wenn wir nun Fibonacci(i) berechnen wollen, schauen wir zuerst in memo[i] nach. Falls der Wert dort bereits be- rechnet wurde, also nicht −1 ist, geben wir ihn direkt zur¨uck. Andernfalls berechnen wir ihn rekursiv. Fibonacci(n)Fibonacci- Zahlen (mit Memoization) 1 memo[1..n] ← new array filled with -1 2 return FibM(n) 1Tats¨achlich ist die Zahl der rekursiven Aufrufe wieder durch die Fibonacci-Zahlen beschrieben. Bezeichnen wir mit R(n) die Zahl der rekursiven Aufrufe, die der naive Fibonacci-Algorithmus f¨ur den Input n durchf¨uhrt. Dann gilt R(1) = 0, R(2) = 2 und R(n) = 2 + R(n − 1) + R(n − 2) f¨ur n ≥ 3. Man kann mit Induktion zeigen, dass dann R(n) = 2 · Fn+1 − 2 gilt. Wir haben fr¨uher schon benutzt, dass Fn = Θ(ϕn) f¨ur ϕ = (1 + √ 5)/2 ist, und daraus folgt auch R(n) = Θ(ϕn). 2Der Begriff leitet sich vom englischen Begriff “memo” ab, der eine kleine Notiz zur Erinnerungs- hilfe bezeichnet. Er wird deshalb ohne r geschrieben. 1.1 Memoization und Bottom-up-Programmierung 3 FibM(n) Rekursion mit Memoization 1 if memo[n] ≥ 0 then return memo[n] 2 if n ≤ 2 then f ← 1 3 else f ← FibM(n − 1) + FibM(n − 2) 4 memo[n] ← f 5 return f Mit Memoization wird die Laufzeit von Fibonacci auf O(n) reduziert, da jedes Teilproblem nur noch einmal berechnet wird. Viele Programmiersprachen haben eine eigene Syntax, mit der sie Memoization unterst¨utzen.3 FibM(6) FibM(5) FibM(4) FibM(3) FibM(2) 1 FibM(1) 1 FibM(2) memo[2] FibM(3) memo[3] FibM(4) memo[4] 1.1.3 Bottom-up Berechnung Anstatt die Fibonacci-Zahlen rekursiv mit Memoization zu berechnen, k¨onnen wir sie auch Bottom-up berechnen. Dazu berechnen wir die Werte F1, F2, . . . , Fn iterativ, beginnend mit F1 und F2. Fibonacci(n) Fibonacci- Zahlen (Bottom-up)1 F [1..n] ← new array 2 F [1] ← 1 3 F [2] ← 1 4 for i ← 3, . . . , n do 3Zum Beispiel ConcurrentHashMap.computeIfAbsent in Java 8. 4 Einleitung 5 F [i] ← F [i − 1] + F [i − 2] 6 return F [n] Die Laufzeit dieses Algorithmus ist O(n). Im Vergleich mit dem rekursiven Algorith- mus mit Memoization ben¨otigt dieser Algorithmus scheinbar mehr Speicherplatz. Allerdings belegen auch die rekursiven Aufrufe der rekursiven Berechnung Speicher. Der Speicherplatz l¨asst sich hier ausserdem von Θ(n) auf Θ(1) verringern, indem man jeweils nur die letzten beiden Werte speichert. 1.1.4 Vergleich der Ans¨atze Welcher der beiden Ans¨atze – Memoization oder Bottom-up – ist besser? Es gibt keine eindeutige Antwort auf diese Frage. Beide Ans¨atze haben Vor- und Nachteile: Vorteile von Rekursion mit Memoization • Einfacher zu implementieren: Die Memoization l¨asst sich oft durch eine einfa- che Modifikation des naiven rekursiven Algorithmus implementieren. • Lesbarer : Teilweise sind Rekursionen einfacher zu verstehen als iterative Kon- struktionen. • Nur ben¨otigte Werte werden berechnet: Bei der Rekursion werden nur die Werte berechnet, die tats¨achlich ben¨otigt werden. Dies kann vorteilhaft sein, wenn nicht alle Werte der Tabelle ben¨otigt werden. • Keine explizite Bestimmung der Reihenfolge n¨otig: F¨ur einen rekursiven An- satz muss man sich nicht explizit ¨uberlegen, welche Werte man vor welchen anderen berechnen muss. Vorteile von Bottom-up • Effizienter : Der Bottom-up-Ansatz ist in der Regel etwas effizienter als die Memoization, da er den Overhead der Rekursionsaufrufe vermeidet. • Speicherplatz kann optimiert werden: Bei vielen Problemen l¨asst sich der Spei- cherplatzbedarf des Bottom-up-Ansatzes reduzieren, indem man alte Werte ¨uberschreibt, sobald sie f¨ur die Berechnung der n¨achsten Werte nicht mehr ben¨otigt werden. • Vermeidung von Stack Limits: Bei rekursiven Aufrufen muss der Computer sich merken, an welcher Stelle der Rekursion er ist. Das kann man gut am Rekursionsbaum sehen: Wenn der Algorithmus an einer bestimmten Stelle im Rekursionsbaum ist, muss er sich zumindest alle Vorfahren dieses Knotens merken, um sp¨ater zu diesen zur¨uckzukehren. Tats¨achlich gen¨ugt es auch, sich diese Vorfahren zu merken.4 Bei den Fibonacci-Zahlen ist die H¨ohe des Re- kursionsbaum Θ(n), man braucht also entsprechend viel Zusatzspeicher. F¨ur Rekursionen ist ein spezieller Speicher im Computer reserviert, der meistens 4Der Computer speichert diese Knoten in einer stack -Datenstruktur, dem call stack oder execu- tion stack. Er f¨uhrt die Rekursion dann entsprechend einer Tiefensuche im Rekursionsbaum aus, ein Algorithmus, den wir im weiteren Verlauf der Vorlesung noch kennenlernen werden. 1.2 Kernidee von DP 5 nicht besonders gross ist.5 Ist dieser Speicher aufgebraucht, erh¨alt man den ber¨uhmten Fehler “stack overflow”.6 • Explizite Bestimmung der Reihenfolge n¨otig: Ein Bottom-up-Ansatz zwingt uns, die Berechnungsreihenfolge der Werte explizit zu ¨uberlegen. Das ist zwar Zusatzarbeit, die aber oft gut investiert ist, weil sie Endlosschleifen verhindert und generell sicherstellt, dass wir das Programm verstehen. Insgesamt ¨ubernimmt ein Bottom-up-Ansatz mehr Details explizit selber und im Vorhinein (bei Programmierung bzw. Kompilierung), statt sie dem Computer w¨ahrend der Ausf¨uhrung des Programms zu ¨uberlassen. Dazu geh¨ort vor allem die Implementierungsreihenfolge. Das f¨uhrt oft dazu, dass ein rekursives Programm et- was einfacher zu schreiben und zu lesen ist, aber verschwenderischer mit Ressourcen wie Speicherplatz umgeht. Wegen letzterem wird in der Praxis oft der Bottom-up- Ansatz bevorzugt, insbesondere wenn der Code Teil eines dauerhaften oder gr¨osseren Softwareprojekts sein soll. 1.2 Kernidee von DP Die Kernidee der dynamischen Programmierung besteht darin, ein geeignetes Teil- problem zu finden, das iterativ oder rekursiv gel¨ost werden kann.7 Anschliessend wird die L¨osung des Gesamtproblems aus den verschiedenen L¨osungen des Teilpro- blems zusammengesetzt. Die wichtigsten Schritte zur Anwendung der dynamischen Programmierung sind: 1. Definiere ein geeignetes Teilproblem. Das Teilproblem hat in der Regel einen oder mehrere Parameter und muss verschiedene Anforderungen erf¨ullen: Es muss m¨oglichst effizient rekursiv oder iterativ l¨osbar sein, und die L¨osung des Gesamtproblems muss sich aus den L¨osungen der Teilprobleme zusammenset- zen lassen. 2. Stelle eine Rekursionsgleichung auf, die die L¨osung eines Teilproblems durch die L¨osungen anderer Teilprobleme ausdr¨uckt. Dazu geh¨ort auch, die Basisf¨alle des Problems zu l¨osen. 3. Berechne die L¨osungen der Teilprobleme bottom-up oder mittels Memoization. Dazu geh¨ort auch die ¨Uberlegung, in welcher Reihenfolge die Teilprobleme gel¨ost werden k¨onnen. 4. Setze die L¨osungen der Teilprobleme zur L¨osung des Gesamtproblems zusam- men. 5. Analysiere Korrektheit und Laufzeit des Algorithmus. Die Korrektheit des Al- gorithmus ergibt sich in der Regel direkt aus der Korrektheit der Schritte 2 und 4. Es bietet sich deshalb oft an, die Korrektheit dieser beiden Schritte 5Zum Beispiel per default 1MB pro thread f¨ur eine Java Virtual Machine. Praktisch entspricht das einer maximalen Rekursionstiefe von rund 1000 − 10.000, je nachdem wie komplex die Daten sind, die pro Aufruf gespeichert werden m¨ussen. 6Ber¨uhmt unter anderem als Namensgeber f¨ur die bekannte Ratgeberseite zum Thema Program- mierung. 7Wenn sich die Teilprobleme nicht ¨uberlappen, spricht man in der Regel von “teile und herrsche” (“divide and conquer”) statt von dynamischer Programmierung. Die Prinzipien sind aber identisch. 6 Einleitung direkt w¨ahrend dieser Schritte zu zeigen. Schliesslich geh¨ort zur Analyse auch die Bestimmung der Laufzeit. 1.2.1 Beispiel: Maximum Subarray Sum Zun¨achst erl¨autern wir diese Schritte der dynamischen Programmierung an einem Beispiel, mit dem wir schon vertraut sind: Maximum Subarray Sum. Zur Erinnerung wiederholen wir hier die Definition. Definition 1.1 (Maximum Subarray Sum). Gegeben sei ein Array A[1..n] mit n ganzen Zahlen, die auch negativ sein d¨urfen. Gesucht ist ein Teilarray A[i..j] mit 1 ≤ i ≤ j ≤ n, so dass die Summe Si,j := ∑j k=i A[k] maximal ist, wobei das leere Teilarray mit S = 0 ebenfalls zugelassen ist. Beispiel. F¨ur das Array A = (2, −4, 3, 1, −2, 4, 2) ist das Teilarray (3, 1, −2, 4, 2) die optimale L¨osung. Die Summe dieses Teilarrays ist 3 + 1 + (−2) + 4 + 2 = 8. Schritt 1: Teilproblem Der zentrale Schritt ist das Finden eines geeigneten Teilproblems. Zur L¨osung des Problems Maximum Subarray Sum hatten wir im ersten Teil der Vorlesung das Rand- maximum als Teilproblem verwendet. Dieses ist f¨ur 1 ≤ j ≤ n wie folgt definiert: Rj := max 1≤i≤j j∑ k=i A[k]. Das Randmaximum Rj ist also die maximale Summe eines Teilarrays von A, das am Index j endet. Schritt 2: Rekursion Um Rj zu berechnen, beobachten wir, dass es zwei M¨oglichkeiten gibt: Entweder das optimale Teilarray, dessen Summe Rj ist, enth¨alt nur das Element A[j], oder aber es enth¨alt auch noch andere Elemente. Im zweiten Fall muss dieses Teilarray die Verl¨angerung eines Teilarrays sein, das am Index j − 1 endet und dessen Summe maximal ist, also Rj−1. Wir erhalten daher die folgende Rekursionsgleichung: Rj = max{A[j], Rj−1 + A[j]}. Als Basisfall der Rekursion erhalten wir R1 = A[1]. Schritt 3: Bottom-up-Berechnung Mit Hilfe der Rekursionsgleichung k¨onnen wir die Werte R1, . . . , Rn in dieser Rei- henfolge in Zeit O(n) berechnen: Randmaxima(A[1..n])Randmaxima 1 R[1..n] ← new array 2 R[1] ← A[1] 3 for j ← 2, 3, . . . , n do 4 R[j] ← max{A[j], R[j − 1] + A[j]} Am Ende enth¨alt das Array R alle Werte R1, . . . , Rn. 1.2 Kernidee von DP 7 Schritt 4: Ablesen der L¨osung Ein maximales Subarray ist entweder leer (S = 0) oder es endet an einem j ∈ {1, .., n}. Die L¨osung des Gesamtproblems l¨asst sich deshalb durch S∗ := max { max 1≤j≤n Rj, 0} berechnen. Schritt 5: Analyse Die Korrektheit des Algorithmus folgt direkt aus der Korrektheit der Schritte 2 und 4, welche wir dort schon jeweils begr¨undet haben. Bei der Berechnung der Randmaxima ben¨otigt die Auswertung der Rekursion in Zeile 4 jeweils Zeit Θ(1). Die Gesamtlaufzeit der bottom-up-Berechnung ist daher Θ(n). Das Ablesen der L¨osung ist ebenfalls in Zeit O(n) m¨oglich, weshalb die Gesamtlaufzeit Θ(n) ist. 8 Einleitung Kapitel 2 Beispiele W¨ahrend die Schritte 2-5 f¨ur trainierte Informatiker meistens kein Problem sind1, ist das Finden eines geeigneten Teilproblems eine Kunst, f¨ur die es keine allgemeinen Regeln gibt. Die beste Lernmethode ist hier, sich viele Beispiele anzuschauen. Wir werden deshalb in diesem Kapitel eine grosse Zahl an Beispielen durchgehen. 2.1 Jump Game Definition 2.1 (Jump Game). Gegeben sei ein Array A[1..n] mit n positiven ganzen Zahlen. Wir starten an Position 1 im Array. Von Position i d¨urfen wir auf eine beliebige Position zwischen i + 1 und i + A[i] springen. Gesucht ist die minimale Anzahl von Spr¨ungen, mit denen man die Position n erreichen kann. Beispiel. Betrachten wir das Array A = (1, 3, 5, 3, 2, 1, 2, 4, 4, 2, 9). Eine m¨ogliche L¨osung des Jump Games ist: 1 → 2 → 5 → 7 → 9 → 11. 1 3 5 3 2 1 2 4 4 2 9 Eine andere m¨ogliche L¨osung ist: 1 → 2 → 3 → 8 → 11. 1 3 5 3 2 1 2 4 4 2 9 Da alle Eintr¨age positive ganze Zahlen sind, ist es immer m¨oglich, von i nach i + 1 zu springen. Daher ist es immer m¨oglich, n mit maximal n − 1 Spr¨ungen zu erreichen. Die Antwort muss also immer zwischen 1 und n − 1 liegen (f¨ur n ≥ 2). 1Ausnahmen best¨atigen die Regel. Zum Beispiel ist die Rekursion nicht immer offensichtlich. 9 10 Beispiele 2.1.1 Erster Ansatz Um das Problem Jump Game mit dynamischer Programmierung zu l¨osen, m¨ussen wir ein geeignetes Teilproblem definieren. Ein nat¨urlicher Kandidat daf¨ur ist das folgende. F¨ur 1 ≤ i ≤ n suchen wir S[i] := minimale Anzahl Spr¨unge, um i zu erreichen. Die L¨osung des Gesamtproblems ist dann einfach S[n]. Rekursion F¨ur i = 1 gilt offenbar S[1] = 0. Um S[i] f¨ur i > 1 rekursiv zu berechnen, gehen wir alle potentiellen Vorg¨anger j von i durch und pr¨ufen, ob wir i von j aus direkt erreichen k¨onnen. Das ist genau dann der Fall, wenn j +A[j] ≥ i ist. Wenn wir dieses j benutzen, ben¨otigen wir S[j] + 1 viele Spr¨unge, n¨amlich S[j] viele Spr¨unge nach j sowie einen weiteren von j nach i. Umgekehrt muss jeder Weg nach i im vorletzten Schritt an irgendeiner solchen Position j sein. Wir erhalten daher die Rekursion S[i] = min{S[j] + 1 | 1 ≤ j < i und j + A[j] ≥ i} f¨ur i > 1. A[1] · · · A[j − 1] A[j] A[j + 1] · · · A[i − 1] A[i] A[i + 1] · · · A[n] S[j] Spr¨unge 1 Sprung, falls j + A[j] ≥ i 1 ≤ j < i Bottom-up-Berechnung Mit Hilfe der Rekursionsgleichung k¨onnen wir die Werte S[1], . . . , S[n] bottom-up berechnen: Jump-Game(A[1..n])Jump Game 1 S[1] ← 0 2 for i ← 2, 3, . . . , n do 3 S[i] ← ∞ 4 for j ← 1, 2, . . . , i − 1 do ▷ Bestimme Minimum 5 if j + A[j] ≥ i then S[i] ← min{S[i], S[j] + 1} 6 return S[n] Die Laufzeit dieses Algorithmus ist Θ( ∑n i=2(i − 1)) = Θ(n2). 2.1 Jump Game 11 2.1.2 Zweiter Ansatz Im ersten Ansatz haben wir f¨ur jedes i berechnet, mit wie vielen Spr¨ungen wir Position i erreichen k¨onnen. Nennen wir die Zahl der Spr¨unge k. Wir haben also f¨ur jeden Wert von i den zugeh¨origen Wert von k berechnet. F¨ur einen alternativen Ansatz drehen wir die Rollen von i und k um. Wir fra- gen also jetzt f¨ur ein gegebenes k, welche Werte i zu diesem k geh¨oren. Vereinfacht ausgedr¨uckt ist das die Frage, welches der maximale Index i ist, den wir mit k Spr¨ungen erreichen k¨onnen. Allgemein kann man von einer DP-L¨osung oft auf alter- native L¨osungen kommen, indem man die Rolle der beteiligten Variablen vertauscht. Wir definieren also f¨ur alle k ≥ 0. M [k] := maximaler Index, den wir mit k Spr¨ungen erreichen k¨onnen. Die L¨osung des Gesamtproblems ist dann der kleinste Wert k, f¨ur den M [k] ≥ n gilt. Rekursion Es gilt offenbar M [0] = 1. Um M [k] f¨ur k ≥ 1 rekursiv zu berechnen, betrachten wir alle Positionen i, die wir in h¨ochstens k − 1 Spr¨ungen erreichen k¨onnen. Das sind die Positionen, die i ≤ M [k − 1] erf¨ullen. Von diesen Positionen aus k¨onnen wir dann in einem weiteren Sprung alle Positionen bis i + A[i] erreichen. Der maximale Index, den wir mit k Spr¨ungen erreichen k¨onnen, ist also das Maximum ¨uber alle i + A[i], f¨ur die i ≤ M [k − 1] gilt. Das f¨uhrt zu der folgenden Rekursionsgleichung: M [k] = max{i + A[i] | 1 ≤ i ≤ M [k − 1]}. Bottom-up-Berechnung Mit Hilfe der Rekursionsgleichung k¨onnen wir die Werte M [0], M [1], . . . Bottom-up berechnen. Da wir lediglich berechnen m¨ussen, bis wir ein k mit M [k] ≥ n finden, k¨onnen wir die Iteration abbrechen, sobald diese Bedingung erf¨ullt ist. Jump-Game(A[1..n]) Jump Game 1 k ← 0; M [0] ← 1 ▷ Initialisierung 2 while M [k] < n do 3 k ← k + 1 4 M [k] ← max{i + A[i] | 1 ≤ i ≤ M [k − 1]} 5 return k Laufzeit Wir wissen, dass k bis maximal n − 1 laufen kann. Ausserdem erh¨oht sich M [k] mit wachsendem k jedes Mal um mindestens 1. Daher m¨ussen wir die while-Schleife h¨ochstens n − 1-mal ausf¨uhren, und jeder Durchlauf kostet Zeit O(n). Also ist die Laufzeit O(n2). 12 Beispiele Aber ist diese Schranke scharf, oder war unsere Analyse ungenau? Um das zu beantworten, m¨ussen wir einen Input finden, f¨ur den der Algorithmus Zeit Ω(n2) braucht.2 Und tats¨achlich ist das aus Einsen bestehende Array A = (1, 1, . . . , 1, 1, 1) ein solcher Input. F¨ur dieses Array ist M [k] = k + 1 f¨ur alle k ≤ n − 1, und daher ist die Laufzeit Θ( ∑n−1 k=1(k − 1)) = Θ(n2). Die Laufzeit ist also im Worst-Case Θ(n2). Verbesserung der Rekursion Betrachten wir das Maximum genauer: Um M [k] zu berechnen, betrachten wir alle i, die mit h¨ochstens k − 1 Spr¨ungen erreicht werden k¨onnen. Es gen¨ugt aber, alle i zu betrachten, die mit genau k − 1 erreicht werden k¨onnen. Das genau diejenigen i, die die Bedingung M [k − 2] < i ≤ M [k − 1] erf¨ullen, denn i ≤ M [k − 2] k¨onnen wir ja schon mit h¨ochstens k − 2 Spr¨ungen erreichen. Die Rekursion l¨asst sich also verbessern zu M [k] = max{i + A[i] | M [k − 2] < i ≤ M [k − 1]} f¨ur k ≥ 2, wobei wir dann einen weiteren Startwert M [1] = A[0] initalisieren m¨ussen. Wenn wir diese Rekursion in Zeile 4 des Algorithmus verwenden, wie ver¨andert sich dann die Laufzeit? Dazu beobachten wir, dass jedes i nur zu einem einzigen Maximum beitr¨agt. Deshalb ist die Gesamtlaufzeit O(n).3 Da die Gesamtzahl der betrachteten Indizes i h¨ochstens n ist, ben¨otigen wir f¨ur diese verbesserte Rekursion insgesamt h¨ochstens n Schritte, und die Laufzeit des Algorithmus Jump-Game betr¨agt O(n). 2.1.3 Untere Schranke Die Laufzeit von O(n) ist optimal. Um das zu sehen, m¨ussen wir zeigen, dass jeder Algorithmus f¨ur einen worst-case Input Zeit Ω(n) ben¨otigt. Hier k¨onnen wir sogar einen einzigen Input konstruieren, auf dem alle Algorithmen langsam sind. Dieser Input ist wieder das Array A = (1, 1, . . . , 1, 1, 1). Offenbar ist der letzte Eintrag A[n] = 1 unwichtig. Ebenso ist der vorletzte Eintrag A[n − 1] = 1 irrelevant. Aber alle n − 2 anderen Eintr¨age m¨ussen zwingend gelesen werden. Nehmen wir an, der Algorithmus h¨atten von diesen erst n − 3 Werte gelesen, der Algorithmus kennt also im besten Fall A = (1, 1, . . . , 1, ∗, 1, 1, . . . , 1, 1, 1), wobei das ∗ anzeigt, dass diese Stelle noch nicht gelesen wurde. Dann kann der Algorithmus nicht entscheiden, welches der richtige Output ist. Falls an der ungelesenen Stelle eine 1 steht, so ist der richtige Output n−1. Falls an der ungelesenen Stelle aber eine 2 steht, kann man die folgende Stelle ¨uberspringen4 und die korrekte Antwort ist n − 2. Der Algorithmus kann die richtige Antwort also nicht wissen, ohne auch den Eintrag ∗ zu lesen. Wir haben also gezeigt, dass jeder korrekte Algorithmus im Worst-Case mindestens n − 2 Eintr¨age lesen muss und somit im Worst-Case eine Laufzeit von Ω(n) hat. 2Oder eine bessere Analyse finden. 3Wir k¨onnen denselben Sachverhalt auch mit Formeln auszudr¨ucken, indem wir die Zeit zur Berechnung von M [k] als O(M [k − 1] − M [k − 2]) schreiben. Bezeichnen wir mit kmax den gr¨oss- ten Wert, den k im Algorithmus annimt (also den Output), so ist die Gesamtlaufzeit daher O(∑kmax k=2 (M [k−1]−M [k−2])). Dies ist eine teleskopierende Reihe, die sich zu O(M [kmax−1]−M [0]) vereinfacht. Da kmax der erste Wert mit M [kmax] ≥ n ist, ist M [kmax − 1] < n. Somit ergibt sich auch auf diese Weise eine Laufzeit von O(n). 4Hier benutzen wir, dass die unbekannte Stelle nicht an Position n − 1 ist, weil man die n-te Stelle nicht ¨uberspringen darf. Alle anderen Stellen kann man aber ¨uberspringen. 2.2 L¨angste gemeinsame Teilfolge 13 2.2 L¨angste gemeinsame Teilfolge Im letzten Abschnitt haben wir uns mit dem Jump Game besch¨aftigt. Dieses konn- ten wir durch DP mit Teilproblemen l¨osen, die nur einen Parameter hatten. Wir betrachten nun ein Problem, bei dem wir Teilprobleme mit zwei Parametern ver- wenden m¨ussen. Definition 2.2 (L¨angste gemeinsame Teilfolge (LGT)). Gegeben seien zwei Strings A = (a1, . . . , an) und B = (b1, . . . , bm). Eine Teilfolge von A ist eine Folge (ai1, ai2, . . . , aik ), sodass 1 ≤ i1 < i2 < . . . < ik ≤ n gilt. Eine gemeinsame Teilfolge von A und B ist eine Zeichenfolge, die sowohl Teilfolge von A als auch von B ist. Gesucht ist die L¨ange einer l¨angsten gemeinsamen Teilfolge (LGT) von A und B. Beispiel. F¨ur die Strings A = “TIGER” und B = “ZIEGE” ist “IGE” eine gemein- same Teilfolge der L¨ange 3. Man sieht leicht, dass es auch keine l¨angere gemeinsame Teilfolge gibt. T I G E R Z I E G E Der Unterschied zwischen Teilfolgen und Subarrays ist, dass Subarrays konse- kutiv sein m¨ussen, also keine Eintr¨age ¨uberspringen d¨urfen. Beide m¨ussen aber die Reihenfolge der Originalfolge bzw. des Originalarrays beibehalten. Anwendungen Das Auffinden von l¨angsten gemeinsamen Teilfolgen ist ein funda- mentales Problem der Informatik mit Anwendungen in vielen Bereichen. Ein Beispiel ist der Vergleich einer ¨alteren mit einer neueren Version desselben Textdokuments, der unter anderem von Versionsverwaltungssystemen wie Git angeboten wird.5 Wie an der obigen Graphik zu sehen ist, erlaubt uns die l¨angste gemeinsame Teilfolge effektiv zu erkennen, welche Teile ge¨andert, hinzugef¨ugt oder gel¨oscht wurden. 2.2.1 Versuch 1 Betrachten wir zun¨achst f¨ur 1 ≤ i ≤ min{n, m} das Teilproblem LGT[i] := eine l¨angste gemeinsame Teilfolge von A[1..i] und B[1..i] Wenn wir versuchen, f¨ur dieses Teilproblem eine Rekursion aufzustellen, stossen wir auf ein Problem. F¨ur das Beispiel mit A = “TIGER” und B = “ZIEGE” w¨are eine m¨ogliche L¨osung f¨ur i = 4 die Teilfolge LGT[4] = “IE”. Tats¨achlich gibt es keine l¨angere gemeinsame Teilfolge von “TIGE” und “ZIEG”, daher ist dieser Wert korrekt. Allerdings l¨asst sich diese Teilfolge nicht ohne Weiteres zu der optimalen Teilfolge LGT[5] = “IGE” erg¨anzen, weil die gefundene L¨osung f¨ur LGT[4] nicht zu den m¨oglichen Fortsetzungen passt. 5Ein praktischer Unterschied ist, dass in solchen F¨allen nicht auf Ebene der Buchstaben auf ¨Ubereinstimmung gepr¨uft wird, sondern auf Ebene der Zeilen. F¨ur das algorithmische Problem spielt dieser Unterschied aber keine Rolle. 14 Beispiele T I G E Z I E G i = 4 −→ T I G E R Z I E G E i = 5 Die in LGT[4] gespeicherte Information reicht also nicht, um LGT[5] einfach zu bestimmen. Dazu m¨ussten wir uns schon alle gemeinsamen Teilfolgen “TIGE” und “ZIEG” merken, und das k¨onnen im Allgemeinen sehr viele sein. Tats¨achlich m¨ussen wir aber f¨ur eine Rekursion nicht die gesamte Teilfolge speichern, sondern nur ihre L¨ange und ihre beiden Endpunkte in A bzw. B. Diese f¨uhrt auf den folgenden Ansatz. 2.2.2 Versuch 2 Teilproblem Wir definieren das folgende Teilproblem f¨ur 1 ≤ i ≤ n und 1 ≤ j ≤ m: L[i, j] := L¨ange einer LGT von (a1, . . . , ai) und (b1, . . . , bj). Die L¨ange einer l¨angsten gemeinsamen Teilfolge des Gesamtproblems ist dann einfach L[n, m]. Rekursion Um L[i, j] zu berechnen, unterscheiden wir drei F¨alle: 1. i = 0 oder j = 0: In diesem Fall ist einer der beiden Strings leer, also ist die LGT ebenfalls leer und hat L¨ange 0. Dies ist der Basisfall. 2. i > 0 und j > 0 und ai = bj: In diesem Fall k¨onnen wir ai = bj als letztes Zeichen in der LGT verwenden. Die restliche LGT muss dann eine gemeinsa- me Teilfolge von (a1, . . . , ai−1) und (b1, . . . , bj−1) sein. Diese Wahl des letzten Zeichens ist mindestens so gut wie jede andere Wahl: Wenn wir als letztes Zei- chen der LGT eine andere Kombination ai′ = bj′ f¨ur 1 ≤ i′ ≤ i und 1 ≤ j ≤ j′ w¨ahlen, so m¨ussen wir den Rest der LGT aus (a1, . . . , ai′−1) und (b1, . . . , bj′−1) bilden. Das l¨asst uns im Vergleich zu (a1, . . . , ai−1) und (b1, . . . , bj−1) weniger Optionen, ohne zus¨atzliche Optionen zu schaffen. Wir k¨onnen deshalb davon ausgehen, dass das letzte Zeichen der LGT ai = bj ist. Die L¨ange der LGT ist daher 1 + L[i − 1, j − 1]. 3. i > 0 und j > 0 und ai ̸= bj: In diesem Fall kann das letzte Zeichen der LGT von (a1, . . . , ai) und (b1, . . . , bj) nicht gleichzeitig ai und bj sein. Also ist die LGT entweder eine gemeinsame Teilfolge von (a1, . . . , ai) und (b1, . . . , bj−1), oder eine gemeinsame Teilfolge von (a1, . . . , ai−1) und (b1, . . . , bj). Nat¨urlich w¨ahlen wir jeweils die l¨angste Variante. Also ist die L¨ange der LGT gleich max{L[i, j − 1], L[i − 1, j]}. Diese Fallunterscheidung f¨uhrt zu der folgenden Rekursion: L[i, j] =    0 falls i = 0 oder j = 0 ist, 1 + L[i − 1, j − 1] falls i > 0 und j > 0 und ai = bj ist, max{L[i, j − 1], L[i − 1, j]} falls i > 0 und j > 0 und ai ̸= bj ist. 2.2 L¨angste gemeinsame Teilfolge 15 Bottom-up-Berechnung Mit Hilfe der Rekursionsgleichung k¨onnen wir die Werte L[i, j] Bottom-up berech- nen, indem wir die Tabelle zeilenweise von links nach rechts (oder spaltenweise von oben nach unten) ausf¨ullen. Longest-Common-Subsequence(A[1..n], B[1..m]) L¨angste gemeinsame Teilfolge1 L[0..n, 0..m] ← new table 2 for i ← 0, 1, . . . , n do L[i, 0] ← 0 3 for j ← 0, 1, . . . , m do L[0, j] ← 0 4 for i ← 1, 2, . . . , n do 5 for j ← 1, 2, . . . , m do 6 if ai = bj then L[i, j] ← 1 + L[i − 1, j − 1] 7 else L[i, j] ← max{L[i, j − 1], L[i − 1, j]} 8 return L[n, m] Analyse Die Korrektheit folgt aus der Korrektheit der Rekursion, die wir schon diskutiert haben. Die Zeilen 6 und 7 des Algorithmus brauchen Zeit Θ(1), also ist die Laufzeit des Algorithmus proportional zur Gr¨osse der Tabelle, also Θ(n · m). Beispiel Wir berechnen die L¨ange der l¨angsten gemeinsamen Teilfolge (LGT) der W¨orter “TI- GER” und “ZIEGE”, indem wir die Tabelle L[i, j] wie oben beschrieben ausf¨ullen. Die Buchstaben der beiden W¨orter schreiben wir dabei an den oberen bzw. linken Rand der Tabelle, um die Indizes zu verdeutlichen (vgl. Abbildung 2.1). Der Eintrag L[5, 5] gibt die L¨ange der LGT der beiden W¨orter “TIGER” und “ZIEGE” an. Die Tabelle zeigt, dass die L¨ange 3 betr¨agt. Die Pfeile zeigen bei- spielhaft f¨ur L[2, 2] und L[4, 4] an, aus welchen Werten man diese Eintr¨age rekursiv berechnet. Finden einer LGT Wir haben erfolgreich das Problem gel¨ost, die L¨ange einer LGT zu bestimmen. Aber wie gehen wir vor, falls wir auch die LGT selbst finden wollen? Das k¨onnen wir durch R¨uckverfolgen (backtracing) der L¨osung. Wir starten in der DP-Tabelle beim Wert L[n, m] und fragen uns, wie dieser Wert zustande kam. • Wenn wir bei der Rekursion im Fall am = bn waren und daher L[n, m] = 1 + L[n − 1, m − 1] ist, so wissen wir, dass eine LGT damit enden kann, und brauchen nur noch nachzuvollziehen, wie der Wert L[n − 1, m − 1] zustande kam. • Wenn wir bei der Rekursion im Fall am ̸= bn waren und daher L[n, m] = max{L[n, m − 1], L[n − 1, m]} ist, so muss L[n, m] = L[n, m − 1] oder L[n, m] = L[n − 1, m] gelten, oder beides. Im ersten Fall reicht es, zur¨uckzuverfolgen, wie der Wert L[n, m − 1] zustande kam. Im zweiten Fall verfolgen wir L[n − 1, m] 16 Beispiele Z I E G E b1 b2 b3 b4 b5 0 0 0 0 0 0 T a1 0 0 0 0 0 0 I a2 0 0 1 1 1 1 G a3 0 0 1 1 2 2 E a4 0 0 1 2 2 3 R a5 0 0 1 2 2 3 Abb. 2.1 Berechnung der L¨ange der l¨angsten gemeinsamen Teilfolge der W¨orter “TI- GER” und “ZIEGE” mittels Bottom-up-Ansatz. Die Tabelle enth¨alt die L¨angen der LGT aller Pr¨afixe der beiden Strings. Der Eintrag L[i, j] gibt die L¨ange der LGT von A[1..i] und B[1..j] an. Die L¨ange der LGT der beiden W¨orter entspricht dem Eintrag L[5, 5] = 3. Der Wert L[i, j] wird aus L[i, j − 1] und L[j − 1, i] berechnet falls A[i] ̸= B[j] ist (z.B. L[4, 4]), und aus L[i − 1, j − 1] falls A[i] = B[j] ist (z.B. L[2, 2]). 2.3 Editierdistanz 17 zur¨uck. Falls beide gleich sind, reicht es, eine der beiden Optionen zur¨uckzu- verfolgen, denn beide Optionen liefern ja eine hinreichend lange LGT. Diese beiden Schritte wiederholen wir, bis wir auf die Basisf¨alle i = 0 oder j = 0 stossen. Z I E G E b1 b2 b3 b4 b5 0 0 0 0 0 0 T a1 0 0 0 0 0 0 I a2 0 0 1 1 1 1 G a3 0 0 1 1 2 2 E a4 0 0 1 2 2 3 R a5 0 0 1 2 2 3 Schnellere Algorithmen Kann man die Laufzeit Θ(n · m) verbessern? Wenn eine Folge sehr viel k¨urzer ist als die andere, dann ist dies m¨oglich. Man kann Laufzeit O(n2 + m) bzw. O(n + m2) zu erreichen.6 F¨ur den Fall m = n hat unser Algorithmus Laufzeit O(n2). Tats¨achlich ist es m¨oglich, wenn auch kompliziert, die Laufzeit ein wenig auf O(n2/ log n) zu verbes- sern. Ob substanziellere Verbesserungen m¨oglich sind, insbesondere ob man einen Algorithmus in Zeit O(n2−ε) f¨ur irgendein ε > 0 finden kann, war jahrzehntelang offen. Erst 2015 wurde diese Frage mit Nein beantwortet.7 2.3 Editierdistanz Wir betrachten nun ein weiteres Beispiel f¨ur die Anwendung der dynamischen Pro- grammierung, die Berechnung der Editierdistanz.8 W¨ahrend hier das Teilproblem einfach zu finden ist (nachdem wir das Beispiel LGT schon kennen), wird es hier aufwendiger sein, sich von der Korrektheit der Rekursion zu ¨uberzeugen. Definition 2.3 (Editierdistanz). Die Editierdistanz ED(A, B) zweier Zeichenfolgen (Strings) A und B ist die minimale Anzahl von Editieroperationen, die notwendig sind, um A in B zu ¨uberf¨uhren. Dabei sind die folgenden Editieroperationen erlaubt: • Einf¨ugen: Ein Zeichen an einer beliebigen Position in den String einf¨ugen. • L¨oschen: Ein Zeichen an einer beliebigen Position aus dem String l¨oschen. • Ersetzen: Ein Zeichen an einer beliebigen Position durch ein anderes Zeichen ersetzen. 6Unter der Annahme, dass das Alphabet fix und von konstanter Gr¨osse ist 7Der negative Beweis fusst auf gewissen Annahmen, ¨uber die die Leser in der Vorlesung “Theo- retische Informatik” mehr lernen werden. Wir werden sp¨ater in dieser Vorlesung die verwandte Annahme P ̸= N P noch erw¨ahnen. 8Auch Levenshtein-Distanz genannt, nach dem sowjetischen Mathematiker Wladimir Lewenstein (englische Transkription Levenshtein). 18 Beispiele Beispiel. Die Editierdistanz von “TIGER” und “ZIEGE” betr¨agt 3. Es gibt verschie- dene M¨oglichkeiten, die Transformation mit 3 Operationen durchzuf¨uhren, z.B.: TIGER Ersetze T durch T −−−−−−−−−−−→ ZIGER L¨osche R −−−−−−→ ZIGE F¨uge E ein −−−−−−−→ ZIEGE Die Editierdistanz l¨asst sich nicht aus der L¨ange einer l¨angsten gemeinsamen Teil- folge (LGT) berechnen. Vergleichen wir etwa die beiden Paare (“TIGER”,“ZIEGE”) und (“TIGER”,“BIBER”). Bei beiden hat die LGT die L¨ange 3 (“IGE” bzw. “IER”), aber das erste Paar hat Editierdistanz 3, w¨ahrend das zweite Paar Editierdistanz 2 hat. Die LGT selbst ist ebenfalls nicht an die Editieroperationen gekoppelt. F¨ur die W¨orter “FERKEL” und “GEIFER” ist die l¨angste gemeinsame Teilfolge “FER”, aber die k¨urzeste Editierdistanz 4 erreicht man nur dadurch, indem man die Buch- staben “F”, “R”, “K”, “L” mit “G”, “I”, “F”, “R” ¨uberschreibt. Man ¨uberschreibt die LGT also hier teilweise. F E R K E L G E I F E R LGT = 3 EDT = 4 FERKEL Ersetze F durch G −−−−−−−−−−−→ GERKEL Ersetze R durch I −−−−−−−−−−−→ GEIKEL Ersetze K durch F −−−−−−−−−−−→ GEIFEL Ersetze L durch R −−−−−−−−−−−→ GEIFER Anwendungen Wie das LGT-Problem ist die Editierdistanz eines der klassischen Probleme der In- formatik. Sie wird etwa in Programmen zur Rechtschreibpr¨ufung angewandt. Ein weiteres wichtiges Anwendungsgebiet ist der Vergleich von Genomsequenzen: F¨ur zwei Varianten desselben Virus misst die Editierdistanz ihrer Genomsequenzen die minimale Zahl an Mutationen, die n¨otig w¨aren, um eine der Sequenzen in die an- dere umzuwandeln. Damit ist die Editierdistanz ein Mass daf¨ur, wie eng die beiden Varianten miteinander verwandt sind.9 9Bei Genomsequenzen verwendet man ein verallgemeinertes Modell, bei dem die Ersetzungs- operation f¨ur manche Buchstaben “billiger” ist als f¨ur andere. Die hier diskutierten Algorithmen k¨onnen aber leicht so angepasst werden, dass sie auch dieses allgemeinere Problem l¨osen. 2.3 Editierdistanz 19 Teilproblem Analog zum LGT-Problem definieren wir das folgende Teilproblem f¨ur 0 ≤ i ≤ n und 0 ≤ j ≤ m: ED[i, j] := Editierdistanz von (a1, . . . , ai) und (b1, . . . , bj), wobei wir die Konvention verwenden, dass (a1, . . . , ai) f¨ur i = 0 der leere String ist, und analog f¨ur j = 0. Das Ursprungsproblem entspricht dann einfach dem Wert ED[n, m]. Rekursion Nehmen wir an, dass 1 ≤ i ≤ n und 1 ≤ j ≤ m. Um die Editierdistanz ED[i, j] der Strings A[1..i] = (a1, . . . , ai) und B[1..j] = (b1, . . . , bj) zu berechnen, k¨onnen wir wie folgt vorgehen. Dazu verfolgen wir gedanklich das letzte Zeichen ai von A[1..i] w¨ahrend des gesamten optimalen Editierprozesses zu B[1..j]. (a1, . . . , ai ) → ? ( b1, . . . , bj ) Auch falls es ¨uberschrieben wird, verfolgen wir das Zeichen trotzdem weiter. Da sich am Ende des Editiervorgangs das Wort B[1..j] ergibt, welches L¨ange j hat, muss einer der folgenden drei F¨alle auftreten: 1. ai wird irgendwann gel¨oscht. (a1, . . . ,\u0000 \u0000ai ) → (b1, . . . , bj) 2. ai wird nicht gel¨oscht und steht am Ende an einer Stelle aus {1, . . . , j − 1}. (a1, . . . , ai ) → ( b1, . . . , bj−1 , bj) 3. ai wird nicht gel¨oscht und steht am Ende an Stelle j. (a1, . . . , ai ) → (b1, . . . , bj ) Falls ai im Laufe des Prozesses gel¨oscht wird, spielt es keine Rolle, wann genau die L¨oschung stattfindet. Das Ergebnis bleibt identisch, wenn wir ai direkt im ersten Schritt l¨oschen. Im ersten Fall ist also ED(i, j) = 1 + ED(i − 1, j). Im zweiten Fall kann kein Zeichen aus A[1..i] am Ende an Stelle j landen, da diese Zeichen ja w¨ahrend des gesamten Vorgangs vor ai bleiben. Deshalb muss irgendwann ein Zeichen X eingef¨ugt werden, das am Ende an Stelle j landet. Dieses muss den Wert bj haben, denn es w¨urde eine ¨uberfl¨ussige Operation kosten, es erst mit einem anderen Wert einzuf¨ugen und es sp¨ater zu ¨uberschreiben. Ebenso muss X am Ende des Strings eingef¨ugt werden, denn alle Zeichen hinter X h¨atten vorher erst eingef¨ugt werden m¨ussen (weil sie damit hinter ai stehen) und m¨ussten sp¨ater wieder gel¨oscht werden (weil zum Schluss ja X das letzte Zeichen ist). Insgesamt muss in diesem Fall also irgendwann ein Zeichen X mit Wert bj am Ende des Strings eingef¨ugt werden. Wiederum spielt es keine Rolle, wann genau diese Operation stattfindet. Wir k¨onnen daher annehmen, dass das Einf¨ugen im ersten Schritt passiert. Also ist in diesem Fall ED(i, j) = 1 + ED(i, j − 1). 20 Beispiele Im dritten Fall k¨onnen hinter ai keine weiteren Zeichen eingef¨ugt werden, weil diese bis zum Schluss wieder gel¨oscht werden m¨ussten, was nicht optimal w¨are. Also bleibt das Zeichen ai im ganzen Editiervorgang am Ende des Strings. Falls ai = bj, wird es auch nicht ¨uberschrieben, weil das nicht optimal w¨are. Dann ist also ED(i, j) = ED(i−1, j −1). Falls ai ̸= bj, muss ai mit dem Zielwert bj ¨uberschrieben werden, also ist in diesem Fall ED(i, j) = 1 + ED(i − 1, j − 1). Zusammengefasst haben wir also die folgende Rekursion f¨ur 1 ≤ i ≤ n und 1 ≤ j ≤ m: ED(i, j) = min    ED(i − 1, j) + 1, ED(i, j − 1) + 1, ED(i − 1, j − 1) + { 1 falls ai ̸= bj ist, 0 falls ai = bj ist. Beachten Sie, dass wir f¨ur die Rekursion implizit zwei Argumentationsrichtungen brauchen. Wir haben schon gezeigt, dass die optimale Editierfolge in einen der drei F¨alle fallen muss. Also kann ED(i, j) auf keinen Fall kleiner sein als das Minimum der drei Zahlen auf der rechten Seite. Andererseits sieht man leicht, dass ED(i, j) auch nicht gr¨osser sein kann. Beispielsweise gilt ED(i, j) ≤ ED(i − 1, j) + 1, denn es ist sehr leicht, A[1..i] in ED(i − 1, j) + 1 vielen Schritten in B[1..j] umzuwandeln. Dazu l¨oschen wir einfach ai und wandeln den Rest in ED(i−1, j) Schritten in B[1..j] um, was ja nach Definition der Funktion ED m¨oglich ist. Ebenso sieht man, dass ED(i, j) auch kleiner gleich der anderen beiden Ausdr¨ucke auf der rechten Seite ist. Damit ist ED(i, j) auch kleiner gleich dem Minimum aus allen drei Ausdr¨ucken. Schliesslich ist ein Basisfall der Rekursion ED(0, j) = j, denn vom leeren String ausgehen m¨ussen wir die j Buchstaben von B[1..j] einf¨ugen. Entsprechend ist der andere Basisfall ED(i, 0) = i, denn in diesem Fall m¨ussen wir alle Zeichen aus A[1..i] l¨oschen, um den leeren String zu erhalten. Bottom-up-Berechnung der Editierdistanz Die ¨Ubersetzung der Rekursion in Pseudocode ist ganz analog zum LGT-Problem. Wir verzichten daher, diese auszuf¨uhren. Die Berechnungsreihenfolge ist die gleiche wie bei LGT, wir berechnen die Indizes mit zwei for-loops aufsteigend in i und j. Analyse Wir haben uns die Korrektheit der Rekursion schon oben ¨uberlegt, und das Auslesen des Ursprungsproblems ist trivial. F¨ur jedes Paar (i, j) l¨asst sich die Rekursion jeweils in Zeit Θ(1) auswerten. Die Laufzeit des Algorithmus ist deshalb proportional zur Gr¨osse der Tabelle, also Θ(n · m). Beispiel Wir berechnen die Editierdistanz der W¨orter “TIGER” und “ZIEGE”, indem wir die Tabelle ED wie oben beschrieben ausf¨ullen. Die Buchstaben der beiden W¨orter schreiben wir dabei an den oberen bzw. linken Rand der Tabelle, um die Indizes zu verdeutlichen (vgl. Abbildung 2.2). Der Eintrag ED(5, 5) gibt die Editierdistanz der beiden W¨orter “ZIEGE” und “TIGER” an. Die Tabelle zeigt, dass die Editierdistanz 3 betr¨agt. 2.3 Editierdistanz 21 Z I E G E b1 b2 b3 b4 b5 0 1 2 3 4 5 T a1 1 1 2 3 4 5 I a2 2 2 1 2 3 4 G a3 3 3 2 2 2 3 E a4 4 4 3 2 3 2 R a5 5 5 4 3 3 3 Abb. 2.2 Berechnung der Editierdistanz der W¨orter “TIGER” und “ZIEGE” mittels Bottom-up-Ansatz. Die Tabelle enth¨alt die Editierdistanzen aller Pr¨afixe der beiden Strings. Der Eintrag ED(i, j) gibt die Editierdistanz von A[1..i] und B[1..j] an. Die Editierdistanz der beiden W¨orter entspricht dem Eintrag ED(5, 5) = 3. Bestimmung einer optimalen Folge von Editieroperationen ¨Ahnlich wie beim LGT-Problem enth¨alt die Tabelle ED nicht nur die Editierdistanz der beiden Strings, sondern auch implizit die Information, welche Editieroperationen durchgef¨uhrt werden m¨ussen, um A in B zu transformieren. Um diese Information zu extrahieren, m¨ussen wir ausgehend von ED[n, m] r¨uckverfolgen, wie der Eintrag zustande kam. Dies wiederholen wir, bis wir den Eintrag ED[0, 0] erreichen. In jedem Schritt betrachten wir dazu die drei Eintr¨age ED[i − 1, j], ED[i, j − 1] und ED[i − 1, j − 1] und w¨ahlen denjenigen Eintrag aus, der zu dem minimalen Wert in ED[i, j] f¨uhrt (gem¨ass der Rekursionsgleichung aus Abschnitt 2.3.1). Der gew¨ahlte Eintrag gibt uns dann an, welche Editieroperation im aktuellen Schritt durchgef¨uhrt werden muss: • ED[i − 1, j]: L¨oschen von ai • ED[i, j − 1]: Einf¨ugen von bj • ED[i−1, j −1]: Ersetzen von ai durch bj (falls ai ̸= bj ist) oder keine Operation (falls ai = bj ist). Abbildung 2.3 zeigt eine optimale Folge von Editieroperationen f¨ur das Beispiel aus Abschnitt 2.3.2. Die Operationen sind in umgekehrter Reihenfolge anzuwenden, also von unten nach oben. In unserem Beispiel erhalten wir die folgende optimale Folge von Editie- roperationen: 22 Beispiele Z I E G E b1 b2 b3 b4 b5 0 1 2 3 4 5 T a1 1 1 2 3 4 5 I a2 2 2 1 2 3 4 G a3 3 3 2 2 2 3 E a4 4 4 3 2 3 2 R a5 5 5 4 3 3 3 (1) (2) (3) T I G E R Z I E G E (1) entferne R −−−−−−−−→ T I G E Z I E G E ✓ ✓ −→ T I G Z I E G ✓ ✓ −→ T I Z I E (2) f¨uge E ein −−−−−−−−→ T I E Z I E ✓ ✓ → T I Z I ✓ ✓ → T Z (3) ¨andere T→Z −−−−−−−−−−→ Z Z ✓ ✓ Abb. 2.3 Beispiel f¨ur die Bestimmung einer optimalen Folge von Editieroperationen. Die Pfeile geben an, von welchem Eintrag der Tabelle ED wir zu dem n¨achsten Eintrag gelangen. Die Operationen sind in umgekehrter Reihenfolge anzuwenden, also von unten nach oben. 2.4 Das Teilsummenproblem 23 1. Ersetze ‘T’ durch ‘Z’. 2. F¨uge ‘E’ ein. 3. L¨osche ‘R’. Bemerkungen • Es gibt in der Regel mehrere optimale Folgen von Editieroperationen. In unse- rem Beispiel k¨onnte man im ersten Schritt auch das ’Z’ l¨oschen und im zweiten Schritt das ’T’ einf¨ugen. • Die Tabelle ED l¨asst sich auch platzsparender implementieren, indem wir uns jeweils nur die (i−1)-te Zeile merken, w¨ahrend wir die i-te Zeile berechnen. Wir brauchen also nur zwei Zeilen im Speicher zu behalten, was nur Speicher Θ(n) braucht, statt Θ(n · m). Alternativ gen¨ugt auch Speicher Θ(m), wenn wir die Tabelle spaltenweise ausf¨ullen. Mit diesen Einsparungen ist die R¨uckverfolgung der optimalen Editierfolge aber nicht mehr ohne Weiteres m¨oglich. 2.4 Das Teilsummenproblem Ein weiteres Beispiel f¨ur die Anwendung dynamischer Programmierung ist das Teil- Teilsummenproblem summenproblem. Dieses Problem tritt zum Beispiel bei der Optimierung von Res- sourcen oder bei der Analyse von Daten auf. Formal betrachten wir das folgende Problem: Definition 2.4 (Teilsummenproblem (Subset Sum)). Gegeben seien n Zahlen A[1], . . . , A[n] und eine weitere Zahl b. Alle diese Zahlen seien nat¨urliche Zahlen. Gesucht ist eine Teilmenge I ⊆ {1, . . . , n}, sodass ∑ i∈I A[i] = b. Die Summe ∑ i∈I A[i] wird auch Teilsumme genannt, daher der Name des Pro- blems. Eine solche Teilsumme gibt es nat¨urlich nicht f¨ur jedes b. Deshalb ist eine m¨ogliche Antwort des Algorithmus, dass keine solche Teilsumme existiert. Beispiel. Betrachten wir das Array A = (5, 3, 10, 7, 3, 1). F¨ur b = 9 gibt es eine passende Teilmenge, n¨amlich I = {1, 5, 6}, denn A[1] + A[5] + A[6] = 5 + 3 + 1 = 9. F¨ur b = 2 gibt es keine passende Teilmenge, denn wenn wir irgendeinen Sum- manden ausser 1 verwenden, ist die Summe bereits zu gross. F¨ur alle b von b = 3 bis b = 26 gibt es passende Teilmengen. F¨ur b = 27 gibt es allerdings keine passende Teilmenge, wie man durch Probieren feststellen kann.10 Spezialfall: Das Partitionsproblem. Ein besonders interessanter Spezialfall ist der Fall b = 1 2 ∑n i=1 A[i]. In diesem Fall fragen wir, ob wir die Zahlen in A in zwei Teilmengen mit gleicher Summe zerlegen k¨onnen. Man nennt diesen Fall auch Parti- tionsproblem. Als Anwendung stellen wir uns einen Computer mit zwei Prozessoren 10Oder man beobachtet, dass das Problem symmetrisch ist. Die Summe aller Elemente ist S = 29. Wenn man eine Menge I mit Teilsumme b hat, dann liefert die Komplementmenge [n]\\I die Summe S − b. Eine Teilmenge f¨ur b = 27 kann es nicht geben, weil es keine Teilmenge f¨ur b = 29 − 27 = 2 gibt. 24 Beispiele vor, der n Aufgaben durchf¨uhren muss, wobei A[i] die ben¨otigte Zeit f¨ur die i-te Auf- gabe angibt. Wir wollen die Aufgaben so auf die beiden Prozessoren aufteilen, dass beide gleichzeitig fertig werden, da das eine optimale Auslastung garantiert. Eine solche perfekte Aufteilung entspricht genau einer L¨osung des Partitionsproblems.11 Naiver Algorithmus Ein naiver Algorithmus zum L¨osen des Teilsummenproblems besteht darin, alle Teilmengen von {1, . . . , n} auszuprobieren und f¨ur jede Teilmenge zu ¨uberpr¨ufen, ob die Summe der entsprechenden Elemente gleich b ist. Dieser Al- gorithmus ist allerdings sehr ineffizient, da die Anzahl der Teilmengen exponentiell in n w¨achst. Genauer gibt es 2n viele Teilmengen. Dynamische Programmierung Um das Teilsummenproblem effizienter zu l¨osen, verwenden wir dynamische Programmierung. Dazu definieren wir zun¨achst ein ge- eignetes Teilproblem. Hierzu bietet es sich an, sich zu ¨uberlegen, welche Teilsummen mit den ersten i Elementen des Arrays gebildet werden k¨onnen. Dies f¨uhrt auf die folgende Definition. Definition 2.5 (Teilproblem). F¨ur jedes i ∈ {0, 1, . . . , n} und jedes s ∈ N sei T (i, s) definiert als die Antwort auf die Frage, ob s eine Teilsumme von A[1..i] ist. Formal: T (i, s) = { 1 falls es eine Teilmenge I ⊆ {1, .., i} gibt mit ∑j∈I A[j] = s, 0 sonst. Rekursion Um den Wert T (i, s) f¨ur i ≥ 1 rekursiv zu berechnen, m¨ussen wir her- ausfinden, ob es eine Teilmenge I ⊆ {1, . . . , i} gibt mit Summe s. Dazu unterscheiden wir zwei Arten von Teilmengen I: 1) Teilmengen, die das Element A[i] nicht enthalten. In diesem Fall m¨ussen wir die Summe s mit den ersten i − 1 Elementen erreichen. Ob das m¨oglich ist, l¨asst sich in T (i − 1, s) = 1 nachschauen. 2) Teilmengen, die das Element A[i] enthalten. In diesem Fall tr¨agt A[i] zum Wert der Summe bei. Die restlichen Elemente m¨ussen sich also zu s − A[i] aufsummieren. Falls s − A[i] < 0 ist, ist das nicht m¨oglich. Sonst steht in T (i − 1, s − A[i]), ob das m¨oglich ist. Wir erhalten also die folgende Rekursion: T (i, s) = T (i − 1, s) ∨ T (i − 1, s − A[i]), wobei wir T (i−1, s−A[i]) als 0 interpretieren, falls s < A[i] ist. Das Zeichen ∨ ist ein logisches “Oder”, liefert also 1 (true), wenn mindestens eines der beiden Argumente 1 ist. Basisf¨alle F¨ur i = 0 k¨onnen wir keine Elemente verwenden. Daher ist T (0, s) = 0 f¨ur alle s > 0. Andererseits ist T (0, 0) = 1, denn die leere Summe hat den Wert 0. 11Eine andere Anwendung ist die gerechte Aufteilung von Wertsachen unter zwei Parteien, oder von Geschenken unter zwei Kindern, sodass beide Kinder Geschenke im gleichen Wert erhalten. Es sei den Lesern als ¨Ubung ¨uberlassen, die Kinder zu ¨uberzeugen, dass sie so fair behandelt werden. 2.4 Das Teilsummenproblem 25 Berechnungsreihenfolge Die Werte T (i, s) k¨onnen aufsteigend nach i berechnet werden. R¨uckverfolgen Der Wert T (n, b) sagt uns, ob eine L¨osung I existiert oder nicht. Da wir I aber auch finden sollen, m¨ussen wir die L¨osung wieder entlang der Tabelle r¨uckverfolgen, falls sie existiert. Wie in den vorigen Beispielen ¨uberlegen wir uns daf¨ur anhand der Rekursionsformel, wie der Wert T (n, b) = 1 zustande gekommen ist. Je nach Fall der Rekursion (also welcher der beiden Werte 1 ist) nehmen wir dabei den Index n in I auf und gehen zu T (i−1, s−A[i]), oder wir nehmen n nicht in I auf und gehen zu T (i − 1, s). Dies wiederholen wir, bis wir bei T (0, 0) angekommen sind. 0 1 · · · s − A[i] · · · s · · · b 0 T (0, 0) 1 ... i − 1 T (i − 1, s − A[i]) T (i − 1, s) i T (i, s) ... n T (n, b) Analyse Wiederum haben wir die Korrektheit schon oben begr¨undet. Um die Werte von T (i, s) zu berechnen, k¨onnen wir eine Tabelle der Gr¨osse (n + 1) × (b + 1) verwenden. Jeder Eintrag der Tabelle l¨asst sich in konstanter Zeit berechnen, da wir nur auf zwei Eintr¨age der vorherigen Zeile zugreifen m¨ussen. Das Ausf¨ullen der Tabelle ben¨otigt also Zeit Θ(n · b). Das R¨uckverfolgen der L¨osung ist sogar in Zeit O(n) m¨oglich. Die Gesamtlaufzeit des Algorithmus ist daher Θ(n · b). Pseudopolynomielle Laufzeit Die beiden Faktoren n und b in der Laufzeit sind von unterschiedlicher Natur. Die Zahl n ist die Anzahl der Zahlen im Inputarray A. Der Inputarray hat also selbst L¨ange Ω(n). Dagegen ist b der Wert einer Eingabe. Gem¨ass unserem Maschinenmodell z¨ahlen wir das also nur als Eingabel¨ange 1 (f¨ur eine Zahl). Selbst wenn man ein genaueres Modell benutzt, in dem man die L¨ange der Zahlen ber¨ucksichtigt, braucht man nur B := ⌈log2 b⌉ Bits, um die Zahl b darzustellen. Im Vergleich zur Eingabegr¨osse ist der Faktor b also exponentiell gross, denn b = Θ(2B). Es hat sich bei Laufzeiten als Konvention durchgesetzt, dass man die Laufzeit relativ zur L¨ange L der Eingabe betrachtet. Das ist deshalb sinnvoll, weil ein Al- gorithmus in aller Regel zwingend Zeit Ω(L) aufwenden muss, um ¨uberhaupt den Input zu verwenden.12 In diesem Fall w¨urde man deshalb nicht von polynomieller 12Das ist jedoch kein Automatismus und erfordert im Einzelfall ein Argument. Es gibt auch Situationen, wo der Algorithmus nicht den ganzen Input lesen muss. Das sind jedoch speziellere 26 Beispiele Laufzeit sprechen. Stattdessen bezeichnet man eine solche Laufzeit als pseudopoly- nomiell. Ob der Algorithmus effizient ist oder nicht, h¨angt vom Wert der Eingabepseudopolynomiell ab. Betrachten wir als Beispiel den Fall b = 2n. Die L¨ange B des Inputs b ist in diesem Fall Θ(n), denn selbst wenn wir b als Bin¨arzahl kodieren, ben¨otigen wir nur n Bits. Die Laufzeit des Algorithmus ist aber Θ(n·2n), also exponentiell in der L¨ange des Inputs.13 Andererseits ist die Laufzeit polynomiell, falls b polynomiell in n ist. Ist bei- spielsweise b = nc f¨ur eine Konstante c, dann ist die Laufzeit O(nc+1). 2.5 Das Rucksackproblem Das Rucksackproblem ist ein weiteres klassisches Problem der Informatik. Definition 2.6 (Rucksackproblem (Knapsack)). Gegeben seien ein Gewichtslimit W und n Gegenst¨ande mit Gewicht wi ∈ N und Profit pi ∈ N f¨ur i = 1, . . . , n. Gesucht ist eine Teilmenge I ⊆ {1, . . . , n}, sodass ∑ i∈I wi ≤ W, und ∑ i∈I pi maximal unter dieser Bedingung ist. Anschaulich gesprochen: Wir wollen einen Rucksack mit Gegenst¨anden f¨ullen, sodass der Gesamtprofit der Gegenst¨ande m¨oglichst gross ist, ohne das Gewichtslimit W des Rucksacks zu ¨uberschreiten. Offenbar liegt die L¨osung zwischen 0 und P :=∑n i=1 pi. Naiver Algorithmus Ein naiver Algorithmus zum L¨osen des Rucksackproblems be- steht darin, alle Teilmengen von {1, . . . , n} auszuprobieren. Dieser Algorithmus ist allerdings sehr ineffizient, da es wieder 2n viele Teilmengen gibt. Greedy-Algorithmen Man k¨onnte versuchen, das Problem mit einem sogenannten Greedy-Algorithmus zu l¨osen.14 Ein Greedy-Algorithmus trifft in jedem Schritt eine lokal optimale Entscheidung, in der Hoffnung, dass dies zu einer global optimalen L¨osung f¨uhrt. Beim Rucksackproblem k¨onnte man zum Beispiel versuchen, immer den Gegenstand mit dem gr¨ossten Profit auszuw¨ahlen. Oder man k¨onnte versuchen, immer den Gegenstand mit dem kleinsten Gewicht auszuw¨ahlen. Oder man k¨onnte versuchen, immer den Gegenstand mit dem besten Profit-Gewicht-Verh¨altnis aus- zuw¨ahlen. Man kann sich allerdings leicht ¨uberlegen, dass diese Strategien alle nicht zu einer optimalen L¨osung f¨uhren.15 Abbildung 2.4 zeigt Beispiel-Inputs, auf denen diese drei Strategien fehlschlagen. Situationen, die Sie erst in h¨oheren Semestern kennenlernen werden. 13Genau genommen macht dieser Fall nur Sinn, wenn auch die Gesamtsumme der Eintr¨age in A mindestens 2n ist. Das kann aber vorkommen, selbst wenn die Gesamtl¨ange von A nur O(n) ist. Zum Beispiel k¨onnte in A eine sehr grosse Zahl vorkommen, die gr¨osser als b ist. 14“Greedy” = “gierig”. 15Alle drei k¨onnen sogar zu extrem schlechten L¨osungen f¨uhren, wie die Beispiele zeigen. 2.5 Das Rucksackproblem 27 i pi wi 1 1 1 ... ... ... W 1 1 W + 1 2 W i pi wi 1 1 1 2 W − 1 W Abb. 2.4 Die Greedy-Strategie, die immer den wertvollsten Gegenstand nimmt, ist auf dem linken Beispiel sehr schlecht, da sie den letzten Gegenstand mit Profit 2 nehmen w¨urde, wonach der Rucksack schon voll ist. Dagegen ist die optimale L¨osung, die W anderen Ge- genst¨ande mit Gesamtprofit W zu nehmen. Das rechte Beispiel ist sehr schlecht f¨ur die Strategie, immer den leichtesten Gegenstand zu nehmen. Dies w¨are der erste Gegenstand mit Profit 1. Danach passt Gegenstand 2 nicht mehr in den Rucksack. Dagegen w¨urde die optimale L¨osung aus Gegenstand 2 bestehen, was Profit W − 1 liefert. Die Strategie, den Gegenstand mit dem besten Profit-Gewicht-Verh¨altnis zu nehmen, trifft im rechten Beispiel die gleiche schlechte Entscheidung, denn das Profit-Gewicht-Verh¨altnis von Gegenstand 1 ist h¨oher als das von Gegenstand 2. Teilproblem Analog zum Teilsummenproblem k¨onnen wir f¨ur alle 0 ≤ i ≤ n, 0 ≤ w ≤ W und 0 ≤ p ≤ P fragen, ob es m¨oglich ist, mit den ersten i Gegenst¨anden und Gewichtslimit w, Profit p zu erreichen: E(i, w, p) = { 1 falls es I ⊆ {1, .., i} gibt mit ∑j∈I wj ≤ w und ∑ j∈I pj ≥ p, 0 sonst. Dies f¨uhrt auf eine Rekursion, die ganz ¨ahnlich zum Teilsummenproblem ist und Laufzeit O(n · W · P ) hat. Tats¨achlich berechnen wir hier aber verschwenderisch viel. Betrachten wir ein festes i und ein festes w. Dann berechnen wir f¨ur alle Profite p, ob sie mit Gewichtslimit w aus den ersten i Gegenst¨anden erreichbar sind. Dabei w¨urde es uns gen¨ugen, den gr¨ossten erreichbaren Profit p zu kennen. Diese Vereinfachung erlaubt es uns, stattdessen mit dem folgenden Teilproblem zu arbeiten. Definition 2.7 (Teilproblem). F¨ur jedes i ∈ {0, 1, . . . , n} und jedes w ∈ N sei P (i, w) definiert als der maximale Profit, den man mit Gewichtslimit w mit den ersten i Gegenst¨anden erreichen kann. Rekursion Um die Werte von P (i, w) rekursiv zu berechnen, unterscheiden wir wieder zwei Arten von Teilmengen I: 1) I enth¨alt den Gegenstand i nicht. In diesem Fall ist der maximale Profit, den wir erreichen k¨onnen, gleich dem maximalen Profit, den wir mit den ersten i − 1 Gegenst¨anden erreichen k¨onnen, also P (i − 1, w). 2) I enth¨alt den Gegenstand i. In diesem Fall ist der maximale Profit, den wir erreichen k¨onnen, gleich dem Profit des Gegenstands i plus dem maximalen 28 Beispiele Profit, den wir mit den ersten i − 1 Gegenst¨anden und dem verbleibenden Gewichtslimit w − wi erreichen k¨onnen, also pi + P (i − 1, w − wi). Dieser Fall ist nat¨urlich nur m¨oglich, falls w ≥ wi ist. Wir erhalten also die folgende Rekursion f¨ur i ≥ 1: P (i, w) = { P (i − 1, w) falls w < wi, max{P (i − 1, w), pi + P (i − 1, w − wi)}, sonst. Als Basisfall f¨ur i = 0 haben wir P (0, w) = 0 f¨ur alle w ≥ 0. Wir f¨ullen die entsprechende Tabelle wieder aufsteigend nach i. Auslesen und R¨uckverfolgen der L¨osung Haben wir die Tabelle ausgef¨ullt, k¨onnen wir den maximalen Profit in P (n, W ) ablesen. Wie f¨ur die vorigen Probleme l¨asst sich die zugeh¨orige Menge I durch R¨uckverfolgen bestimmen, siehe Abbildung. 0 1 · · · w − wi · · · w · · · W 0 0 0 · · · 0 · · · 0 · · · 0 1 0 ... ... i − 1 0 P (i − 1, w − wi) P (i − 1, w) i 0 P (i, w) ... ... n 0 P (n, W ) Analyse Die Korrektheit ergibt sich wieder aus der Korrektheit der Rekursion. Um die Werte von P (i, w) zu berechnen, k¨onnen wir eine Tabelle der Gr¨osse (n + 1) × (W +1) verwenden. Jeder Eintrag der Tabelle l¨asst sich in konstanter Zeit berechnen, da wir nur auf zwei Eintr¨age der vorherigen Zeile zugreifen m¨ussen. Das Ausf¨ullen der Tabelle ben¨otigt daher Zeit Θ(n·W ). Das R¨uckverfolgen ben¨otigt nur Zeit O(n), daher ist die Gesamtlaufzeit des Algorithmus Θ(n · W ). Diese Laufzeit ist wiederum pseudopolynomiell, denn die Laufzeit ist zwar po- lynomiell in n und W , aber W ist eine Zahl im Input und nicht die Anzahl der Gegenst¨ande. Alternatives DP Kehren wir wieder zur urspr¨unglichen Ausgangsgr¨osse E(i, w, p) zur¨uck. F¨ur festes i und w hatten wir uns ¨uberlegt, dass es gen¨ugt, nur den maxima- len Profit p zu kennen. Wir k¨onnen die Rollen der Variablen aber auch vertauschen. Wir haben schon fr¨uher gesehen, dass eine solche Rollenumkehr zu neuen L¨osungen 2.5 Das Rucksackproblem 29 f¨uhren kann. Halten wir i und p fest16, so fragen wir f¨ur jedes w, ob es m¨oglich ist, den Profit p aus den ersten i Gegenst¨anden mit Gewichtslimit w zu erreichen. Auch hier berechnen wir verschwenderisch viel. Es w¨urde uns gen¨ugen, das kleinste Gewichtslimit w zu kennen, mit dem wir dieses Ziel erreichen k¨onnen. Das f¨uhrt auf das folgende alternative Teilproblem. Definition 2.8 (Alternatives Teilproblem). F¨ur jedes 0 ≤ i ≤ n und jedes 0 ≤ p ≤ P sei G(i, p) definiert als das minimale Gewicht, das man ben¨otigt, um mit den ersten i Gegenst¨anden den Profit p zu erreichen oder zu ¨uberschreiten. Falls es nicht m¨oglich ist, mit den ersten i Gegenst¨anden den Profit p zu erreichen, so definieren wir G(i, p) = ∞. Rekursion Um die Werte von G(i, p) f¨ur i ≥ 1 rekursiv zu berechnen, unterscheiden wir wieder zwei m¨ogliche Teilmengen I: 1) I enth¨alt den Gegenstand i nicht. In diesem Fall ist das minimale Gewicht, das wir ben¨otigen, gleich dem minimalen Gewicht, das wir mit den ersten i − 1 Gegenst¨anden ben¨otigen, also G(i − 1, p). 2) I enth¨alt den Gegenstand i. In diesem Fall ist das minimale Gewicht, das wir ben¨otigen, gleich dem Gewicht des Gegenstands i plus dem minimalen Gewicht, das wir mit den ersten i − 1 Gegenst¨anden ben¨otigen, um den Profit p − pi zu erreichen, also wi + G(i − 1, p − pi). Falls p ≥ pi ist, haben wir G(i − 1, p − pi) schon berechnet. Falls p < pi ist, so reicht pi allein schon aus, um den gew¨unschten Zielprofit zu erreichen. In diesem Fall ben¨otigen wir insgesamt also Gewicht wi aus. Diesen Fall k¨onnen wir elegant abdecken, indem wir G(i − 1, p − pi) = 0 f¨ur p − pi ≤ 0 setzen. Wir erhalten also die folgende Rekursion: G(i, p) = min{G(i − 1, p), wi + G(i − 1, p − pi)}, wobei wir G(i − 1, p − pi) als 0 interpretieren, falls p < pi ist. Als Basisfall f¨ur i = 0 haben wir G(0, 0) = 0, da wir den Profit 0 mit der leeren Menge und Gewichtslimit 0 erreichen k¨onnen, und G(0, p) = ∞ f¨ur p > 0. Die Berechnungsreihenfolge ist wieder aufsteigend in i. Auslesen und R¨uckverfolgen der L¨osung Das Auslesen des optimalen Profits aus der Tabelle ist diesmal trickreicher. Daf¨ur suchen wir in der Zeile i = n nach dem gr¨ossten Profit p0, sodass G(n, p0) ≤ W ist. Dies ist der optimale Profit, denn p0 ist mit Budget W erreichbar, w¨ahrend der Profit p0 + 1 wegen G(n, p0 + 1) > W nicht mehr mit Budget W erreichbar ist. F¨ur die R¨uckverfolgung starten wir also in G(n, p0) und verfolgen durch die Tabelle zur¨uck, wie dieser Wert zustande gekommen ist. 16Man k¨onnte auch versuchen, p und w festzulassen und i zu berechnen. In diesem Fall gibt es aber keine offensichtliche Vereinfachung. Es gen¨ugt f¨ur eine Rekursion eben nicht, in diesem Fall nur das maximale i zu kennen, mit dem man Profit p mit Gewichtslimit w aus den ersten i Gegenst¨anden erreichen kann, weil man f¨ur gr¨ossere Werte p und w vielleicht auf noch unbenutzte Gegenst¨ande unter den ersten i zugreifen muss. 30 Beispiele 0 · · · p − pi · · · p · · · p0 · · · P 0 1 ... i − 1 G(i − 1, p − pi) G(i − 1, p) i G(i, p) ... n G(n, p0) Gr¨osstes p0, f¨ur das G(n, p0) ≤ W ist Analyse Wir haben uns schon von der Korrektheit der Rekursion ¨uberzeugt. Die Tabelle hat Gr¨osse (n + 1) × (P + 1). Jeder Eintrag der Tabelle l¨asst sich in kon- stanter Zeit berechnen, da wir nur auf zwei Eintr¨age der vorherigen Zeile zugreifen m¨ussen. Das Ausf¨ullen der Tabelle ben¨otigt daher Zeit Θ(n · P ). Das R¨uckverfol- gen ist schneller: Um den Wert p0 zu finden, brauchen wir mit bin¨arer Suche nur Zeit O(log W ), und das eigentliche R¨uckverfolgen ben¨otigt danach Zeit O(n). Die Gesamtlaufzeit des Algorithmus ist daher Θ(n · P ). Diese Laufzeit ist wiederum pseudopolynomiell, da die Laufzeit zwar polynomiell in n und P ist, aber P eine Zahl im Input ist und nicht die Anzahl der Gegenst¨ande. Sie h¨angt diesmal aber nicht von der Gr¨osse W , sondern von einer anderen Gr¨osse P ab. Es gibt Anwendungen, in denen P klein und W gross ist, und andere Anwen- dung mit der umgekehrten Konstellation. Daher ist je nach Anwendung mal die eine Variante besser und mal die andere. 2.6 Geht es besser? P vs. NP Sowohl f¨ur das Teilsummenproblem als auch f¨ur das Rucksackproblem haben wir nun pseudopolynomielle Algorithmen gefunden. Die Frage ist nun, ob es auch Algo- rithmen gibt, deren Laufzeit polynomiell in der L¨ange des Inputs ist. Die Vermutung ist nein. Sowohl f¨ur das Teilsummenproblem als auch f¨ur das Rucksackproblem wird vermutet, dass es keinen Algorithmus gibt, dessen Laufzeit polynomiell in der L¨ange des Inputs ist. Um diese Vermutung besser zu verstehen, greifen wir der Vorlesung Theoretische Informatik etwas vor und f¨uhren zwei wichtige Komplexit¨atsklassen ein: P und NP. Die Komplexit¨atsklassen P und NP Die Komplexit¨atsklasse P ist die Menge aller Entscheidungsprobleme17, die in polynomieller Zeit l¨osbar sind. Das bedeutet, dass 17Entscheidungsprobleme sind Probleme, bei denen es nur zwei m¨ogliche Antworten gibt, “Ja” oder “Nein”. Das ist meistens keine wesentliche Einschr¨ankung. Beim Teilsummenproblem haben wir mit dynamischer Programmierung erst das Entscheidungsproblem gel¨ost und dann mit R¨uck- verfolgen die Teilsumme rekonstruiert. Ebenso l¨asst sich auch das Rucksackproblem als Entschei- dungsproblem formulieren, indem wir im Input zus¨atzlich eine Zahl t angeben. Wir fragen dann, 2.6 Geht es besser? P vs. NP 31 es f¨ur jedes Problem in P einen Algorithmus gibt, dessen Laufzeit polynomiell in der L¨ange des Inputs ist. Die Komplexit¨atsklasse NP ist die Menge aller Entscheidungsprobleme, bei denen man eine m¨ogliche L¨osung in polynomieller Zeit ¨uberpr¨ufen kann. Das bedeutet, dass es f¨ur jedes Problem in NP einen Algorithmus gibt, der • als Eingabe den Input des Problems und eine m¨ogliche L¨osung erh¨alt, • in polynomieller Zeit ¨uberpr¨uft, ob die L¨osung korrekt ist, und • “Ja” ausgibt, falls die L¨osung korrekt ist, und “Nein” sonst. Es ist klar, dass P eine Teilmenge von NP ist.18 Denn wenn wir ein Problem in polynomieller Zeit l¨osen k¨onnen, dann k¨onnen wir insbesondere auch eine m¨ogliche L¨osung in polynomieller Zeit ¨uberpr¨ufen. Die Vermutung P ̸= NP besagt, dass es Probleme in NP gibt, die nicht in P liegen. Das bedeutet, dass es Probleme gibt, bei denen wir zwar eine m¨ogliche L¨osung in polynomieller Zeit ¨uberpr¨ufen k¨onnen, aber f¨ur die es keinen Algorithmus gibt, der das Problem in polynomieller Zeit l¨ost. Sowohl das Teilsummenproblem als auch das Rucksackproblem liegen in NP. Denn wenn uns jemand eine Teilmenge I als L¨osung angibt, dann k¨onnen wir in polynomieller Zeit ¨uberpr¨ufen, ob die Summe der entsprechenden Elemente gleich t ist (beim Teilsummenproblem) bzw. ob die Summe der Gewichte kleiner gleich W ist und die Summe der Profite gr¨osser gleich t ist (beim Rucksackproblem). NP-Vollst¨andigkeit Ein verbl¨uffendes Theorem aus der theoretischen Informatik ist das folgende. Theorem 2.9. Wenn sich das Teilsummenproblem in polynomieller Zeit l¨osen l¨asst, so ist P = NP. L¨ost man also das Teilsummenproblem in polynomieller Zeit, so hat man gleich- zeitig auch das Rucksackproblem in polynomieller Zeit gel¨ost. Theorem 2.9 ist auch konstruktiv, d.h. man kann eine polynomielle L¨osung des Teilsummenproblems auch in eine polynomielle L¨osung des Rucksackproblems umwandeln.19 Ebenso h¨atte man dann jedes andere Problem in NP in polynomieller Zeit gel¨ost, darunter viele zentrale Probleme der Informatik, die seit Jahrzehnten offen sind. Noch verbl¨uffender ist, dass das Teilsummenproblem in der Hinsicht nichts be- sonderes ist. Theorem 2.9 gilt ebenso f¨ur das Rucksackproblem: Theorem 2.10. Wenn sich das Rucksackproblem in polynomieller Zeit l¨osen l¨asst, so ist P = NP. Inzwischen hat man Zehntausende20 Probleme identifiziert, f¨ur die Theorem 2.9 sinngem¨ass gilt. Solche Probleme nennt man NP-schwer bzw. NP-vollst¨andig (letz- teres, wenn das Problem selbst in NP liegt). ob es eine Teilmenge I ⊆ {1, . . . , n} gibt mit ∑ i∈I wi ≤ W und ∑ i∈I pi ≥ t. Allgemein l¨asst sich aus einem solchen Entscheidungsproblem in der Regel mit R¨uckverfolgen auch die Antwort des Berechnungs- oder Findungsproblems rekonstruieren. 18Das mag in der Formulierung hier nicht v¨ollig offensichtlich sein. Das liegt aber nur daran, dass wir nicht pr¨azise gemacht haben, was eigentlich eine “L¨osung” ist. 19Die sich ergebende Polynomialzeit hat allerdings einen hohen Exponenten. 20Sch¨atzung des Dozenten. Es h¨angt etwas davon ab, wann man eine neue Variante als “neues” Problem betrachtet. So oder so ist die Liste sehr lang, und jedes Jahr kommen Hunderte von Problemen hinzu. 32 Beispiele Ein polynomieller Algorithmus f¨ur das Teilsummenproblem oder das Rucksack- problem w¨are wegen dieser Konsequenzen der gr¨osste Durchbruch in der theoreti- schen Informatik der letzten 50 Jahre.21 Allgemein wird daher vermutet, dass es keinen solchen Algorithmus gibt. 2.7 Approximationsalgorithmus f¨ur das Rucksackproblem Da wir nicht erwarten, einen Algorithmus mit polynomieller Laufzeit zu finden, der das Rucksackproblem exakt l¨ost, wollen wir stattdessen versuchen, das Problem approximativ zu l¨osen. Das Ziel ist, einen Algorithmus zu finden, der • eine Laufzeit hat, die polynomiell in der L¨ange des Inputs ist, und • eine L¨osung zur¨uckgibt, deren Wert m¨oglichst nahe am Wert der optimalen L¨osung liegt. Die Idee ist, die Profite pi der Gegenst¨ande zu runden und dann das Rucksack- problem mit den gerundeten Profiten zu l¨osen. Dazu w¨ahlen wir eine nat¨urliche Zahl K und ersetzen jeden Profit pi durch pi := K · ⌊ pi K ⌋ . Das bedeutet, dass wir pi auf das n¨achste Vielfache von K abrunden. Beispiel F¨ur K = 10 und (p1, . . . , pn) = (112, 78, 1001, 237, 17, . . .) erhalten wir (p1, . . . , pn) = (110, 70, 1000, 230, 10, . . .). Effizienz Erinnern wir uns an den DP-Algorithmus, der das Rucksackproblem in Zeit O(n·P ) l¨ost, wobei P = ∑n i=1 pi der Gesamtprofit des Inputs ist. Dieser benutzt eine DP-Tabelle der Gr¨osse (n + 1) × (P + 1). Das Rucksackproblem mit den gerun- deten Profiten pi l¨asst sich mit dieser Methode effizienter l¨osen als das urspr¨ungliche Problem. Da alle auftretenden Profite durch K teilbar sind, gen¨ugt es, auch nur diese Spalten in der DP-Tabelle auszuf¨ullen. Im Beispiel mit K = 10 m¨ussen wir nur jede zehnte Spalte der Tabelle ausf¨ullen. F¨ur eine praktische Implementierung k¨onnen wir die Tabelle reskalieren, sodass wir den Speicher in den anderen Spalten nicht unbenutzt vergeuden. Wir k¨onnen also auch den Speicherbedarf um den Fak- tor K reduzieren. Wir k¨onnen das gerundete Problem also in Zeit Θ(nP/K) und Speicherplatz Θ(nP/K) l¨osen.22 Beobachtungen Bevor wir mit der eigentlichen Analyse beginnen, sammeln wir erst ein paar einfache Beobachtungen. • Die gerundeten Profite pi sind nicht viel kleiner als die urspr¨unglichen Profite pi. Genauer gilt pi ≤ pi ≤ pi + K. (1) 21Die Frage, ob P=NP ist, wurde im Jahr 2000 auch zu einem der sieben Millennium-Probleme gek¨urt. Diese Frage w¨urde mit so einem Algorithmus positiv beantwortet. 22Tats¨achlich gilt das nur, wenn K ≤ P ist, weil die exakte Zahl an Spalten ⌈P/K⌉ + 1 ist. F¨ur K ≤ P ist das asymptotisch gleich Θ(P/K), f¨ur viel gr¨ossere K w¨urde das nicht mehr gelten. Da so grosse Werte von K nicht sinnvoll sind, erlauben wir uns hier diese technische Ungenauigkeit. 2.7 Approximationsalgorithmus f¨ur das Rucksackproblem 33 • Dadurch, dass wir nur die Profite und nicht die Gewichte ver¨andern, passen immer noch dieselben Teilmengen von Gegenst¨anden in den Rucksack. • Falls es einen Index i gibt mit wi > W , so passt schon dieser Gegenstand alleine nicht in den Rucksack. Das gilt sowohl f¨ur das urspr¨ungliche als auch f¨ur das gerundete Problem. Wir k¨onnen solche Gegenst¨ande also bedenkenlos vorher aussortieren, was in Zeit O(n) m¨oglich ist. Da dieser Schritt keine Probleme verursacht, gehen wir im Folgenden direkt davon aus, dass wi ≤ W f¨ur alle 1 ≤ i ≤ n gilt. Sei pmax = max{p1, . . . , pn} der maximale Profit eines Gegenstands. Wegen der gerade getroffenen Annahme gilt ∑ i∈OPT pi ≥ pmax, (2) da wir zumindest den Gegenstand mit dem maximalen Profit in den Rucksack packen k¨onnen. Andererseits gilt auch ∑ i∈OPT pi ≤ n∑ i=1 pi ≤ n · pmax, (3) denn OPT ist ja eine Teilmenge von {1, . . . , n}. Ausgabe Sei OPT die optimale L¨osung f¨ur das urspr¨ungliche Problem und OPT die optimale L¨osung f¨ur das Problem mit den gerundeten Profiten. Wir haben gesehen, dass wir OPT deutlich schneller ausrechnen k¨onnen aus OPT. Ausserdem ist OPT auch eine g¨ultige L¨osung f¨ur das Ausgangsproblem, d.h. die Gegenst¨ande passen tats¨achlich in den Rucksack. Deshalb wird unser Algorithmus darin bestehen, OPT zu berechnen und auszugeben. Allerdings ist OPT nicht unbedingt eine optimale L¨osung f¨ur das Ausgangsproblem. Wir werden aber nun zeigen, dass der Profit von OPT nicht viel kleiner ist als der Profit von OPT. Analyse Wir bezeichnen mit p(OPT) bzw. p(OPT) den Profit von OPT und OPT f¨ur das Ausgangsproblem, also p(OPT) = ∑i∈OPT pi und p(OPT) = ∑ i∈OPT pi. Zun¨achst beobachten wir, dass OPT optimal f¨ur das Problem mit den gerunde- ten Profiten ist. Das bedeutet, dass f¨ur jede Teilmenge I ⊆ {1, . . . , n}, die in den Rucksack passt, gilt: ∑ i∈OPT pi ≥ ∑ i∈I pi. Diese Ungleichung gilt insbesondere auch f¨ur I = OPT: ∑ i∈OPT pi ≥ ∑ i∈OPT pi. (4) Nun wollen wir den Profit p(OPT) von OPT f¨ur das urspr¨ungliche Problem 34 Beispiele absch¨atzen. Dazu verwenden wir die Ungleichung (1) und erhalten: p(OPT) = ∑ i∈OPT pi (1) ≥ ∑ i∈OPT pi (4) ≥ ∑ i∈OPT pi (1) ≥ ∑ i∈OPT(pi − K) = p(OPT) − K · |OPT|, wobei |OPT| die Anzahl der Elemente in OPT bezeichnet. Da |OPT| ≤ n ist, erhalten wir p(OPT) ≥ p(OPT) − K · n. (5) Wir wollen nun K so w¨ahlen, dass K · n klein ist im Vergleich zu p(OPT). Dazu f¨uhren wir einen Parameter ε > 0 ein und versuchen zu erreichen, dass K · n ≤ ε · p(OPT) ist. Wir erinnern uns, dass p(OPT) ≥ pmax nach (2)ist, und setzen daher K := ε · pmax n . Dann gilt wie gew¨unscht K · n = ε · pmax ≤ ε · p(OPT). Setzen wir dies in (5) ein, so erhalten wir p(OPT) ≥ p(OPT) − K · n ≥ p(OPT) − ε · p(OPT) = (1 − ε) · p(OPT). Das bedeutet, dass der Profit von OPT mindestens (1 − ε) mal so gross ist wie der Profit von OPT. Wir haben also eine (1 − ε)-Approximation gefunden. Laufzeit Wir hatten uns schon ¨uberlegt, dass die Laufzeit (und der Speicherbedarf) des Algorithmus O(nP/K) ist. Setzen wir nun unser gew¨ahltes K = ε · pmax/n ein, so erhalten wir die Laufzeit O(n2P/(ε · pmax)). Dies k¨onnen wir weiter vereinfachen, weil P ≤ n · pmax nach (3) gilt. Damit ist die Laufzeit h¨ochstens O(n3/ε). Insbesondere ist f¨ur jedes konstante ε > 0 die Laufzeit O(n3). Setzen wir etwa ε = 0.1, so erhalten wir einen Algorithmus, der in Zeit O(n3) eine Approximation berechnet, die mindestens 90% des Profites der optimalen L¨osung erreicht, f¨ur ε = 0.01 erhalten wir einen anderen Algorithmus, der ebenfalls in Zeit O(n3) eine 99%- Approximation erreicht, und so weiter. Wir k¨onnen f¨ur ε sogar Werte w¨ahlen, die von n abh¨angen. Zum Beispiel erhalten wir f¨ur ε = 1 n eine (1 − 1 n )-Approximation in Zeit O(n4). Eine solche Familie von Algorithmen (einer f¨ur jedes ε) wird auch polynomial time approximation scheme (PTAS) genannt. Das bedeutet, dass wir f¨ur jedes ε > 0 einen Algorithmus haben, der eine (1 − ε)-Approximation in polynomieller Zeit berechnet. Geht ε wie hier sogar nur polynomiell in die Laufzeit ein, dann spricht man von einem fully polynomial time approximation scheme (FPTAS).23 23Ein Beispiel f¨ur ein PTAS, das kein FPTAS ist, w¨are ein Algorithmus mit Laufzeit O(n 1/ε). Auch 2.8 L¨angste aufsteigende Teilfolge 35 2.8 L¨angste aufsteigende Teilfolge Hier wollen wir ein Beispiel f¨ur die Anwendung dynamischer Programmierung ken- nenlernen, das komplexer ist als die bisherigen: die Suche nach der l¨angsten aufstei- genden Teilfolge in einem Array. Definition 2.11 (L¨angste aufsteigende Teilfolge). Gegeben sei ein Array A[1..n] von n verschiedenen24 ganzen Zahlen. Gesucht ist die L¨ange einer l¨angsten aufsteigenden Teilfolge von A. Beispiel. Betrachten wir das Array A = (2, 13, 17, 9, 11, 4, 78, 28, 15, 25, 99). Eine aufsteigende Teilfolge ist zum Beispiel (2, 13, 17), denn 2 < 13 und 13 < 17. Weitere Beispiele sind (2, 13, 17, 78, 99) (L¨ange 5) und (2, 9, 11, 15, 25, 99) (L¨ange 6). Die l¨angste aufsteigende Teilfolge hat in diesem Fall die L¨ange 6. Im Folgenden werden wir “aufsteigende Teilfolge” mit “AT” abk¨urzen und “l¨angs- te aufsteigende Teilfolge” mit “LAT”. Anwendung Eine Anwendung aus dem Chipdesign ist die folgende. Wir haben zwei parallele Reihen von je n Kontakten. Jeder Kontakt in der ersten Reihe hat einen Partnerkontakt in der zweiten Reihe, welche wir mit den Zahlen 1, . . . , n beschreiben, siehe Graphik. 1 2 3 4 5 6 7 4 6 2 1 3 5 7 Wir wollen nun m¨oglichst viele Kontakte durch eine Verbindungslinie mit ihren Partnerkontakten verbinden, ohne dass sich zwei Verbindungslinien kreuzen. Man ¨uberzeugt sich schnell, dass daf¨ur die Kontakte in der zweiten Reihe eine AT bilden m¨ussen, da es sonst zu Kreuzungen kommt. Wir m¨ussen hier also eine LAT in der zweiten Reihe finden. Teilproblem Um dieses Problem mit dynamischer Programmierung zu l¨osen, m¨ussen wir zun¨achst ein geeignetes Teilproblem finden. Wir werden dazu mehrere Versuche brauchen, da die Wahl des Teilproblems in diesem Fall nicht ganz einfach ist. Versuch 1 Ein naheliegendes Teilproblem w¨are, die L¨ange der l¨angsten aufsteigen- den Teilfolge im Bereich A[1..i] zu berechnen. Definition 2.12 (Teilproblem (Versuch 1)). F¨ur i ∈ {1, . . . , n} sei LAT(i) eine LAT von A[1..i]. hier erhalten wir f¨ur jedes (konstante) ε > 0 eine polynomielle Zeit, zum Beispiel O(n 2) f¨ur ε = 1/2, O(n 10) f¨ur ε = 0.1, und so weiter. Im Gegensatz zu einem FPTAS h¨angt der Exponent des Polynoms nun aber vom Wert von ε ab. 24Die Annahme, dass alle Zahlen verschieden sind, ist keine wirkliche Einschr¨ankung. Man kann sie leicht umgehen, indem man im Array zus¨atzlich zu der Zahl A[i] auch noch den Index i speichert. Sind also zwei Zahlen gleich, so ist das Paar (A[i], i) dennoch von dem Paar (A[j], j) verschieden, sofern i ̸= j ist. 36 Beispiele Beispiel. Betrachten wir das Array A = (1, 2, 5, 3, 4). Dann ist LAT(1) = (1), LAT(2) = (1, 2), LAT(3) = (1, 2, 5), und LAT(4) = (1, 2, 5). Allerdings ist LAT(5) = (1, 2, 3, 4), da wir die 4 an die Teilfolge (1, 2, 3) anh¨angen k¨onnen. Es ist daher nicht offensichtlich, wie wir LAT(5) aus LAT(4) ablesen k¨onnen. Dieses Beispiel zeigt, dass dieses Teilproblem nicht geeignet ist, da wir nicht wissen, wie wir von LAT(i − 1) zu LAT(i) gelangen k¨onnen. Wir m¨ussten alle LAT von A[1..i − 1] kennen, nicht nur eine. Wir k¨onnten also versuchen, alle LAT zu speichern, aber das k¨onnen schnell sehr viele werden (sogar exponentiell viele). Das w¨are also ineffizient. Wir k¨onnen diesen Gedanken aber verbessern, indem wir jeweils nur die Endpunkte aller LAT speichern. Versuch 2 F¨ur jedes i speichern wir alle Endpunkte von LAT in A[1..i]. Beispiel. Betrachten wir das Array A = (1, 5, 6, 2, 3, 4). Dann ist der einzige End- punkt einer LAT von A[1..3] die Zahl 6, der einzige Endpunkt einer LAT von A[1..4] ebenfalls 6, aber die Endpunkte der LAT von A[1..5] sind die Zahlen 3 und 6. Also ist wiederum nicht klar, wie wir aus der fr¨uheren Information auf die LAT (1, 2, 3) in A[1..5] kommen sollten. Auch dieses Teilproblem ist also nicht geeignet. Um eine LAT f¨ur A[1..i] zu finden, m¨ussen wir uns auch k¨urzere AT merken. Auch hier w¨are es wieder zu auf- wendig, sich alle AT von A[1..i] zu speichern. Aber wir k¨onnen uns die Endpunkte zusammen mit der L¨ange merken. Dies k¨onnten wir tun, indem wir f¨ur jedes i eine Liste aus Endpunkten und zugeh¨origen L¨angen speichern. F¨ur schnelleren Zugriff ist es aber besser, die Informationen in einer zweidimensionalen Tabelle zu speichern. Die f¨uhrt auf das folgende Teilproblem. Versuch 3 Definition 2.13 (Teilproblem (Versuch 3)). F¨ur jedes i ∈ {1, . . . , n} und jedes l ∈ {1, . . . , n} sei E(i, l) definiert als E(i, l) = { 1 falls es eine aufsteigende Teilfolge der L¨ange l gibt, die in A[i] endet, 0 sonst. Rekursion Um die Werte von E(i, l) rekursiv zu berechnen, unterscheiden wir zwei F¨alle: 1) l = 1: In diesem Fall ist E(i, l) = 1, da wir immer eine AT der L¨ange 1 finden k¨onnen, die in A[i] endet. 2) l ≥ 2: In diesem Fall ist E(i, l) = 1 genau dann, wenn es ein j < i gibt, sodass E(j, l − 1) = 1 ist und A[j] < A[i] gilt. Denn in diesem Fall k¨onnen wir die AT der L¨ange l − 1, die in A[j] endet, um das Element A[i] erweitern. Formal l¨asst sich diese Rekursion wie folgt schreiben: E(i, l) =    1 falls l = 1, 1 falls l ≥ 2 und es ein j < i gibt mit E(j, l − 1) = 1 und A[j] < A[i], 0 sonst. 2.8 L¨angste aufsteigende Teilfolge 37 Laufzeitanalyse Um die Werte von E(i, l) zu berechnen, k¨onnen wir eine Tabelle der Gr¨osse n × n verwenden.25 Um den Eintrag E(i, l) zu berechnen, m¨ussen wir im schlimmsten Fall alle Eintr¨age E(j, l − 1) mit j < i ¨uberpr¨ufen. Die Laufzeit f¨ur einen einzelnen Eintrag ist also O(i) ≤ O(n). Die Gesamtlaufzeit des Algorithmus ist daher O ( n∑ l=1 n∑ i=1 n ) = O(n3). Dies ist erst mal nur eine obere Schranke, da wir ja zum O(i) durch O(n) abgesch¨atzt haben. Man k¨onnte genauer rechnen, indem man den Summanden durch O(i) ersetzt. Das w¨urde aber an der Asymptotik O(n3) der Summe nichts ¨andern. Damit haben wir endlich eine L¨osung f¨ur das Problem gefunden. Es bleibt aber die Frage, ob es nicht noch bessere L¨osungen gibt. Versuch 5 Tats¨achlich k¨onnen wir den vorigen Versuch verbessern. Betrachten wir zum Beispiel die Teilfolgen (1, 5, 6) und (1, 2, 3) im vorherigen Beispiel. Wenn wir eine Zahl an die Teilfolge (1, 5, 6) anh¨angen k¨onnen, dann k¨onnen wir sie auch an die Teilfolge (1, 2, 3) anh¨angen. Die Teilfolge (1, 2, 3) ist insofern also “besser” als die Teilfolge (1, 5, 6). Das entscheidende Kriterium ist, dass (1, 2, 3) in einem kleineren Element endet. Es gen¨ugt also, wenn wir uns die kleinstm¨ogliche Endung f¨ur jede L¨ange merken. Definition 2.14 (Teilproblem (Versuch 5)). F¨ur jedes i ∈ {1, . . . , n} und jedes l ∈ {1, . . . , n} sei M (i, l) definiert als die kleinstm¨ogliche Endung einer aufsteigenden Teilfolge der L¨ange l im Bereich A[1..i]. Falls es keine solche Teilfolge gibt, so sei M (i, l) = ∞. Rekursion Um die Werte von M (i, l) rekursiv zu berechnen, unterscheiden wir zwei F¨alle: 1) i = 1: In diesem Fall ist M (i, l) = { A[1] falls l = 1, ∞ sonst. 2) i ≥ 2: In diesem Fall betrachten wir zwei M¨oglichkeiten: a) Wir verwenden das Element A[i] nicht. In diesem Fall ist M (i, l) = M (i− 1, l). b) Wir verwenden das Element A[i]. Dies ist nur m¨oglich, falls M (i − 1, l − 1) < A[i] gilt, denn nur dann k¨onnen wir das Element A[i] an eine aufstei- gende Teilfolge der L¨ange l−1 anh¨angen. In diesem Fall ist M (i, l) = A[i], Wir m¨ussen also das Minimum der beiden Werte M (i − 1, l) und A[i] nehmen. 25Man kann leichte Optimierungen vornehmen, indem man feststellt, dass E(i, l) = 0 f¨ur alle l > i gilt. Diese ¨andert aber nichts an der asymptotischen Laufzeit. 38 Beispiele Formal l¨asst sich diese Rekursion wie folgt schreiben: M (i, l) =    A[1] falls i = 1 und l = 1, ∞ falls i = 1 und l > 1, min{M (i − 1, l), A[i]} falls i ≥ 2 und M (i − 1, l − 1) < A[i], M (i − 1, l) sonst. Laufzeitanalyse Um die Werte von M (i, l) zu berechnen, k¨onnen wir eine Tabelle der Gr¨osse n × n verwenden. Jeder Eintrag der Tabelle l¨asst sich in konstanter Zeit berechnen. Die Gesamtlaufzeit des Algorithmus ist daher O(n2). Weitere Verbesserung Wir k¨onnen die Laufzeit noch weiter verbessern, indem wir die Zeilen M (i, ·) der DP-Tabelle genauer untersuchen. Zun¨achst beobachten wir, dass jede Teilfolge einer AT wieder aufsteigend ist. Wir k¨onnen deshalb jede AT der L¨ange l + 1 zu einer AT der L¨ange l abk¨urzen, indem wir einfach eines der Elemente weglassen. Wenn es also eine AT der L¨ange l + 1 gibt, die in einem Wert endet, dann endet auch eine AT der L¨ange l in diesem Wert. Da M (i, l) den kleinsten erreichbaren Endwert einer AT in A[1..i] bezeichnet, gilt also M (i, l) ≤ M (i, l + 1) f¨ur alle i und l. Mit anderen Worten: Die Zeilen der DP-Tabelle sind sortiert. i\\l 1 2 3 4 5 1 3 ∞ ∞ ∞ ∞ 2 3 7 ∞ ∞ ∞ 3 3 7 8 ∞ ∞ 4 3 4 8 ∞ ∞ 5 3 4 5 ∞ ∞ Abb. 2.5 Beispiel der Tabelle M (i, l) mit A = [3, 7, 8, 4, 5] Schauen wir uns das Beispiel in Abbildung 2.5 an, so stellen wir ausserdem fest, dass sich von Zeile i zu Zeile i+1 nur ein einziger Wert ¨andert, und zwar in der Spalte l mit M (i, l − 1) < A[i + 1] ≤ M (i, l), wobei wir die erste Bedingung ignorieren, falls A[i+1] ≤ M [i, 1] ist. Die beiden Eintr¨age M (i, l−1) und M (i, l) sind durch rote Pfeile markiert. Dies liegt daran, dass es wegen der ersten Bedingung eine aufsteigende Teilfolge der L¨ange l − 1 gibt, die wir durch A[i + 1] verl¨angern k¨onnen. Dadurch verbessert sich der Wert M (i + 1, l) im Vergleich zu M (i, l) auf A[i + 1]. Dagegen k¨onnen wir A[i + 1] wegen der zweiten Bedingung nicht an aufsteigende Teilfolgen der L¨ange ≥ l anh¨angen. F¨ur L¨angen < l k¨onnen wir A[i + 1] zwar anh¨angen, aber 2.8 L¨angste aufsteigende Teilfolge 39 A[i + 1] ist als Endwert schlechter als der schon bekannten Wert, weshalb sich f¨ur solche l ebenfalls nichts ¨andert. Durch diese Beobachtung k¨onnen wir die Berechnung beschleunigen, indem wir ein eindimensionales Array T [1..n] benutzen, in dem wir in der i-ten Iteration die Werte M [i, l] speichern. Ein Beispiel ist in Abbildung 2.6 angegeben. Dies f¨uhrt auf den folgenden Pseudocode, um die L¨ange einer LAT zu berechnen. Longest-Ascending-Subsequence(A[1..n]) L¨angste aufsteigende Teilfolge1 T [1..n] ← new table 2 T [1] ← A[1]; for l ← 2, 3, . . . , n do T [l] ← ∞ ▷ initialization for i = 1 3 for i ← 2, 3, . . . , n do 4 l ← smallest index with A[i] ≤ T [l] ▷ use binary search 5 T [l] ← A[i] ▷ only need to update one entry 6 return max{l : T [l] < ∞} ▷ maximal length l 1 2 3 4 5 6 7 M (∗, l) ∞ ∞ ∞ ∞ ∞ ∞ ∞ 2 13 17 78 25 99 9 11 28 4 15 Abb. 2.6 Berechnung der L¨ange einer LAT mit einem einzelnen Array, das jeweils geup- datet wird, f¨ur den Input 2, 13, 17, 9, 11, 4, 78, 28, 15, 25, 99. Anfangs steht ∞ in jeder Zelle. Jeder neue Wert ¨uberschreibt einen der alten Werte, beispielsweise wird f¨ur ℓ = 2 der Wert ∞ im Laufe der Zeit durch 13, dann durch 9 und schliesslich durch 4 ¨uberschrieben. Dabei k¨onnen wir jeweils bin¨are Suchen benutzen, um die Stelle l zu finden, die wir ¨andern m¨ussen. Jede solche Suche braucht Zeit O(log n). Da wir n Zeilen haben, ist die Gesamtlaufzeit O(n log n). Am Ende stehen in T f¨ur jede L¨ange l entweder der kleinste Endwert einer aufsteigenden Teilfolge mit L¨ange l in A[1..n], oder ∞ falls es keine aufsteigende Teilfolge der L¨ange l gibt. Wir geben daher das gr¨osste l aus, f¨ur das T [l] < ∞ ist. Man kann mit einem informationstheoretischen Argument zeigen, dass alle ver- gleichsbasierten Algorithmen im Worst Case eine Laufzeit von Ω(n log n) haben. Wir haben also einen Algorithmus mit optimaler Laufzeit gefunden. Das Argument f¨ur die untere Schranke ist trickreicher als die bisherigen unteren Schranken f¨ur Suchen und f¨ur Sortieren, da man f¨ur die Zahl der zu unterscheidende F¨alle im Entschei- dungsbaum nicht einfach die Zahl der m¨oglichen Outputs nimmt. Wir verzichten daher auf diesen Beweis. 40 Beispiele R¨uckverfolgung Mit obigem Pseudocode k¨onnen wir zwar die L¨ange einer LAT bestimmen, aber nicht die LAT selbst finden. R¨uckverfolgen funktioniert auch nicht, weil wir die Werte M (i, l) f¨ur i < n ja ¨uberschrieben haben. Wir k¨onnen das aber leicht beheben, indem wir etwas Zusatzinformation speichern. 2 13 17 9 11 4 78 28 15 25 99 Abb. 2.7 In einem separaten Array speichern wir Zusatzinformationen (Pfeile) f¨ur die R¨uckverfolgung der LAT. Der Input ist wie oben 2, 13, 17, 9, 11, 4, 78, 28, 15, 25, 99. Aus Ab- bildung 2.6 wissen wir, dass eine LAT L¨ange 6 hat und in 99 endet. Daher starten wir in 99 und erhalten die LAT durch R¨uckverfolgen der Pfeile (in blau). F¨ur jedes i haben wir den Wert A[i] ja nur in einer einzigen Spalte gespeichert, d.h. es gab nur eine einzige L¨ange l, f¨ur die eine AT mit Endpunkt A[i] relevant war. Wir k¨onnen deshalb in einem separaten Array R[1..n] f¨ur jedes i den Vorg¨anger des Endpunkt A[i] f¨ur diese AT speichern. Das heisst, falls l die Stelle ist, die wir mit T [l] ← A[i] ¨uberschreiben, dann speichern wir den Wert R[n] ← T [l − 1], denn wir erreichen eine Folge mit L¨ange l und Endwert A[i] ja dadurch, dass wir A[i] an eine Folge mit L¨ange l − 1 und Endwert T [l − 1] anh¨angen. Mit dieser Zusatzinformation ist die Rekonstruktion der LAT dann durch R¨uckverfolgen im Array R m¨oglich, siehe Abbildung 2.7. 2.9 Matrixkettenmultiplikation In diesem Kapitel betrachten wir das Problem der Matrixkettenmultiplikation. Ge- geben seien n Matrizen A1, A2, . . . , An. Die Matrix Ai habe dabei die Dimension ki−1 × ki. Gesucht ist eine m¨oglichst effiziente Berechnung der Matrix A1 · A2 · · · An. Beispiel. Betrachten wir drei Matrizen A1, A2, A3 der Dimensionen k × 1, 1 × k und k×1. Die naive Methode, zuerst A1·A2 und anschliessend (A1·A2)·A3 auszurechnen, ben¨otigt Θ(k2) viele Operationen. Hingegen ben¨otigt die Berechnung von A1 ·(A2 ·A3) nur Θ(k) viele Operationen. 2.9 Matrixkettenmultiplikation 41 A1 × A2 × A3 (A1 · A2) · A3 Θ(k2) Ops = A1 · A2 × A3 Θ(k2) Ops = A1 · A2 · A3 A1 · (A2 · A3) Θ(k) Ops = A1 × A2 · A3 Θ(k) Ops = A1 · A2 · A3 Das Problem besteht darin, die beste Klammerung f¨ur das Produkt A1 · A2 · · · An zu finden. Die Anzahl der m¨oglichen Klammerungen w¨achst exponentiell in n, daher ist es nicht effizient, alle Klammerungen auszuprobieren.26 Dynamische Programmierung Um das Problem effizient zu l¨osen, verwenden wir dynamische Programmierung. Dazu definieren wir das folgende Teilproblem: Definition 2.15 (Teilproblem). F¨ur 1 ≤ i ≤ j ≤ n sei M (i, j) die minimale Anzahl an Operationen, die man ben¨otigt, um das Produkt Ai · Ai+1 · · · Aj zu berechnen. Der Einfachheit halber z¨ahlen wir hier nur Multiplikationen von Eintr¨agen. Die Zahl der Additionen liefert asymptotisch dieselbe Gr¨ossenordnung. Rekursion Um die Werte von M (i, j) rekursiv zu berechnen, betrachten wir alle m¨oglichen Positionen s, an denen wir das Produkt Ai · Ai+1 · · · Aj in zwei Teilpro- dukte aufteilen k¨onnen, wir unterscheiden also nach der Position der letzten Multi- plikation, die wir in diesem Bereich ausf¨uhren. Falls diese Multiplikation zwischen den Stellen s und s + 1 liegt, m¨ussen wir am Ende die beiden Matrizen (Ai · . . . · As) und (As+1 · . . . · Aj) miteinander multiplizieren. Das erste ist eine ki−1 × ks-Matrix, das zweite eine ks × kj-Matrix. Die Ergebnismatrix hat ki−1 × kj Eintr¨age, und jeden davon k¨onnen wir als das Skalarprodukt zweier Vektoren der Dimension ks berech- nen, wof¨ur wir ks Multiplikationen von reellen Zahlen ben¨otigen (sowieso ks − 1 Additionen, die wir hier aber ignorieren). Wir k¨onnen die Matrixmultiplikation also 26Diese Anzahl wird auch die n-te Catalan-Zahl genannt. ¨Ahnlich wie die Fibonacci-Zahlen treten Catalan-Zahlen an den verschiedensten Stellen in Mathematik und Informatik auf. 42 Beispiele mit ki−1 · ks · kj Operationen durchf¨uhren.27 Wir erhalten die folgende Rekursion: M (i, j) = { 0 falls i = j, mini≤s<j{M (i, s) + M (s + 1, j) + ki−1 · ks · kj} sonst. Berechnungsreihenfolge Anders als bei bisherigen Problemen berechnen wir die Werte hier nach aufsteigender L¨ange j − i. Wir berechnen also erst die Werte auf der Diagonalen i = j, und bewegen uns dann von der Diagonalen weg. M j 0 i 0 0 Laufzeitanalyse Um die Werte von M (i, j) zu berechnen, k¨onnen wir eine Tabelle der Gr¨osse n × n verwenden. Jeder Eintrag der Tabelle l¨asst sich in Zeit O(j − i) ≤ O(n) berechnen. Die Gesamtlaufzeit des Algorithmus ist daher O   n∑ i=1 n∑ j=i n   = O(n3). Wiederum k¨onnten wir versuchen, genauer zu rechnen und ¨uber j − i statt ¨uber n zu summieren. Dies ergibt jedoch trotzdem Θ(n3), denn man kann auch dann Θ(n2) Summanden finden, die alle Gr¨osse Θ(n) haben, zum Beispiel die Summanden mit 1 ≤ i ≤ n/3 und 2n/3 ≤ j ≤ n. 27Dies ist die ben¨otigte Zahl der Operationen mit der naiven Methode aus der Linearen Alge- bra. ¨Ahnlich wie bei der Multiplikation von nat¨urlich Zahlen kann man auch Matrizen schneller multiplizieren. Die beste bekannte Methode f¨ur quadratische n × n-Matrizen ben¨otigt O(n 2.37...) Operationen, w¨ahrend die naive Methode O(n 3) Operationen durchf¨uhrt. Es ist eine bedeutende offene Frage der Informatik, welche der beste erreichbare Exponent ist.","libVersion":"0.3.2","langs":""}
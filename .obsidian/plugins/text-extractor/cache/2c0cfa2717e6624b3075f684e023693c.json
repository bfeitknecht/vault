{"path":"sem3/LinAlg/VRL/extra/misc/cs-lens/LinAlg-lens-gauss-cost.pdf","text":"Linear Algebra ETH Z¨urich, HS 2024, 401-0131-00L The Computer Science Lens Multiplying Matrices and Solving Systems of Linear Equations Faster Bernd G¨artner October 17, 2024 The Cost of Gauss Elimination Solving a system Ax = b of m equations in m variables using Gauss Elimination takes O(m3) operations. Can we do it faster? Yes, by doing something else faster: matrix multiplication! 2 / 12 Cost of Matrix Multiplication (square case m × m) AB =     |u1||u2|...|um|      ︸ ︷︷ ︸ A, row notation   | | | v1 v2 · · · vm | | |   ︸ ︷︷ ︸ B, column notation =      u1 · v1 u1 · v2 · · · u1 · vm u2 · v1 u2 · v2 · · · u2 · vm ... ... . . . ... um · v1 um · v2 · · · um · vm      ︸ ︷︷ ︸ m2 scalar products Scalar product of u, v ∈ Rm: u · v = u1v1 + u2v2 + · · · + umvm. Cost of computing AB: ▶ m multiplications per scalar product m3 multiplications in total ▶ m − 1 additions per scalar product m3 − m2 additions in total Can we do it with less operations (multiplications / additions)? Volker Strassen (1969): yes! [Str69] 3 / 12 2 × 2, standard way: 8 multiplications (·), 4 additions (+) [ a11 a12 a21 a22 ] ︸ ︷︷ ︸ A [ b11 b12 b21 b22 ] ︸ ︷︷ ︸ B = [ a11 · b11 + a12 · b21 a11 · b12 + a12 · b22 a21 · b11 + a22 · b21 a21 · b12 + a22 · b22 ] ︸ ︷︷ ︸ AB = [ c11 c12 c21 c22 ] ︸ ︷︷ ︸ C Graphically: C =                    c11 c12 ▶ ▶ ▶ ▶ ▶ ▶ ▶ ▶ c21 c22                          a11 a12 a21 a22 b11b12b21b22 ▶ ▶ = a11b11 + a12b21       4 / 12 2 × 2, Strassen way: 7 multiplications (·), 18 additions (+, −) (a11 + a22) (a21 + a22) a11 a22 (a11 + a12) (a21 − a11) (a12 − a22) · · · · · · · (b11 + b22) b11 (b12 − b22) (b21 − b11) b22 (b11 + b12) (b21 + b22) ▶ ▶ ▶ ▶ ▶ ▶ ▶ ◀ ◀ ▶ ▶ ▶ ◀ ◀ ▶ ▶ ▶ ▶ ◀ ◀ p1 p2 p3 p4 p5 p6 p7 Auxiliary terms: 7 multiplications, 10 additions (◀: product has negative sign) p1 + p4 − p5 + p7 p3 + p5 p2 + p4 p1 − p2 + p3 + p6 ▶ ▶◀ ▶ ▶◀ ▶◀ ▶◀ ▶◀ ▶ ▶◀ ▶ ▶ ▶◀ ▶ ▶◀ ▶◀ ▶◀ ▶◀ ▶ ▶◀ ▶ c11 c12 c21 c22 Entries of C = AB: 8 additions 5 / 12 4 × 4: = 2 × 2 with matrices (2 × 2), not numbers! A11 A12    a11 a12 a13 a14 a21 a22 a23 a24 a31 a32 a33 a34 a41 a42 a43 a44     A21 A22 ︸ ︷︷ ︸ A B11 B12    b11 b12 b13 b14 b21 b22 b23 b24 b31 b32 b33 b34 b41 b42 b43 b44     B21 B22 ︸ ︷︷ ︸ B = [A11 A12 A21 A22 ] ︸ ︷︷ ︸ 2 × 2 block form of A [ B11 B12 B21 B22 ] ︸ ︷︷ ︸ 2 × 2 block form of B = [ A11B11 + A12B21 A11B12 + A12B22 A21B11 + A22B21 A21B12 + A22B22 ] ︸ ︷︷ ︸ 2 × 2 block form of AB ← check this! Standard way: 8 multiplications and 4 additions . . . of 2 × 2 matrices Strassen way: 7 multiplications and 18 additions . . . of 2 × 2 matrices 6 / 12 Cost (how many operations on numbers?) 4 × 4: Standard Strassen 43 43 − 42 7 multiplications and 18 additions of 2 × 2 matrices (4 × 4) · (4 × 4) · + 64 48 7 · (2 × 2) · (2 × 2) · + 7 18 + 18 · (2 × 2) + (2 × 2) + 4 = (4 × 4) · (4 × 4) · + 49 198 8 × 8 (use 2 × 2 block form with 4 × 4 matrices as blocks): Standard Strassen 83 83 − 82 7 multiplications and 18 additions of 4 × 4 matrices (8 × 8) · (8 × 8) · + 512 448 7 · (4 × 4) · (4 × 4) · + 49 198 + 18 · (4 × 4) + (4 × 4) + 16 = (8 × 8) · (8 × 8) · + 343 1674 7 / 12 Cost (how many operations on numbers?) 2k × 2k (general formula; officially needs proof by induction): Standard Strassen (2k × 2k ) · (2k × 2k ) · + 8k 8k − 4k (2k × 2k ) · (2k × 2k ) · + 7k 6(7k − 4k ) Checking... Standard Strassen · + · + k 8k 8k − 4k 7k 6(7k − 4k ) 1 8 4 7 18 2 64 48 49 198 3 512 448 343 1674 8 / 12 Is Strassen ever faster? Let’s count total number of operations! Standard Strassen Strassen − Standard ·/+ ·/+ ·/+ k 2 · 8k − 4k 7 · 7k − 6 · 4k 7 · 7k − 2 · 8k − 5 · 4k 1 12 25 13 2 112 247 135 3 960 2017 1057 ... 9 268173312 280902385 12729073 10 2146435072 1971035287 −175399785 11 17175674880 13816121377 −3359553503 ... For 1024 × 1024 (and larger) matrices, Strassen is faster! 9 / 12 m × m There is a version of Strassen’s algorithm that works for all m (not only m = 2k ). Standard Strassen ·/+ ·/+ m ≈ 2m3 ≈ 4.7m2.8 log2(7) = 2.80735 . . . Strassen’s algorithm started an ongoing race for better exponents than 2.8. The “2.37 . . . family”: since 1990 ▶ ≈ cm2.376 (c some large constant) [CW90] ▶ Latest: ≈ c ′m2.371866 (c ′ some even larger constant) [DWZ23]. Some people believe that ≈ Cm2 (C a super large constant) is possible, but nobody knows how to get there. 10 / 12 Applications How important is matrix multiplication? Very important! Many matrix problems (some of them introduced later in this course) can be reduced to matrix multiplication and therefore be solved faster using the algorithms by Strassen and his successors. Important for us: ▶ Computation of the inverse with ≈ cm2.37... operations ▶ Proof by reduction of inverse computation to matrix multiplication [THCS22] ▶ Since solving Ax = b reduces to inverse computation (x = A−1b), we can also solve systems of linear equations faster than using Gauss elimination. ▶ Also true (but more difficult) if system has no unique solution / A−1 does not exist [Sch72, KG85] ▶ Big theoretical improvement over ≈ cm3 that we get from Gauss elimination ▶ Practical improvements only for impractically large m 11 / 12 References Don Coppersmith and Shmuel Winograd. Matrix multiplication via arithmetic progressions. Journal of Symbolic Computation, 9(3):251–280, 1990. https://doi.org/10.1016/S0747-7171(08)80013-2. Ran Duan, Hongxun Wu, and Renfei Zhou. Faster matrix multiplication via asymmetric hashing, 2023. https://arxiv.org/abs/2210.10173. Walter Keller-Gehrig. Fast algorithms for the characteristics polynomial. Theoretical Computer Science, 36:309–317, 1985. https://doi.org/10.1016/0304-3975(85)90049-0. A. Sch¨onhage. Unit¨are Transformationen großer Matrizen. Numerische Mathematik, 20(5):409–417, 1972. https://doi.org/10.1007/BF01402563. Volker Strassen. Gaussian elimination is not optimal. Numerische Mathematik, 13(4):354–356, 1969. https://doi.org/10.1007/BF02165411. Ronald L. Rivest Thomas H. Cormen, Charles E. Leiserson and Clifford Stein. Introduction to Algorithms, Fourth Edition. The MIT Press, 2022. https://mitpress.mit.edu/9780262046305/introduction-to-algorithms/. 12 / 12","libVersion":"0.5.0","langs":""}
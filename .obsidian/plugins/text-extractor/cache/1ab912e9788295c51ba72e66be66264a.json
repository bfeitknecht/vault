{"path":"sem2/PProg/PV/summaries/Summary.pdf","text":"Parallele Programmierung Based on fschwinn fs22 summary Parallele Programmierung Threads Implementing States Critical Section Wait/Notify Important Thread Properties Hardware Pipelining Speedup Calculations Amdahl Gustafson Visualizations Task Graphs State Space Diagram Dependency Graph Fork/Join Problem Types Executor Service Locks MPI Transactions Histories Threads Implementing Können erstellt werden in dem man: Runnable implementiert new Thread(new MyClassThread(args)).start() Thread Subklasse new MyClassThread(args).start() In beiden fällen muss die run Methode überschrieben werden mit dem Code der im Thread ausgeführt werden soll. Klassen können auch inline erstellt werden: new Thread(new Runnable() { public void run() { // code here } }).start() States A thread always has a certain state: New: Created/Instantiated Runnable: After start() is called, can now be scheduled, default state during lifetime Blocked: Failed to acquire lock Waiting: After wait() is called, exits via notify() by a different thread Terminated: interrupt() called or execution completed Critical Section A code block only one thread at a time may execute/enter. Declared using synchronized Wait/Notify Methods are always called inside synchronized(lock) lock.wait() inside while loop as long as entry condition is false releases the lock, execution only continues after notification notify() -> the highest priority thread is woken up, can cause deadlocks notifyAll() -> all are woken up Conditions group threads: lock.newCondition() threads can await on a specific condition notify -> signal (same for All) Important Thread Properties Thread.currentThread() gets the Thread (object) that is executing this code getId() setName() setPriority(Thread.MAX_PRIORITY) getState() == State.TERMINATED Hardware Different methods are employed to speedup (also sequential) computation on a hardware level: Vectorization: Common parallel tasks such as adding two vectors have dedicated instructions Instruction Level Parallelism (ILP): Independent Instructions get calculated in parallel, combined with Out-of-Order and speculative execution Pipelining: Hardware elements on a CPU are arranged to be used most effectively Pipelining Important Definitions: Throughput: max time of a single stage Latency: Time for one execution of the pipeline, constant over time if balanced Balanced: All stages have equal length Lead In: time until the last user enters the first stage Lead Out: time from end of full utilization to all stages free Speedup Calculations Definition Speedup: Amdahl Calculate Time speedup for a fixed amount of work Derivation: 1. 2. 3. Plug in: Gustafson Speedup/Increase in work over a fixed time Visualizations Task Graphs Visualizes sequential and parallel parts of a program : sum of nodes T_\\inf: sum of nodes on critical path Processors for max. Speedup: to the width (necessarily), instead at every stage, look wether another processor added could speed up the process (one processor could \"do 2 widths\" because something is taking longer) State Space Diagram No ... when: Mutual Exclusion: State with both processes in CS Deadlock: state without outgoing edges that isn't the final state Starvation: Final State unreachable Dependency Graph Different symbols visualize resources and processes Relations: Resource has process Process wants resource Cycle: Deadlock Fork/Join Implement recursive multi-threaded algorithms Task Class: - extends RecursiveTask<Integer> - extends RecursiveAction for return type void (often multi-output, in-place modification) - initialised with all inputs required for computation (generally an array, startIdx and length to operate on) - often maintains a static CUTOFF to decide when to sequentially compute - public protected T compute() function implemented to do the actual work Recurse by: - Instantiate MyTask n-times with required attributes - .fork() all but one - Merging: Call .compute() on non-forked, and then .join() on the rest, these calls return the calculated values Starting: ForkJoinPool f = new ForkJoinPool(); f.invoke(new MyTask(args)); Problem Types Reduce Map Pack: array filter: \"bit-vector\": int (1/0) array wether to keep element i prefix sum of that, if element kept, this indicates its position in new array make new array using this info Prefix: Map, using information about previous and this element Executor Service Maintains a Thread Pool and lets us submit tasks to be executed on these: Tasks implement Runnable (void return) or Callable<T> Instantiate new Executors.newFixedThreadPool(4) Submit: e.submit(new MyTask()) (result contained in a Future) Locks Not covered here because a good overview of them already exists in the exam prep by @toffermann. MPI MPI.COMM.Send and Recv are the only relevant functions for this exam which do what they say (point to point) workers are grouped as communicator can communicate inside their group a worker has a unique rank (id) inside their communicator Transactions Intuitive Histories Analysis: Linearizability: We can find invocation/realisation points s.t. the history makes sense Sequential Consistency: We can move around threads as a whole and widen gaps, s.t. the history makes sense Definitions: Equivalent: per-thread projections equal complete: every invocation returns well-formed: per-thread projections are sequential legal: functions behave as they are defined sequential: no overlapping methods","libVersion":"0.3.2","langs":""}
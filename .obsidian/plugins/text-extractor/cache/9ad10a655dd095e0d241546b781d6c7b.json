{"path":"sem2/PProg/VRL/extra/kuhn/PProg-w12-kuhn.pdf","text":"Parallel Programming Session 12 Spring 2024, Sarah Kuhn Schedule Post-Discussion Assignment 11 Theory Recap Quiz Pre-Discussion Assignment 12 Fork Join Framework the semester so far Last week Question about locking the tail. Accepted both at the exam J Depends on how hand-over-hand locking is implemented but for «correct adding», not necessary.Post-Discussion Ex.11 Assignment 11 Won’t go through everything in class -> look at the solutions You need to know about coarse, fine, optimistic and lazy synchronization/locking Does someone have a specific wish ? Look at a certain implementation specifically ? Recap Coarse vs fine- grained ? How many list traversal for add/remove ? Recap Coarse vs fine- grained ? How many list traversal for add/remove ? Invariant of hand-over-hand locking ? Recap Coarse vs fine- grained ? How many list traversal for add/remove ? Invariant of hand-over-hand locking ? Optimistic vs. fine-grained locking ? Recap Coarse vs fine- grained ? How many list traversal for add/remove ? Invariant of hand-over-hand locking ? Optimistic vs. fine grained locking ? How many lock releases in big-O Notation for optimistic add vs. fine grained add ? Recap Coarse vs fine- grained ? How many list traversal for add/remove ? Invariant of hand-over-hand locking ? Optimistic vs. fine grained locking ? How many lock releases in big-O Notation for optimistic add vs. fine-grained add ? What is similar in lazy and optimistic synchronization ? What is diffrent ? Structure Initialisation, point to the start of the list Structure Initialisation, point to the start of the list Find the node (if existent, else return false) Structure Initialisation, point to the start of the list Find the node (if existent, else return false) Do the work ( add or remove, modify references f.eg .next() =…..) Position of the locks and unlocks depend on your locking strategy Structure Initialisation, point to the start of the list Find the node (if existent, else return false) Do the work ( add or remove, modify references f.eg .next() =…..) Position of the locks and unlocks depend on your locking strategy Which locking method is it ? Code snippets «Quiz» Contains-method() To which locking method(s) does it belong ? Code snippets «Quiz» To which locking method(s) does it belong ? Code snippets «Quiz» Looking for a node To which locking method(s) does it belong ? Code snippets «Quiz» To which locking method does it belong ? Code snippets «Quiz» To which locking method(s) does it belong ? Fine grained Locking 21 Optimistic Locking 22 Lazy Locking 23 Take-Away You should know the difference between these different approaches and what the Pro’s/Con’s of each method are. Theory Recap RWLocks again & lock-free algorithms Readers-writers lock 26 Reader-Writer Lock data type for synchronization : reader/writer lock 3 states: “not held” “held for writing” by one thread «held for reading» by one/multiple threads Reader-Writer Lock data type for synchronization : reader/writer lock 3 states: “not held” “held for writing” by one thread «held for reading» by one/multiple threads Invariants: 29 Readers-writers lock with monitorsAssesment Is the lock fair ? Assesment Is the lock fair ? prioritizes writers… Assesment Is the lock fair ? prioritizes writers… What about its performance, do you have an optimization ? Assesment Is the lock fair ? prioritizes writers… What about its performance, do you have an optimization ? Lock Conditions !!! RW Lock Skip ListSkip List Las Vegas Algorithm: Result always correct but runtime is a random variable Skip List Las Vegas Algorithm: Result always correct but runtime is a random variable You have n lists stacked on top of each other -> get sparser as n grows Skip List Las Vegas Algorithm: Result always correct but runtime is a random variable You have n lists stacked on top of each other -> get sparser as n grows “If (current > key) -> go to lower level via prev, else follow the next pointer in the same level” Skip List Las Vegas Algorithm: Result always correct but runtime is a random variable You have n lists stacked on top of each other -> get sparser as n grows “If (current > key) -> go to lower level via prev, else follow the next pointer in the same level” Search: Expected runtime O(log(n)), worst case same as fully locked. Skip List Las Vegas Algorithm: Result always correct but runtime is a random variable Skip List “If (current > key) -> go to lower level via prev, else follow the next pointer in the same level” Skip List Las Vegas Algorithm: Result always correct but runtime is a random variable in expectation skip half the nodes O(log n) search Skip List Las Vegas Algorithm: Result always correct but runtime is a random variable Skip List Find insertion point and lock predecessor, add(6): Skip List Las Vegas Algorithm: Result always correct but runtime is a random variable Locks :/ With skip lists we used locks Locks :/ With skip lists we used locks Locks -> easily make operations atomic but….. lot of disadvantages: Locks :/ With skip lists we used locks Locks -> easily make operations atomic but….. lot of disadvantages: ->pessimistic by design -> locks waste resources (->Amdahl’s law) -> spinlocks/ busy waiting with some locks ->blocking semantics (if a thread dies in CS, all suffer) + other major risks…. Problems with locksProblems with locksProblems with locksMotivation for non-blockingRecap: CAS “Updates if current value like the expected value” Non-blocking counter Implement an atomic counter using CAS getValue() and inc() method Public class CasCounter{ private AtomicInteger value; Non-blocking counter: solution Public class CasCounter{ private AtomicInteger value; Public int getVal(){ return value.get(); } Public int inc(){ int v; do{ v= value.get(); } while (!value.compareAndSet(v,v+1); return value; Read current value, try to set it and return if success else redo. Non-blocking counter: solution Public class CasCounter{ private AtomicInteger value; Public int getVal(){ return value.get(); } Public int inc(){ int v; do{ v= value.get(); } while (!value.compareAndSet(v,v+1); return value; Is it a problem if one thread dies, are the others affected ? Non-blocking counter: solution Public class CasCounter{ private AtomicInteger value; Public int getVal(){ return value.get(); } Public int inc(){ int v; do{ v= value.get(); } while (!value.compareAndSet(v,v+1); return value; If CAS succeeds is it guaranteed that no other threads modified the value ? Progress conditions with& without locks Blocking: a thread can indefinitely delay another thread (imagine thread holding lock dies in CS) Non-blocking: failure or suspension of one thread could never cause failure or suspension of another thread. “never blocks other threads” example: CAS Progress conditions with& without locks Blocking: a thread can indefinitely delay another thread (imagine thread holding lock dies in CS) Non-blocking: failure or suspension of one thread could never cause failure or suspension of another thread. example: CAS Non blocking in Java ? Java.util.concurrent.atomic Non blocking in Java ? Java.util.concurrent.atomic We have something similar like CAS compareAndSet() // like CAS Returns true if succeeded, not the old value like CAS In Java Implement lock/ unlock with getAndSet() compareAndSet() boolean set(); boolean get(); boolean compareAndSet(boolean expect, boolean update); boolean getAndSet(boolean newValue); atomically set to value update iff current value is expect. Return true on success. sets newValue and returns previous value. DCAS Double compare and swap DCAS Double compare and swap AtomicMarkableReference<T>: encapsule reference to an object of type T & boolean mark bit DCAS Double compare and swap AtomicMarkableReference<T>: encapsule reference to an object of type T & boolean mark bit Can update both atomically at once ! DCAS Double compare and swap AtomicMarkableReference<T>: encapsule reference to an object of type T & boolean mark bit Can update both atomically at once ! Takes 4 values: 2 expected, 2 updates DCAS(mem1, mem2, next1, next2) DCAS Double compare and swap AtomicMarkableReference<T>: encapsule reference to an object of type T & boolean mark bit Can update both atomically at once ! Takes 4 values: 2 expected, 2 updates DCAS(mem1, mem2, next1, next2) !!! not practical because often not supported in hardware Progress conditions with& without locks Non-blocking -> use of CAS and other atomic operations ! now: implement lock-free data structures Lock-free stackLock-free stack We could use CAS on the top pointer: to update it Lock-free stack We could use CAS on the top pointer: to update it Quick: How would we implement it blocking ? Lock-free stack We could use CAS on the top pointer: to update it Quick: How would we implement it blocking ? ->synchronize the methods Lock-free stackLock-free stackAssumptions Now every time we push something we create a new node Assumptions Now every time we push something we create a new node Every time we pop something we leave it to the OS to handle it -> garbage collector Assumptions Now every time we push something we create a new node Every time we pop something we leave it to the OS to handle it -> garbage collector But what if we reuse our nodes ? remove them -> put them in a node pool push a new node -> take the new node from the node pool Assumptions Now every time we push something we create a new node Every time we pop something we leave it to the OS to handle it -> garbage collector But what if we reuse our nodes ? remove them -> put them in a node pool push a new node -> take the new node from the node pool What does that change for us ? Node Pool Instead of creating new node each time, reuse nodes from a node pool Node Pool Instead of creating new node each time, reuse nodes from a node pool Seen in lecture: massive execution time improvement with node pool BUT some runs show wrong behaviour/error. Why ? ABA problemABA problemABA problemABA problemABA problemABA problemABA problem \"The ABA problem ... occurs when one activity fails to recognize that a single memory location was modified temporarily by another activity and therefore erroneously assumes that the overall state has not been changed.\" ABA problem \"The ABA problem ... occurs when one activity fails to recognize that a single memory location was modified temporarily by another activity and therefore erroneously assumes that the overall state has not been changed.\" Out of the perspective of one single thread the state has not changed because it still sees the same ABA problem \"The ABA problem ... occurs when one activity fails to recognize that a single memory location was modified temporarily by another activity and therefore erroneously assumes that the overall state has not been changed.\" Out of the perspective of one single thread the state has not changed because it still sees the same… But it ignores that the state in between might has changed, hence the overall state has changed. ABA problemABA problem So the problem is, thread assumes nothing has changed because from his perspective nothing changed. Any ideas on how to solve it ? ABA problem DCAS (double compare and swap): check that head and head.next() are as expected Attempts on solving it : ABA problem DCAS (double compare and swap) check that head and head.next() are as expected Garbage Collection then would not need a node pool (slow + doesn’t always exist) Attempts on solving it : ABA problem DCAS (double compare and swap) check that head and head.next() are as expected Garbage Collection then would not need a node pool (slow + doesn’t always exist) Pointer Tagging does not cure the problem, rather delay it can be practical Attempts on solving it : ABA problem DCAS (double compare and swap) check that head and head.next() are as expected Garbage Collection then would not need a node pool (slow + doesn’t always exist) Pointer Tagging does not cure the problem, rather delay it can be practical Hazard Pointers Attempts on solving it : ABA problem DCAS (double compare and swap) check that head and head.next() are as expected Garbage Collection then would not need a node pool (slow + doesn’t always exist) Pointer Tagging does not cure the problem, rather delay it can be practical Hazard Pointers (Transactional Memory -> later ) Attempts on solving it : Pointer TaggingPointer Tagging ABA happens often with a CAS on a pointer -> f.eg the top pointer. Idea: use some bits top tag the pointer Pointer Tagging ABA happens often with a CAS on a pointer -> f.eg the top pointer. Idea: use some bits top tag the pointer f.eg pointer aligned modulo 32 bit -> spare 5 bits Pointer Tagging ABA happens often with a CAS on a pointer -> f.eg the top pointer. Idea: use some bits top tag the pointer f.eg pointer aligned modulo 32 bit -> spare 5 bits Now: each time you use the pointer, increment the counter aka the last few unused bits Pointer Tagging Does it solve the ABA problem ? Pointer Tagging Does it solve the ABA problem ? no but less probable, 32 versions of each pointer exist Hazard Pointers ABA : some thread has read the pointer P but not completed CAS yet, another thread also uses P and modifies the state. So problem really comes from reusing the pointer. Hazard Pointers ABA : some thread has read the pointer P but not completed CAS yet, another thread also uses P and modifies the state. So problem really comes from reusing the pointer. Idea: before you read the pointer mark it as “hazardous” in an array Hazard Pointers ABA : some thread has read the pointer P but not completed CAS yet, another thread also uses P and modifies the state. So problem really comes from reusing the pointer. Idea: before you read the pointer mark it as “hazardous” in an array Hazard Pointers ABA : some thread has read the pointer P but not completed CAS yet, another thread also uses P and modifies the state. So problem really comes from reusing the pointer. Idea: before you read the pointer mark it as “hazardous” in an array when finished (-> after CAS), remove it from the array Hazard Pointers ABA : some thread has read the pointer P but not completed CAS yet, another thread also uses P and modifies the state. So problem really comes from reusing the pointer. Idea: before you read the pointer mark it as “hazardous” in an array when finished (-> after CAS), remove it from the array if another thread tries to use P, first checks the array ConclusionConclusion Lock-free programming: new kind of problems in comparison to lock-based programming Exam TaskExam Task Lock-free programming: new kind of problems in comparison to lock-based programming Exam TaskExam Task Lock-free programming: new kind of problems in comparison to lock-based programming Exam TaskExam Taskblocking algorithms Upon till now we mainly used blocking synchronization -> use of locks CAS & TAS were our first lock-free synchronization methods Non-blocking algorithms Non-blocking programming different from lock/blocking algorithms f.eg non-blocking stack, ABA problem Non-blocking algorithms Non-blocking programming different from lock/blocking algorithms f.eg non-blocking stack, ABA problem Now: definitions J Progress conditions with& without locks Blocking: threads can go into blocked state, one thread can delay all other threads Progress conditions with& without locks Blocking: threads can go into blocked state, one thread can delay all other threads Non-blocking: threads never enter a blocked state (->implies use of no locks), one thread cannot block all the other threads. Progress conditions with& without locksProgress conditions with& without locks TO DO with locks, thread can delay/bock all other threads without locks, Progress conditions with& without locks TO DO with locks, thread can delay/bock all other threads without locks, Progress conditions with& without locks TO DO with locks, thread can delay/bock all other threads without locks, Progress conditions with& without locks TO DO with locks, thread can delay/bock all other threads without locks, you have to know them !!! Extra: I think of it as : Lock-free = deadlock-free + we don’t need to progress assumptions Wait-free = starvation-free + we don’t need to progress assumptions Lock-free & wait-free are “stronger” (give us guarantees even when threads fail in CS) Hence, Lock-free -> Deadlock-free Wait-free -> Starvation-free Progress assumptions: no thread dies in CS, no thread can block all threads forever. Progress conditions: formal with& without locks Deadlock-free: Whenever at least one thread calls a method/cs, some thread will complete a call in finite number of steps, system-wide progress blocking non blocking Progress conditions: formal with& without locks Deadlock-free: Whenever at least one thread calls a method/cs, some thread will complete a call in finite number of steps, system-wide progress Starvation-free: No thread is blocked from the CS forever. A thread calling a method will complete the call in a finite number of steps. blocking non blocking Operations & data structures without using locks rather using atomic operations like CAS Progress AssumptionsProgress conditions: formal with& without locks Deadlock-free: (assuming progress assumptions) at least one thread is guaranteed to proceed into CS, system-wide progress Starvation-free: (assuming progress assumptions) No thread is blocked from the CS forever. Will enter at some point in time if it wants. Lock-free: whenever a thread is calling a method, some method call completes in a finite number of steps blocking non blocking Progress conditions with& without locks Deadlock-free: (assuming progress assumptions) at least one thread is guaranteed to proceed into CS, system-wide progress Starvation-free: (assuming progress assumptions) No thread is blocked from the CS forever. Will enter at some point in time if it wants. Lock-free: whenever a thread is calling a method, some method call completes in a finite number of steps Wait-free: Every method call finishes in a finite number of steps. blocking non blocking Progress conditions with& without locks Deadlock-free: (assuming progress assumptions) at least one thread is guaranteed to proceed into CS, system-wide progress Starvation-free: (assuming progress assumptions) No thread is blocked from the CS forever. Will enter at some point in time if it wants. Lock-free: whenever a thread is calling a method, some method call completes in a finite number of steps Wait-free: Every method call finishes in a finite number of steps. blocking non blocking Don’t need progress assumptions anymore Implications Wait-free -> Lock-free ? Wait-free -> starvation-free ? Starvation-free -> deadlock-free ? Lock-free -> deadlock-free ? Implications Wait-free -> Lock-free ? Wait-free -> starvation-free ? Starvation-free -> deadlock-free ? Lock-free -> deadlock-free ? Does every algorithm fit into one category ? Implications Wait-free -> Lock-free ? Wait-free -> starvation-free ? Starvation-free -> deadlock-free ? Lock-free -> deadlock-free ? All of the above implications hold J Does every algorithm fit into one category ? No, f.eg algorithms that deadlock. Exam TaskExam Task: solExam TaskExam Task Pre-Discussion Ex.12 Assignment Implement a sensor Different threads: writer threads: -> write the sensor data reader threads: -> read/monitor the sensor data Multi-Sensor SystemYour taskYour task Implement different version of the sensor data class: Your task Implement different version of the sensor data class: blocking version -> based on readers-writers lock Your task Implement different version of the sensor data class: blocking version -> based on readers-writers lock lock-free version Blocking version Procedure: first implement it using standard lock (get and update methods) think where you would only need a write/read lock write it using reader/writer lock in Java (replace lock/unlock with lock/unlock of reader/writer lock) Assignment Have this sensor and many threads could call update, you need to make it thread safe Assignment Have this sensor and many threads could call update, you need to make it thread safe Assignment Have this sensor and many threads could call update, you need to make it thread safe Place calls to lock and unlock accordingly Use RWLocks RW LockRW LockBlocking version Procedure: first implement it using standard lock (get and update methods) think where you would only need a write/read lock write it using reader/writer lock in Java remember: RW Locks in Java aren’t fair, prefer writers ! Blocking version Procedure: first implement it using standard lock (get and update methods) think where you would only need a write/read lock write it using reader/writer lock in Java implement your own fair RWLock ? (see lecture code) 165 Readers-writers lock with monitorsAssignment Have this sensor and many threads could call update, you need to make it thread safe Assignment Have this sensor and many threads could call update, you need to make it thread safe Assignment Have this sensor and many threads could call update, you need to make it thread safe You have the sensor data class, use it here !!! Maybe do something with Atomic Reference to this class ? Lock-free version Procedure: (more detailed on last slide) Lock-free version Procedure: with a single reference update -> need to change all the data at once. How ? Lock-free version Procedure: with a single reference update -> need to change all the data at once. How ? maybe a single CAS on data object fields ? Lock-free version Procedure: with a single reference update -> need to change all the data at once. How ? maybe a single CAS on data object fields ? won’t work because data object has multiple fields. You cannot write multiple fields with one CAS Lock-free version Procedure: with a single reference update -> need to change all the data at once. How ? maybe a single CAS on data object fields ? won’t work because data object has multiple fields. You cannot write multiple fields with one CAS But maybe use the reference to the data object itself and not its fields ? CAS on object references f.eg AtomicReference<SensorData> data; Hint/Help Create a reference where we can atomically update it Hint/Help Create a reference where we can atomically update it Now try to somehow CAS it after you did some preparation of the new Sensor data Hint/Help Create a reference where we can atomically update it Now try to somehow CAS it after you did some preparation of the new Sensor data -> Attention Complete spoiler on the next slide SpoilerLet’s start See you next week J","libVersion":"0.3.2","langs":""}
{"path":"sem1/AuD/extra/AuD_script.pdf","text":"Skript zur Vorlesung Algorithmen und Datenstrukturen Herbstsemester 2016 Stand: 15. Dezember 2017 Markus P¨uschel Peter Widmayer Daniel Graf Tobias Pr¨oger Inhaltsverzeichnis 1 Einleitung 1 1.1 Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 1.2 Beispiele des Algorithmenentwurfs . . . . . . . . . . . . . . . . . . . 3 1.2.1 Multiplikation ganzer Zahlen . . . . . . . . . . . . . . . . . . 3 1.2.2 Star ﬁnden . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5 1.3 Kostenmodell . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7 1.3.1 O-Notation . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7 1.3.2 Komplexit¨at, Kosten und Laufzeit . . . . . . . . . . . . . . . 10 1.4 Mathematische Grundlagen . . . . . . . . . . . . . . . . . . . . . . . 11 1.4.1 Beweise per Induktion . . . . . . . . . . . . . . . . . . . . . . 11 1.4.2 Summenformeln . . . . . . . . . . . . . . . . . . . . . . . . . 13 1.4.3 Kombinatorik . . . . . . . . . . . . . . . . . . . . . . . . . . . 15 1.4.4 Rekurrenzen . . . . . . . . . . . . . . . . . . . . . . . . . . . 17 1.5 Maximum Subarray Sum . . . . . . . . . . . . . . . . . . . . . . . . 17 2 Sortieren und Suchen 25 2.1 Suchen in sortierten Arrays . . . . . . . . . . . . . . . . . . . . . . . 25 2.1.1 Bin¨are Suche . . . . . . . . . . . . . . . . . . . . . . . . . . . 25 2.1.2 Interpolationssuche . . . . . . . . . . . . . . . . . . . . . . . . 26 2.1.3 Exponentielle Suche . . . . . . . . . . . . . . . . . . . . . . . 26 2.1.4 Untere Schranke . . . . . . . . . . . . . . . . . . . . . . . . . 27 2.2 Suchen in unsortierten Arrays . . . . . . . . . . . . . . . . . . . . . . 28 2.3 Elementare Sortierverfahren . . . . . . . . . . . . . . . . . . . . . . . 29 2.3.1 Bubblesort . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30 2.3.2 Sortieren durch Auswahl . . . . . . . . . . . . . . . . . . . . . 31 2.3.3 Sortieren durch Einf¨ugen . . . . . . . . . . . . . . . . . . . . 32 2.4 Heapsort . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33 2.5 Mergesort . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37 2.5.1 Rekursives 2-Wege-Mergesort . . . . . . . . . . . . . . . . . . 38 2.5.2 Reines 2-Wege-Mergesort . . . . . . . . . . . . . . . . . . . . 39 2.5.3 Nat¨urliches 2-Wege-Mergesort . . . . . . . . . . . . . . . . . . 40 2.6 Quicksort . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40 2.7 Eine untere Schranke f¨ur vergleichsbasierte Sortierverfahren . . . . . 46 3 Dynamische Programmierung 49 3.1 Einleitung . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49 3.2 L¨angste aufsteigende Teilfolge . . . . . . . . . . . . . . . . . . . . . . 52 3.3 L¨angste gemeinsame Teilfolge . . . . . . . . . . . . . . . . . . . . . . 56 3.4 Minimale Editierdistanz . . . . . . . . . . . . . . . . . . . . . . . . . 58 3.5 Matrixkettenmultiplikation . . . . . . . . . . . . . . . . . . . . . . . 59 i 3.5.1 Exkurs: Multiplikation zweier Matrizen . . . . . . . . . . . . 60 3.6 Subset Sum Problem . . . . . . . . . . . . . . . . . . . . . . . . . . . 61 3.7 Rucksackproblem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 64 4 Datenstrukturen f¨ur W¨orterb¨ucher 69 4.1 Abstrakte Datentypen . . . . . . . . . . . . . . . . . . . . . . . . . . 69 4.2 Hashing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 74 4.2.1 Universelles Hashing . . . . . . . . . . . . . . . . . . . . . . . 76 4.2.2 Hashverfahren mit Verkettung der ¨Uberl¨aufer . . . . . . . . . 76 4.2.3 Oﬀenes Hashing . . . . . . . . . . . . . . . . . . . . . . . . . 78 4.3 Selbstanordnung . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 81 4.4 Nat¨urliche Suchb¨aume . . . . . . . . . . . . . . . . . . . . . . . . . . 84 4.5 AVL-B¨aume . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 89 5 Graphenalgorithmen 97 5.1 Grundlagen . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 97 5.1.1 Graphentheorische Grundlagen und Begriﬀe . . . . . . . . . . 98 5.1.2 Beispiele f¨ur Graphen und Graphprobleme . . . . . . . . . . . 99 5.1.3 Datenstrukturen f¨ur Graphen . . . . . . . . . . . . . . . . . . 100 5.1.4 Beziehung zur Linearen Algebra . . . . . . . . . . . . . . . . 102 5.1.5 Beziehung zu Relationen . . . . . . . . . . . . . . . . . . . . . 103 5.1.6 Berechnung der reﬂexiven und transitiven H¨ulle . . . . . . . . 104 5.2 Durchlaufen von Graphen . . . . . . . . . . . . . . . . . . . . . . . . 105 5.2.1 Tiefensuche . . . . . . . . . . . . . . . . . . . . . . . . . . . . 105 5.2.2 Breitensuche . . . . . . . . . . . . . . . . . . . . . . . . . . . 108 5.3 Zusammenhangskomponenten . . . . . . . . . . . . . . . . . . . . . . 109 5.4 Topologische Sortierung . . . . . . . . . . . . . . . . . . . . . . . . . 110 5.5 K¨urzeste Wege . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 113 5.5.1 K¨urzeste Wege in Graphen mit uniformen Kantengewichten . 114 5.5.2 K¨urzeste Wege in Graphen mit nicht-negativen Kantengewichten115 5.5.3 K¨urzeste Wege in Graphen mit allgemeinen Kantengewichten 119 5.5.4 K¨urzeste Wege zwischen allen Paaren von Knoten . . . . . . 120 ii Kapitel 1 Einleitung 1.1 Motivation Liesst man in der Zeitung Artikel ¨uber Algorithmen, dann bekommt man oft den Eindruck, Algorithmen seien ein eher b¨oses Ding, welchem einem empﬁehlt rote Kugelschreiber zu kaufen, weil man k¨urzlich blaue Kugelschreiber gekauft hat. Wir als Informatiker verstehen darunter aber etwas anderes, n¨amlich eine systematische Anleitung zum L¨osung von Problemen wie etwa die Multiplikation zweier Zahlen. Viele Algorithmen kennt man bereits aus dem allt¨aglichen Leben, ohne sie explizit als Algorithmus zu erkennen: So sind etwa schon Kochrezepte oder IKEA-Anleitungen Algorithmen im AlltagBeispiele f¨ur Algorithmen. Als einf¨uhrendes Beispiel betrachten wir folgende Situation: Eine Kuh steht auf Kuhproblem einer Weide, entlang derer ein Zaun verl¨auft. Die Weide ist komplett abgegrast, aber auf der anderen Seite des Zauns gibt es noch viel Gras. Gl¨ucklicherweise hat der Zaun ein Loch, durch das die Kuh auf die gegen¨uberliegende Seite des Zauns wechseln kann. Die Kuh weiss aber nicht, wo das Loch ist. Wir nehmen nun vereinfachend an, die Kuh sei punktf¨ormig, und der Zaun sei eine unendliche lange Gerade. Die Kuh kann jedes Mal einen Schritt nach links oder nach rechts machen, und sie erkennt das Loch im Zaun nur dann, wenn sie direkt davor steht. Wir nehmen an, dass der initiale Abstand zwischen Kuh und Loch exakt D Schritte betrage. Abbildung 1.1 zeigt die Situation f¨ur D = 4. Abb. 1.1 Situation beim Kuhproblem mit D = 4. Wie sollte die Kuh nun vorgehen, um zum Loch zu kommen? Oﬀensichtlich ist es nicht ausreichend, einfach in irgendeine Richtung (z.B. nach rechts) zu laufen, bis das Loch gefunden wird, denn der Zaun ist unendlich lang und das Loch k¨onnte in der entgegengesetzten Richtung (also links von der Kuh) liegen. Das Problem liegt also darin, dass die Kuh nicht weiss, in welche Richtung sie laufen muss. Ein m¨oglicher Ausweg besteht darin, hin- und her zu laufen, also zun¨achst einen Schritt nach rechts L¨osung zu machen, dann zwei Schritte nach links, dann drei Schritte nach rechts, usw. Auf diese Weise wird die Kuh das Loch auf jeden Fall nach endlicher Zeit ﬁnden. Wie viele Schritte werden dazu ben¨otigt? Oﬀensichtlich macht die Kuh 1 + 2 + · · · + Anzahl Schritte (2D − 1) viele Schritte, bis sie zum ersten Mal D Schritte weit vom Ausgangspunkt 1 2 Einleitung entfernt ist. Sie beﬁndet sich dann rechts vom Ausgangspunkt. Liegt das Loch aber links vom Ausgangspunkt, dann ben¨otigt die Kuh weitere 2D Schritte, um zum Loch zu kommen. Insgesamt ﬁndet sie also mit diesem Verfahren nach sp¨atestens 1 + 2 + · · · + 2D vielen Schritten das Loch im Zaun. Tats¨achlich werden wir in der ¨Ubung sehen, dass bessere Strategien gibt, die das Loch (zumindest f¨ur grosse D) mit weniger Schritten ﬁnden. Um die Rolle von Algorithmen in der Informatik einzusch¨atzen, werfen wir einenAlgorithmen und ihre Bedeutung Blick auf eine Deﬁnition der Informatik, die 1986 von der US-amerikanischen Infor- matikervereinigung ACM speziﬁziert wurde. Diese besagt: “Computer science is the systematic study of algorithms and data structures, speciﬁcally 1) their formal properties, 2) their mechanical and linguistic realizations, and 3) their applications.” Algorithmen sind also das zentrale Thema der Informatik (siehe auch die Folien zur ersten Vorlesung). In dieser Vorlesung werden wir viele Algorithmen kennenlernen und ihre formalen Eigenschaften wie Korrektheit oder Eﬃzienz studieren. Man k¨onn-Korrektheit Effizienz te einwenden, dass bei den heutigen Rechenleistungen die Eﬃzienz von Algorithmen nur noch eine untergeordnete Rolle spielt. Das folgende Beispiel verdeutlicht, dass diese Aussage naiv ist. Dazu betrachten wir das Problem des Handlungsreisenden (engl.: Travelling Sa-Problem des Handlungs- reisenden lesman Problem, TSP). Es seien n St¨adte auf einer Landkarte gegeben, und wir wollen annehmen, dass zwischen jedem Paar von zwei St¨adten i und j eine Strassen- verbindung der L¨ange dij existiert. Eine Rundreise startet in einer Stadt s, besucht danach jede andere Stadt s′ ∈ {1, . . . , n}\\{s} genau einmal und f¨uhrt schlussendlich zum Startpunkt s zur¨uck. Gesucht wird nun eine Rundreise mit minimaler Ge- samtl¨ange. Wenn wir die Reihenfolge festlegen, in der wir die St¨adte besuchen m¨ochten, dann kann die gesamte Reisel¨ange mit n − 1 Additionen ermittelt werden, indem die Abst¨ande zwischen den entsprechenden St¨adten aufsummiert werden. F¨ur eine feste Reise kann ihre L¨ange also eﬃzient ermittelt werden. Leider gibt (n − 1)! viele m¨ogliche Rundreisen, was enorm viel ist. Zur Veranschaulichung: Schon f¨ur n = 43 St¨adte existieren mehr m¨ogliche Rundreisen durch diese St¨adte als Atome auf der Erde. W¨urden wir alle m¨oglichen Rundreisen aufz¨ahlen und jedesmal ihre L¨ange berechnen, dann ﬁelen n! = n · (n − 1) · · · 2 · 1 ≈ √ 2πn ( n e )n viele Additionen an (die Approximation der Fakult¨at ist nicht trivial, sie ist un- ter dem Namen Stirling-Formel bekannt). Bereits vor langer Zeit wurde ein besserer Algorithmus entdeckt, der ungef¨ahr 2n viele Operationen ausf¨uhrt. Mit diesem konn- ten im Jahr 1970 Rundreisen gefunden werden, die bis zu n = 120 St¨adte umfass- ten. W¨urde man diesen Algorithmus heute auf einem aktuellen Rechner ausf¨uhren, dann k¨onnten nur Rundreisen durch maximal n = 140 St¨adte gefunden werden. Tats¨achlich aber k¨onnen heute Rundreisen berechnet werden, die mehr als 100′000 St¨adte besuchen. Diese enorme Verbesserung wurde haupts¨achlich durch Fortschrit- te in der Algorithmik erm¨oglicht, nicht aber durch alleinige Erh¨ohung der Rechen- leistung. Dieses Beispiel zeigt eindrucksvoll, wie wichtig die Entwicklung eﬃzienter Algorithmen ist. 1.2 Beispiele des Algorithmenentwurfs 3 1.2 Beispiele des Algorithmenentwurfs 1.2.1 Multiplikation ganzer Zahlen Bereits in der Primarschule haben wir einen einfachen Algorithmus kennengelernt, n¨amlich denjenigen zur Multiplikation zweier Zahlen. Gegeben seien dabei zwei Zah- Multiplikation: Primarschul- methode len z1 und z2 in Dezimaldarstellung, und gesucht ist das Produkt z1 · z2 dieser bei- den Zahlen (ebenfalls in Dezimaldarstellung). Dabei multiplizieren wir jede Ziﬀer der einen Zahl mit jeder Ziﬀer der anderen Zahl, und summieren die (entsprechend nach links verschobenen) Teilprodukte auf, um das Endergebnis zu erhalten. Ab- bildung 1.2 zeigt beispielhaft die Multiplikation der Zahlen 62 und 37 nach dieser Methode. Abb. 1.2 Multiplikation von 62 und 37 nach der Primarschulmethode. Algorithmus von Karatsuba und Ofman Die Primarschulmethode ben¨otigt zur Anzahl einstelliger Multiplikatio- nen Multiplikation zweier zweistelliger Zahlen also 2 · 2 = 4 Multiplikationen von Ziﬀern. Es ist leicht zu sehen, dass die Methode zur Multiplikation zweier n-stelliger Zahlen n2 einstellige Multiplikationen ben¨otigt. Karatsuba und Ofman schlugen 1962 ein verbessertes Verfahren vor, das mit weniger einstelligen Multiplikationen auskommt. Die Kosten f¨ur die Additionen ignorieren wir f¨ur den Moment. Um nun mit weniger Multiplikationen auszukommen, beobachten wir, dass f¨ur Verbesserung zwei zweistellige Zahlen z1 = 10a + b und z2 = 10c + d (10a + b) · (10c + d) = 100a · c + 10a · c + 10b · d + b · d + 10(a − b) · (d − c) gilt (nachrechnen!). Schaut man diesen Ausdruck genau an, wird man feststellen, dass hier nur noch drei verschiedene Produkte zweier Ziﬀern vorhanden sind, n¨amlich a · c, b · d, und (a − b) · (d − c). Ein kritischer Leser wird nun m¨oglicherweise einwen- den, dass auch die Multiplikation mit 10 oder 100 eine Multiplikation ist. Das stimmt nat¨urlich, wir z¨ahlen Multiplikationen mit Zehnerpotenzen aber dennoch nicht, da sie verh¨altnism¨assig leicht realisiert werden k¨onnen: Wird eine Zahl z mit 10k mul- tipliziert, m¨ussen an die Dezimaldarstellung von z lediglich k Nullen angeh¨angt werden. Wir haben also eine Methode gefunden, zwei zweistellige Zahlen mit ledig- lich drei einstelligen Multiplikationen auszurechnen. Abbildung 1.3 zeigt erneut die Multiplikation der Zahlen 62 und 37, diesmal nach der verbesserten Methode. In der Informatik, z.B. in der Kryptographie, braucht man heute h¨auﬁg sehr grosse Zahlen. Es stellt sich die Frage, ob die obige Methode auch zur Multiplikation zweier Zahlen mit mehr als zwei Ziﬀern benutzt werden kann. Betrachten wir zum Gr¨ossere ZahlenBeispiel das Produkt 6237·5898. Wir beobachten nun, dass wir die Faktoren als zwei zweistellige Zahlen mit den “Ziﬀern” 62, 37, 58, 98 auﬀassen und dann rekursiv bzw. induktiv dieselbe Methode anwenden k¨onnen. In diesem Beispiel w¨urde unsere neue Induktives PrinzipMethode 9 einstellige Multiplikationen ben¨otigen, w¨ahrend die Schulmethode 16(= 4 Einleitung Abb. 1.3 Multiplikation von 62 und 37 nach der Methode von Karatsuba und Ofman. Das oberste Teilprodukt entspricht b · d (und ist daher nicht nach links verschoben), die mittleren Teilprodukte entsprechen 10(b · d), 10(a − b) · (d − c) und 10a · c (und sind daher um eine Stelle nach links verschoben), das unterste entspricht 100a · c (und ist daher um zwei Stellen nach links verschoben). 4 · 4) ben¨otigt. Dieses Prinzip der induktiven Anwendung kommt in der Algorithmik sehr h¨auﬁg vor. Haben wir allgemein zwei n-stellige Zahlen (wobei wir vereinfachend annehmenVerall- gemeinerung wollen, dass n = 2k eine Zweierpotenz ist), dann k¨onnen wir diese als 10n/2a + b bzw. 10n/2c + d schreiben. Wie fr¨uher beobachten wir nun, dass (10n/2a + b) · (10n/2c + d) = 10 na · c + 10n/2a · c + 10n/2b · d + b · d + 10n/2(a − b) · (d − c) gilt. Die Produkte a · c, b · d und (a − b) · (d − c) berechnen wir dann rekursiv. Wir analysieren nun das Verfahren genauer, um zu untersuchen, wie viele einstelligeAnalyse Multiplikationen es ausf¨uhrt. Dazu deﬁnieren wir M (n) als die Anzahl einstelliger Multiplikationen bei zwei Zahlen mit je n = 2k Ziﬀern mit unserer neuen Methode. Wir haben gesehen, dass wir zwei einstellige Zahlen mit einer elementaren Multi- plikation multiplizieren k¨onnen, und zwei zweistellige Zahlen mit drei elementaren Multiplikationen. Allgemein erhalten wir M (2 k) = { 1 falls k = 0 ist 3 · M (2k−1) falls k > 0 ist. (1) Um nun die Rekursionsgleichung (1) aufzul¨osen, teleskopieren wir, d.h., wir setzenTeleskopieren die Rekursionsformel einige Male ein, bis wir eine Vermutung f¨ur die explizite Formel erhalten: M (2 k) = 3 · M (2 k−1) = 3 · 3 · M (2 k−2) = 3 2 · M (2 k−2) = · · · ! = 3 k · M (2 0) = 3 k. Wir vermuten also, dass M (2k) = 3k gilt. Dies beweisen wir nun mittels vollst¨andiger Induktion (die in Abschnitt 1.4.1 noch genauer besprochen wird): Induktionsvermutung: Wir vermuten, dass M (2k) = 3k gilt.Induktionsbeweis Induktionsanfang (k = 0): Es ist M (20) = 30 = 1, also ist die Induktionsvermutung f¨ur k = 0 korrekt. Induktionsschritt (k → k + 1): F¨ur k > 1 gilt M (2k+1) Def. = 3M (2k) I.V. = 3 · 3k = 3k+1 (Hinweis: I.V. steht hier abk¨urzend f¨ur Induktionsvermutung). Damit ist die Aussage f¨ur alle k korrekt. 1.2 Beispiele des Algorithmenentwurfs 5 Wir hatten fr¨uher argumentiert, dass die Primarschulmethode zur Multiplikation Verbesserung zweier n-stelliger Zahlen n2 einstellige Multiplikationen ausf¨uhrt. Um zu sehen, wie viele solche Operationen die Methode von Karatsuba und Ofman ben¨otigt, ersetzen wir in der eben berechneten Formel 2k durch n (und k durch log2(n)) und erhalten M (n) = 3 log2 n = (2 log2 3)log2 n = 2 (log2 3)(log2 n) = nlog2 3 ≈ n1.58, (2) was bedeutend besser als die Primarschulmethode ist. F¨ur grosse Zahlen ist der Algorithmus von Karatsuba und Ofman also schnell um ein Vielfaches schneller als die Primarschulmethode. Als konkretes Beispiel: F¨ur zwei tausendstellige Zahlen ist unser neues Verfahren 10002 10001.58 ≈ 18 Mal schneller als die Primarschulmethode. Im Idealfall m¨ochte man zus¨atzlich h¨auﬁg gerne noch eine theoretische untere Untere SchrankeSchranke ﬁnden, um zu zeigen, dass es gar nicht schneller gehen kann. Man kann sich die Frage stellen, wie viele einstellige Multiplikationen mindestens notwendig sind, um zwei n-stellige Zahlen zu multiplizieren. Diese Frage ist noch nicht endg¨ultig gekl¨art. Man weiss jedoch, dass es mindestens n elementare Multiplikationen sein m¨ussen. Ein nicht ganz pr¨azises Argument daf¨ur: W¨urden wir weniger als n 2 ein- stellige Multiplikationen durchf¨uhren, so k¨onnten wir erst gar nicht alle Ziﬀern der Eingabe anschauen. 1.2.2 Star ﬁnden Wie im vorigem Abschnitt gesehen gehen Algorithmenentwurf und dessen Analyse Hand in Hand. W¨are eine ¨Ubungsaufgabe gewesen “Finde ein schnelleres Verfahren f¨ur die Multiplikation zweier Zahlen”, w¨are es schwierig gewesen, die Methode von Karatsuba einfach so zu ﬁnden. H¨auﬁger ist der Algorithmenentwurf aber eine sehr systematische, nachvollziehbare Sache. Dazu betrachten wir ein weiteres Beispiel. Gegeben sei ein Raum mit n Personen. Gesucht ist ein Star. Ein Star ist eine Problem- beschreibungPerson, den alle im Raum kennen, und der selber niemanden anders kennt. Wir erlauben nur eine einzige elementare Operation, n¨amlich eine Frage an eine beliebige Person A, ob sie eine andere Person B kennt. Als m¨ogliche Antworten sind nur “Ja” und “Nein” erlaubt. Andere Fragen sind nicht erlaubt. Wir m¨ochten nun mit m¨oglichst wenigen Fragen ermitteln, ob sich im Raum ein Star beﬁndet. Bevor wir uns ¨uberlegen, wie das gehen k¨onnte, ¨uberlegen wir zun¨achst, welche Problem- eigenschaftenEigenschaften das Problem hat. Wir beobachten: • Es kann sein, dass es keinen Star gibt (z.B. wenn jeder jeden anderen kennt). • Es kann sein, dass es genau einen Star gibt (z.B. wenn George Clooney in den Raum k¨ame). • Es kann nicht mehr als einen Star geben. Angenommen, es g¨abe zwei Stars S1 und S2. Nun es gibt es zwei M¨oglichkeiten: Entweder, S1 kennt S2, oder nicht. Im ersten Fall w¨are S1 kein Star, ansonsten w¨are S2 kein Star. Algorithmus 1 (Naiv) Eine naive Strategie zur L¨osung des Problems besteht darin, Naive L¨osung jeden ¨uber jeden anderen auszufragen. Wir erzeugen eine Tabelle mit n Zeilen und n Spalten, und tragen in dem Eintrag in Zeile A und Spalte B genau dann “Ja” ein, wenn die Person A die Person B kennt, und “Nein” sonst. Die Diagonalelemente k¨onnen wir ignorieren, da wir annehmen, dass jeder Mensch sich selbst kennt. Wie ﬁnden wir nun den Star in dieser Tabelle? Wir suchen eine Person, sodass ihre Spalte 6 Einleitung 1 2 3 1 - Ja Nein 2 Nein - Nein 3 Ja Ja - Abb. 1.4 Beispiel f¨ur eine Situation, in der ein Star existiert, n¨amlich 2. nur “Ja” enth¨alt (alle kennen sie) und ihre Zeile nur aus “Nein” besteht (sie kennt niemanden). Abbildung 1.4 zeigt ein Beispiel f¨ur eine solche Situation: Person 2 ist ein Star. Ein Nachteil dieses naiven Verfahrens ist, dass sehr viele Fragen gestellt werden,Anzahl gestellter Fragen n¨amlich n · (n − 1) (also alle m¨oglichen). Bei der Multiplikation zuvor haben wir argumentiert, dass es nicht besser gehen kann, als jede Ziﬀer mindestens einmal anzuschauen. Hier ist das ein bisschen anders: Es ist nicht ausgeschlossen, dass wir den Star ﬁnden k¨onnen oder mit Sicherheit sagen k¨onnen, dass es keinen Star gibt, ohne jede m¨ogliche Frage zu stellen. Algorithmus 2a (Induktiv) Im vorigen Abschnitt hat es uns geholfen, das ProblemInduktive L¨osung in kleinere Teile zu zerlegen, d.h., es induktiv zu l¨osen. Wenn es im Raum n = 2 Personen gibt, dann k¨onnen wir immer einen Star mit F (2) = 2 Fragen ﬁnden. Gibt es im Raum n > 2 Person, dann k¨onnten wir wie folgt vorgehen: Wir schicken eine Person nach draussen, bestimmen rekursiv den potentiellen Star unter den verbleibenden Personen und holen die abwesende Person wieder in den Raum. F¨ur diese Person m¨ussen wir pr¨ufen, ob sie der Star ist, was 2(n − 1) Fragen kosten kann. Damit werden im schlimmsten Fall insgesamt F (n) = 2(n − 1) + F (n − 1) = 2(n − 1) + 2(n − 2) + · · · + 2 = n(n − 1) viele Fragen gestellt, was leider noch keine Verbesserung gegen¨uber dem naiven Verfahren darstellt. Algorithmus 2b (Verbesserung) Wieso sparen wir keine Fragen? Das Problem be-Verbesserte L¨osung steht darin, dass die herausgeschickte Person genau der Star sein kann. Dann n¨amlich brauchen wir viele Fragen, wenn er den Raum wieder betritt. Wir m¨ussten also ir- gendwie garantieren, dass wir nicht den Star aus dem Raum schicken. Dies ist aber einfach machbar: Wir fragen eine beliebige Person A im Raum, ob sie eine beliebige andere Person B im Raum kennt. Falls ja, dann ist A kein Star, ansonsten ist B kein Star. Wenn die zuvor herausgeschickte Person nun den Raum wieder betritt, dann reichen zwei weitere Fragen um herauszuﬁnden, ob der ggf. im Raum gefun- dene potentielle Star wirklich ein Star ist. F¨ur die Anzahl der maximal gestelltenAnalyse Fragen ergibt sich also F (n) = { 2 f¨ur n = 2 1 + F (n − 1) + 2 f¨ur n > 2. (3) Wie zuvor teleskopieren wir und erhalten F (n) = 3 + F (n − 1) = 3 + 3 + F (n − 2) = · · · = 3(n − 2) + 2 = 3n − 4, (4) was nun noch mit vollst¨andiger Induktion ¨uber n bewiesen werden muss ( ¨Ubung!). Wir sehen, dass in unserem neuen Verfahren deutlich weniger Fragen als im naiven Verfahren gestellt werden. 1.3 Kostenmodell 7 Abb. 1.5 Ein stark vereinfachtes Rechnermodell mit drei Komponenten: Prozessor, Spei- cher und ein Bus, der Prozessor und Speicher miteinander verbindet. 1.3 Kostenmodell Um die Eﬃzienz von Algorithmen formal zu untersuchen, m¨ussen wir zun¨achst ¨uber- legen, wie wir ihre Kosten bestimmen. Dazu deﬁnieren ein stark vereinfachtes Rech- Rechnermodell nermodell, das lediglich aus einem Prozessor, einem (unbeschr¨ankt grossen) Spei- cher sowie einem Bus, der Prozessor und Speicher miteinander verbindet, besteht. M¨ogliche Kostenmasse w¨aren nun z.B. die Anzahl vom Prozessor ausgef¨uhrter Ope- rationen, der benutzte Speicher, oder die Anzahl der Datenbewegungen zwischen dem Prozessor und dem Speicher. Beispiele f¨ur die vom Prozessor ausf¨uhrbaren ele- Elementar- operationmentaren Operationen sind • Rechenoperationen wie die Addition, Subtraktion, Multiplikation oder Division zweier nat¨urlicher Zahlen, • Vergleichsoperationen wie z.B. “<”, “>” oder “=” zwischen zwei nat¨urlichen Zahlen, • Zuweisungen der Form x ← A, wo der Variable x auf der linken Seite der Zahlenwert des Ausdrucks A auf der rechten Seite zugewiesen wird. Weiter ins Detail, auf die Ebene der einzelnen Bits und Bytes, wollen wir in dieser Vorlesung meist nicht gehen. Die entscheidende Idee ist also, zu abstrahieren. Wie lange eine einzelne der obengenannten Operationen eﬀektiv dauert, h¨angt von vie- len Faktoren ab: der Taktzahl unseres Prozessors, der Eﬃzienz des Compilers, der Ausnutzung des Cache-Speichers, der Wahl der Programmiersprache usw. In jedem realen Rechner ist die Laufzeit dieser Operationen aber schlimmstenfalls konstant. Eine erste Idee besteht nun darin, konstante Faktoren ignorieren, da diese von Ma- schine zu Maschine variieren. Wir weisen nun vereinfachend jeder der obengenannten Operationen die Kosten 1 zu, und sprechen daher auch vom Einheitskostenmodell. Einheitskosten- modellDieses nimmt also an, dass der Aufwand f¨ur arithmetische Operationen unabh¨angig von der Gr¨osse der Operanden ist. 1.3.1 O-Notation Eine weitere Idee ist, dass wir uns nur f¨ur grosse Eingabewerte interessieren, bei denen der Algorithmus lange l¨auft, denn bei kleinen Eingaben ist auch ein naiver Al- gorithmus vern¨unftig schnell. Wollen wir zwei Algorithmen miteinander vergleichen, dann ist derjenige besser, der auf grossen Eingaben schneller l¨auft. Dar¨uber hinaus interessiert uns nur das Wachstum einer Funktion. Um dies mathematisch pr¨azise zu beschreiben, wollen wir erneut vereinfachend alle konstanten Faktoren ignorieren. 8 Einleitung Abb. 1.6 Die Funktion g liegt in O(f ), denn f¨ur alle n ≥ n0 ist g(n) ≤ cf (n). Eine lineare Wachstumskurve mit Steigung 1 erachten wir als gleich schnell wie eine Kurve mit Steigung 20. Sei f : N → R+ eine Kostenfunktion. Wir deﬁnieren nun eine Menge von Funk-O-Notation tionen, die auch nicht schneller wachsen als f , konkret O(f ) := {g : N → R+ \f \f \f \f es gibt c > 0, n0 ∈ N so, dass g(n) ≤ cf (n) f¨ur alle n ≥ n0 }. (5) Anschaulich bedeutet dies, dass f (bis auf einen konstanten Faktor) asymptotisch gesehen eine obere Schranke f¨ur g bildet (siehe Abbildung 1.6). Diese O-Notation (auch O-Kalk¨ul oder Bachmann-Landau-Notation genannt) erlaubt uns nun, Aus- dr¨ucke zu vereinfachen und nach oben abzusch¨atzen. So ist z.B. 3n − 4 ∈ O(n). Dies kann man sehen, indem man etwa c = 3 und n0 = 1 w¨ahlt. Weitere Beispiele sindBeispiele • 2n ∈ O(n2) (mit c = 2 und n0 = 1), • n2 + 100n ∈ O(n2) (mit c = 2 und n0 = 100), • n + √n ∈ O(n) (mit c = 2 und n0 = 1). Die O-Notation erlaubt es uns also nicht nur, alle Konstanten wegzulassen, wirNutzen k¨onnen auch Terme niedrigerer Ordnung ignorieren. So ist z.B. auch n2 + n1,9 + 17 √n + 3 log(n) ∈ O(n2). Wir k¨onnen also f¨ur jeden Term den einfachsten Vertreter w¨ahlen. Dies ist sinnvoll, da uns, wie vorher erw¨ahnt, nicht die genaue Kostenfunk- tion, sondern lediglich ihr Wachstumsverhalten (z.B. linear, quadratisch, kubisch, usw.) f¨ur grosse n interessiert. Die O-Notation hat einige angenehme Eigenschaften, z.B. abgeschlossen unterAddition Additionen zu sein: Sind sowohl g1 ∈ O(f ) als auch g2 ∈ O(f ), dann ist auch g1 + g2 ∈ O(f ). Dies sieht man wie folgt: Ist g1 ∈ O(f ), dann gibt es Konstanten c1 > 0 und n1, sodass g1(n) ≤ c1f (n) f¨ur alle n ≥ n1 gilt. Analog gibt es Konstanten c2 > 0 und n2, sodass g2(n) ≤ c2f (n) f¨ur alle n ≥ n2 gilt. Wir w¨ahlen nun c = c1 +c2 sowie n0 = max{n1, n2}, und sehen dass dann g1(n) + g2(n) ≤ c1f (n) + c2f (n) = cf (n) f¨ur alle n ≥ n0 gilt, was unsere Aussage beweist. Die O-Notation benutzen wir, um obere Schranken anzugeben. F¨ur untere Schran-Ω-Notation ken deﬁnieren wir analog Ω(f ) := {g : N → R+ \f \f \f \f es gibt c > 0, n0 ∈ N so, dass g(n) ≥ cf (n) f¨ur alle n ≥ n0 }. (6) 1.3 Kostenmodell 9 Anschaulich bedeutet dies, dass g asymptotisch mindestens so schnell wie f w¨achst. Liegt eine Funktion g sowohl in O(f ) als auch in Ω(f ), dann sagen wir, dass sie asymptotisch genauso schnell wie f w¨achst. Wir schreiben dann auch f ∈ Θ(g), und Θ-Notation deﬁnieren Θ(f ) := O(f ) ∩ Ω(f ). (7) Um die Konzepte zu vertiefen, betrachten wir nun einige weitere Beispiele. Beispiele • n ∈ O(n2): Diese Aussage ist korrekt, aber ungenau. Tats¨achlich gelten ja auch n ∈ O(n) und sogar n ∈ Θ(n). • 3n2 ∈ O(2n2): Auch diese Aussage ist korrekt, man w¨urde aber ¨ublicherweise O(n2) statt O(2n2) schreiben, da Konstanten in der O-Notation weggelassen werden k¨onnen. • 2n2 ∈ O(n): Diese Aussage ist falsch, da 2n2 n = 2n −−−→ n→∞ ∞ und daher durch keine Konstante nach oben beschr¨ankt werden kann. • O(n) ⊆ O(n2): Diese Aussage ist korrekt, da alle Funktionen, die h¨ochstens linear wachsen, auch nur h¨ochstens quadratisch wachsen. Mathematisch falsch w¨are die Aussage O(n) ∈ O(n2), da O(n) eine Menge und kein Element ist. • Θ(n) ⊆ Θ(n2): Diese Aussage ist falsch, denn alle Funktionen in Θ(n2) erf¨ullen auch Ω(n2). Andererseits ist enth¨alt Θ(n) Funktionen wie f (n) = n, die nicht in Ω(n2) liegen. N¨utzlich zur Untersuchung, in welcher Beziehung zwei Funktionen f und g zueinan- der stehen, ist das folgende Theorem. Theorem 1.1. Seien f, g : N → R+ zwei Funktionen. Dann gilt: O-Notation und Grenzwerte 1) Ist limn→∞ f (n) g(n) = 0, dann ist f ∈ O(g), und O(f ) ⊊ O(g). 2) Ist limn→∞ f (n) g(n) = C > 0 (wobei C konstant ist), dann ist f ∈ Θ(g). 3) Ist limn→∞ f (n) g(n) = ∞, dann ist g ∈ O(f ), und O(g) ⊊ O(f ). Beweis. Wir beweisen nur die erste Aussage. Der Beweis der ¨ubrigen Aussagen verl¨auft analog. Ist limn→∞ f (n) g(n) = 0, dann gibt es f¨ur jedes ε > 0 ein n0, sodass f (n) g(n) < ε f¨ur alle n ≥ n0 gilt. Wir k¨onnen also ein beliebiges ε > 0 w¨ahlen, und die Deﬁnition des Grenzwerts garantiert uns, dass ein geeignetes n0 existiert, sodass f (n) ≤ εg(n) f¨ur alle n ≥ n0 gilt. Damit folgt direkt f ∈ O(g). Wir wissen daher auch sofort, dass O(f ) ⊆ O(g) gilt. Angenommen, es w¨are zus¨atzlich O(f ) = O(g). Dann w¨are nat¨urlich auch g ∈ O(f ). Also g¨abe es ein c > 0 und ein n0, sodass g(n) ≤ cf (n) f¨ur alle n ≥ n0 gilt. Dann w¨are aber lim n→∞ f (n) g(n) ≥ lim n→∞ 1 c = 1 c > 0, was ein Widerspruch zur Voraussetzung ist. Also ist O(f ) ⊊ O(g). 10 Einleitung ¨Ublicherweise schreibt man vereinfachend f = O(g) anstatt f ∈ O(g). Mathema-Schreibweise tisch gesehen ist dies nat¨urlich falsch, da f eine Funktion und O(g) eine Menge bezeichnet. Ausserdem folgt aus f1 = O(g) und f2 = O(g) nicht notwendigerweise f1 = f2. So zum Beispiel sind sowohl n = O(n2) als auch n2 = O(n2), aber nat¨urlich ist n ̸= n2. Die Notation ist eher im Sinne des umgangssprachlichen “ist ein” zu verstehen: Eine Kuh ist ein Tier, aber nicht jedes Tier ist ein Kuh. Gleichungen der Form f = O(g) m¨ussen also von links nach rechts gelesen werden, und weiter rechts wird es m¨oglicherweise ungenauer. So zum Beispiel ist 2n2 + 1 = O(2n2) = O(n2), und wir erlauben sogar Schreibweisen wie 5n + 7 = O(n) = O(n2). Der zweite Gleichheitszeichen muss also als Teilmengenzeichen interpretiert werden. Diese ver- einfachte Schreibweise ist Tradition und hat sich als praktisch erwiesen. Wir erlauben diesen Missbrauch der Notation, wenn aus dem Kontext heraus v¨ollig klar ist, was gemeint ist. Dies heisst aber auch, dass im Zweifelsfall auf jeden Fall die pr¨azise Mengen-basierte Notation verwendet werden sollte! 1.3.2 Komplexit¨at, Kosten und Laufzeit Wir haben bereits fr¨uher gesehen, dass Algorithmen verwendet werden, um ProblemeProbleme, Algorithmen und Programme zu l¨osen. Es gibt nun viele Arten, Algorithmen zu beschreiben, etwa textlich (wie wir das beim einfachen Algorithmus zur L¨osung des Kuhproblems getan haben), bildlich (z.B. durch Flussdiagramme), durch Pseudocode, oder eben durch richtige Programme. Als Programm bezeichnen wir Code, der auf einem konkreten Rechner (ggf. kompiliert und dann) ausgef¨uhrt werden kann. Ein Programm ist also eine konkrete Implementierung eines Algorithmus in einer Programmiersprache. F¨ur jeden Algorithmus k¨onnen wir nun (zumindest theoretisch) seine Kosten,Kosten d.h., die Anzahl der durchgef¨uhrten elementaren Operationen, bestimmen. Analog k¨onnen wir f¨ur ein Programm seine Laufzeit (z.B. in Sekunden) messen, wenn esLaufzeit auf einem realen Rechner ausgef¨uhrt wird. Gibt es nun eine eindeutige BeziehungBeziehung Kosten und Laufzeit zwischen den Kosten eines Algorithmus A und der Laufzeit eines Programms P , das A implementiert? Oﬀensichtlich ist die Laufzeit von P nicht einfach nur ein Vielfa- ches der Kosten von A, da die Laufzeiten von einer Operation nicht immer gleich sind. Denken wir etwa an die Addition zweier Zahlen: Beﬁnden sich diese bereits im Speicher, dann kann die Operation vermutlich schneller ausgef¨uhrt werden, als wenn die Zahlen erst von einem Externspeicher (z.B. einer langsamen Festplatte) gelesen werden m¨ussten. Wir beobachten aber auch, dass auf einem konkreten Rechner die Laufzeit jeder Operation durch eine Konstante sowohl nach unten, als auch nach oben beschr¨ankt werden kann. Prozessorkerne in modernen Rechnern arbeiten oft mit 3GHz oder mehr, d.h., es gibt 3 · 109 Takte pro Sekunde. Pro Takt k¨onnen eine bestimmte Anzahl Operationen ausgef¨uhrt werden (z.B. 8), also gibt es eine untere Schranke. Auch eine obere Schranke k¨onnen wir angeben: Mit Sicherheit dauert eine einzelne Operation auf einem realen Rechner niemals l¨anger als eine Stunde. Diese Konstanten f¨ur die untere und die obere Schranke liegen nat¨urlich sehr weit aus- einander. Wir beobachten aber, dass die Kosten eines Algorithmus und die Laufzeit einer Implementierung asymptotisch gesehen ¨ubereinstimmen. K¨onnen wir von den Kosten eines Algorithmus auch auf die Schwierigkeit des zugrundeliegenden Problems schliessen? Ja, aber wir erhalten lediglich eine obere Schranke. Es k¨onnte n¨amlich andere Algorithmen geben, die wir noch nicht kennen, und die das Problem mit geringeren Kosten l¨osen. Wir deﬁnieren also die Komple-Komplexit¨at xit¨at eines Problems P als die minimalen Kosten ¨uber alle Algorithmen A, die P 1.4 Mathematische Grundlagen 11 Problem Komplexit¨at O(n) O(n) O(n2) ↑ ↑ ↑ Algorithmus Kosten (# el. Op.) 3n − 4 O(n) Θ(n2) ↓ ↕ ↕ Programm Laufzeit (Sek.) Θ(n) O(n) Θ(n2) Abb. 1.7 Beziehungen zwischen der Komplexit¨at eines Problems, den Kosten eines Algo- rithmus f¨ur dieses Problem und der Laufzeit einer Implementierung von diesem Algorithmus. l¨osen. Da die Menge aller Algorithmus unendlich gross ist, k¨onnen wir nur f¨ur we- nige Probleme die Komplexit¨at exakt angeben. Die Komplexit¨at der Multiplikation zweier Zahlen der L¨ange n ist oﬀenbar in Ω(n), denn jede Ziﬀer der Eingabe muss ber¨ucksichtigt werden. Ebenso ist sie in O(nlog3(2)), denn der Algorithmus von Ka- ratsuba und Ofman hat genau diese Kosten. Abbildung 1.7 zeigt die Beziehungen zwischen den deﬁnierten Begriﬀen. 1.4 Mathematische Grundlagen 1.4.1 Beweise per Induktion In diesem Abschnitt wird eine sehr wichtige Beweistechnik eingef¨uhrt, n¨amlich den Beweis per Induktion. Beim klassischen Induktionsbeweis geht es darum, zu zei- Induktions- beweisegen, dass eine Aussage f¨ur alle nat¨urlichen Zahlen n ∈ N G¨ultigkeit besitzt. Eine Induktion besteht aus den folgenden Komponenten: 1) Induktionsanfang: Zeige, dass die Aussage f¨ur n = 1 gilt. 2) Induktionshypothese: Wir nehmen an, die Aussage sei g¨ultig f¨ur ein allgemeines n ∈ N. 3) Induktionsschritt: Zeige, dass aus der G¨ultigkeit der Aussage f¨ur n (Induktions- hypothese) die G¨ultigkeit der Aussage f¨ur n + 1 folgt. Eine verallgemeinerte Variante der Induktion erlaubt eine st¨arkere Induktionshypo- Verallge- meinerungthese, n¨amlich dass die Aussage g¨ultig f¨ur alle k ≤ n sei (aus der dann nat¨urlich ebenfalls im Induktionsschritt die G¨ultigkeit der Aussage f¨ur n + 1 geschlussfolgert werden muss). Ebenso kann der Induktionsanfang f¨ur eine Zahl n0 > 1 erfolgen (dann gilt die Aussage aber nicht mehr f¨ur alle n ∈ N, sondern lediglich f¨ur alle n ∈ N mit n ≥ n0). Beispiel 1 Wir m¨ochten zeigen, dass (1 + x)n ≥ 1 + nx f¨ur alle n ∈ N und alle x ≥ −1 gilt (dies ist die sog. Bernoulli-Ungleichung). Bernoulli- Ungleichung Induktionsanfang (n = 1): Es ist (1 + x)1 = 1 + x ≥ 1 + 1 · x, also ist die Behauptung f¨ur n = 1 wahr. Induktionshypothese: Angenommen, es gelte (1 + x)n ≥ 1 + nx f¨ur ein n ∈ N. Induktionsschritt (n → n + 1): Wir beobachten, dass (1 + x)n+1 = (1 + x)n(1 + x) gilt, und sch¨atzen (1 + x)n mittels der Induktionshypothese nach oben ab. 12 Einleitung Abb. 1.8 Eine Kuhherde mit n = 11 K¨uhen. Konkret erhalten wir also (1 + x) n+1 = (1 + x) n(1 + x) I.H. ≥ (1 + nx)(1 + x) = 1 + x + nx + nx2 ≥ 1 + x + nx = 1 + (n + 1)x. Beispiel 2 Induktionsbeweise m¨ussen gr¨undlich gef¨uhrt werden, da man sonst leicht auch falsche Aussagen “beweisen” kann, wie das folgende Beispiel zeigt. Jemand be- hauptet “Alle K¨uhe einer Kuhherde haben die gleiche Farbe” und zeigt den folgenden “Induktionsbeweis”, um seine Behauptung zu untermauern. Induktionsanfang (n = 1): Wir betrachten eine Kuhherde mit genau einer Kuh. Die- se hat trivialerweise die gleiche Farbe wie alle anderen K¨uhe in der Herde (es gibt keine), folglich ist die Behauptung f¨ur n = 1 wahr. Induktionshypothese: Angenommen, alle K¨uhe in einer Herde mit n K¨uhen h¨atten die gleiche Farbe. Induktionsschritt (n → n + 1): Betrachte eine Herde mit n + 1 K¨uhen. Wir k¨onnen nun eine Kuh aus der Herde entfernen und erhalten eine Herde mit n K¨uhen. In Abbildung 1.8 sind das alle K¨uhe im roten Kreis. Diese haben gem¨ass In- duktionshypothese alle die gleiche Farbe. Nun f¨uhren wir die entfernte Kuh wieder der Herde zu und entfernen daf¨ur eine andere Kuh aus der Herde. Wie- der erhalten wir eine Herde mit n K¨uhen. In Abbildung 1.8 sind das alle K¨uhe im gr¨unen Kreis. Da auch diese gem¨ass Induktionshypothese alle die gleiche Farbe haben und sich die Herden im roten und im gr¨unen Kreis ¨uberschneiden, haben alle n + 1 K¨uhe der urspr¨unglichen Herde die gleiche Farbe. Der obige Beweis ist oﬀensichtlich inkorrekt, aber warum? Das Problem liegt hier im Induktionsschritt. Wir nehmen an, dass der Schnitt des gr¨unen und des roten Kreises immer mindestens eine Kuh enth¨alt. Dies ist aber f¨ur n = 2 nicht der Fall. Tats¨achlich liegt genau hier das Problem: F¨ur n = 2 K¨uhe unterteilen wir die Herde in zwei Herden mit je einer Kuh, die nicht notwendigerweise die gleiche Farbe haben. K¨onnten wir beweisen, dass je zwei K¨uhe immer die gleiche Farbe haben, dann w¨are der obige Beweis korrekt. 1.4 Mathematische Grundlagen 13 1.4.2 Summenformeln In diesem Abschnitt werden wir einige Summen der Form ∑n k=1 ak kennenlernen und untersuchen, wie sie aufgel¨ost werden k¨onnen. Sind zum Beispiel a1 = · · · = nk = 1, dann ist relativ leicht ersichtlich, dass ∑n k=1 1 n∑ k=1 n0 = n∑ k=1 1 = 1 + · · · + 1 = n (8) gilt. Weniger oﬀensichtlich, aber vielen sicherlich bekannt, ist die Formel ∑n k=1 kSn = n∑ k=1 k = 1 + 2 + · · · + n = n(n + 1) 2 = 1 2 n2 + n. (9) Die Korrektheit einer solchen Formel kann man (fast immer) mit vollst¨andiger In- duktion ¨uber n beweisen. Bei der obigen Formel (9) k¨onnen wir noch einen weiteren Trick anwenden: Wir schreiben die Summanden einmal vorw¨arts und direkt darunter in umgekehrter Reihenfolge auf. Wir beobachten 1 + 2 + · · · + n = Sn n + n − 1 + · · · + 1 = Sn n + 1 n + 1 · · · n + 1 = n(n + 1), d.h. Sn + Sn = n(n + 1), also ist Sn = n(n+1) 2 . Wie ﬁnden wir aber eine geschlossene Form f¨ur andere Summen? Dazu betrachten wir als weiteres Beispiel die Summe ∑n k=1 k2S′ n = n∑ k=1 k2 = 1 2 + 22 + · · · + n2. (10) Idee 1 1) Vermute, S′ n sei von der Form an3 + bn2 + cn + d. 2) Setze n = 1, 2, 3, 4 ein und erhalte ein Gleichungssystem mit vier Gleichungen und vier Unbekannten: a · 1 3 + b · 12 + c · 11 + d · 10 = 1 = 12 = S1 a · 2 3 + b · 22 + c · 21 + d · 20 = 5 = 12 + 22 = S2 a · 3 3 + b · 32 + c · 31 + d · 30 = 14 = 12 + 22 + 32 = S3 a · 4 3 + b · 42 + c · 41 + d · 40 = 30 = 12 + 22 + 32 + 42 = S4. Mit Methoden, die wir bald in linearer Algebra lernen, k¨onnen wir dieses l¨osen und erhalten die L¨osung a = 1 3 , b = 1 2 , c = 1 6 , d = 0, also vermuten wir S′ n ! = n(n + 1)(2n + 1) 6 . (11) 3) Beweise Gleichung (11) mit vollst¨andiger Induktion ¨uber n. Induktionsanfang (n = 1): Es ist S′ 1 = 1 = 1·2·3 6 = 1(1+1)(2·1+1) 6 , also ist die Behauptung f¨ur n = 1 wahr. 14 Einleitung Abb. 1.9 Absch¨atzung von ∑n k=1 k2 nach unten (blau) und nach oben (rot) durch∫ n 0 x2 dx bzw. ∫ n 0 (x + 1)2 dx. Induktionshypothese: Angenommen, es gelte S′ n = n(n+1)(2n+1) 6 f¨ur ein n ∈ N. Induktionsschritt (n → n + 1): S′ n+1 = n+1∑ k=1 k2 = ( n∑ k=1 k2) + (n + 1)2 = S′ n + (n + 1)2 I.H. = n(n + 1)(2n + 1) 6 + 6(n + 1)2 6 = n(n + 1)(2n + 1) 6 + n(n + 1) · 2 6 + 2(n + 1)(2n + 3) 6 = n(n + 1)(2n + 3) 6 + 2(n + 1)(2n + 3) 6 = (n + 2)(n + 1)(2n + 3) 6 = (n + 1)((n + 1) + 1)(2(n + 1) + 1) 6 . Idee 2 Ein Integral hat die anschauliche Interpretation, den Fl¨acheninhalt unterAbsch¨atzung einer Summe durch Integrale dem Graphen im entsprechenden Intervall anzugeben. Auch die Summe ∑n k=1 k2 k¨onnen wir geometrisch interpretieren, n¨amlich als Summe der Fl¨acheninhalte von Rechtecken mit der Breite 1 und der H¨ohe k2 (f¨ur k = 1, 2, . . . , n). Abbildung 1.9 zeigt die Situation. Es sollte nun m¨oglich sein, die Summe durch geeignete Integrale nach oben und nach unten abzusch¨atzen. Die Hoﬀnung besteht darin, dass diese Integrale wesentlich einfacher auszurechnen sind. Tats¨achlich gilt, wie Abbildung 1.9 zeigt, die Absch¨atzung ∫ n 0 x2 dx ≤ n∑ k=1 k2 ≤ ∫ n 0 (x + 1)2 dx. (12) L¨osen wir diese Integrale nun, dann erhalten wir 1 3 n3 ≤ n∑ k=1 k2 ≤ 1 3 (n + 1)3 = 1 3 n3 + n2 + n + 1 3 . Somit erhalten wir zwar keine exakte Absch¨atzung, wir sehen aber, dass ∑n k=1 k2 = ∑n k=1 kr 1 3 n3+O(n2) ⊆ Θ(n3) gilt. Wir k¨onnen die Idee zu folgender Aussage verallgemeinern: Sei r ∈ N0 beliebig. F¨ur alle n ∈ N gilt n∑ k=1 kr = 1 r + 1 nr+1 + O(nr). (13) 1.4 Mathematische Grundlagen 15 Eine weitere sehr wichtige Summenart, die uns immer wieder begegnen wird, ist die Geometrische Summesog. geometrische Summe. Sie hat die Form ∑n k=0 xk, und kann zu ∑n k=1 xkS′′ n = n∑ k=0 xk = 1 + x + x2 + · · · + xn = 1 − xn+1 1 − x (14) aufgel¨ost werden. Diese Auﬂ¨osung kann man leicht mit einem ¨ahnlichen Beweis, wie wir ihn bereits vorhin zur Auﬂ¨osung von ∑n k=1 k benutzt haben, verwendet werden. Wir schreiben wieder S′′ n hin, und darunter xS′′ n. Es ergibt sich S′′ n = 1 + x + x2 + · · · + xn xS′′ n = x + x2 + · · · + xn + xn+1 S′′ n − xS′′ n = 1 − xn+1, was die Auﬂ¨osung (14) beweist. Sie bedeutet auch, dass ∞∑ k=0 xk = lim n→∞ n∑ k=0 xk = 1 1 − x f¨ur |x| < 1 (15) gilt. Eine letzte Summe wollen wir untersuchen, und zwar ∑n k=0 k · xk. Auch hier ∑n k=0 k · xk ist nicht oﬀensichtlich, wie sie aufgel¨ost werden kann, daher braucht es wieder einen Trick. Wir setzen f (x) = ∑n k=0 xk und beobachten, dass f ′(x) = ∑n k=0 k · xk−1 gilt. Daher ergibt sich ∑n k=0 k · xk = x · f ′(x). Warum hat uns das geholfen? Wir haben ja bereits vorher eine explizite Formel f¨ur f (x) bewiesen, n¨amlich 1−xn+1 1−x . Also erhalten wir f ′(x), indem wir diesen Ausdruck einfach diﬀerenzen. Wir haben also die Berechnung einer Summe auf die Berechnung einer anderen Summe zur¨uckgef¨uhrt. 1.4.3 Kombinatorik Permutationen Im Folgenden sei M eine Menge mit n < ∞ Elementen. Eine bijektive Abbildung π : M → M heisst Permutation. Solch eine Permutation kann Permutation man als Anordnung (π(1), π(2), . . . , π(n)) der Menge M verstehen: An erster Stelle steht das Element π(1), an zweiter Stelle π(2), usw. So zum Beispiel hat die Menge M = {1, 2, 3} genau 6 Permutationen, n¨amlich (1, 2, 3), (1, 3, 2), (2, 1, 3), (2, 3, 1), (3, 1, 2) und (3, 2, 1). Mengen mit n Elementen haben n · (n − 1) · · · 2 · 1 =: n! (16) (sprich: n Fakult¨at) viele Permutationen, denn f¨ur das Element π(1) gibt es n M¨oglich- Fakult¨at keiten, f¨ur π(2) noch n − 1 (alle Elemente in M ausser π(1)), usw. Wir wollen nun untensuchen, wie schnell n! w¨achst. Es ist leicht ersichtlich, dass Wachstum von n!2n ≤ n! ≤ nn f¨ur n ≥ 2 gilt. Um eine bessere Absch¨atzung zu erhalten, beobachten wir zun¨achst, dass ln(a · b) = ln(a) + ln(b) und damit auch ln(n!) = ∑n i=1 ln(i) gilt. Diese Summe k¨onnen wir nun wie im vorigen Abschnitt gesehen durch Integrale geeignet nach unten und nach oben absch¨atzen, und erhalten ln(n!) = n ln(n) − n + O(ln n) (17) ⇒ n! = e O(ln n) · ( n e )n. (18) Man beachte, dass eO(ln n) ̸= O(n) ist, denn eO(ln n) enth¨alt zum Beispiel die Funktion e2 ln n = (eln n)2 = n2, die nicht in O(n) liegt. Eine genauere Absch¨atzung liefert die Stirling-Formel Stirling-Formel n! ≈ √2πn ( n e )n. (19) 16 Einleitung Potenz- und Teilmengen Die Menge aller Teilmengen von M , P(M ) = {A | A ⊆ M }, heisst Potenzmenge von M . Hat |M | = n Elemente, dann hat die PotenzmengePotenzmenge von M Kardinalit¨at |P(M )| = 2n. Um dies zu sehen, nummerieren wir die Elemente von M zun¨achst von 1 bis n. Jede Teilmenge M ′ von M kann nun durch einen Bitvektor (b1, . . . , bn) der L¨ange n codiert werden, wobei bi genau dann 1 ist, wenn i ∈ M ′ gilt, und 0 sonst. Da es 2n viele Bitvektoren der L¨ange n gibt und jeder Bitvektor zu genau einer Teilmenge von M korrespondiert, hat die Potenzmenge von M folglich 2n viele Elemente. Es gibt also 2n Teilmengen von M . Wie viele Teilmengen der Gr¨osse k gibt es?Anzahl k-elementiger Teilmengen F¨ur das erste Element haben wir n M¨oglichkeiten, f¨ur das zweite n − 1, und f¨ur das k-te n − k + 1. Insgesamt ergeben sich so n · (n − 1) · · · (n − k + 1) viele M¨oglich- keiten. Allerdings haben wir einige Teilmengen doppelt gez¨ahlt: Da die Reihenfolge der Elemente in der Teilmenge selbst egal ist und jede k-elementige Menge auf k! viele Arten angeordnet werden kann, wurde in obigem Produkt jede Menge k! Mal gez¨ahlt. Folglich m¨ussen wir noch durch k! teilen. Die korrekte Anzahl k-elementiger Teilmengen einer n-elementigen Menge ist also n · (n − 1) · · · (n − k + 1) k! = n! k!(n − k)! =: ( n k ). (20) Den Ausdruck (n k) bezeichnen wir als Binomialkoeﬃzient und sagen dazu “n ¨uber k”Binomial- koeffizient (engl.: “n choose k”). Er ist f¨ur alle n, k ∈ N0 mit 0 ≤ k ≤ n deﬁniert. Es stellt sich aber die Frage, was (n 0) ist, denn bisher haben wir 0! noch nicht deﬁniert. Wir beobachten, dass es genau eine 0-elementige Teilmenge von M gibt (n¨amlich die leere Menge), folglich sollte (n 0) = 1 sein. Damit erhalten wir (n 0) = n! 0!(n−0)! = 1 0! = 1, und aus diesem Grund deﬁnieren wir 0! := 1. F¨ur Binomialkoeﬃzienten k¨onnen wir viele Identit¨aten beweisen, zum Beispiel die Folgenden:Identit¨aten • ∑n k=0 (n k) = 2n. Die Aussage k¨onnen wir mit einem kombinatorischen Be- weis zeigen, indem wir geeignete kombinatorische Objekte (hier: Teilmengen von M ) auf zwei verschiedene Arten z¨ahlen. Zum einen beobachten wir, dass es genau (n k) k-elementige Teilmengen von M gibt (linke Seite). Zum anderen haben wir aber auch gesehen, dass M insgesamt 2n viele Teilmengen besitzt (rechte Seite). • ( n n−k) = (n k), denn f¨ur jede k-elementige Teilmenge M ′ k¨onnen wir auch die (n − k)-elementige Teilmenge M ′′ = M \\M ′ z¨ahlen. Alternativ kann man die Aussage nat¨urlich auch beweisen, indem man die Deﬁnition von ( n n−k) hin- schreibt und durch geeignete Termumformung in (n k) ¨uberf¨uhrt. • (n−1 k−1) + (n−1 k ) = (n k) f¨ur 1 ≤ k ≤ n. Dies kann ebenfalls durch Termumformung der Deﬁnition bewiesen werden: ( n − 1 k − 1 ) + ( n − 1 k ) = (n − 1)! (k − 1)!(n − k)! + (n − 1)! k!(n − 1 − k)! = (n − 1)! (k − 1)!(n − k − 1)! · ( 1 n − k + 1 k ) = (n − 1)! (k − 1)!(n − k − 1)! · ( n k(n − k) ) = (n k ) . • (x + y)n = ∑n k=0 (n k)xkyn−k f¨ur alle x, y ∈ R. Dies kann durch vollst¨andige Induktion ¨uber n bewiesen werden ( ¨Ubung). 1.5 Maximum Subarray Sum 17 1.4.4 Rekurrenzen Wir haben bereits fr¨uher Rekursionsgleichungen kennengelernt, n¨amlich F (n) = F (n − 1) + 2(n − 1) (Typ 1, Star ﬁnden), sowie (21) M (n) = 3 · M ( n 2 ) (Typ 2, Algorithmus von Karatsuba und Ofman). (22) Wir betrachten und l¨osen diese Gleichungen nun in einem etwas allgemeineren Kon- text. Sei C : N0 → R eine beliebige Funktion. Gleichungen vom Typ 1 k¨onnen wir nun zu Typ 1S(0) = C(0), S(n) = a · S(n − 1) + C(n) f¨ur n ≥ 1 (23) verallgemeinern, wobei wir annehmen wollen, dass a ∈ N konstant ist. Gleichungen dieses Typs werden immer dann verwendet, wenn ein Algorithmus ein Problem der Gr¨osse n in a Probleme der Gr¨osse n − 1 zerlegt, und zus¨atzlich C(n) zus¨atzliche Operationen ausf¨uhrt. Die Rekursionsgleichung (23) hat die L¨osung S(n) = n∑ i=0 aiC(n − i) = a nC(0) + n−1∑ i=0 a iC(n − i), (24) was sich leicht mit vollst¨andiger Induktion ¨uber n beweisen l¨asst ( ¨Ubung). Gleichun- gen vom Typ 2 verallgemeinern wir zu Typ 2T (1) = D(1), T (n) = a · T ( n 2 ) + D(n) f¨ur n = 2 k, k ≥ 1, (25) wobei wir wie vorher annehmen, dass a ∈ N konstant und D : N → R eine beliebige Funktion ist. Gleichungen vom Typ 2 werden in der Analyse von Algorithmen ver- wendet, die ein Problem der Gr¨osse n in a Teilprobleme der Gr¨osse n/2 zerlegen und zus¨atzlich D(n) zus¨atzliche Operationen ausf¨uhren. Gleichungen vom Typ 2 k¨onnen gel¨ost werden, indem Sie in eine Gleichung vom Typ 1 ¨uberf¨uhrt und analog zu (24) aufgel¨ost werden (die Details auszuarbeiten ist Teil einer ¨Ubung). 1.5 Maximum Subarray Sum Viele Algorithmen operieren “induktiv”, d.h. sie l¨osen zuerst rekursiv ein oder meh- rere Teilprobleme kleinerer Gr¨osse und benutzen ihre L¨osungen, um daraus die endg¨ultige L¨osung zu konstruieren. Sowohl der Algorithmus zum Finden eines Stars (1 Teilproblem mit Gr¨osse n − 1) als auch der Algorithmus von Karatsuba und Of- man (3 Teilprobleme mit Gr¨osse n/2) arbeiten nach diesem Prinzip. Im Allgemeinen gibt es f¨ur ein Problem mehrere Algorithmen, die dieses Problem l¨osen. Unser Ziel besteht jeweils in der Entwicklung des (asymptotisch) eﬃzientesten. Dabei inter- essieren uns insbesondere die Kosten (also die Anzahl durchgef¨uhrter elementarer Operationen) sowie der Speicherbedarf. Wir wollen in diesem Abschnitt noch einmal den Prozess des systematischen Algorithmenentwurfs anschauen und betrachten da- her das Maximum Subarray Sum Problem. In diesem ist ein Array1 von n rationalen Problem- definitionZahlen a1, . . . , an gegeben, und gesucht ist ein Teilst¨uck mit maximaler Summe (d.h., 1Wir werden bald genau lernen, was ein Array ist. Im Moment betrachten wir es als Menge von Elementen in einer gegebenen Reihenfolge. 18 Einleitung Indizes i, j mit 1 ≤ i ≤ j ≤ n, sodass ∑j k=i ak maximal ist). Zus¨atzlich erlauben wir auch die leere Summe als L¨osung, sodass der Algorithmus immer eine L¨osung mit nicht-negativem Wert zur¨uckliefert. W¨are die Eingabe zum Beispiel (a1, . . . , a9) = (7, −11, 15, 110, −23, −3, 127, −12, 1), dann w¨aren die gesuchten Indizes i = 3 und j = 7 mit ∑j k=i ak = 226. Bei manchen Eingaben gibt es mehr als eine maximale L¨osung. Wir begn¨ugenVereinfachende Annahmen uns aber mit der Berechnung irgendeiner dieser maximalen L¨osungen (welcher, ist egal). Ebenso berechnen die im folgenden vorgestellten Algorithmen nur den Wert einer besten L¨osung (also z.B. 226 f¨ur die obige Eingabe) und nicht die Indizes selbst. Die Algorithmen k¨onnten aber sehr einfach modiﬁziert werden, sodass nicht allein der beste Wert, sondern auch die zugeh¨origen Indizes selbst gespeichert w¨urden. Das Maximum Subarray Sum Problem hat zum Beispiel die folgende anschau- liche Interpretation. Wenn die Zahlen ¨Anderungen eines Aktienkurses beschreiben, dann m¨ochte man r¨uckwirkend berechnen, wann der beste Zeitpunkt f¨ur den Kauf (i) bzw. den Verkauf (j) gewesen w¨are. Algorithmus 1 (Naiv) Eine einfache Idee besteht darin, einfach alle m¨oglichen In- tervalle auszuprobieren, die Summe S im entsprechenden Intervall auszurechnen und sich die maximale Summe zu merken. Wir erhalten also den folgenden Algorithmus: MSS-Naiv(a1, . . . , an)Naiver Algorithmus 1 maxS ← 0 2 F¨ur i ← 1, . . . , n (alle Anf¨ange) 3 F¨ur j ← i, . . . , n (alle Enden) 4 S ← ∑j k=i ak (berechne Summe) 5 Merke maximales S Theorem 1.2. Der naive Algorithmus f¨ur das Maximum Subarray Sum ProblemAnalyse f¨uhrt Θ(n3) viele Additionen durch. Beweis. Wir beobachten, dass die Berechnung der Summe in Schritt 3 genau j − i viele einzelne Additionen ben¨otigt. Damit betr¨agt die Anzahl insgesamt durchgef¨uhrter Additionen genau n∑ i=1 n∑ j=i (j − i) = n∑ i=1 n−i∑ j′=0 j′ = n∑ i=1 n−i∑ j′=1 j′ = n∑ i=1 (n − i)(n − i + 1) 2 = n−1∑ i′=0 i′(i′ + 1) 2 = 1 2 ( n−1∑ i′=1 (i ′)2 + n−1∑ i′=1 i ′) = 1 2 (Θ(n3) + Θ(n2) ) = Θ(n3). 1.5 Maximum Subarray Sum 19 Abb. 1.10 Zur Berechnung von ∑j k=i ak gen¨ugt es, Si−1 von Sj zu subtrahieren. Man k¨onnte argumentieren, dass nicht allein die Berechnung der Summe, sondern Weitere Operationenauch andere Schritte wie zum Beispiel das Merken des Maximums gez¨ahlt werden sollten. Eine genauere Analyse zeigt aber, dass die Anzahl aller Merke-Operationen durch O(n2) nach oben beschr¨ankt ist, was an der Gesamtanzahl von Θ(n3) vielen Operationen nichts ¨andert. Der eben vorgestellte Algorithmus ist der Einfachheit halber in Pseudocode for- Java-Imple- mentierungmuliert worden, damit die zugrundeliegende Idee direkt ersichtlich ist. In einer kon- kreten Programmiersprache gibt es viel mehr technische Details, die man beachten muss. In Java zum Beispiel k¨onnte ein entsprechendes Codefragment wie folgt aus- sehen (man beachte, dass in den anderen Vorlesungen noch nicht alle Konzepte vorgestellt wurden): double maximalesS=0.0; for (int i=0; i<n; i=i+1) // Anfang for (int j=i; j<n; j=j+1) { // Ende double S=0.0; for (int k=i; k<=j; k=k+1) { // Berechne Summe S=S+a[k]; if (S>maximalesS) // Aktualisiere Maximum maximalesS=S; } } Algorithmus 2 (Vorberechnung der Pr¨aﬁxsummen) Ein Problem des naiven Al- gorithmus ist, dass manche Teilsummen wieder und wieder neu berechnet werden, obwohl sie bereits fr¨uher aufsummiert wurden. Oﬀenbar gen¨ugt es auch, lediglich alle Pr¨aﬁxsummen zu berechnen: Wir berechnen f¨ur jede Position i die Summe Si = ∑i k=1 ai, also Summe der Zahlen von Position 1 bis und mit Position i. All diese Werte Si k¨onnen wir f¨ur aufsteigende i in linearer Zeit, also in O(n), berech- nen. Zur Berechnung von Si gen¨ugt es n¨amlich, die i-te Zahl zur bereits berechneten Summe Si−1 zu addieren. Wie k¨onnen wir diese Pr¨aﬁxsummen nun benutzen? Wir beobachten, dass j∑ k=i ak = ( j∑ k=1 ak) − ( i−1∑ k=1 ak) = Sj − Si−1 (26) gilt. Zur Berechnung der Summe aller Zahlen im Bereich i, i + 1, . . . , j − 1, j reicht es also aus, Si−1 von Sj abzuziehen (siehe Abbildung 1.10). Da sowohl Si−1 als auch Sj bereits vorberechnet wurden, kann ∑j k=i ak also in Zeit O(1) berechnet werden. Wir erhalten also den folgenden Algorithmus: 20 Einleitung MSS-Pr¨afixsummen(a1, . . . , an)Pr¨afixsummen- Algorithmus 1 S0 ← 0 2 F¨ur i ← 1, . . . , n 3 Si ← Si−1 + ai 4 maxS ← 0 5 F¨ur i ← 1, . . . , n 6 F¨ur j ← i, . . . , n 7 S ← Sj − Si−1 8 Merke maximales S In den Schritten 1–3 werden also also n + 1 Pr¨aﬁxsummen S0, . . . , Sn vorberechnet. Die Schritte 4–7 benutzen dann diese Pr¨aﬁxsummen zur Berechnung der entspre- chenden Teilsummen ∑j k=i ak. Theorem 1.3. Der Pr¨aﬁxsummen-Algorithmus f¨ur das Maximum Subarray SumAnalyse Problem f¨uhrt Θ(n2) viele Additionen und Subtraktionen durch. Beweis. Die Berechnung der Pr¨aﬁxsummen S0, . . . , Sn in den Schritten 1–3 erfordert genau n Additionen. In Schritt 6 wird genau eine Subtrakti- on durchgef¨uhrt, also ist die Gesamtanzahl durchgef¨uhrter Subtraktionen genau n∑ i=1 n∑ j=i 1 = n∑ i=1(n − i + 1) = n∑ i′=1 i′ = Θ(n2). Algorithmus 3 (Divide-and-Conquer) Wir haben bereits fr¨uher das Prinzip von Divide-and-Conquer kennengelernt, bei dem ein Problem zun¨achst in kleinere Teil- probleme zerlegt wird, aus deren L¨osung dann die L¨osung f¨ur das Gesamtproblem berechnet wird (wie zum Beispiel im Algorithmus von Karatsuba und Ofman). Wir wollen nun dieses Prinzip auch zur L¨osung des Maximum Subarray Sum Problems einsetzen. Dazu teilen wir die gegebenen Zahlen a1, . . . , an zun¨achst in zwei gleich (ann¨ahernd) grosse H¨alften ⟨a1, . . . , a⌊n/2⌋⟩ und ⟨a⌊n/2⌋+1, . . . , an⟩ auf. Der Einfach- heit halber nehmen wir im Folgenden an, dass n = 2k f¨ur ein k ∈ N0 gilt, d.h. n eine Zweierpotenz ist. Sind nun i, j mit 1 ≤ i ≤ j ≤ n die Indizes einer maximalen L¨osung (d.h., ∑j k=i ak ist maximal), dann k¨onnen exakt drei F¨alle auftreten (siehe auch Abbildung 1.11): 1. Fall: Die L¨osung liegt vollst¨andig in der ersten H¨alfte (1 ≤ i ≤ j ≤ n/2). 2. Fall: Die L¨osung liegt vollst¨andig in der zweiten H¨alfte (n/2 < i ≤ j ≤ n). 3. Fall: Die L¨osung l¨auft ¨uber die Mitte (1 ≤ i ≤ n/2 < j ≤ n). Wir beobachten nun, dass die ersten beiden F¨alle durch einen rekursiven Aufruf auf den ersten bzw. den letzten n/2 Elementen gel¨ost werden k¨onnen. Diese rekursiven Aufrufe zerlegen ihrerseits wieder die Eingabe in zwei H¨alften, bis diese nur noch ein Element enthalten. F¨ur den dritten Fall machen wir nun folgende entscheidende Beobachtung: L¨auft die L¨osung ¨uber die Mitte, dann ist sie aus genau zwei Teilen zusammengesetzt, 1.5 Maximum Subarray Sum 21 Abb. 1.11 Die drei m¨oglichen F¨alle, die beim Divide-and-Conquer-Algorithmus auftreten k¨onnen. n¨amlich dem besten Teilst¨uck, das aus den letzten Elementen der ersten und den ersten Elementen der zweiten H¨alfte besteht. Formaler gesprochen betrachten wir alle Suﬃxsummen S1, . . . , Sn/2 mit Si = ∑n/2 k=i ak (also die Summen der Elemente i bis und mit n/2) und alle Pr¨aﬁxsummen Pn/2+1, . . . , Pn mit Pj = ∑j k=n/2+1 ak (also die Summen der Elemente n/2 + 1 bis und mit j), und die beste L¨osung, die in beiden H¨alften liegt, hat dann den Wert maxi Si + maxj Pj. Um den Wert einer besten L¨osung zu ermitteln, die ¨uber die Mitte l¨auft, reicht es also aus, die gr¨osste Suﬃxsumme in der ersten und die gr¨osste Pr¨aﬁxsumme in der zweiten H¨alfte zu berechnen, und diese Werte dann zu addieren. Nat¨urlich wissen wir im Vorfeld nicht, ob die optimale L¨osung komplett in einer der beiden H¨alften liegt oder in beiden. Das macht aber nichts, denn wir k¨onnen einfach rekursiv die beste L¨osung in der ersten H¨alfte, rekursiv die beste L¨osung in der zweiten H¨alfte sowie die beste L¨osung ¨uber die Mitte wie oben beschrieben berechnen, und geben dann die beste dieser drei L¨osungen (bzw. ihren Wert) zur¨uck. MSS-Divide-and-Conquer(a1, . . . , an) Divide-and- Conquer- Algorithmus1 Wenn n = 1 ist, dann gib max{a1, 0} zur¨uck. 2 Wenn n > 1 ist: 3 Teile die Eingabe in A1 = ⟨a1, . . . , an/2⟩ und A2 = ⟨an/2+1, . . . , an⟩ auf. 4 Berechne rekursiv den Wert W1 einer besten L¨osung f¨ur das Array A1. 5 Berechne rekursiv den Wert W2 einer besten L¨osung f¨ur das Array A2. 6 Berechne gr¨osste Suﬃxsumme S in A1. 7 Berechne gr¨osste Pr¨aﬁxsumme P in A2. 8 Setze W3 ← S + P . 9 Gib max{W1, W2, W3} zur¨uck. Theorem 1.4. Der Divide-and-Conquer-Algorithmus f¨ur das Maximum Subarray Analyse Sum Problem f¨uhrt Θ(n log n) viele Additionen und Vergleiche durch. Beweis. Wir beobachten zun¨achst einmal, dass Schritt 1 nur konstante Kosten c hat. Schritte 3, 8 und 9 sind bereits in O(1). Die Schritte 6 und 7 haben Kosten O(n), denn es m¨ussen n/2 Suﬃx- und n/2 Pr¨aﬁxsummen berechnet werden. Da Si aus Si+1 und Pj+1 aus Pj mittels einer Ad- dition berechnet werden k¨onnen, ist der Gesamtaufwand in O(n), d.h., 22 Einleitung er ist maximal a · n mit einer Konstante a. Beziehen wir die rekursiven Aufrufe mit ein, erhalten wir also folgende Rekurrenz zur Beschreibung der Kosten bei einer Eingabe mit n Zahlen: T (n) = { c falls n = 1 ist 2T ( n 2 ) + an falls n > 1 ist. (27) Da nun n = 2k gilt, deﬁnieren wir ¯T (k) = T (2k) = T (n), d.h., aus Gleichung (27) wird ¯T (k) = { c falls k = 0 ist 2 ¯T (k − 1) + a · 2k falls k > 0 ist. (28) Wie fr¨uher gesehen hat Gleichung (28) die Auﬂ¨osung ¯T (k) = 2 k · c + k−1∑ i=0 2i · a · 2 k−i = c · 2 k + a · k · 2 k = Θ(k · 2k), (29) und damit ist T (n) = Θ(n log n). Man k¨onnte sich nun fragen, warum wir die Konstanten c und a nicht genauer bestimmt haben. Der Grund ist, dass der genaue Wert keine Rolle spielt, da diese beiden Konstanten in der L¨osung von ¯T (k) nur als konstante Faktoren auftauchen und daher in der Θ-Notation verschwinden. Algorithmus 4 (Induktiv von links nach rechts) K¨onnen wir es noch besser schaf- fen? Dazu versuchen wir nochmals eine Induktion von links nach rechts. Dann neh- men wir an, dass wir nach dem (i − 1)-ten Schritt den Wert max einer optimalen L¨osung f¨ur die ersten i − 1 Elemente kennen (initial: max = 0). Wenn wir nun das i-te Element dazunehmen, dann wollen wir rasch herausﬁnden, ob dieses neue Ele- ment zum besten Intervall geh¨ort. Dazu merken wir uns f¨ur den Teil bis i nicht nur das bisherige Maximum, sondern auch den Wert randmax einer besten L¨osung, die am rechten Rand, also an Position i, endet (initial: randmax = 0). Damit k¨onnen wir dann leicht pr¨ufen, ob wir mit dem neuen Element ein neues Maximum erreichen k¨onnen oder nicht (siehe Abbildung 1.12). MSS-Induktiv(a1, . . . , an)Induktiver Algorithmus 1 randmax ← 0 2 maxS ← 0 3 F¨ur i ← 1, . . . , n: 4 randmax ← randmax + ai 5 Wenn randmax > maxS: 6 maxS ← randmax 7 Wenn randmax < 0: 8 randmax ← 0 9 Gib maxS zur¨uck. Theorem 1.5. Der induktive Algorithmus f¨ur das Maximum Subarray Sum ProblemAnalyse f¨uhrt Θ(n) viele Additionen und Vergleiche durch. 1.5 Maximum Subarray Sum 23 Abb. 1.12 Ein gr¨osseres Maximum kann nur durch randmax + ai entstehen. Komplexit¨at des Problems Nun werden wir ehrgeizig und wollen es noch besser machen. K¨onnen wir auch Algorithmen mit Kosten von Θ( √ n) oder sogar Θ(log(n)) entwerfen, oder ist geht es nicht besser als Θ(n)? Wir ¨uberlegen uns nun, dass jeder korrekte Algorithmus f¨ur das Maximum Sub- array Sum Problem Kosten Ω(n) hat, indem wir zeigen, dass jeder korrekte Algo- rithmus alle Elemente a1, . . . , an ansehen muss. Angenommen, wir haben einen Algorithmus, der nicht jedes Element anschauen Untere Schrankemuss (das w¨are etwa dann der Fall, wenn wir einen Algorithmus mit Laufzeit Θ(√n) h¨atten). Dann ist er nicht korrekt: Fall 1: Der Algorithmus berechnet eine L¨osung, die ai enth¨alt. Dann setzen wir ai := −∞ (oder auf einen Wert, der so klein ist, dass ai auf keinen Fall Teil einer optimalen L¨osung ist, z.B. −n maxk |ak| − 1). Fall 2: Der Algorithmus berechnet eine L¨osung, die ai nicht enth¨alt. Dann setzen wir ai := ∞ (oder auf einen Wert, der so gross ist, dass ai auf jeden Fall Teil einer optimalen L¨osung sein muss, z.B. n maxk |ak| + 1). In beiden F¨allen berechnet ein Algorithmus, der ai nicht anschaut, eine falsche L¨osung. Damit sind wir in der gl¨ucklichen (und seltenen) Lage, die Komplexit¨at Problem- komplexit¨atdes Maximum Subarray Sums exakt einsch¨atzen zu k¨onnen. Sie ist in Ω(n) ∩ O(n) = Θ(n). (30) Die untere Schranke von Ω(n) erhalten wir durch den soeben gef¨uhrten Beweis, die obere Schranke von O(n) durch den induktiven Algorithmus. 24 Einleitung Kapitel 2 Sortieren und Suchen 2.1 Suchen in sortierten Arrays Angenommen, wir haben ein Telefonbuch mit einer Million Eintr¨age, und wir wollen einen bestimmen Namen ﬁnden. Formaler nehmen wir an, dass ein sortiertes Array A mit n Elementen (Schl¨usseln) A[1], . . . , A[n] und A[1] ≤ A[2] ≤ · · · ≤ A[n] sowie ein Element (Schl¨ussel) b gegeben sind, und gesucht ist ein Index k mit 1 ≤ k ≤ n, sodass A[k] = b ist, bzw. “nicht gefunden” falls ein solcher Index nicht existiert. Die Aufgabe besteht also darin zu entscheiden, ob A den Schl¨ussel b enth¨alt, und wenn ja, die entsprechende Position im Array zu berechnen. 2.1.1 Bin¨are Suche Eine naheliegende Strategie besteht darin, das Suchproblem mittels Divide-and- Idee Conquer zu l¨osen. Dazu k¨onnte man wie folgt vorgehen: Ist das Array leer, dann enth¨alt es b mit Sicherheit nicht und wir geben “nicht gefunden” aus. Ansonsten bestimmen wir die (ann¨ahernd) mittlere Position m = ⌊n/2⌋ im Array und unter- scheiden drei F¨alle: 1) Ist b = A[m], dann haben wir den Schl¨ussel b an Position m gefunden und geben daher m zur¨uck. 2) Ist b < A[m], dann suchen wir rekursiv in der linken H¨alfte (also auf den Positionen 1, . . . , m − 1) weiter nach b. 3) Ist b > A[m], dann suchen wir rekursiv in der rechten H¨alfte (also auf den Positionen m + 1, . . . , n) weiter nach b. Dieses Verfahren wird bin¨are Suche genannt. Die Korrektheit der bin¨aren Suche Korrektheit folgt direkt aus der Tatsache, dass A aufsteigend sortiert ist. Ist also b < A[m], dann wissen wir bereits, dass die Positionen m, . . . , n nur Schl¨ussel enthalten, die gr¨osser als b sind. Also reicht es, die Suche auf die ersten m − 1 Positionen einzuschr¨anken. Die Begr¨undung f¨ur den Fall b > A[m] verl¨auft analog. Da der Suchbereich (die Anzahl der noch m¨oglichen Positionen) in jedem Schritt um mindestens ein Element kleiner wird, endet das Verfahren auch nach einer endlichen Zahl von Schritten. Wie viele Schritte sind dies im schlimmsten Fall? Dieser tritt oﬀenbar dann ein, Laufzeit wenn erfolglos nach einem Schl¨ussel gesucht wird. F¨ur ein Array der L¨ange n = 2k ergibt sich die folgende Rekurrenz zur Absch¨atzung der maximal durchgef¨uhrten Operationen bei einem Array A der L¨ange n: T (n) = { c falls n = 0 ist, T (n/2) + d falls n ≥ 1 ist, (31) 25 26 Sortieren und Suchen wobei c und d jeweils konstant sind. Mit den fr¨uher in der Vorlesung vorgestell- ten Methoden erhalten wir T (n) ∈ O(log n), was sehr schnell ist. In der Realit¨at w¨urde man zudem die bin¨are Suche iterativ statt rekursiv implementieren, was nicht schwierig ist, wie der folgende Pseudocode zeigt. Binary-Search(A = (A[1], . . . , A[n]), b)Bin¨are Suche 1 left ← 1; right ← n ▷ Initialer Suchbereich 2 while left ≤ right do 3 middle ← ⌊(left+right)/2⌋ 4 if A[middle] = b then return middle ▷ Element gefunden 5 else if A[middle] > b then right ← middle−1 ▷ Suche links weiter 6 else left ← middle+1 ▷ Suche rechts weiter 7 return “Nicht vorhanden” 2.1.2 Interpolationssuche Zu Beginn dieses Abschnitts wurde die bin¨are Suche mit der Suche nach einem Namen in einem Telefonbuch verglichen, was nicht ganz angemessen ist: Namen wie “Becker” w¨urde man direkt eher im vorderen Bereich suchen, w¨ahrend man “Wawrinka” vermutlich ziemlich weit hinten vermuten w¨urde. Bin¨are Suche setzt aber in Schritt 4 immer middle = ⌊left + 1 2 (right − left) ⌋ (32) und teilt daher den Suchbereich unabh¨angig vom zu suchenden Element b in zwei gleich grosse Teile auf. Vermutet man b eher links im Array, dann sollte der Faktor 1/2 verringert werden, um den linken Suchbereich zu verkleinern. Analog sollte der Faktor eher gr¨osser als 1/2 gew¨ahlt werden, wenn sich b vermutlich weit rechts im Array ﬁndet. F¨ur Arrays aus Zahlen wird diese Idee von der Interpolationssuche aufgegriﬀen. Sie ersetzt den statischen Faktor 1/2 durch Erwartete Position des Suchschl¨ussels ρ = b − A[left] A[right] − A[left] ∈ [0, 1], (33) und betrachtet die Position left + ρ(right − left), was ann¨ahernd der erwarteten Position des Suchschl¨ussels b im Array A entspricht, wenn die Schl¨usselwerte in dem Bereich einigermassen gleich verteilt sind. Man kann zeigen, dass Interpolationssuche auf Arrays, die aus n unabh¨angigen und gleichverteilten Zufallszahlen bestehen, nurLaufzeit O(log log n) viele Vergleiche ben¨otigt. Andererseits werden im schlimmsten Fall Ω(n) viele Vergleiche ausgef¨uhrt, was wesentlich schlechter als etwa die bin¨are Suche ist. 2.1.3 Exponentielle Suche Angenommen, wir haben starke Anzeichen daf¨ur, dass sich der zu suchende Schl¨ussel weit vorn im Array beﬁndet. K¨onnen wir etwas schneller als die herk¨ommliche bin¨are Suche sein, ohne eine lineare Laufzeit im schlimmsten Fall (wie bei der Interpolati- onssuche) zu riskieren? 2.1 Suchen in sortierten Arrays 27 Abb. 2.1 Bin¨are Suche auf einem Array der L¨ange 6 als Entscheidungsbaum visualisiert. Da sich das zu suchende Element im Erfolgsfall auf sechs m¨oglichen Positionen beﬁnden kann, hat der Entscheidungsbaum die gleiche Anzahl von Knoten. Im ersten Schritt wird A[3] mit b verglichen. Bei Gleichheit ist der Algorithmus fertig, ansonsten werden A[1] bzw. A[5] verglichen, usw. Da der Baum H¨ohe 3 hat (also aus drei “Schichten” besteht), ist die bin¨are Suche auf einem Array mit sechs Elementen nach sp¨atestens drei Vergleichen fertig. Um das Problem zu l¨osen, legen wir zun¨achst die rechte Grenze des Suchbereichs auf r = 1 fest. Diese wird dann so lange verdoppelt, bis entweder der dort gespei- cherte Schl¨ussel A[r] gr¨osser als der zu suchende Schl¨ussel b ist, oder aber r > n gilt (die rechte Grenze also ausserhalb des urspr¨unglichen Arrays liegt). Nachdem wir r auf diese Art bestimmt haben, f¨uhren wir eine bin¨are Suche auf dem Bereich 1, . . . , min(r, n) durch. Exponential-Search(A = (A[1], . . . , A[n]), b) Exponentielle Suche 1 r ← 1 ▷ Initiale rechte Grenze 2 while r ≤ n and b > A[r] ▷ Finde rechte Grenze 3 r ← 2 · r ▷ Verdopple rechte Grenze 4 return Binary-Search((A1, . . . , A[min(r, n)]), b) ▷ Weiter mit bin¨arer Suche Beﬁndet sich das zu suchende Element auf Position p, dann braucht diese sog. ex- ponentielle Suche nur O(log p) viele Schritte (die Schleife im zweiten Schritt wird Laufzeit lediglich ⌈log p⌉ Mal durchlaufen, und die bin¨are Suche in Schritt 4 ben¨otigt auch nur O(log p) viele Schritte). Nat¨urlich hat diese Art zu suchen nur dann Vorteile, wenn p ≪ n gilt. An der Laufzeit von O(log n) im schlechtesten Fall ¨andert sich nichts. 2.1.4 Untere Schranke Wie wir in den vorigen Abschnitten gesehen haben, ben¨otigen sowohl die bin¨are als auch die exponentielle Suche im schlimmsten Fall Θ(log n) viele Vergleiche; die Interpolationssuche kann sogar linear viele Vergleiche ben¨otigen. Dies wirft die Frage auf, ob die Suche in einem sortierten Array im schlechtesten Fall vielleicht immer Zeit Ω(log n) ben¨otigt. Wir werden jetzt zeigen, dass alle Suchalgorithmen, die nur Vergleiche benutzen, im schlechtesten Fall tats¨achlich mindestens so viele Vergleiche ausf¨uhren m¨ussen. Um zu argumentieren, dass es nicht schneller geht, stellen wir uns einen beliebigen deterministischen Suchalgorithmus als Entscheidungsbaum vor, der in jedem Knoten Entscheidungs- baumeinen Schl¨usselvergleich durchf¨uhrt und dann je nach Ergebnis entweder erfolgreich endet oder in einem von zwei Teilb¨aumen fortf¨ahrt. Abbildung 2.1 visualisiert die bin¨are Suche auf einem Array mit sechs Elementen. 28 Sortieren und Suchen Wir beobachten nun folgendes: Ist eine Suche nach einem Element b erfolgreich, dann kann b an jeder der n Positionen des Arrays stehen. F¨ur jede dieser n m¨oglichen Ergebnisse der Suche muss der Entscheidungsbaum mindestens einen Knoten ent- halten. Also muss die Gesamtanzahl der Knoten mindestens n betragen. Die Anzahl von Vergleichen, die ein Algorithmus im schlechtesten Fall ausf¨uhrt, entspricht exakt der H¨ohe des Baums. Diese ist deﬁniert als die maximale Anzahl von Knoten auf einem Weg von der Wurzel (dem “obersten” Knoten) zu einem Blatt (einem Knoten ohne Nachfolger). Wir beobachten nun, dass jeder Knoten maximal zwei Nachfolger hat, denn wir suchen entweder im linken Teilbaum weiter, oder im rechten (oder aber b wurde gefunden, dann ist die Suche beendet). Ein solcher Baum der H¨ohe h hat nun h¨ochstens 20 + 21 + 22 + · · · + 2h−1 = 2 h − 1 < 2 h (34) viele Knoten (denn die erste “Schicht” enth¨alt nur die Wurzel, und die i-te “Schicht” h¨ochstens doppelt so viele Knoten wie die dar¨uberliegende (i − 1)-te “Schicht”), und nun direkt folgt n ≤ Anzahl Knoten im Entscheidungsbaum < 2h ⇒ h > log2(n). (35) Da die Anzahl der im schlimmsten Fall ausgef¨uhrten Vergleiche h betr¨agt und unsere Argumentation f¨ur beliebige Entscheidungsb¨aume gilt, haben wir also bewiesen dass jedes vergleichsbasierte Suchverfahren auf einem sortierten Array im schlechtesten Fall Ω(log n) viele Vergleiche durchf¨uhrt. 2.2 Suchen in unsortierten Arrays Wir haben bereits gesehen, dass wir in sortierten Arrays in Zeit Θ(log n) suchen k¨onnen. Was aber, wenn das Array unsortiert ist? Die naivste Variante, in solchen Arrays zu suchen, ist die lineare Suche, bei der alle Elemente des Arrays A sukzessive mit dem suchenden Schl¨ussel b verglichen werden. Linear-Search(A = (A[1], . . . , A[n]), b)Lineare Suche 1 for i ← 1, 2, . . . , n do 2 if A[i] = b then return i 3 return “nicht gefunden” Die Laufzeit der linearen Suche betr¨agt im schlechtesten Fall oﬀensichtlich Θ(n).Laufzeit Tats¨achlich werden wir jetzt zeigen, dass es nicht besser geht, denn jeder Algorithmus f¨uhrt bei der Suche auf einem unsortierten Array im schlechtesten Fall n Vergleiche aus. Intuitiv k¨onnte man argumentieren, dass der Schl¨ussel b ja mit allen Elementen in A vergleichen werden muss, sonst k¨onnen wir nicht mit Sicherheit sagen, ob er in A vorkommt oder nicht. Das Argument ist aber nicht ausreichend, denn wir m¨ussen auch Vergleiche von Schl¨usseln innerhalb von A ber¨ucksichtigen. K¨onnten wir z.B. ein Array A in Zeit O(log n) sortieren (was nicht m¨oglich ist, wie wir sp¨ater sehen werden), dann w¨are eine Suche in Zeit O(log n) m¨oglich. 2.3 Elementare Sortierverfahren 29 Abb. 2.2 Eine Situation, bei der r = 5 Vergleiche innerhalb von A durchgef¨uhrt wurden. Es gibt vier Gruppen, die in verschiedenen Farben dargestellt sind (Elemente der gleichen Farbe beﬁnden sich in der gleichen Gruppe). Untere Schranke Um nun zu beweisen, dass die Suche in ungeordneten Arrays Untere Schrankeim schlimmsten Fall immer Ω(n) viele Vergleiche ausf¨uhrt, betrachten wir wieder einen beliebigen vergleichsbasierten Suchalgorithmus, und deﬁnieren r als die An- zahl durchgef¨uhrter Vergleiche von Schl¨usseln innerhalb von A, und s als die Anzahl durchgef¨uhrter Vergleiche von Schl¨usseln aus A mit b. Die lineare Suche z.B. ver- gleicht r = 0 Schl¨ussel innerhalb von A, und im schlimmsten Fall s = n Schl¨ussel mit b (n¨amlich dann, wenn b das letzte Element ist, oder in A gar nicht vorkommt). Wir beobachten nun, dass die r Vergleiche von Schl¨usseln innerhalb von A das Ar- ray A in g Gruppen unterteilen. Eine Gruppe enth¨alt all diejenigen Schl¨ussel, die durch eine Kette von Vergleichen miteinander verbunden sind (vgl. Abbildung 2.2). Zu Beginn des Algorithmus ist kein Schl¨ussel aus A mit einem anderen Schl¨ussel aus A verglichen worden, folglich gibt es n Gruppen (jeder einzelne Schl¨ussel bildet eine Gruppe der Gr¨osse 1). Um zwei Gruppen miteinander zu verbinden, reicht ein Vergleich. Da das Array n Schl¨ussel speichert (die anfangs n Gruppen darstellen) und wir annehmen, dass es g Gruppen gibt, waren dazu also mindestens n − g viele Vergleiche n¨otig. Folglich gilt also auch r ≥ n − g (es m¨ussen mindestens n − g Schl¨ussel innerhalb von A verglichen werden). Auch k¨onnen wir argumentieren, dass eine erfolglose Suche mindestens einen Vergleich pro Gruppe ben¨otigt. Also m¨ussen mindestens g Schl¨ussel mit b verglichen werden, und damit ist s ≥ g. Insgesamt erhalten wir nun r + s ≥ (n − g) + g = n, (36) d.h., jedes Suchverfahren ben¨otigt auf einem Array der L¨ange n im schlimmsten Fall mindestens n viele Vergleiche (entweder von Schl¨usseln innerhalb von A, oder von Schl¨usseln in A mit b). 2.3 Elementare Sortierverfahren Im Zeitalter von Big Data ist es essentiell, Suchanfragen innerhalb k¨urzester Zeit Motivation beantworten zu k¨onnen. Wir haben bereits gesehen, dass die Schl¨ussel in einem sor- tierten Array signiﬁkant schneller als in einem unsortierten Array gefunden werden k¨onnen. Deswegen wollen wir nun untersuchen, wie wir ein Array sortieren k¨onnen. Formal deﬁnieren wir das Sortierproblem wie folgt: Eingabe: Ein Array A = (A[1], . . . , A[n]) der L¨ange n Definition Sortierproblem Ausgabe: Eine Permutation A′ von A, die sortiert ist, d.h., es gilt A′[i] ≤ A′[j] f¨ur alle i, j mit 1 ≤ i ≤ j ≤ n. Oftmals wollen wir A′ gar nicht getrennt von A berechnen, sondern wollen das Ar- ray A selbst so umordnen, dass es am Ende sortiert ist, d.h., die Ausgabe beﬁndet sich an der Stelle, wo vorher die Eingabe stand. Sortieralgorithmen, die neben der Eingabe nur O(log n) viel zus¨atzlichen Speicher ben¨otigen, werden als “in-place” 30 Sortieren und Suchen oder “in-situ” bezeichnet. Wir werden im Folgenden verschiedene Sortieralgorith- men vorstellen und analysieren, wie viele Schl¨usselvergleiche und wie viele Schl¨ussel-Kostenmodell bewegungen bzw. -vertauschungen sie jeweils im besten und im schlechtesten Fall ausf¨uhren. Weitere Kostenmasse wie z.B. der benutzte Speicher sind denkbar. 2.3.1 Bubblesort Als Vor¨uberlegung f¨ur das erste vorgestellte Sortierverfahren machen wir uns zu-Sortiertheit pr¨ufen n¨achst klar, dass wir mit n − 1 Vergleichen pr¨ufen k¨onnen, ob ein gegebenes Array A sortiert ist. Dazu pr¨ufen wir, ob A[1] ≤ A[2] gilt, ob A[2] ≤ A[3] gilt, usw. Wenn mindestens einer dieser Vergleiche falsch ist, dann wissen wir sofort, dass das Array nicht sortiert ist. Is-Sorted(A = (A[1], . . . , A[n]))Sortiertheit pr¨ufen 1 for j ← 1 to n − 1 do 2 if A[i] > A[i + 1] then return “nicht sortiert” 3 return “sortiert” Wir versuchen nun zu sortieren, indem wir dieses Pr¨ufverfahren ganz leicht mo-Modifikation diﬁzieren: Jedes Mal, wenn A[i] > A[i + 1] gilt, vertauschen wir die Schl¨ussel an den Positionen i und i + 1 (denn sie beﬁnden sich oﬀenbar in der falschen Reihenfolge). Gen¨ugt dies, um ein sortiertes Array zu erhalten? Oﬀenbar nicht, wie etwa das Array (5, 9, 8, 7) zeigt: Nachdem das modiﬁzierte Verfahren durchgelaufen ist, erhalten wir (5, 8, 7, 9), was noch immer nicht sortiert ist. Wir machen aber eine entscheidende Beobachtung: Nach einem solchen Durchlauf ist das gr¨osste Element an die letzteBeobachtung Position des Arrays gewandert. Wiederholen wir das Ganze, dann ist das zweitgr¨oss- te Element an die vorletzte Position verschoben worden, usw. Also sollten insgesamt n − 1 Wiederholungen des obigen Verfahrens zur Sortierung des Arrays ausreichen. Da man sich anschaulich vorstellen kann, dass die Schl¨ussel im Array wie Blasen in einem Wasserglas aufsteigen, nennt man dieses Sortierverfahren Bubblesort. Bubblesort(A = (A[1], . . . , A[n]))Bubblesort 1 for j ← 1 to n − 1 do 2 for i ← 1 to n − 1 do 3 if A[i] > A[i + 1] then Vertausche A[i] und A[i + 1]. Wie viele Operationen f¨uhrt der Algorithmus aus? Oﬀenbar werden in jedem FallAnalyse (n − 1)2 ∈ Θ(n2) viele Schl¨ussel miteinander verglichen. Im schlechtesten Fall (wenn A absteigend sortiert ist) wird zudem bei jedem Vergleich zweier Schl¨ussel eine Ver- tauschung vorgenommen, also gibt es im schlechtesten Fall Θ(n2) viele Schl¨ussel- vertauschungen. Im besten Fall (wenn A bereits sortiert ist) dagegen werden keine Schl¨ussel vertauscht. Man k¨onnte nun einwenden, dass die obige Implementierung von Bubblesort sehrVerbesserung naiv ist. So z.B. muss die innere Schleife eigentlich nur bis n − j laufen, denn die Schl¨ussel an den Positionen n − j + 2, . . . , n beﬁnden sich bereits an der korrekten Position. Wir k¨onnen uns ausserdem merken, ob bei einem Durchlauf der inneren Schleife ¨uberhaupt eine Vertauschung vorgenommen wurde. Ist dies n¨amlich nicht 2.3 Elementare Sortierverfahren 31 Abb. 2.3 Ausf¨uhrung in Bubblesort auf dem Array (3, 7, 5, 1, 4). Blau markierte Schl¨ussel werden in diesem Schritt miteinander verglichen und ggf. vertauscht (dargestellt ist die Situation nach der m¨oglichen Vertauschung). Gr¨un markierte Schl¨ussel sind bereits an der ﬁnalen Position. Der Einfachheit halber sind die letzten Schritte, in denen sich das Array nicht mehr ¨andern, nicht dargestellt. der Fall, dann ist das Array bereits fertig sortiert und der Algorithmus kann vorzeitig beendet werden. Obwohl damit die Anzahl der Schl¨usselvergleiche im besten Fall von Θ(n2) auf n − 1 sinkt, ¨andert dies nichts an den Θ(n2) Schl¨usselvergleichen bzw. -vertauschungen im schlechtesten Fall. 2.3.2 Sortieren durch Auswahl Betrachten wir noch einmal Bubblesort. In der j-ten Phase wird jeweils das j-gr¨osste Element an die korrekte Position A[n − j + 1] gebracht. Das heisst, nach Abschluss von j Phasen beﬁnden sich an den letzten j Positionen des Arrays bereits die j gr¨ossten Schl¨ussel. Das Problem bei Bubblesort war, dass u.U. sehr viele Schl¨usselvertauschungen vorgenommen werden, n¨amlich Θ(n2) im schlechtesten Fall. Der Grund ist, dass wir einen Schl¨ussel immer nur lokal mit seinem Nachbarn austauschen. Stattdessen Induktives Vorgehenk¨onnten wir auch induktiv wie folgt vorgehen. Angenommen, die letzten j Positio- nen des Arrays enthalten bereits die j gr¨ossten Schl¨ussel in der richtigen Reihenfol- ge, d.h., sie beﬁnden sich schon an ihrem endg¨ultigen Platz. Wir suchen jetzt den (j + 1)-gr¨ossten Schl¨ussel. Dieser ist der Schl¨ussel mit dem gr¨ossten Wert im Be- reich A[1], . . . , A[n − j]. Dann tauschen wir ihn und den Schl¨ussel auf der Position A[n − j] aus, erh¨ohen j um 1 und fahren so fort, bis das Array sortiert ist. Dieses Sortierverfahren ist unter dem Namen Sortieren durch Auswahl bekannt. SelectionSort(A) Sortieren durch Auswahl 1 for k ← n downto 2 do ▷ k Schl¨ussel sind noch nicht sortiert 2 Berechne den Index i des maximalen Schl¨ussels in A[1], . . . , A[k]. 3 Vertausche A[i] und A[k]. ▷ A[k] enth¨alt (n − k + 1)-gr¨ossten Schl. Haben wir gegen¨uber Bubblesort etwas gewonnen? Zun¨achst einmal beobachten wir, Analyse dass zur Berechnung des maximalen Schl¨ussels im Bereich A[1], . . . , A[k] immer k −1 32 Sortieren und Suchen Abb. 2.4 Ausf¨uhrung von Sortieren durch Auswahl auf dem Array (3, 7, 5, 1, 4). Blau markierte Schl¨ussel sind das Maximum unter den noch zu sortierenden Schl¨usseln. Gr¨un markierte Schl¨ussel sind bereits an der ﬁnalen Position. Vergleiche anfallen. Damit werden also grunds¨atzlich ∑n k=1(k − 1) ∈ Θ(n2) viele Schl¨ussel miteinander verglichen, was gegen¨uber Bubblesort keine Verbesserung dar- stellt. Allerdings wird in jedem Durchlauf der Schleife nur eine Schl¨usselvertauschung vorgenommen, damit betr¨agt die Anzahl der Schl¨usselvertauschungen lediglich n−1. F¨uhren wir zudem die Vertauschung nur dann aus, wenn i ̸= k gilt, dann werdenVerbesserung im besten Fall ¨uberhaupt keine Schl¨ussel mehr vertauscht, und im schlechtesten Fall weiterhin nur n − 1. Sortieren durch Auswahl wurde hier so beschrieben, dass der sortierte BereichVariante am Ende w¨achst, d.h., nach k Durchl¨aufen der ¨ausseren Schleife die letzten k Po- sitionen im Array die jeweils k gr¨ossten Schl¨ussel speichern. Nat¨urlich kann man auch in den ersten k Positionen die k kleinsten Schl¨ussel speichern, und im Bereich A[k + 1], . . . , A[n] das Minimum suchen und an die Stelle A[k + 1] tauschen. Dies ¨andert weder die Korrektheit, noch die Laufzeit des Verfahrens. 2.3.3 Sortieren durch Einf¨ugen Eine andere Art, einen induktiven Sortieralgorithmus zu entwerfen, besteht in der Annahme, dass das Array bis zu einer gewissen Position k bereits sortiert ist, diese Positionen aber nicht unbedingt schon die k kleinsten Schl¨ussel enthalten. Anders als bei (der zuletzt diskutierten Variante von) Sortieren durch Auswahl beﬁnden sich dort also irgendwelche Schl¨ussel des Arrays, die aber in aufsteigender Reihenfolge angeordnet sind. Der n¨achste Schl¨ussel A[k + 1] muss demnach an der richtigen Position in A[1], . . . , A[k] eingef¨ugt werden (oder an der Position k + 1 verbleiben, falls A[k + 1] ≥ A[k] ist). Um die korrekte Position des Schl¨ussels A[k + 1] im bereits sortierten Bereich A[1], . . . , A[k] zu ﬁnden, f¨uhren wir eine bin¨are Suche nach A[k +1] auf A[1], . . . , A[k] durch. Diese gibt den Index i ∈ {1, . . . , k +1} der Position, an die A[k + 1] eingef¨ugt werden muss, zur¨uck. Es gilt dann oﬀenbar A[i − 1] ≤ A[k + 1] ≤ A[i] (bzw. A[k + 1] ≤ A[i] falls i = 1 ist). Da ein Array ein starre Struktur hat, k¨onnen wir nicht einfach A[k + 1] zwischen die bestehenden Schl¨ussel A[i] und A[i + 1] einf¨ugen. Stattdessen muss A[k + 1] zun¨achst in einer tempor¨aren Variable b zwischengespeichert werden, A[k] auf A[k + 1] kopiert werden, A[k − 1] auf A[k], usw., und abschliessend kann A[i] auf b gesetzt und b verworfen werden. 2.4 Heapsort 33 Abb. 2.5 Ausf¨uhrung von Sortieren durch Einf¨ugen auf dem Array (3, 7, 5, 1, 4). Blau markierte Schl¨ussel sind im n¨achsten Schritt zu sortieren. Die gr¨un markierten Schl¨ussel zeigen den bereits sortierten Bereich an. InsertionSort(A = (A[1], . . . , A[n])) Sortieren durch Einf¨ugen 1 for k ← 1 to n − 1 do ▷ k Schl¨ussel sind bereits sortiert 2 Benutze bin¨are Suche auf A[1], . . . , A[k], um die Position i zu ﬁnden, an die A[k + 1] eingef¨ugt werden muss. 3 b ← A[k + 1] ▷ Speichere A[k + 1] in b zwischen 4 for j ← k downto i do ▷ Verschiebe A[i], . . . , A[k] 5 A[j + 1] ← A[j] ▷ auf A[i + 1], . . . , A[k + 1] 6 A[i] ← b ▷ Speichere A[k + 1] an A[i] Um die Anzahl der Schl¨usselvergleiche zu analysieren, erinnern wir uns zun¨achst, Analyse dass bin¨are Suche auf k Schl¨usseln h¨ochstens Zeit O(log k) ben¨otigt. Es gibt also eine Konstante a, sodass die bin¨are Suche h¨ochstens a log(k) viele Vergleiche ausf¨uhrt. Damit f¨uhrt Sortieren durch Einf¨ugen grunds¨atzlich insgesamt h¨ochstens n−1∑ k=1 a log(k) = a log((n − 1)!) ∈ O(n log n) (37) viele Vergleiche aus (die Absch¨atzung der Summe ﬁndet sich in der Mitschrift zu den mathematischen Grundlagen). Im besten Fall werden nur Θ(n) viele Schl¨ussel bewegt (und sogar keiner, wenn man nur dann verschiebt, wenn i ̸= k + 1 ist). Im schlechtesten Fall allerdings wird in jedem Schleifendurchlauf der Schl¨ussel A[k + 1] an die erste Stelle verschoben, was insgesamt ∑n k=2(k − 1) ∈ Θ(n2) viele Verschie- bungen zur Folge hat. Wir sehen aber auch, dass die Laufzeit wesentlich besser ist, wenn das Array bereits vollst¨andig bzw. zum grossen Teil vorsortiert ist. 2.4 Heapsort Wir erinnern uns kurz an Sortieren durch Auswahl. Die quadratische Laufzeit dieses Verfahrens ergab sich aus der linearen Laufzeit zur Bestimmung des maximalen Schl¨ussels. Wenn wir also das Maximum eﬃzienter bestimmen k¨onnten, dann erg¨abe sich ein Sortierverfahren, das mit weniger als quadratischer Zeit auskommt. Der im Folgenden vorgestellte Heap erlaubt die Extraktion des maximalen Schl¨ussels in Zeit O(log n), wenn n Schl¨ussel verwaltet werden. 34 Sortieren und Suchen Abb. 2.6 Darstellung des Max-Heaps A = (193, 140, 141, 139, 110, 120, 127, 111) als bin¨arer Baum. Der Index rechts neben einem Knoten mit Schl¨ussel k entspricht der Po- sition von k im Array A. Heaps Ein Array A = (A[1], . . . , A[n]) mit n Schl¨usseln heisst Max-Heap, wennMax-Heap alle Positionen k ∈ {1, . . . , n} die Heap-Eigenschaft Heap- Eigenschaft ((2k ≤ n) ⇒ (A[k] ≥ A[2k]) ) und ((2k + 1 ≤ n) ⇒ (A[k] ≥ A[2k + 1])) (38) erf¨ullen. Obwohl ein Max-Heap intern als Array gespeichert wird, kann er als bin¨arer Baum visualisiert werden, wobei jeder Schl¨ussel in genau einem Knoten gespeichert wird (vgl. Abbildung 2.6). Wir beobachten, dass die Nachfolger(knoten) des in A an Position k gespeicherten Knotens im Array an den Positionen 2k sowie 2k +1 gespei- chert sind, sofern diese existieren. Die Heap-Eigenschaft besagt damit anschaulich, dass f¨ur einen Knoten mit Schl¨ussel x die Schl¨ussel der entsprechenden Nachfolger h¨ochstens so gross wie x selbst sind. Folglich ist der maximale Schl¨ussel des Heaps in A[1] bzw. im obersten Knoten gespeichert. Weiterhin sehen wir, dass jeder unterAuslesen des Maximums einem Knoten gespeicherte Teilbaum ebenfalls als Heap interpretiert werden kann. W¨ahrend das reine Auslesen des maximalen Schl¨ussels also einfach ist, ist nichtExtraktion des Maximums oﬀensichtlich, wie er eﬃzient aus dem Heap extrahiert (d.h. entfernt) werden kann. Das Problem liegt in der starren, durch das Array implizit vorgegebenen Struktur des Heaps. Wir l¨osen das Problem wie folgt. Sei m eine Variable, die die Anzahl der Schl¨ussel eines Heaps (A[1], . . . , A[m]) speichert. Wir speichern zu extrahierenden Schl¨ussel A[1], kopieren den in A[m] gespeicherten Schl¨ussel nach A[1] und verringern m um 1. Nun aber ist (A[1], . . . , A[m]) im Allgemeinen kein Heap mehr, denn an der Wurzel ist die Heap-Eigenschaft verletzt (der dort gespeicherte Schl¨ussel ist kleiner als die Schl¨ussel der Nachfolger). Daher wird der in der Wurzel gespeicherte Schl¨ussel mit dem gr¨osseren der an den beiden Nachfolgern gespeicherten Schl¨ussel vertauscht. Somit ist die Heap- Eigenschaft an der Wurzel erf¨ullt, kann aber am entsprechenden Nachfolger verletzt sein. Folglich wird genau dort die Heap-Eigenschaft auf die gleiche Art wiederherge- stellt, und die Wiederherstellung wird f¨ur die jeweiligen Nachfolger fortgesetzt, bis (A[1], . . . , A[m]) wieder ein Heap ist. Man beachte, dass die Heap-Eigenschaft jeweils nur f¨ur den Nachfolger w1 wiederhergestellt werden muss, dessen Schl¨ussel mit dem Schl¨ussel des jeweiligen Vorg¨angers v vertauscht wurde. F¨ur den anderen Nachfolger w2 (sofern existent) ist die Heap-Eigenschaft sowieso erf¨ullt, weil in dem unter w2 gespeicherten Teilbaum ¨uberhaupt keine Schl¨ussel ver¨andert wurden, und weil der in w1 vorher gespeicherte Schl¨ussel gr¨osser als der in w2 gespeicherte Schl¨ussel ist. 2.4 Heapsort 35 Abb. 2.7 Extraktion des Maximums (Schl¨ussel 193) aus dem in Abbildung 2.6 darge- stellten Heap. Im ersten Schritt wird der in A[8] gespeicherte Schl¨ussel nach A[1] kopiert. Abb. 2.8 Wiederherstellung der Heap-Eigenschaft f¨ur die in Abbildung 2.7 dargestellte Struktur. Zun¨achst werden die Schl¨ussel 111 und 141 vertauscht, danach 111 und 127. Abb. 2.9 Der rekonstruierte Heap A = (141, 140, 127, 139, 110, 120, 111). Restore-Heap-Condition(A, i, m) Wiederher- stellung des Heaps1 while 2 · i ≤ m do ▷ A[i] hat linken Nachfolger 2 j ← 2 · i ▷ A[j] ist linker Nachfolger 3 if j + 1 ≤ m then ▷ A[i] hat rechten Nachfolger 4 if A[j] < A[j + 1] then j ← j + 1 ▷ A[j] ist gr¨osserer Nachfolger 5 if A[i] ≥ A[j] then STOP ▷ Heap-Bedingung erf¨ullt 6 Vertausche A[i] und A[j] ▷ Reparatur 7 i ← j ▷ Weiter mit Nachfolger Die Laufzeit von Restore-Heap-Condition ist oﬀenbar in O(log m): Jeder der Laufzeit Schritte 2–7 ben¨otigt nur konstante Zeit, initial ist i ≥ 1, Schritt 7 verdoppelt den Wert von i mindestens, und die Schleife stoppt sobald erstmalig i > m/2 ist. Die Anzahl der Schleifendurchl¨aufe (und damit die Gesamtlaufzeit) ist also durch O(log m) nach oben beschr¨ankt. Schaut man etwas genauer hin, kann man sogar sehen, dass die Laufzeit sogar in O(log(m/i)) ist. Erzeugung eines Heaps Im vorigen Abschnitt wurde gezeigt, wie der maximale Schl¨ussel eﬃzient aus dem Heap extrahiert werden kann. Wie aber kann aus einer 36 Sortieren und Suchen Menge von n Schl¨usseln (A[1], . . . , A[n]) eﬃzient ein Heap zu dieser Schl¨usselmenge erstellt werden? Wir beobachten zun¨achst, dass f¨ur die Positionen ⌊n/2⌋ + 1, . . . , n die Heap-Eigenschaft sofort gilt (anschaulich gesprochen besitzen diese keine Nach- folgerknoten und k¨onnen als Heaps mit genau einem Schl¨ussel interpretiert wer- den). F¨ur die Position ⌊n/2⌋ muss aber die Heap-Eigenschaft nicht notwendiger- weise erf¨ullt sein. Wir rufen nun f¨ur i ∈ {⌊n/2⌋, . . . , 1} sukzessive den Algorithmus Restore-Heap-Condition(A, i, n) auf. Vor dem Aufruf mit Parameter i galt die Heap-Eigenschaft bereits f¨ur alle k ∈ {i + 1, . . . , n}, und nach Terminierung des Auf- rufs gilt die Heap-Eigenschaft f¨ur alle k ∈ {i, . . . , n}. Folglich ist nach dem letzten Aufruf mit dem Parameter i = 1 das Array (A[1], . . . , A[n]) ein Max-Heap. Da wir zum Aufbauen des Heaps nur O(n) Mal Restore-Heap-ConditionLaufzeit aufrufen und jeder solche Aufruf nur Zeit O(log n) ben¨otigt, kann ein unsortier- tes Array in Zeit O(n log n) in einen Max-Heap ¨uberf¨uhrt werden. Diese Schranke kann noch verbessert werden, denn wir hatten bereits im Vorfeld argumentiert, dass Restore-Heap-Condition(A, i, n) nur Zeit O(log(n/i)) ben¨otigt. Damit betr¨agt die Zeit zum Aufbauen des Heaps lediglich C ⌊n/2⌋∑ i=1 ln(n/i) ≤ C ⌈n/2⌉∑ i=1 ln(n/i) = C ln   ⌈n/2⌉∏ i=1 n i   = C ln ( n⌈n/2⌉ ∏⌈n/2⌉ i=1 i ) = C ln ( n⌈n/2⌉ (⌈n/2⌉)! ) = C( ln (n⌈n/2⌉) − ln ((⌈n/2⌉)! )) (39) (∗) ≤ C(⌈n/2⌉ ln n − ⌈n/2⌉ ln(⌈n/2⌉) + ⌈n/2⌉) (40) ≤ C(⌈n/2⌉( ln n − ln(n/2) ) + ⌈n/2⌉) (41) ≤ C(⌈n/2⌉( ln n − ln n + ln 2) ) + ⌈n/2⌉ ) ≤ Cn (42) f¨ur eine geeignet gew¨ahlte Konstante C. Die Ungleichung (∗) gilt aufgrund der fr¨uher bewiesenen Absch¨atzung ln(n!) ≥ n ln(n) − n. Heapsort Sei A = (A[1], . . . , A[n]) das zu sortierende Array. Zur Sortierung von A benutzen wir nun zun¨achst das im vorigen Abschnitt vorgestellte Verfahren zur Erzeugung eines Heaps aus A, und danach extrahieren wir n − 1 Mal das Maximum aus dem Heap und tauschen es an den Anfang des bereits sortierten Bereichs (am Ende des Arrays). Heapsort(A)Heapsort 1 for i ← ⌊n/2⌋ downto 1 do 2 Restore-Heap-Condition(A, i, n) 3 for m ← n downto 2 do 4 Vertausche A[1] und A[m] 5 Restore-Heap-Condition(A, 1, m − 1) Die Korrektheit des Vorgehens haben wir bereits vorher erl¨autert. Wir sehen auch, dass die Anzahl der verglichenen und vertauschten Schl¨ussel stets in O(n log n) liegt, denn es gibt O(n) Aufrufe von Restore-Heap-Condition, von denen jeder O(log n) viele Schl¨ussel vergleicht bzw. vertauscht. Wir haben also endlich ein Sor- tierverfahren entworfen, das selbst im schlechtesten Fall Laufzeit O(n log n) hat. 2.5 Mergesort 37 2.5 Mergesort Idee Schon beim Maximum-Subarray-Problem haben wir gesehen, dass Divide- and-Conquer helfen kann, eﬃziente Algorithmen zu entwerfen. Dieses Prinzip des rekursiven Aufteilens f¨uhrt zu folgender Idee f¨ur ein Sortierverfahren: Die Folge A[1], . . . , A[n] wird in die zwei ann¨ahernd gleich grossen Teilfolgen A[1], . . . , A[⌊n/2⌋] sowie A[⌊n/2⌋ + 1], . . . , A[n] aufgeteilt, die rekursiv sortiert werden. Nach der Sortie- rung der Teilfolgen werden diese wieder zu einer sortierten Gesamtfolge der L¨ange n zusammengef¨ugt. Wir zeigen zun¨achst, wie diese Verschmelzung sortierter Teil- folgen realisiert werden kann. Danach beschreiben wir Sortierverfahren, die bereits sortierte Teilfolgen verschmelzen und so eine insgesamt sortierte Folge erzeugen. Verschmelzen sortierter Teilfolgen Seien F1 und F2 zwei sortierte Teilfolgen. Die sortierte Gesamtfolge F wird erzeugt, indem F1 und F2 mit zwei Zeigern von vorn nach hinten durchlaufen werden. Dies geschieht mithilfe von zwei Variablen i und j, die wir mit 1 initialisieren. Ist F1[i] < F2[j], dann wird F1[i] das n¨achste Element von F , und der Zeiger i wird um 1 erh¨oht. Ansonsten wird F2[j] das n¨achste Element von F , und j wird um 1 erh¨oht. Dieses Vorgehen wird wiederholt, bis entweder F1 oder F2 vollst¨andig durchlaufen sind. Danach wird die noch nicht ersch¨opfte Folge komplett an das Ende von F geh¨angt. Der im Folgenden vorgestellte Algorithmus Merge realisiert die Verschmelzung zweier bereits sortierter Teilfolgen. Diesem Algorithmus werden die vier Parameter A, left, middle und right ¨ubergeben. Dabei ﬁndet sich die bereits sortierte Teilfolge F1 in A[left], . . . , A[middle] und F2 in A[middle + 1], . . . , A[right]. Die verschmolzene Folge F soll schliesslich in A[left], . . . , A[right] gespeichert werden. Da dies genau die Positionen in A sind, an denen F1 und F2 gespeichert sind, muss die sortierte Folge zun¨achst in einem Hilfsarray B der L¨ange right−left+1 gespeichert werden. Die Inhalte von B werden dann im letzten Schritt auf die entsprechenden Positionen im Array A kopiert. Merge(A, left, middle, right) Verschmelzen der Teilfolgen 1 B ← new Array[right-left+1] ▷ Hilfsarray zum Verschmelzen 2 i ← left; j ← middle+1; k ← 1 ▷ Zeiger zum Durchlaufen 3 ▷ Wiederhole, solange beide Teilfolgen noch nicht ersch¨opft sind while (i ≤ middle) and (j ≤ right) do 4 if A[i] ≤ A[j] then B[k] ← A[i]; i ← i + 1 5 else B[k] ← A[j]; j ← j + 1 6 k ← k + 1 7 ▷ Falls die erste Teilfolge noch nicht ersch¨opft ist, h¨ange sie hinten an while i ≤ middle do B[k] ← A[i]; i ← i + 1; k ← k + 1 8 ▷ Falls die zweite Teilfolge noch nicht ersch¨opft ist, h¨ange sie hinten an while j ≤ right do B[k] ← A[j]; j ← j + 1; k ← k + 1 9 ▷ Kopiere Inhalte von B nach A zur¨uck for k ← left to right do A[k] ← B[k − left + 1] 38 Sortieren und Suchen Lemma 2.1. Seien (A[1], . . . , A[n]) ein Array, 1 ≤ l ≤ m ≤ r ≤ n und die TeilarraysKorrektheit (A[l], . . . , A[m]) als auch (A[m + 1], . . . , A[r]) bereits sortiert. Nach dem Aufruf von Merge(A, l, m, r) ist (A[l], . . . , A[r]) komplett sortiert. Beweis. Wir zeigen zun¨achst induktiv die folgende Aussage: Nach k Durchl¨aufen der Schleife in Schritt 3 ist (B[1], . . . , B[k]) sortiert, und es sind B[k] ≤ B[i], falls i ≤ m, sowie B[k] ≤ B[j], falls j ≤ r. Induktionsanfang (k = 0): Vor dem ersten Schleifendurchlauf hat das Array (B[1], . . . , B[0]) L¨ange 0 und die Aussage gilt trivialerweise. (!) Induktionshypothese: Sei nach k Durchl¨aufen der Schleife (B[1], . . . , B[k]) sortiert, und B[k] ≤ A[i], falls i ≤ m, sowie B[k] ≤ A[j], falls j ≤ r. Induktionsschluss (k → k + 1): Betrachte den (k + 1)-ten Durchlauf der Schleife in Schritt 3. Es seien o.B.d.A. A[i] ≤ A[j], i ≤ m und j ≤ r. Nach der Induktionshypothese ist (B[1], . . . , B[k]) sortiert, und B[k] ≤ A[i]. Wird also B[k + 1] ← A[i] gesetzt, dann ist (B[1], . . . , B[k + 1]) noch immer sortiert, und B[k + 1] = A[i] ≤ A[i + 1], falls (i + 1) ≤ m, sowie B[k + 1] ≤ A[j], falls j ≤ r. Anschliessend werden sowohl i als auch k um 1 erh¨oht, also gilt die Aussage auch nach dem (k + 1)-ten Schleifendurchlauf. Der Fall A[j] < A[i] wird analog bewiesen. Nach der Terminierung der Schleife in Schritt 3 gilt entweder i > m oder j > r. Also wird genau eine der Schleifen in den Schritten 7 und 8 ausgef¨uhrt. Sei o.B.d.A. i ≤ m. Dann ist nach k Durchl¨aufen der Schleife im dritten Schritt B[k] ≤ A[i], und da (A[i], . . . , A[m]) sortiert ist, k¨onnen die verbleibenden Elemente von (A[i], . . . , A[m]) an das Ende von B geh¨angt werden, und nach Schritt 8 ist (B[1], . . . , B[r − l + 1)] komplett sortiert. Lemma 2.2. Seien (A[1], . . . , A[n]) ein Array, 1 ≤ l < r ≤ n, m = ⌊(l + r)/2⌋Laufzeit und die Teilarrays (A[l], . . . , A[m]) als auch (A[m + 1], . . . , A[r]) bereits sortiert. Im Aufruf von Merge(A, l, m, r) werden Θ(r − l) viele Schl¨usselbewegungen und Vergleiche ausgef¨uhrt. Beweis. Der Aufwand zur Initialisierung des Arrays der Gr¨osse (r −l +1) im ersten Schritt betr¨agt Θ(r − l). Die Schleifen in den Schritten 3 und 9 werden Θ(r − l) Mal durchlaufen, die Schleifen in den Schritten 7 und 8 nur h¨ochstens O(r − l) Mal. Da f¨ur alle anderen Schritte nur Zeit O(1) anf¨allt, ergibt sich eine Gesamtlaufzeit von Θ(r − l). In jedem Durchlauf der Schleife in Schritt 3 wird genau ein Schl¨usselvergleich ausgef¨uhrt. Ausserdem wird jedes Element genau einmal nach B und genau einmal zur¨uck nach A kopiert. Damit liegt die Anzahl der bewegten und vergli- chenen Schl¨ussel ebenfalls in Θ(r − l). 2.5.1 Rekursives 2-Wege-Mergesort Der im letzten Abschnitt vorgestellte Algorithmus zur Verschmelzung zweier sortier- ter Teilfolgen kann nun benutzt werden, um ein Array rekursiv zu sortieren. Dem im Folgenden vorgestellten Algorithmus Mergesort werden die drei Parameter A, left und right ¨ubergeben, und die Aufgabe besteht in der Sortierung des Teilarrays 2.5 Mergesort 39 (A[left], . . . , A[right]). Zur Sortierung des gesamten Arrays A = (A[1], . . . , A[n]) wird dann Mergesort(A, 1, n) aufgerufen. Mergesort(A, left, right) Rekursives Mergesort 1 if left < right then 2 middle ← ⌊(left + right)/2⌋ ▷ Mittlere Position 3 Mergesort(A, left, middle) ▷ Sortiere vordere H¨alfte von A 4 Mergesort(A, middle + 1, right) ▷ Sortiere hintere H¨alfte von A 5 Merge(A, left, middle, right) ▷ Verschmilz Teilfolgen Zur Bestimmung der Laufzeit von Mergesort stellen wir eine Rekursionsgleichung Laufzeit C(n) f¨ur den Aufwand zur Sortierung eines Arrays mit n Schl¨usseln auf. F¨ur n = 1 ist oﬀenbar C(1) ∈ Θ(1). Zum Verschmelzen zweier ann¨ahernd gleich langer Teilfolgen mit Gesamtl¨ange n/2 werden nach Lemma 2.2 Θ(n) Schl¨usselvergleiche ben¨otigt. Daher f¨uhrt Mergesort auf einer Eingabe der L¨ange n stets C(n) = C (⌈ n 2 ⌉) + C (⌊ n 2 ⌋) + Θ(n) ∈ Θ(n log n) (43) viele Schl¨usselvergleiche und -bewegungen aus. 2.5.2 Reines 2-Wege-Mergesort Die rekursiven Aufrufe im Mergesort machen gar nicht viel ausser mit den Indizes herumzurechnen. Stattdessen kann man Mergesort auch Bottom-up ausf¨uhren, so wie mit der Struktur des Heaps. Dazu sortieren wir zuerst die Teilst¨ucke der L¨ange 2, dann kombinieren (d.h., verschmelzen) wir immer je zwei St¨ucke zu Teilst¨ucken der L¨ange 4, usw. So gehen wir durch alle Zweierpotenzen, bis wir die L¨ange des Arrays erreichen. StraightMergesort(A) Reines 2-Wege- Mergesort 1 length ← 1 ▷ L¨ange bereits sortierter Teilfolgen 2 while length < n do ▷ Verschmilz Folgen d. L¨ange length 3 right ← 0 ▷ A[1], . . . , A[right] ist abgearbeitet 4 while right+length < n do ▷ Es gibt noch mind. zwei Teilfolgen 5 left ← right+1 ▷ Linker Rand der ersten Teilfolge 6 middle ← left+length−1 ▷ Rechter Rand der ersten Teilfolge 7 right ← min(middle+length, n) ▷ Rechter Rand der zweite Teilfolge 8 Merge(A, left, middle, right) ▷ Verschmilz beide Teilfolgen 9 length ← length·2 ▷ Verdoppelte L¨ange der Teilfolgen Wie rekursives Mergesort f¨uhrt reines 2-Wege-Mergesort immer Θ(n log n) viele Laufzeit Schl¨usselvergleiche und -bewegungen aus. 40 Sortieren und Suchen 2.5.3 Nat¨urliches 2-Wege-Mergesort Nat¨urliches 2-Wege-Mergesort vermeidet wie reines 2-Wege-Mergesort rekursive Auf- rufe, beginnt aber initial mit der Verschmelzung von m¨oglichst langen bereits sor- tierten Teilfolgen, w¨ahrend reines 2-Wege-Mergesort immer mit sortierten Folgen der L¨ange 1 beginnt. Das zu sortierende Array A bestehe nun aus k l¨angsten be- reits sortierten Teilfolgen (sog. Runs) R1, . . . , Rk. Ein neuer Run beginnt also genau dann, sobald direkt hinter einem Schl¨ussel ein kleinerer steht. Nat¨urliches 2-Wege- Mergesort verschmilzt R1 mit R2, danach R3 mit R4 usw. Dieses Verfahren wird so lange wiederholt, bis es nur noch einen Run (das sortierte Array A) gibt. NaturalMergesort(A)Nat¨urliches 2-Wege- Mergesort 1 repeat 2 right ← 0 ▷ Elemente bis A[right] sind bearbeitet 3 while right < n do ▷ Finde und verschmilz die n¨achsten Runs 4 left ← right+1 ▷ Linker Rand des ersten Runs 5 middle ← left ▷ A[left], . . . , A[middle] ist bereits sortiert 6 while (middle < n) and A[middle + 1] ≥ A[middle] do 7 middle ← middle+1 ▷ Ersten Run um ein Element vergr¨ossern 8 if middle < n then ▷ Es gibt einen zweiten Run 9 right ← middle+1 ▷ Rechter Rand des zweiten Runs 10 while (right < n) and A[right + 1] ≥ A[right] do 11 right ← right+1 ▷ Zweiten Run um ein Element vergr¨ossern 12 Merge(A, left, middle, right) 13 else right ← n ▷ Es gibt keinen zweiten Run 14 until left = 1 Genau wie rekursives und reines 2-Wege-Mergesort f¨uhrt nat¨urliches MergesortLaufzeit im schlechtesten und im durchschnittlichen Fall Θ(n log n) viele Schl¨usselvergleiche und -bewegungen aus. Im besten Fall dagegen ist das Array bereits sortiert, d.h. es besteht nur aus einem Run. Dann ist A[middle + 1] ≥ A[middle] in Schritt 6 immer wahr, und die Schleife terminiert f¨ur middle = n. Folglich wird in Schritt 13 right ← n gesetzt, und die Schleife in Schritt 3 terminiert nach einem Durchlauf. Es werden also keine keine Schl¨ussel bewegt, und die Anzahl der Vergleiche betr¨agt n − 1. 2.6 Quicksort R¨uckblick Erinnern wir uns kurz zur¨uck an Mergesort. Dort wird das Array in derR¨uckblick Mitte geteilt, sowohl der linke als auch der rechte Teil jeweils rekursiv sortiert und dann die sortierten Teilfolgen zu einer sortierten Gesamtfolge verschmolzen. Wir hatten bereits gesehen, dass sowohl die Anzahl der Schl¨usselvergleiche als auch die Anzahl der Bewegungen im schlimmsten Fall durch O(n log n) nach oben beschr¨ankt ist, daf¨ur aber das Verschmelzen Θ(n) viel Zusatzspeicher ben¨otigt. Um mit weniger Zusatzspeicher auszukommen, werden wir nun ¨uberlegen, wie wir das Verschmelzen umgehen k¨onnen ohne dabei die Korrektheit des Verfahrens aufzuheben. 2.6 Quicksort 41 Abb. 2.10 Umordnung des Arrays A = (5, 9, 2, 1, 17, 11, 8) mit Partition. Als Pivotele- ment wird 8 gew¨ahlt (blau dargestellt). Die Schl¨ussel 9 und 1 beﬁnden sich in falscher Rei- henfolge und werden daher vertauscht. Am Ende des Aufteilungsschritts werden die Schl¨ussel 9 und 8 vertauscht und die Position 4 zur¨uckgeliefert (denn dort beﬁndet sich das Pivot- element). Der Schl¨ussel 8 beﬁndet sich dann an der korrekten Position im Array, und die Teilfolgen (A[1], A[2], A[3]) sowie (A[5], A[6], A[7]) werden rekursiv sortiert. Idee Das sp¨atere Verschmelzen k¨onnten wir uns sparen, wenn wir bereits w¨ussten, Sortieren ohne zu verschmelzendass alle Schl¨ussel in der linken Teilfolge kleiner als alle Schl¨ussel in der rechten Teilfolge w¨aren. Um dies sicherzustellen, investieren wir ein wenig mehr Arbeit in die Aufteilung des Arrays als vorher (in Mergesort ist die Aufteilung in zwei gleich grosse Teile trivial). Dazu nehmen wir f¨ur den Moment an, wir h¨atten bereits eine Methode Partition, die ein Array A im Bereich l, . . . , r so umsortiert, dass sich an irgendeiner Position k ∈ {l, . . . , r} bereits der korrekte Schl¨ussel beﬁndet, alle Schl¨ussel links der Position k kleiner als A[k] und alle Schl¨ussel rechts der Position k gr¨osser als A[k] sind (siehe Abbildung 2.10). Wir nehmen ausserdem an, Partition w¨urde die Position k zur¨uckliefern, die das Array in zwei Teile teilt. Dann k¨onn- ten wir wie folgt rekursiv sortieren, ohne die sortierten Teilfolgen verschmelzen zu m¨ussen: Quicksort(A, l, r) Hauptalgorithmus 1 if l < r then ▷ Array enth¨alt mehr als einen Schl¨ussel 2 k = Partition(A, l, r) ▷ F¨uhre Aufteilung durch 3 Quicksort(A, l, k − 1) ▷ Sortiere linke Teilfolge rekursiv 4 Quicksort(A, k + 1, r) ▷ Sortiere rechte Teilfolge rekursiv Aufteilungsschritt Wie aber kann das Array geeignet aufgeteilt werden? Es ist Idee zur Aufteilungschwierig, das Array in zwei exakt gleich grosse Teile zu teilen, sodass alle Schl¨ussel links kleiner als alle Schl¨ussel rechts sind. Daher w¨ahlt man einfach irgendeinen Schl¨ussel p aus (das sog. Pivotelement), pr¨uft dann f¨ur die anderen Schl¨ussel, ob sie Pivotelement kleiner oder gr¨osser als p sind, und ordnet sie entsprechend um. Als Pivotelement p w¨ahlen wir den Schl¨ussel am rechten Rand des zu sortierenden Bereichs. Wir durchlaufen dann das Array zun¨achst von links, bis wir einen Schl¨ussel A[i] ﬁnden, der gr¨osser als p ist. Dann durchlaufen wir das Array von rechts, bis wir einen Schl¨ussel A[j] ﬁnden, der kleiner als p ist. Ist nun i < j, dann sind sowohl A[i] als auch A[j] jeweils in der falschen Seite des Arrays und werden daher vertauscht. Dann fahren wie soeben beschrieben fort, bis i ≥ j ist. Nun muss nur noch das Pivotelement korrekt positioniert werden. Dazu vertauschen wir A[i] mit p und sind fertig, denn alle Schl¨ussel links vom Pivotelement p (das sich jetzt an Position i beﬁndet) sind kleiner als p, und alle Schl¨ussel rechts von p sind gr¨osser als p. Der folgende Algorithmus realisiert die Aufteilung von (A[l], . . . , A[r]). 42 Sortieren und Suchen Partition(A, l, r)Aufteilungs- schritt 1 i = l 2 j = r − 1 3 p = A[r] 4 repeat 5 while i < r and A[i] < p do i = i + 1 6 while j > l and A[j] > p do j = j − 1 7 if i < j then Vertausche A[i] und A[j] 8 until i ≥ j 9 Tausche A[i] und A[r] 10 return i Zum Nachweis der Korrektheit beobachten wir zun¨achst, dass es ausreichend ist,Korrektheit sich auf den Fall l < r zu beschr¨anken (denn nur f¨ur solche Indizes wird Partition im Hauptalgorithmus Quicksort aufgerufen). Ausserdem nehmen wir wie immer an, dass alle Schl¨ussel im zu sortierenden Array A verschieden sind. Damit kann insbesondere das Pivotelement p nur einmal vorkommen. Wir sehen schonmal, dass die Schritte 5–7 auf jeden Fall dann korrekt sind, wenn am Ende i < j ist. Da j initial r − 1 ist und danach h¨ochstens noch kleiner wird, gilt also i < j < n, also enthalten weder A[i] noch A[j] das Pivotelement p (denn dieses beﬁndet sich ja auf Position r). Sind die Schleifen in den Schritten 5 und 6 abgearbeitet, dann ist A[j] < p < A[i], und damit sind sowohl A[j] als auch A[i] auf der falschen Seite im Array und d¨urfen vertauscht werden (was Schritt 7 tut). Gilt dagegen nach Ablauf der Schritte 5–7 i ≥ j, dann zeigt A[i] auf jeden Fall auf ein Element, welches nicht kleiner als p ist (unter der Annahme, dass alle Schl¨ussel verschieden sind, gilt A[i] < p genau dann, wenn i < r gilt). Zudem wissen wir, dass A[i′] < p f¨ur alle i′ < i gilt, und A[i′] > p f¨ur alle i′ > i mit i′ ̸= r gilt. Tauschen wir also nach der Terminierung der ¨ausseren Schleife in Schritt 8 die Schl¨ussel A[i] und A[r], dann enth¨alt die Position i das Pivotelement p, alle Schl¨ussel links von i sind kleiner als p und alle Schl¨ussel rechts von i sind gr¨osser als p, und der Aufteilungsschritt wurde korrekt durchgef¨uhrt. Praktische ¨Uberlegungen In Schritt 5 des Aufteilungsschritts pr¨ufen wir ja zu-Vergleiche in Schritt 5 n¨achst, ob i < r gilt, und ist dies der Fall, dann pr¨ufen wir weiterhin, ob zus¨atzlich A[i] < p gilt. Erst dann wird i erh¨oht. Schaut man nun genauer hin, dann bemerkt man, dass es ausreichend ist, lediglich A[i] < p zu pr¨ufen, denn f¨ur i = r ist A[i] = p, folglich ist der Vergleich A[i] < p f¨ur i = r immer falsch und die Schleife terminiert. Das Pivotelement dient also quasi als “Stopper”. K¨onnen wir einen ¨ahnlichen Trick f¨ur die Schleife in Schritt 6 anwenden, um denVergleiche in Schritt 6 Vergleich j > l zu eliminieren? Wir k¨onnten vor dem Aufruf von Partition(A, l, r) den Wert von A[l−1] in einer tempor¨aren Variablen x speichern, dann A[l−1] = −∞ setzen (wobei −∞ f¨ur einen Schl¨ussel steht, der kleiner als alle im Array vorkom- menden Schl¨ussel ist) und nach der Terminierung von Partition(A, l, r) wieder A[l − 1] = x setzen. Aufpassen m¨ussen wir nur f¨ur l = 1, denn oftmals haben wir auf das 0-te Element keinen Zugriﬀ (bzw. auf das (−1)-te Element, wenn das Array von 0 bis n − 1 indiziert ist). 2.6 Quicksort 43 Abb. 2.11 Wurde ein Array so umgeordnet, dass nach dem Aufteilungsschritt das obige Array vorliegt (wobei als Pivotelement 11 gew¨ahlt worden ist), dann wurden maximal zwei Schl¨ussel miteinander vertauscht. Eine praktische Implementierung von Partition m¨usste zudem ber¨ucksichtigen, Mehrfach vorkommende Schl¨ussel dass in der Realit¨at Schl¨ussel durchaus mehrfach vorkommen k¨onnen. Eine solche Anpassung ist zwar konzeptionell nicht schwierig, aber recht technisch, weshalb wir dies in diesem Skript nicht weiter verfolgen wollen. Zudem w¨urde man Quicksort Sortieren von wenigen Schl¨usseln nicht rekursiv fortsetzen, wenn der zu sortierende Bereich nur wenige Schl¨ussel um- fasst. Stattdessen sollte man besser ein elementares Sortierverfahren wie etwa Sor- tieren durch Einf¨ugen anwenden. Anzahl verglichener Schl¨ussel Der Aufteilungsschritt selbst vergleicht nur O(r −l) viele Schl¨ussel miteinander. Wie viele Schl¨ussel der gesamte Quicksort-Algorithmus insgesamt miteinander vergleicht, h¨angt oﬀenbar stark von der Wahl des Pivot- elements ab. Im besten Fall wird das Pivotelement immer so gew¨ahlt, dass wir zwei m¨oglichst gleich grosse Teile entstehen, und die Anzahl insgesamt verglichener Schl¨ussel bei einer Eingabe der L¨ange n betr¨agt Anzahl verglichener Schl¨ussel im besten Fall T (n) = 2T (n/2) + c · n, T (1) = 0 (44) f¨ur eine geeignete Konstante c, was T (n) ∈ O(n log n) impliziert. W¨ahlen wir aber in jedem Aufteilungsschritt ein ung¨unstiges Pivotelement (n¨amlich den kleinsten oder den gr¨ossten Schl¨ussel), dann erzeugen wir eine Teilfolge der L¨ange 0 und eine der L¨ange n − 1. Folglich vergleicht Quicksort im schlimmsten Fall also Anzahl verglichener Schl¨ussel im schlechtesten Fall T ′(n) = T ′(n − 1) + c · n, T (1) = 0, (45) d.h. Θ(n2) viele Schl¨ussel! Erschwerend kommt dazu, dass solch ein ung¨unstiger Fall gar nicht allzu schwierig zu konstruieren ist: Da im Aufteilungsschritt immer den am weitesten rechts stehenden Schl¨ussel als Pivotelement w¨ahlt, f¨uhrt Quicksort auf bereits sortierten Arrays also quadratisch viele Schl¨usselvergleiche aus. Anzahl bewegter Schl¨ussel Wir haben soeben gesehen, dass Quicksort im schlech- testen Fall quadratisch viele Schl¨usselvergleiche vornimmt, aber wie sieht es mit der Anzahl bewegter Schl¨ussel aus? Die Analyse der Schl¨usselbewegungen im besten Fall bleibt als ¨Ubung dem Leser vorbehalten. F¨ur die Analyse der Schl¨usselbewe- gungen im schlechtesten Fall machen wir zun¨achst eine entscheidende Beobachtung: Beobachtung Ist ein Aufteilungsschritt vorbei, dann wurden h¨ochstens so viele Schl¨ussel ver- tauscht wie die k¨urzere der beiden noch zu sortierenden Teilfolgen lang ist (siehe Abbildung 2.11)! Enth¨alt die Eingabe des Aufteilungsschritts also n Schl¨ussel, dann werden im allgemeinen h¨ochstens n/2 viele Vertauschungen vorgenommen. Aller- dings f¨uhren die rekursiven Aufrufe weitere Vertauschungen durch, was die Analyse zun¨achst kompliziert erscheinen l¨asst. Daher bedienen wir uns eines Tricks: F¨ur je- Trick de durchgef¨uhrte Vertauschung nehmen wir an, dass der Schl¨ussel, der im sp¨ateren k¨urzeren Teil landet, eine M¨unze zahlt. Der andere an der Vertauschung beteiligte Schl¨ussel zahlt nichts. Die Gesamtanzahl der eingezahlten M¨unzen entspricht dann exakt der Anzahl von Schl¨usselvertauschungen. 44 Sortieren und Suchen Wie oft kann ein einzelner Schl¨ussel zahlen? Dazu ¨uberlegen wir, dass ein Schl¨us-Kosten pro Schl¨ussel sel nur dann zahlt, wenn er in der k¨urzeren der noch zu sortierenden Teilfolgen landet. Diese hat, wie wir soeben gesehen haben, maximal halb so viele Schl¨ussel wie die urspr¨ungliche Folge. Jedes Mal, wenn ein Schl¨ussel zahlt, wird also die L¨ange des Bereichs, in dem er sich beﬁndet, mindestens um die H¨alfte k¨urzer. Da wir urspr¨unglich einen Bereich der L¨ange n hatten und nach log(n) vielen Halbierungen nur noch einen Bereich der L¨ange 1 haben (der trivialerweise sortiert ist), zahlt jeder Schl¨ussel also maximal log(n) viele M¨unzen. Da es insgesamt nur n Schl¨ussel gibt, werden also im schlechtesten Fall O(n log n) viele Schl¨ussel vertauscht. Randomisiertes Quicksort Obwohl Quicksort im schlechtesten Fall eine quadrati- sche Laufzeit hat, wird der Algorithmus in der Praxis h¨auﬁg eingesetzt. Ein Grund daf¨ur besteht darin, dass nur wenige Wahlen eines Pivotelements zu einer quadrati- schen Laufzeit f¨uhren. Um nun zu vermeiden, dass in jedem Aufteilungsschritt ein ung¨unstiges Pivotelement gew¨ahlt wird, ersetzt man die deterministische Wahl eines Pivotelements (z.B., stets den am weitesten rechts liegenden Schl¨ussel) durch eine zuf¨allige Wahl. Das heisst, im ersten Schritt von Partition(A, l, r) w¨ahlen wir eineZuf¨allige Wahl des Pivotelements zuf¨allige nat¨urliche Zahl z aus, die jeden der Werte {l, l + 1, . . . , r − 1, r} mit glei- cher Wahrscheinlichkeit 1/(r − l + 1) annimmt, tauschen A[z] und A[r] und f¨uhren den Aufteilungsschritt wie bisher durch. Wie schlecht kann dies werden? Nun, im schlechtesten Fall ¨andert sich nat¨urlich nichts, denn wir k¨onnten nach wie vor jedes Mal zuf¨allig ein extrem schlechtes Pivotelement w¨ahlen. Solch ein Fall ist aber sehr unwahrscheinlich. Wir werden jetzt zeigen, dass eine zuf¨allige Wahl im Durchschnitt zu guten Ergebnissen f¨uhrt. Wir haben bereits im Vorfeld argumentiert, dass die Anzahl bewegter Schl¨ussel bei einer Eingabe der L¨ange n immer in O(n log n) liegt. Also gen¨ugt es, die erwarteteErwartete Anzahl von Schl¨usselver- gleichen Anzahl T (n) miteinander verglichener Schl¨ussel zu analysieren. Dazu ¨uberlegen wir zun¨achst, dass eine geschickte Implementierung des Aufteilungsschritts auf einem Array der L¨ange n nur n − 1 viele Schl¨ussel miteinander vergleichen muss (das Pivotelement wird genau einmal mit jedem anderen Schl¨ussel verglichen). Beﬁndet sich nach dem Aufteilungsschritt das Pivotelement auf der Position k, dann k¨onnen wir erwarten, dass das Sortieren des linken Teilbereichs T (k − 1) viele Schl¨ussel miteinander vergleicht, und das Sortieren des rechten Teilbereichs T (n − k) viele Schl¨ussel miteinander vergleicht. Da das Pivotelement zuf¨allig gleichverteilt gew¨ahlt wurde, beﬁndet es sich nach Ende des Aufteilungsschritts auf jeder der Positionen {1, . . . , n} mit Wahrscheinlichkeit 1/n. Die erwartete Anzahl verglichener Schl¨ussel bei einer Eingabe der L¨ange n betr¨agt also T (n) = (n − 1) + 1 n n−1∑ k=1 (T (k − 1) + T (n − k) ), T (0) = T (1) = 0. (46) Setzen wir nun einige Werte f¨ur n in obige Formel ein, kann man zur Vermutung gelangen, dass T (n) ≤ 4n log n gilt (wobei wir 0 log 0 := 0 deﬁnieren). Dies wollen wir nun durch vollst¨andige Induktion ¨uber n beweisen. Induktionsanfang (n = 0, n = 1): Da sowohl T (0) = 0 ≤ 4 · 0 log 0 als auch T (1) = 0 ≤ 4 · 1 · log 1 gelten, ist die Behauptung sowohl f¨ur n = 0 als auch f¨ur n = 1 korrekt. Induktionshypothese: Angenommen, es g¨abe ein n ≥ 2 sodass T (n′) ≤ 4n′ log(n′) f¨ur alle n′ mit 0 ≤ n′ ≤ 2 gilt. 2.6 Quicksort 45 Induktionsschritt (n − 1 → n): T (n) = ( 2 n n−1∑ k=1 T (k) ) + n − 1 (47) I.H. ≤ ( 2 n n−1∑ k=1 4k log k ) + n − 1 (48) (∗) = 2 n    n/2∑ k=1 4k log k | {z } ≤(log n)−1 + n−1∑ k=n/2+1 4k log k | {z } ≤log n  |  + n − 1 (49) = 8 n   ( log n − 1 ) n/2∑ k=1 k + log n n−1∑ k=n/2+1 k   + n − 1 (50) = 8 n  log n n−1∑ k=1 k − n/2∑ k=1 k   + n − 1 (51) = 8 n ( log n · n(n − 1) 2 − n 4 ( n 2 + 1)) + n − 1 (52) = 8 (log n · n − 1 2 − n 8 − 1 4 ) + n − 1 (53) = 4(n − 1) log n − n − 2 + n − 1 (54) = 4n log n − 4 log n − 3 ≤ 4n log n. (55) Quicksort vergleicht also im Erwartungswert nur O(n log n) viele Schl¨ussel mitein- ander. Tats¨achlich ist auch die Konstante 4 zu hoch. Eine detaillierte Analyse (die wir hier nicht machen) w¨urde sogar T (n) ≤ 3/2n log n ergeben. Zus¨atzlich ben¨otigter Speicher Wir hatten Quicksort ja urspr¨unglich hergeleitet, um keinen zus¨atzlichen Platz mehr zu ben¨otigen. Wir speichern auch keine Teilfolgen Naive Implemen- tierungmehr zwischen, aber daf¨ur wird Extraplatz zur Verwaltung der rekursiven Aufrufe ben¨otigt. Schon fr¨uher haben wir uns ¨uberlegt, dass Quicksort die Eingabefolge der L¨ange n im schlimmsten Fall in eine Folge der L¨ange n − 1 (und eine weitere der L¨ange 0) aufteilt. Wird diese Aufteilung so fortgesetzt, werden nicht nur quadratisch viele Schl¨ussel miteinander verglichen, wir haben auch eine Rekursionstiefe von n (denn der Aufruf auf der Eingabe der L¨ange n erzeugt einen Aufruf auf einer Eingabe der L¨ange n − 1, diese erzeugt einen Aufruf auf einer Eingabe der L¨ange n − 2, usw). Da die Verwaltung von jedem dieser rekursiven Aufrufe mindestens konstant viel Speicher braucht, ben¨otigen wir im schlechtesten Fall insgesamt Ω(n) viel Speicher. Das Problem tritt nur dann auf, wenn wir die gr¨ossere der beiden Teilfolgen Rekursionstiefe beschr¨ankenrekursiv sortieren. W¨urde hingegen nur die kleinere rekursiv sortiert, dann w¨aren wir nach sp¨atestens O(log n) vielen rekursiven Aufrufen fertig, da sich die Gr¨osse des entsprechenden Bereichs mindestens halbiert. Also tun wir exakt dies: Wir f¨uhren die Rekursion nur auf dem k¨urzeren Teil durch. Statt nun den l¨angeren Teil rekursiv zu sortieren, f¨uhren wir den Aufteilungsschritt erneut auf dem l¨angeren Teil durch, und sortieren dort wieder nur den kleineren Teil. Auf die gleiche Art verfahren wir so weiter, bis der verbleibende Bereich nur noch ein oder zwei Elemente umfasst. 46 Sortieren und Suchen Abb. 2.12 Quicksort mit konstantem Extraplatz Diese Modiﬁkation sorgt also f¨ur eine Rekursionstiefe von O(log n), und damit ist der benutzte Speicher in der gleichen Gr¨ossenordnung. F¨ur Jahrzehnte war es unklar, ob es noch besser geht, vielleicht sogar mit nurKonstanter Extraplatz konstantem Extraplatz. Dies geht in der Tat mit folgender Idee. Bevor wir in den linken Teil der Rekursion absteigen, m¨ussen wir uns das Pivotelement p irgendwie merken. Doch wie soll das gehen ohne Extraplatz? Wir merken uns die Grenze p, die den als zweites zu sortierenden Teilbereich markiert, mit Hilfe von q, dem Pivot- element des Bereichs links von p. Statt die Grenze p explizit als Funktionsargument auf den Stack zu kopieren, “verstecken” wir sie an der Position, an der sonst das Pivotelement q steht. Ist der linke Teil sortiert, so k¨onnen wir die L¨ange des rechten Teils rekonstruieren, indem wir einfach nach rechts gehen, bis wir einen Schl¨ussel ﬁnden, der gr¨osser als p ist. Wir vertauschen q und p und fahren mit dem Teil zwi- schen q und p fort. Danach wissen wir, dass der ganze Array links von p sortiert ist und wir k¨onnen mit dem Teil rechts von p fortfahren (siehe Abbildung 2.12). Ganz so einfach ist es in der konkreten Implementierung dann aber doch nicht, denn wir m¨ussen diesen “Versteck-Schritt” ja rekursiv mehrfach durchf¨uhren. Da- bei m¨ussen wir sicherstellen, dass wir die Kette der versteckten Pivots der Reihe nach zur¨ucktauschen k¨onnen. Wenn wir das gleiche p einfach immer weiter hinun- terschieben, geht das nicht. Aber man kann das zum Beispiel erreichen, wenn man nicht den Pivot versteckt, sondern das Element rechts vom Pivot. Man ¨uberlege sich die Details als Hausaufgabe. Obwohl diese modiﬁzierte Variante von Quicksort mit O(1) Extraplatz auskommt, wird sie in der Praxis nicht verwendet, da der zus¨atzlich betriebene Aufwand f¨ur reale Anwendungen zu gross ist, und O(log n) Extraplatz einerseits v¨ollig akzeptabel und andererseits auch leicht erreichbar ist. 2.7 Eine untere Schranke f¨ur vergleichsbasierte Sortierver- fahren Alle bisher betrachteten Sortierverfahren haben gemeinsam, dass sie im schlech- testen Fall mindestens Ω(n log n) viele Schl¨usselvergleiche durchf¨uhren. Wir werden im Folgenden nur sog. vergleichsbasierte Sortierverfahren anschauen, die allein durchVergleichs- basiertes Sortieren Schl¨usselvergleiche und -vertauschungen sortieren, nicht aber durch Rechnungen mit Schl¨usseln oder ¨ahnlichem. Alle bisher vorgestellten Sortierverfahren (also Bubble- 2.7 Eine untere Schranke f¨ur vergleichsbasierte Sortierverfahren 47 Abb. 2.13 Der Ablaufbaum f¨ur Bubblesort auf einem Array mit drei Schl¨usseln. Jeder innere Knoten (rund) steht f¨ur den Vergleich zweier Schl¨ussel, jedes Blatt (eckig) f¨ur eine ermittelte sortierte Reihenfolge. Da die H¨ohe des Baums 4 ist, fallen im schlechtesten Fall genau drei Schl¨usselvergleiche an. sort, Sortieren durch Auswahl, Sortieren durch Einf¨ugen, Heapsort, Mergesort und Quicksort) sind vergleichsbasiert. Wir ¨uberlegen uns nun, dass jedes vergleichsba- sierte Sortierverfahren im schlechtesten Fall mindestens Ω(n log n) viele Schl¨ussel miteinander vergleichen muss. Wie zum Beweis der unteren Schranke f¨ur die Suche auf sortierten Arrays ¨uber- Schlechtester Falllegen wir zun¨achst, dass jedes vergleichsbasierte Sortierverfahren als Entscheidungs- baum visualisiert werden kann (siehe Abbildung 2.13), in dem jeder innere Knoten einen Vergleich und jedes Blatt f¨ur eine ermittelte sortierte Reihenfolge steht. Die Anzahl der vom Algorithmus im schlechtesten Fall verglichenen Schl¨usselpaare ent- spricht der H¨ohe des Baums (abz¨uglich 1). Da ein korrektes Sortierverfahren jede m¨ogliche sortierte Reihenfolge korrekt erkennen muss, ben¨otigt der Baum mindes- tens n! viele Knoten (denn genau so viele Reihenfolgen gibt es). Da keine weiteren Vergleiche anfallen, sobald die Reihenfolge feststeht, braucht der Baum sogar n! viele Bl¨atter. Ein bin¨arer Baum mit n! vielen Bl¨attern besitzt, wie fr¨uher gesehen, mindestens H¨ohe log(n!), was in Ω(n log n) liegt (zu sehen z.B. mit der fr¨uher be- wiesenen Absch¨atzung ln(n!) ≥ n ln n − n). Jedes vergleichsbasierte Sortierverfahren muss also im schlechtesten Fall mindestens Ω(n log n) viele Schl¨ussel miteinander vergleichen. Im schlechtesten Fall k¨onnen wir also nicht besser werden. Vielleicht k¨onnten wir Durchschnitt- licher Fallaber ein Sortierverfahren entwerfen, das durchschnittlich weniger als O(n log n) vie- le Schl¨usselvergleiche durchf¨uhrt. Wir werden nun zeigen, dass dies ebenfalls nicht m¨oglich ist. Da jedes Blatt des Entscheidungsbaums eine m¨ogliche sortierte Reihen- folge enth¨alt und die Tiefe des Blatts die Anzahl der vom Algorithmus verglichenen Schl¨usselpaare angibt, analysieren wir die durchschnittliche Tiefe eines Blatts. Sei Tn ein beliebiger Entscheidungsbaum mit n Bl¨attern und m(Tn) die mittlere Tiefe eines Blatts in Tn. Wir zeigen nun durch Widerspruch, dass stets m(Tn) ≥ log n gilt. Angenommen, es g¨abe einen Baum, f¨ur den die Aussage nicht gilt. Unter al- len solchen B¨aumen w¨ahlen wir einen mit minimaler Blattanzahl b, d.h. es gelte m(Tb) < log b. Der Baum Tb besteht aus einer Wurzel mit einem linken Teilbaum Tbl mit bl Bl¨attern und einem rechten Teilbaum Tbr mit br Bl¨attern (siehe Abbil- dung 2.14). O.B.d.A. nehmen wir an, dass sowohl Tbl als auch Tbr mindestens ein Blatt haben (man ¨uberlege als Hausaufgabe, warum wir dies annehmen k¨onnen). Damit liegt jedes Blatt von T entweder in Tbl oder in Tbr , und wir haben b = bl + br. Ausserdem sind sowohl bl als auch br strikt kleiner als b. Da b die kleinstm¨ogliche 48 Sortieren und Suchen Abb. 2.14 Der Aufbau des Baums Tb aus einer Wurzel mit einem linken Teilbaum Tbl und einem rechten Teilbaum Tbr . Der linke Teilbaum hat bl Bl¨atter, der rechte br Bl¨atter. Anzahl von Bl¨attern war, deren durchschnittliche H¨ohe strikt kleiner als log b ist, wissen wir, dass m(Tbl) ≥ log bl und m(Tbr ) ≥ log br gelten. Die durchschnittliche Tiefe eines Blatts in Tbl und in Tbr ist in Tb um 1 h¨oher. F¨ur die mittlere Tiefe eines Blatts in Tb erhalten wir damit m(Tb) ≥ bl b ( log bl + 1) + br b ( log br + 1) (56) = (bl( log bl + 1) + br( log br + 1)) · 1 b (57) = (bl log bl + br log br + b ) · 1 b (58) ≥ b 2 ( log b 2 + 1) · 2 · 1 b = log b, (59) was ein Widerspruch zur Annahme m(Tb) < log b ist (die letzte Ungleichung folgt aus der Tatsache, dass x log x konvex ist, damit ist y log y + z log z ≥ (y + z) log y+z 2 f¨ur alle y, z ∈ R+). Damit ist die durchschnittliche Tiefe eines Blatts in jedem Entscheidungsbaum mit n Bl¨attern mindestens log(n). Da dies der durchschnitt- lichen Anzahl verglichener Schl¨ussel entspricht und der Entscheidungsbaum jedes vergleichsbasierten Sortierverfahrens mindestens n! viele Bl¨atter besitzt, ben¨otigt jedes solche Verfahren auch im Durchschnitt log(n!) ∈ Ω(n log n) viele Schl¨usselver- gleiche. Kapitel 3 Dynamische Programmierung 3.1 Einleitung Schon fr¨uher haben wir mehrfach gesehen, dass Induktion beim systematischen L¨osen von Problemen hilfreich sein kann. Es gibt viele M¨oglichkeiten, Probleme induktiv zu l¨osen, und wir wollen jetzt mit der sog. Dynamischen Programmierung eine weitere kennenlernen. Als einleitendes Beispiel betrachten wir einen Algorith- mus zur Berechnung der sog. Fibonacci-Zahlen. Diese sind rekursiv als Fibonacci- Zahlen F1 := 1, F2 := 1, Fn := Fn−1 + Fn−2 f¨ur n ≥ 3 (60) deﬁniert. Oﬀenbar sind also F1 = F2 = 1, F3 = 2, F4 = 3, F5 = 5, usw. Um nun f¨ur ein gegebenes n ∈ N die n-te Fibonacci-Zahl zu berechnen, k¨onnten wir den folgenden rekursiven Algorithmus benutzen: Fibonacci-Recursive(n) Rekursive Berechnung 1 if n ≤ 2 then f ← 1 2 else f ← Fibonacci-Recursive(n − 1) + Fibonacci-Recursive(n − 2) 3 return f Sei nun T (n) die Anzahl der von Fibonacci-Recursive(n) ausgef¨uhrten Opera- Laufzeit tionen. F¨ur n = 1 und n = 2 ist der Aufwand nur konstant, folglich ist T (1) = Θ(1). F¨ur n ≥ 3 haben wir einen rekursiven Aufruf f¨ur n − 2, einen f¨ur n − 1, und zus¨atz- lich wird noch konstante Extrazeit zur Addition der Zahlen ben¨otigt. Folglich ist T (n) = T (n − 2) + T (n − 1) + c f¨ur eine geeignete Konstante c. Nun gilt T (n) = T (n − 2) + T (n − 1) + c ≥ 2T (n − 2) + c ≥ 2 n/2c ′ = ( √2) nc ′ (61) f¨ur eine geeignete Konstante c′. Der Algorithmus zur rekursiven Berechnung der n-ten Fibonacci-Zahl ist also exponentiell in n! Der Grund f¨ur diese schlechte Laufzeit ist, dass manche identischen Teilproble- me wieder und wieder gel¨ost werden (siehe Abbildung 3.1). Um dieses Problem zu beheben, wenden wir einen einfachen Trick an, der unter dem Namen Memoizati- Memoization on bekannt ist: Wir speichern alle Zwischenergebnisse (also alle L¨osungen bereits gel¨oster Teilprobleme) und pr¨ufen vor jedem Aufruf der Methode, ob das entspre- chende Teilergebnis fr¨uher schon einmal berechnet wurde. Falls ja, dann geben wir einfach den gespeicherten Wert zur¨uck. Nur wenn das Ergebnis noch nie berechnet wurde, berechnen wir es wie gehabt. Bevor wir es zur¨uckgeben, speichern wir es, damit es ggf. sp¨ater erneut verwendet werden kann. 49 50 Dynamische Programmierung Abb. 3.1 Die obersten Ebenen des Rekursionsbaums, wenn Fibonacci-Recursive f¨ur n = 47 aufgerufen wird. Zur Berechnung von F47 m¨ussen F46 und F45 berechnet werden, zur Berechnung von F46 entsprechend F45 und F44 usw. Viele Zahlen werden mehrfach berechnet. Man sieht z.B., dass f¨unf redundante Aufrufe zur Berechnung von F43 stattﬁnden! Wir modiﬁzieren nun den soeben gezeigten rekursiven Algorithmus, indem wir ein Array memo verwenden, das von 1 bis n indiziert ist, und das an Position i die i-te Fibonacci-Zahl Fi speichert, falls sie schonmal berechnet wurde, und null ansonsten. Damit erhalten wir den folgenden Algorithmus. Fibonacci-Memoization(n)L¨osung mit Memoization 1 if n-te Fibonacci-Zahl bereits berechnet then 2 f ← memo[n] ▷ Benutze gespeicherten Wert 3 else ▷ Berechne n-te Fibonacci-Zahl 4 if n ≤ 2 then f ← 1 5 else f ← Fibonacci-Memoization(n − 1)+ Fibonacci-Memoization(n − 2) 6 memo[n] ← f ▷ Speichere berechneten Wert 7 return f Auf den ersten Blick hat sich nicht viel ver¨andert. Wir beobachten jetzt aber fol-Laufzeit gendes: Wird in Schritt 5 die Summe berechnet, dann sind nach dem Aufruf von Fibonacci-Memoization(n − 1) sowohl Fn−1 als auch Fn−2 bereits vorberech- net. Der zweite Summand Fibonacci-Memoization(n − 2) kann also in Zeit O(1) ausgerechnet werden. Abbildung 3.2 zeigt einen Teil des Rekursionsbaums f¨ur die Eingabe n = 47. Der Aufwand T (n) f¨ur die Berechnung der n-ten Fibonacci-Zahl ist also konstant, falls sie fr¨uher schon einmal berechnet wurde, und betr¨agt ansonsten lediglich T (n − 1) + O(1) (wobei T (1) ebenfalls konstant ist). L¨osen wir diese Rekur- renz auf, erhalten wir T (n) ∈ O(n), was eine betr¨achtliche Verbesserung gegen¨uber dem naiven Algorithmus darstellt. Wir brauchen lediglich zus¨atzlichen Speicher in der Gr¨ossenordnung von Θ(n). Allerdings ben¨otigte auch der naive Algorithmus Θ(n) viel Speicher zur Verwaltung der rekursiven Aufrufe. Anschaulich k¨onnen wir uns vorstellen, dass wir die Knoten des Baums von oben nach unten berechnen, bis wir an den Bl¨attern ankommen, die den Elementarf¨allen entsprechen oder bereits berechnete Ergebnisse speichern. Ein solches Vorgehen wird daher auch Top-Down-Ansatz genannt.Top-Down 3.1 Einleitung 51 Abb. 3.2 Die obersten Ebenen des Rekursionsbaums, wenn Fibonacci-Memoization f¨ur n = 47 aufgerufen wird. Wie vorher m¨ussen zur Berechnung von F47 sowohl F46 und F45 berechnet werden, zur Berechnung von F46 entsprechend F45 und F44 usw. Im Gegensatz zum naiven Algorithmus sind jetzt aber die entsprechenden Teilergebnisse beim zweiten Aufruf bereits gespeichert und m¨ussen daher nicht erneut berechnet werden. Rund dargestellte Knoten enthalten Werte, die berechnet werden m¨ussen, eckig dargestellte Knoten beinhalten Werte, die bereits fr¨uher berechnet wurden. Wir k¨onnten auch umgekehrt vorgehen und die Werte zun¨achst f¨ur die Elemen- tarf¨alle F1 und F2 explizit deﬁnieren und aufbauend auf diesen Werten F3, F4, . . . berechnen. Ein solches Vorgehen nennt man Bottom-Up-Ansatz, und wir sprechen Bottom-Up dann auch von dynamischer Programmierung. Anschaulich gesprochen berechnen Dynamische Programmie- rung wir also den Baum von unten nach oben. Zur Berechnung der n-ten Fibonacci-Zahl ergibt sich dann der folgende Algorithmus. Fibonacci-Dynamic-Program(n) Dynamisches Programm 1 F [1] ← 1 2 F [2] ← 1 3 for i ← 3, . . . , n do 4 F [i] ← F [i − 1] + F [i − 2] 5 return F [n] Obwohl dieser Bottom-Up-Algorithmus den gleichen asymptotischen Zeit- und Platz- Vorteil bedarf wie der zuvor vorgestellte Top-Down-Algorithmus besitzt, hat er dennoch einen grossen Vorteil: Er ist wesentlich kompakter und leichter verst¨andlich. Dynamische Programmierung: Vorgehen Wenn wir Probleme mit dynamischer Programmierung l¨osen, verwalten wir immer eine DP-Tabelle (auch Tableau ge- DP-Tabelle / Tableaunannt), welche Informationen ¨uber bereits gel¨oste Teilprobleme enth¨alt. Oftmals sind dies die Werte optimaler L¨osungen der entsprechenden Teilprobleme, aber auch Informationen ¨uber die L¨osung selbst k¨onnten dort gespeichert werden. Zu Beginn werden all die Eintr¨age gef¨ullt, die den Elementar- bzw. Randf¨allen entsprechen. Wie wir f¨ur die sp¨ater diskutierten Beispiele noch sehen werden, sind diese oftmals sehr einfach berechenbar. Danach werden die weiteren Eintr¨age der Tabelle sukzes- sive ausgef¨ullt. Dabei wird im Allgemeinen auf weitere, bereits fr¨uher berechnete Eintr¨age der Tabelle zugegriﬀen. Da diese weiteren Eintr¨age vor der Berechnung eines Eintrags bereits fertig berechnet sein m¨ussen, muss man also im Vorfeld die Reihenfolge speziﬁzieren, in der die Tabelle gef¨ullt werden soll. Nachdem die Tabelle 52 Dynamische Programmierung komplett berechnet ist, muss noch die L¨osung f¨ur das urspr¨ungliche Problem abge- lesen werden. Bei der L¨osung eines Problems mittels dynamischer ProgrammierungSystematisches Vorgehen sollte man also stets die folgenden vier Aspekte ber¨ucksichtigen: 1) Deﬁnition der DP-Tabelle: Welche Dimensionen hat die Tabelle? Was ist die Bedeutung jedes Eintrags? Beispiel: Wir benutzen eine Tabelle T der Gr¨osse 1 × n, wobei der i-te Eintrag die i-te berechnete Fibonacci-Zahl enth¨alt. 2) Berechnung eines Eintrags: Wie berechnet sich ein Eintrag aus den Werten von anderen Eintr¨agen? Welche Eintr¨age h¨angen nicht von anderen Eintr¨agen ab? Beispiel: F¨ur i = 1 und i = 2 setzen wir T [i] ← 1. F¨ur ein allgemeines i ≥ 3 setzen wir T [i] ← T [i − 1] + T [i − 2]. 3) Berechnungsreihenfolge: In welcher Reihenfolge kann man die Eintr¨age berech- nen, so dass die jeweils ben¨otigten anderen Eintr¨age bereits vorher berechnet wurden? Beispiel: Die Eintr¨age T [i] werden mit aufsteigendem i berechnet. Wir berech- nen also zuerst T [1], dann T [2], dann T [3], usw. 4) Auslesen der L¨osung: Wie l¨asst sich die L¨osung am Ende aus der Tabelle auslesen? Beispiel: Die zu berechnende n-te Fibonacci-Zahl ist am Ende im Eintrag T [n] gespeichert. Die Laufzeit eines dynamischen Programms berechnet sich oftmals einfach aus der Gr¨osse der Tabelle multipliziert mit dem Aufwand, jeden Eintrag zu berechnen. Dies ist auch der Fall f¨ur das soeben diskutierte Beispiel: Die Tabelle hat n Eintr¨age und die Berechnung eines jeden Eintrags erfordert lediglich konstante Zeit, folglich ist die Gesamtlaufzeit in O(n). In dynamischen Programmen f¨ur andere Probleme kann aber auch der Aufwand zur Berechnung einer geeigneten Reihenfolge oder zum Auslesen der L¨osung die Gesamtlaufzeit dominieren. Um ein Problem mit dynamischer Programmierung zu l¨osen, sollte man sich zuerst ¨uberlegen, wie man das Problem in geeignete Teilprobleme mit einer iden- tischen Struktur zerlegen kann. Um sich dies klarzumachen, kann es hilfreich sein, das Problem zun¨achst rekursiv zu l¨osen. Danach beginnt die eigentliche Arbeit: Man muss sich n¨amlich ¨uberlegen, wie man die Ergebnisse der rekursiven Aufrufe geeig- net in der DP-Tabelle speichern kann. Um das eigentliche dynamische Programm aufzustellen, sollte man dann die zuvor genannten vier Aspekte ber¨ucksichtigen. Wir werden nun f¨ur einige Problem anschauen, wie sie mit dynamischer Programmierung gel¨ost werden k¨onnen. 3.2 L¨angste aufsteigende Teilfolge Motivation Wir untersuchen jetzt ein Problem, das in ¨ahnlicher Form beim De- sign von VLSI-Chips auftritt. In diesem sind zwei gegen¨uberliegende Reihen von punktf¨ormigen Anschl¨ussen gegeben. Die Anschl¨usse der ersten Reihe sind von links nach rechts mit den Zahlen 1, . . . , n nummeriert. Die Anschl¨usse der zweiten Reihe 3.2 L¨angste aufsteigende Teilfolge 53 Abb. 3.3 Zwei m¨ogliche L¨osungen des Anschlussverbindungsproblems. Auf der linken Seite ist eine g¨ultige L¨osung dargestellt, in der die Anschl¨usse mit der Nummer 1 korrekt miteinander verbunden sind. Jede weitere Verbindung zwischen zwei anderen passenden Anschl¨ussen (also z.B. von 2 oben nach 2 unten) w¨urde die rote Verbindung kreuzen, und die entstehende L¨osung w¨are ung¨ultig. Auf der rechte Seite ist eine g¨ultige L¨osung dargestellt, die so viele Anschl¨usse wie m¨oglich miteinander verbindet. tragen ebenfalls die Nummern 1, . . . , n, aber diese Zahlen sind in beliebiger Reihen- folge angeordnet (vgl. Abbildung 3.3). Wir wollen nun so viele passende Anschl¨usse (d.h., Anschluss i in der ersten Reihe mit Anschluss i in der zweiten Reihe) wie m¨oglich miteinander verbinden, dabei aber vermeiden, dass zwei Verbindungen sich kreuzen (denn wenn zwei elektrische Leitungen sich kreuzen, gibt es einen Kurz- schluss). Modellierung Bevor wir uns ¨uberlegen, wie dieses Problem gel¨ost werden kann, m¨ussen wir es zun¨achst etwas formalisieren. Dazu nehmen wir an, dass die An- schl¨usse in der zweiten Reihe von links nach rechts mit den Zahlen a1, . . . , an num- meriert sind. Um die Kreuzungsfreiheit zu modellieren, machen wir folgende Beob- achtung: In jeder g¨ultigen, kreuzungsfreien L¨osung f¨ur das Anschlussverbindungspro- blem sind die Nummern der verbundenen Anschl¨usse in der zweiten Reihe von links nach rechts aufsteigend geordnet. Wir m¨ussen also in der Sequenz A = (a1, . . . , an) L¨angste aufsteigende Teilfolge eine l¨angste aufsteigende Teilfolge suchen. Dies ist eine Teilsequenz von A, deren Elemente von links nach rechts aufsteigend sortiert sind. Ist zum Beispiel die Se- quenz A = (1, 2, 4, 3) gegeben, dann sind sowohl (1, 2, 4) als auch (1, 2, 3) l¨angste aufsteigende Teilfolgen. Auch (1), (2), (4), (3), (1, 2), (1, 4), (1, 3), (2, 4) und (2, 3) sind aufsteigende Teilfolgen von A, sie sind aber nicht l¨angstm¨oglichst. Die Teilfolge (2, 4, 3) dagegen ist nicht aufsteigend, da 4 > 3 gilt. Im Folgenden verallgemeinern wir das Problem ein wenig, indem wir auch Einga- ben zulassen, die andere als die Zahlen {1, . . . , n} enthalten. Auch erlauben wir, dass manche Zahlen in der Eingabe mehrfach vorkommen. Gesucht wird dann eine strikt aufsteigende Teilfolge. Eine l¨angste aufsteigende Teilfolge der Eingabe (2, 3, 3, 3, 5, 1) ist etwa (2, 3, 5) (und nicht (2, 3, 3, 3, 5)). Wir wollen nun ¨uberlegen, wie man das Problem zur Berechnung einer l¨angs- ten gemeinsamen Teilfolge (im Folgenden verk¨urzend LAT genannt) auf geeignete kleinere Probleme zur¨uckf¨uhren kann. Dazu werden wir einige m¨ogliche Ideen un- tersuchen. Entwurf 1 Angenommen, wir h¨atten bereits eine LAT f¨ur die ersten k Elemente berechnet, und wir wollen nun eine LAT f¨ur die ersten k + 1 Elemente berechnen. Dazu betrachten wir das Element ak+1. Falls dieses an die vorher berechnete LAT passt, dann sind wir fertig. Was k¨onnen wir aber tun, falls ak+1 nicht an diese LAT passt? Ein Problem bei diesem Entwurf besteht darin, dass die LAT im allgemeinen nicht eindeutig ist. Angenommen, es w¨are A = (1, 2, 5, 3, 4) gegeben, und wir kennen 54 Dynamische Programmierung bereits die LAT der ersten k = 3 Elemente (also f¨ur die Teilsequenz (1, 2, 5)). Diese LAT ist nat¨urlich (1, 2, 5). Das Element ak+1 = 3 kann nun nicht angeh¨angt werden. Dies w¨are aber wichtig, um sp¨ater die LAT (1, 2, 3, 4) f¨ur die ersten f¨unf Elemente (also f¨ur die Sequenz A selbst) zu berechnen. Entwurf 2 Die vorige Annahme, nur irgendeine LAT f¨ur die ersten k Elemente zu kennen, war oﬀenbar zu schwach. Nehmen wir also nun an, wir h¨atten bereits alle LATs f¨ur die ersten k Elemente berechnet. Um nun alle LATs f¨ur die ersten k + 1 Elemente zu berechnen, k¨onnen wir einfach pr¨ufen, an welche LATs das Element ak+1 passt, und die Folgen entsprechend erweitern. Dies ist aber nicht unproblema- tisch, wie das Beispiel A = (1, 2, 5, 4, 3) zeigt. Angenommen, wir kennen bereits alle LATs f¨ur die ersten k = 4 Elemente. Diese LATs sind (1, 2, 5) und (1, 2, 4). Das Element ak+1 = 3 passt an keine der bestehenden LATs. Wir beobachten aber, dass auch (1, 2, 3) eine LAT ist. Folglich m¨usste die Liste der LATs verl¨angert werden, und wir m¨ussten uns nicht nur alle LATs maximaler L¨ange l merken, sondern auch noch alle LATs der L¨ange l − 1, l − 2, usw. Dies ist deﬁnitiv zu viel, daher ist der Entwurf nicht praktikabel. Entwurf 3 Die Annahme im ersten Entwurf war zu schwach, die Annahme im zweiten Entwurf war zu stark. Das soeben gezeigte Beispiel, in dem die LATs der ersten vier Elemente genau (1, 2, 5) und (1, 2, 4) waren, l¨asst jedoch vermuten, dass es m¨oglicherweise gar nicht erforderlich ist, sich alle LATs zu merken. Stattdessen gen¨ugt es vielleicht auch, sich diejenige LAT zu merken, die mit dem kleinsten Ele- ment endet, denn kann diese LAT nicht erweitert werden, dann kann es auch keine andere. Was k¨onnen wir aber in solch einem Fall tun? Angenommen, eine solche LAT der ersten k Elemente hat L¨ange l, das Element ak+1 passt nicht an diese LAT (da ak+1 kleiner als das letzte Element der LAT ist), aber an die ersten k − 1 Elemente der LAT. Ein Beispiel w¨are die Eingabe A = (1, 2, 5, 4, 3), wo die entsprechende LAT der ersten k = 4 Elemente genau (1, 2, 4) w¨are, die nicht durch ak+1 = 3 erweitert werden kann. Wird dann das (k + 1)-te Element hinzugenommen, ist die LAT nicht mehr (1, 2, 4), sondern (1, 2, 3). Sind wir also fertig? Entwurf 4 (Final) Wir m¨ussen noch ber¨ucksichtigen, dass u.U. auch LATs k¨urzererIdee L¨ange aktualisiert werden m¨ussen. Dies kann im sp¨ateren Verlauf des Algorithmus noch wichtig werden, wie z.B. die Eingabe A = (1, 1000, 1001, 2, 3, 4, . . . , 999) zeigt. Die einzige LAT der ersten k = 3 Elemente ist (1, 1000, 1001). Wird jetzt das Ele- ment ak+1 = 2 gefunden, dann kann dieses nur an die 1 angeh¨angt werden. Dies wird im sp¨ateren Verlauf tats¨achlich noch gebraucht, denn sonst k¨onnte die LAT (1, 2, 3, . . . , 999) nicht berechnet werden. Wir merken uns also f¨ur jede m¨ogliche L¨ange l ∈ {1, . . . , k} diejenige LAT der L¨ange l, die mit dem kleinsten Element endet. Wird dann ein neues Element ak+1 betrachtet, dann suchen wir die l¨angste LAT, die noch durch ak+1 erweiterbar ist. Sei l′ die L¨ange dieser LAT. Wir h¨angen ak+1 an diese LAT an und speichern sie als diejenige LAT der L¨ange l′ + 1, die mit dem kleinsten Element endet. Dynamisches Programm Nachdem wir uns eine L¨osungsidee bereits ¨uberlegt ha- ben, wollen wir nun ein geeignetes dynamisches Programm formulieren. Dazu spei- chern wir keine vollst¨andigen LATs zwischen, sondern merken uns f¨ur jede L¨ange l 3.2 L¨angste aufsteigende Teilfolge 55 lediglich das letzte Element der entsprechenden LAT. Man beachte, dass diese Ele- mente mit aufsteigender L¨ange l aufsteigend sortiert sind. Um sp¨ater die LAT selbst rekonstruieren zu k¨onnen, speichern wir zudem f¨ur jedes Element ak, welches Ele- ment der Vorg¨anger in einer LAT ist, die in ak endet. 1) Deﬁnition der DP-Tabelle: Wir benutzen eine Tabelle T , die von 0 bis n indi- Dynamisches Programmziert ist. F¨ur l > 0 speichert T [l] das letzte Element einer LAT der L¨ange l, deren letztes Element kleinstm¨oglich ist, falls eine solche existiert. Ansonsten ist T [l] = +∞. T [0] speichert stets −∞. Zudem benutzen wir eine weitere Ta- belle V , die von 1 bis n indiziert ist. Der Eintrag V [i] speichert den Vorg¨anger von ai in einer LAT, deren letztes Element ai ist. 2) Berechnung eines Eintrags: Vor Beginn des dynamischen Programms muss die Tabelle T initialisiert werden. Dazu setzen wir T [0] ← −∞ und T [l] ← +∞ f¨ur alle L¨angen l > 0. F¨ur jedes k ∈ {1, . . . , n} wollen wir die l¨angste LAT ermitteln, die um ak erweitert werden kann. Da die Eintr¨age in T aufsteigend sortiert sind, f¨uhren wir eine bin¨are Suche in T aus, um die Position l des am weitesten rechts stehenden Elements in T zu ﬁnden, das kleiner als ak ist. Nach Terminierung der bin¨aren Suche gilt also T [l] < ak < T [l + 1]. Da T [l] das kleinste letzte Element einer LAT der L¨ange l speichert, kann die entsprechende LAT durch ak erweitert werden. Folglich setzen wir T [l + 1] ← ak. Als Vorg¨anger dieses Elements setzen wir V [k] ← T [l] (denn T [l] ist das letzte Element derjenigen LAT, an die das aktuelle Element ak geh¨angt wurde). 3) Berechnungsreihenfolge: Die Eintr¨age T [i] und V [i] werden mit aufsteigendem i berechnet. Wir berechnen also zuerst T [0], dann T [1] und V [1], dann T [2] und V [2], usw. 4) Auslesen der L¨osung: Wir rekonstruieren die L¨osung r¨uckw¨arts, indem wir die Eingabe A r¨uckw¨arts durchlaufen und die Tabellen T und V benutzen. Zuerst wird T von rechts her durchlaufen, um die gr¨osste Position l mit T [l] < ∞ zu ﬁnden. Dann ist l die L¨ange einer LAT, und T [l] ist das letzte Element einer LAT. Wir geben also T [l] aus und suchen nun den Index i1 von T [l] in A, indem A von rechts her durchlaufen wird. Nun geben wir den Vorg¨anger von T [l] aus. Dieser ist in V [i1] gespeichert (daher musste der Index von T [l] erst berechnet werden). Nun suchen wir nach dem Index i2 von V [i1] in A, indem A von i1 ausgehend weiter nach links durchlaufen wird. Dann geben wir V [i2] aus, suchen den Index i3 mit ai3 = V [i2], und verfahren auf diese Art weiter, bis alle Elemente der LAT rekonstruiert sind. Wie eﬃzient ist dieser Algorithmus? In der Initialisierung werden genau n+1 ∈ Θ(n) Laufzeit viele Zuweisungen ausgef¨uhrt. Zur Berechnung des k-ten Eintrags wird zun¨achst eine bin¨are Suche auf den Positionen {1, . . . , k} durchgef¨uhrt, danach werden nur noch konstant viele Zuweisungen vorgenommen. Der Gesamtaufwand zur Berechnung der Tabelle betr¨agt also n∑ k=1 ( log(k) + O(1) ) = O(n) + n∑ k=1 log(k) = Θ(n log n). (62) Zur Rekonstruktion der L¨osung muss im Wesentlichen das Array A einmal von rechts nach links durchlaufen werden. Dar¨uber hinaus werden pro rekonstruiertem Element 56 Dynamische Programmierung nur noch konstant viele zus¨atzliche Operationen ausgef¨uhrt, folglich kann die L¨osung in Zeit O(n) aus der Tabelle extrahiert werden. Die Gesamtlaufzeit des dynamischen Programms betr¨agt also Θ(n log n) + O(n) = Θ(n log n). 3.3 L¨angste gemeinsame Teilfolge Problemformulierung Wir wollen nun ein ¨ahnliches wie das soeben betrachtete Problem untersuchen, und auch f¨ur dieses ¨uberlegen, wie dynamische Programmie- rung zur L¨osung benutzt werden kann. Eine Teilfolge einer Zeichenkette Z ist eine Auswahl von Zeichen aus Z, von links nach rechts geschrieben. Die Zeichenkette KUH etwa hat acht Teilfolgen, n¨amlich die leere Teilfolge, die drei Teilfolgen K, U und H der L¨ange 1, die drei Teilfolgen KU, UH und KH der L¨ange 2, sowie die Teilfolge KUH der L¨ange 3. Dagegen sind z.B. KB, UHU und HK keine Teilfolgen von KUH. Die Eingabe unseres Problems besteht aus zwei Zeichenketten A = (a1, . . . , am)Problem- formulierung und B = (b1, . . . , bn) mit jeweils m bzw. n Zeichen. Gesucht ist eine l¨angste gemein- same Teilfolge (LGT) von A und B. Die LGT von A = IGEL und B = KATZE ist also E, die LGT von A = RIND und B = PFERD ist RD, und die LGT von A = TIGER und B = ZIEGE ist IGE. Anwendung ﬁndet dieses Problem etwa in der Biologie, um die ¨Ahnlichkeit von DNA-Sequenzen zu untersuchen. Rekursive L¨osung Wir ¨uberlegen zun¨achst, wie wir das Problem rekursiv l¨osen k¨onnten. Man kann sich vorstellen, die Zeichenketten A und B so untereinander zu schreiben, dass man die LGT direkt sieht. Dazu m¨ussen ggf. Leerzeichen eingescho- ben werden. F¨ur die Eingaben A = TIGER und B = ZIEGE erhalten wir z.B. T I G E R Z I E G E Wie hilft uns dies nun zur rekursiven L¨osung des Problems? Angenommen, wir k¨onnten bereits f¨ur jedes i ∈ {0, . . . , n} und jedes j ∈ {0, . . . , n} (ausgenommen f¨ur i = m und j = n gleichzeitig) die L¨ange L(i, j) der LGT von A[1..i] und B[1..j] berechnen (also die L¨ange der LGT der ersten i Zeichen von A und den ersten j Zeichen von B). Betrachten wir jetzt nur die letzten beiden Zeichen am von A und bn von B, dann gibt es nur drei M¨oglichkeiten: 1) Die LGT von A und B entspricht der LGT von A[1..m − 1] und B[1..n − 1] (falls am ̸= bn) bzw. der LGT von A[1..m − 1] und B[1..n − 1] um am erweitert (falls am = bn). Dann gilt oﬀenbar L(m, n) = L(m − 1, n − 1) + δmn, wobei δmn = 1 ist, falls am = bn gilt, und δmn = 0 ansonsten. 2) A wird um ein Leerzeichen erweitert, folglich wird bn ignoriert. Es gilt also L(m, n) = L(m, n − 1). 3) B wird um ein Leerzeichen erweitert, folglich wird am ignoriert. Es gilt also L(m, n) = L(m − 1, n). Da wir nicht wissen, welcher dieser drei M¨oglichkeiten maximale L¨ange hat, berech- nen wir einfach rekursiv alle M¨oglichkeiten und setzen daher L(m, n) ← max (L(m − 1, n − 1) + δmn, L(m, n − 1), L(m − 1, n) ), (63) 3.3 L¨angste gemeinsame Teilfolge 57 L Z I E G E 0 0 0 0 0 0 T 0 0 0 0 0 0 I 0 0 1 1 1 1 G 0 0 1 1 2 2 E 0 0 1 2 2 3 R 0 0 1 2 2 3 Abb. 3.4 Die DP-Tabelle zur Berechnung einer l¨angsten gemeinsamen Teilfolge f¨ur die Eingabe A = TIGER und B = ZIEGE. Zur Rekonstruktion der l¨angsten gemeinsamen Teilfolge IGE werden die markierten Tabelleneintr¨age betrachtet. und f¨ur die Randf¨alle legen wir explizit L(0, ·) ← 0 und L(·, 0) ← 0 fest (denn eine LGT einer Zeichenkette und einer leeren Zeichenkette umfasst 0 Zeichen). Dynamisches Programm Die L¨osung im vorigen Abschnitt kann direkt in ein dy- namisches Programm ¨uberf¨uhrt werden, indem einfach alle Zwischenergebnisse in einer zweidimensionalen Tabelle gespeichert werden. 1) Deﬁnition der DP-Tabelle: Wir benutzen eine zweidimensionale Tabelle L, die Dynamisches Programmin der ersten Dimension von 0 bis m und in der zweiten Dimension von 0 bis n indiziert ist. Dabei gibt L[i, j] die L¨ange einer LGT der Zeichenketten (a1, . . . , ai) und (b1, . . . , bj) an. 2) Berechnung eines Eintrags: Die Tabelle L wird initialisiert, indem L[i, 0] ← 0 f¨ur alle i ∈ {0, . . . , m} und L[0, j] ← 0 f¨ur alle j ∈ {1, . . . , n} gesetzt werden. Zur Berechnung von L[i, j] mit i, j ≥ 1 setzen wir L[i, j] ← max (L[i − 1, j − 1] + δij, L[i, j − 1], L[i − 1, j] ), wobei δij = 1 f¨ur ai = bj ist, und δij = 0 sonst. 3) Berechnungsreihenfolge: Zur Berechnung des Eintrags L[i, j] m¨ussen die Ein- tr¨age L[i − 1, j − 1], L[i, j − 1] und L[i − 1, j] bereits berechnet sein. Es gibt mehrere Berechnungsreihenfolgen, die dies garantieren. Wir k¨onnen z.B. die Eintr¨age L[i, j] nach aufsteigendem i, und f¨ur gleiches i nach aufsteigendem j berechnen. Wir berechnen also zuerst L[0, 0], dann L[0, 1] bis L[0, n], dann L[1, 0] bis L[1, n], usw. 4) Auslesen der L¨osung: Am Ende speichert L[m, n] die L¨ange einer LGT von A und B. Um die LGT selbst zu rekonstruieren, laufen wir in der Tabelle zur¨uck und geben immer dann das entsprechende Zeichen aus, wenn die L¨ange um 1 erh¨oht wurde. Konkret setzen wir initial i ← m und j ← n. In jedem Schritt pr¨ufen wir dann, ob ai = bj und L[i, j] = L[i − 1, j − 1] + 1 gelten. Falls ja, dann geben wir ai aus, setzen i ← i − 1 und j ← j − 1. Falls nein, dann pr¨ufen wir, ob L[i, j] = L[i − 1, j] oder L[i, j − 1] gilt und verringern entsprechend i oder j um 1. Wir fahren auf die gleiche Art fort, bis entweder i = 0 oder j = 0 gilt. Danach haben wir die LGT (r¨uckw¨arts gelesen) rekonstruiert. Schaut man sich den Berechnungsschritt genau an, dann wird man merken, dass es beim Auslesen der L¨osung schon gen¨ugt, nur ai = bj zu pr¨ufen. In 58 Dynamische Programmierung diesem Fall gilt immer L[i, j] = L[i − 1, j − 1] + 1, und wir k¨onnen die Rekon- struktion von der Position L[i − 1, j − 1] aus fortsetzen. Ansonsten fahren wir mit der Position L[i, j − 1] fort, falls L[i, j] = L[i, j − 1] gilt, und bei L[i − 1, j] sonst. Die Laufzeit dieses dynamischen Programms l¨asst sich leicht ermitteln. Die DP-Laufzeit Tabelle hat (m + 1) · (n + 1) viele Eintr¨age, und jeder Eintrag l¨asst sich durch eine konstante Anzahl von Zuweisungen und Vergleichen berechnen. Die ben¨otigte Zeit zur Berechnung der Tabelle ist also in O(mn). Beim Auslesen der L¨osung starten wir mit i = m und j = n und verringern in jedem Schritt entweder i oder j (oder sogar beide) um 1, bis i = 0 oder j = 0 (oder beides) gilt. Damit kann die (r¨uckw¨arts gelesene) L¨osung in Zeit O(m + n) ermittelt werden. Insgesamt ergibt sich damit also eine Laufzeit von O(mn). 3.4 Minimale Editierdistanz Ein weiteres Problem, das gewisse ¨Ahnlichkeiten mit der Berechnung einer l¨angsten gemeinsamen Teilfolge hat, ist die Berechnung der Editierdistanz zweier gegebener Zeichenketten A = (a1, . . . , am) und B = (b1, . . . , bn). Die sogenannten Editierope-Editier- operationen rationen f¨ur eine gegebene Zeichenkette sind • die Einf¨ugung eines neuen Zeichens, • die L¨oschung eines bestehenden Zeichens, sowie • die ¨Anderung eines bestehenden Zeichens. Man k¨onnte diese Operationen auch gewichten. So z.B. k¨onnte man festlegen, dass die Einf¨ugung des Zeichens X Kosten 24 und die L¨oschung des Zeichens Y Kosten 1 hat, aber so weit wollen wir jetzt nicht gehen. Stattdessen wollen wir einfach nurProblem- formulierung untersuchen, wie viele Editieroperationen mindestens n¨otig sind, um eine gegebene Zeichenkette A in eine Zeichenkette B zu ¨uberf¨uhren. Wollen wir z.B. die Zeichenkette A = TIGER in B = ZIEGE ¨uberf¨uhren, k¨onnenBeispiel wir zuerst das T durch ein Z ersetzen, dann zwischen I und G ein E einf¨ugen, und schliesslich den letzten Buchstaben R l¨oschen. Die Editierdistanz von A und B ist also h¨ochstens 3 (man kann leicht feststellen, dass man tats¨achlich nicht mit weniger Editieroperationen auskommt). Zur L¨osung dieses Problems k¨onnen wir ¨ahnlich wie zur Berechnung einer l¨angs-Idee ten gemeinsamen Teilfolge vorgehen. Dazu benutzen wir wieder eine zweidimensio- nale DP-Tabelle E, die in der ersten Dimension von 0 bis m und in der zweiten Dimension von 0 bis n indiziert ist. Ein Eintrag E[i, j] gibt die Editierdistanz der Teilzeichenketten A′ = (a1, . . . , ai) und B′ = (b1, . . . , bj) an. Diese berechnen wir als E[i, j] ← min (E[i − 1, j] + 1, E[i, j − 1] + 1, E[i − 1, j − 1] + 1 − δij) (64) (mit δij = 1 genau dann, wenn ai = bj ist, und δij = 0 sonst), denn betrachten wir nur die jeweils letzten Zeichen von A′ und B′, dann k¨onnen wir entweder • das letzte Zeichen von A′ l¨oschen (E[i − 1, j] + 1), • B′ ein Zeichen hinzuf¨ugen (E[i, j − 1] + 1), oder 3.5 Matrixkettenmultiplikation 59 E Z I E G E 0 1 2 3 4 5 T 1 1 2 3 4 5 I 2 2 1 2 3 4 G 3 3 2 2 2 3 E 4 4 3 3 3 2 R 5 5 4 4 4 3 Abb. 3.5 Die DP-Tabelle zur Berechnung der Editierdistanz der Zeichenketten A = TIGER und B = ZIEGE. Zur Rekonstruktion der ben¨otigten Editieroperationen werden die markierten Tabelleneintr¨age betrachtet. • ai durch bj ersetzen (E[i − 1, j − 1] falls ai = bj ist, und E[i − 1, j − 1] + 1 sonst). F¨ur die Randf¨alle setzen wir E[i, 0] ← i f¨ur alle i ∈ {0, . . . , m} (denn die Editierdis- tanz zwischen einer Zeichenkette der L¨ange i und der leeren Zeichenkette betr¨agt exakt i), sowie E[0, j] ← j f¨ur alle j ∈ {1, . . . , n} (denn die Editierdistanz zwischen einer leeren Zeichenkette und einer Zeichenkette der L¨ange j betr¨agt exakt j). Die Gesamtlaufzeit des Verfahrens betr¨agt O(mn). Da das Vorgehen ¨ahnlich zur Laufzeit Berechnung einer l¨angsten gemeinsamen Teilfolge ist, werden wir das dynamische Programm nicht genauer beschreiben. Daher sei dem Leser an dieser Stelle dringend empfohlen, die Details auszuarbeiten und sich insbesondere zu ¨uberlegen, wie man aus der ausgef¨ullten Tabelle die entsprechende Folge von Editieroperationen auslesen kann. 3.5 Matrixkettenmultiplikation Angenommen, wir haben n Matrizen A1, . . . , An und wollen das Produkt Problem A1 × A2 × · · · × An (65) berechnen. Eine naive Vermutung ist, dass man einfach P1 := (A1 × A2) berechnen sollte, dann P2 := (P1 × A3), dann P3 := (P2 × A4), usw. Dieses Vorgehen ist aber oftmals nicht sinnvoll, denn die Matrizenmultiplikation ist assoziativ. Das heisst also, wir k¨onnen die Klammerung bei der Matrizenmultiplikation beliebig w¨ahlen. So zum Beispiel gilt ((A1 × ((A2 × A3) × A4)) × A5) = ((A1 × A2) × A3) × (A4 × A5). (66) Das Resultat ist zwar immer gleich, aber der Rechenaufwand kann sich je nach Klammerung ¨andern (siehe Abbildung 3.6). Die Multiplikation einer (r × s)-Matrix A1 mit einer (s × u)-Matrix A2 hat die Kosten r · s · u, und als Ergebnis erhalten wir eine (r × u)-Matrix. Wir erhoﬀen uns nun, dass die Bestimmung einer optimalen Klammerung wesentlich schneller als die anschliessende Ausf¨uhrung der Multiplika- tionen dauert. F¨ur eine Bibliothek mathematischer Software kann es dann durchaus Sinn machen, sich vorher Gedanken ¨uber die beste Klammerung zu machen. Induktiv ¨uberlegen wir uns, welche beiden Teilprodukte als letztes miteinan- Vorgehen der multipliziert werden sollen. Die beiden Operanden dieser ﬁnalen Multiplikation h¨angen davon ab, welche zusammenh¨angenden Teilst¨ucke der Matrizenfolge schon 60 Dynamische Programmierung Abb. 3.6 Angenommen, es sind drei Matrizen A1, A2 und A3 gegeben. Dabei haben A1 und A3 die Dimensionen (k × 1), w¨ahrend A2 die Dimension (1 × k) hat (links). Klammern wir ((A1 × A2) × A3), dann berechnen wir zuerst die (k × k)-Matrix (A1 × A2), an die A3 multipliziert wird (Mitte). Dabei fallen insgesamt O(k2) viele Operationen an. Klammern wir dagegen (A1 × (A2 × A3)), dann berechnen wir zuerst die (1 × 1)-Matrix (A2 × A3), die an A1 multipliziert wird (rechts). Dabei fallen lediglich O(k) viele Operationen an. miteinander multipliziert wurden. Wenn wir f¨ur einen Index i bereits die Matrizen A1 bis Ai miteinander multipliziert haben und auch schon Ai+1 bis An berechnet haben, dann verbleibt als letztes lediglich (A1 × A2 × · · · × Ai) × (Ai+1 × Ai+2 × · · · × An) zu berechnen. Wir suchen nun das beste i, also die beste Aufteilung in zwei Teilst¨ucke, um den Gesamtaufwand zu minimieren. Dazu deﬁnieren wir eine zweidimensionale Tabelle M , wobei M [p, q] die KostenIdee f¨ur dynamisches Programm der besten Klammerung von Ap × · · · × Aq angibt. Dieser Eintrag kann durch M [p, q] ← min p≤i<q ( M [p, i] + M [i + 1, q] + Kosten der Multiplikation von (Ap × · · · × Ai) mit (Ai+1 × · · · × Aq) ) (67) berechnet werden. Als Randf¨alle legen wir M [p, p] ← 0 f¨ur alle p ∈ {1, . . . , n} fest. In welcher Reihenfolge sollten die Eintr¨age nun berechnet werden? Dazu m¨ussen wirBerechnungs- reihenfolge zun¨achst sicherstellen, dass im Berechnungsschritt keine kreisf¨ormigen Abh¨angig- keiten entstehen (dies w¨are z.B. der Fall, wenn die Berechnung eines Eintrags A die Berechnung von B voraussetzt, die Berechnung von B die Berechnung von C voraussetzt, und die Berechnung von C die Berechnung von A voraussetzt). Um zu sehen, dass der oben beschriebene Berechnungsschritt keine solchen kreisf¨ormigen Abh¨angigkeiten erzeugt, betrachten wir q −p: Die Berechnung von M [p, q] h¨angt nur von zuvor berechneten Eintr¨agen M [p′, q′] mit q′ − p′ < q − p ab. Folglich sollte die Tabelle diagonal gef¨ullt werden. Wir berechnen also zun¨achst M [1, 1], . . . , M [n, n], danach M [1, 2], M [2, 3], . . . , M [n − 1, n], dann M [1, 3], . . . , M [n − 2, n] und fahren auf diese Weise fort, bis schlussendlich M [1, n] berechnet wurde. Wie aus dieser Ta- belle die entsprechende Reihenfolge ausgelesen werden kann, bleibt dem Leser als Hausaufgabe ¨uberlassen. Wie schnell ist der soeben beschriebene Algorithmus? Zun¨achst beobachten wir,Laufzeit dass die DP-Tabelle n2 viele Eintr¨age besitzt. Zur Berechnung eines Eintrags m¨ussen im schlechtesten Fall bis zu n − 1 viele andere Eintr¨age betrachtet werden. Somit ergibt sich eine Gesamtlaufzeit O(n3). 3.5.1 Exkurs: Multiplikation zweier Matrizen Als letztes wollen wir noch kurz ¨uberlegen, wie eﬃzient wir zwei (n × n)-MatrizenProblem A und B miteinander multiplizieren k¨onnen. Das entstehende Produkt C = A × B hat Gr¨osse n × n, und eine naive Methode zur Multiplikation f¨uhrt zur Berechnung eines Eintrags in C genau n elementare Multiplikationen aus (genauer: Sind A = (aij)1≤i,j≤n, B = (bij)1≤i,j≤n und C = (cij)1≤i,j≤n, dann gilt cij = ∑n k=1 aik · bkj). Also ben¨otigt ein naiver Algorithmus zur Multiplikation zweier (n × n)-Matrizen Θ(n3) viele elementare Multiplikationen. 3.6 Subset Sum Problem 61 Abb. 3.7 Multiplikation zweier Matrizen A und B und ihre Aufteilung in vier Teilma- trizen. Bereits bei der Multiplikation von Zahlen haben wir gesehen, wie Divide-and- Idee Conquer helfen kann, mit weniger elementaren Operationen auszukommen. Wieder wollen wir die Kosten f¨ur die Additionen der einzelnen Teile ignorieren und uns nur auf die Anzahl durchgef¨uhrter Multiplikationen konzentrieren. Der Einfachheit halber nehmen wir an, dass n = 2k f¨ur ein k ∈ N0 gilt. Wir unterteilen nun A, B und C jeweils in vier gleich grosse (n/2 × n/2)-Teilmatrizen (siehe Abbildung 3.7) und berechnen die Eintr¨age der Teilmatrizen in C rekursiv. Wir berechnen also die acht (n/2 × n/2)-Teilmatrizen e × a, e × b, f × c, f × d, g × a, g × b, h × c und h × d. Die Anzahl durchgef¨uhrter elementarer Multiplikationen bei der Multiplikation zweier (n × n)-Matrizen betr¨agt damit M (n) = 8M (n/2), M (1) = 1, (68) was die Auﬂ¨osung M (n) = 8log2 n = nlog2 8 = n3 besitzt. Wir haben also bisher noch nichts gewonnen. Strassen beobachtete nun, dass es ausreicht, die sieben Produkte (f −h)×(c+d), Verbesserung (e − g) × (a + b), (e + h) × (a + d), (e + f ) × d, (g + h) × a, e × (b − d), h × (c − a) zu berechnen, denn aus diesen lassen sich alle Teile von C berechnen! So z.B. ergibt sich e × b + f × d als Summe aus (e + f ) × d und e × (b − d). Die anderen drei Teilmatrizen von C k¨onnen auf ¨ahnliche Weise durch Additionen und Subtraktionen aus den zuvor berechneten Produkten zusammengesetzt werden (nachpr¨ufen!). Damit verringert sich die Anzahl der elementaren Multiplikationen auf Laufzeit M ′(n) = 7M ′(n/2), M ′(1) = 1, (69) was die Auﬂ¨osung M ′(n) = 7log2n = nlog2 7 ≈ n2.807 besitzt. Das Verfahren von Strassen f¨uhrt also weniger elementare Multiplikationen als das naive Verfahren aus. Mittlerweile sind Verfahren bekannt, die nur noch etwa O(n2.373) viele Operationen ben¨otigen. Ob man zwei Matrizen auch schneller, vielleicht sogar in Zeit Θ(n2) multiplizieren kann, ist unbekannt. 3.6 Subset Sum Problem Alice und Bob sind Geschwister und haben zusammen n Geschenke {1, . . . , n} zu Problem- definitionWeihnachten bekommen. Das i-te Geschenk hat dabei den Wert ai. Da Alice und Bob ¨ahnliche Interessen haben, beschliessen sie die Geschenke gerecht untereinander 62 Dynamische Programmierung aufzuteilen, sodass beide Geschwister Geschenke vom gleichen Wert haben. In diesem Abschnitt wollen wir Algorithmen zur L¨osung dieses Problems entwerfen. Dazu nehmen wir an, dass als Eingabe n Zahlen a1, . . . , an ∈ N gegeben sind, undFormalisierung wollen entscheiden, ob eine Auswahl I ⊆ {1, . . . , n} mit ∑i∈I ai = ∑ i∈{1,...,n}\\I ai existiert. Falls ja, dann soll eine entsprechende Menge I mit dieser Eigenschaft auch ausgegeben werden. Dieses Problem ist unter dem Namen Subset Sum Problem be-Subset Sum Problem kannt. Algorithmus 1 (Naiv) Jede Auswahl I ⊆ {1, . . . , n} kann durch einen BitvektorNaiver Algorithmus b = (b1, . . . , bn) ∈ {0, 1}n der L¨ange n codiert werden, bei dem bi = 1 genau dann gilt, wenn i ∈ I ist. Ein naiver Algorithmus w¨urde alle 2n m¨oglichen Bitvektoren generieren und pr¨ufen, ob die Summe der Werte aller Gegenst¨ande i mit bi = 0 exakt der Summe der Werte aller Gegenst¨ande i mit bi = 1 entspricht. Falls ja, wird die entsprechende Auswahl ausgegeben und der Algorithmus terminiert. Ansonsten wird mit dem n¨achsten Bitvektor fortgefahren, bis entweder ein entsprechender Bitvektor gefunden wurde, oder aber alle Bitvektoren erfolglos getestet wurden. In diesem Fall existiert keine gerechte Aufteilung aller Geschenke. Da der Algorithmus im schlech- testen Fall 2n viele Bitvektoren betrachtet und f¨ur jeden solchen mindestens einen Schritt ausf¨uhren muss, liegt die Laufzeit dieses naiven Algorithmus im schlechtesten Fall zwischen Ω(2n) und O(n2n). Algorithmus 2 (Zerlegung in Teilprobleme) Wir zerlegen die Eingabe zun¨achst inVerbesserung zwei gleich grosse Teile a1, . . . , an/2 sowie an/2+1, . . . , an (o.B.d.A. sei n gerade). F¨ur jeden dieser zwei Teile generieren wir alle erreichbaren 2n/2 Teilsummen Sk 1 , . . . , Sk 2n/2 (f¨ur k ∈ {1, 2}), indem wir wie im naiven Algorithmus ¨uber alle Bitvektoren der L¨ange n/2 iterieren, die Werte aller Gegenst¨ande in der entsprechenden Auswahl aufsummieren und die erhaltene Teilsumme abspeichern. F¨ur jeden Teil getrennt sortieren wir dann alle Teilsummen, sodass am Ende Sk 1 ≤ Sk 2 ≤ · · · ≤ Sk 2n/2 f¨ur k ∈ {1, 2} gilt. Wir wollen nun pr¨ufen, ob es eine Teilsumme S1 i des ersten Teils und eine Teilsumme S2 j des zweiten Teils gibt, die zusammen z := 1 2 ∑n i=1 ai ergeben. Ist z ̸∈ N, dann wissen wir, dass es solche Teilsummen nicht gibt und sind fertig. Ansonsten setzen wir i ← 1 und j ← 2n/2, und unterscheiden drei F¨alle: 1) Ist S1 i + S2 j = z, dann haben wir zwei solche Teilsummen gefunden, ermitteln die Menge I aller Gegenst¨ande, deren aufsummierte Werte genau S1 i und S2 j ergeben, geben I zur¨uck und sind fertig. 2) Ist S1 i + S2 j < z, dann erh¨ohen wir i um 1. 3) Ansonsten ist S1 i + S2 j > z und wir verringern j um 1. Das Verfahren terminiert, wenn entweder i > n oder j < 1 gilt; in diesem Fall gibt es keine solchen Teilsummen (und auch keine gerechte Aufteilung der Geschenke). Die Generierung aller Teilsummen in jedem der zwei Teile ben¨otigt jeweils ZeitLaufzeit O(n2n/2), das Sortieren entsprechend O(2n/2 log(2n/2)) = O(n2n/2). Ob zwei Teil- summen S1 i und S2 j mit S1 i + S2 j = z existieren, kann in Zeit O(2n/2) entschieden werden. Die Gesamtlaufzeit ist also in O(n2n/2), was O(n( √2)n) entspricht. Dies ist schon bedeutend schneller als der naive Algorithmus, da √2 ≈ 1, 4142 gilt. Man k¨onnte auf die Idee kommen, dass eine Aufteilung in noch kleinere Teil- probleme vielleicht zu einem noch schnelleren Algorithmus f¨uhrt. Leider ist derzeit 3.6 Subset Sum Problem 63 nicht bekannt, ob und wie so etwas konkret funktionieren k¨onnte. Wir brauchen also neue Ideen. Algorithmus 3 (Dynamische Programmierung) Wie im vorigen Abschnitt deﬁnie- ren wir z := 1 2 ∑n i=1 ai. Wir wollen nun einen Algorithmus entwerfen, der nach dem Prinzip der dynamischen Programmierung arbeitet und feststellt, ob es eine Aus- wahl I der Gegenst¨ande {1, . . . , n} gibt, sodass ∑ i∈I ai = z gilt, und diese Auswahl ggf. zur¨uckliefert. 1) Deﬁnition der DP-Tabelle: Wir benutzen eine zweidimensionale Tabelle T , die Dynamisches Programmin der ersten Dimension von 0 bis n und in der zweiten Dimension von 0 bis z indiziert ist. Jeder Eintrag enth¨alt entweder “wahr” oder “falsch”, und T [k, s] gibt an, ob es eine Auswahl I der ersten k Gegenst¨ande {1, . . . , k} gibt, sodass∑ i∈I ai = s gilt. 2) Berechnung eines Eintrags: Wir initialisieren die Tabelle T , indem in T [0, 0] der Wert “wahr” und in T [0, s] f¨ur alle s ∈ {1, . . . , z} der Wert “falsch” gespeichert wird (mit k = 0 Gegenst¨anden kann allein die Teilsumme 0 erreicht werden, aber keine gr¨osseren Teilsummen). Zur Berechnung des Eintrags T [k, s] pr¨ufen wir zun¨achst, ob der k-te Gegen- stand ¨uberhaupt benutzt werden kann. Ist n¨amlich s < ak, dann kann dieser Gegenstand nicht dazu benutzt werden, um die Summe s zu erreichen, denn sein Wert ist zu hoch. In diesem Fall gilt also oﬀenbar T [k, s] = T [k − 1, s]. An- sonsten ist s ≥ ak, und wir k¨onnen den k-ten Gegenstand entweder benutzen (dann muss eine Auswahl der ersten k − 1 Gegenst¨ande existieren, mit denen die Summe s − ak erreicht werden kann) oder nicht benutzen (dann muss ei- ne Auswahl der ersten k − 1 Gegenst¨ande existieren, mit denen die Summe s erreicht werden kann). Wir setzen also T [k, s] ← { T [k − 1, s] falls s < ak, T [k − 1, s] ∨ T [k − 1, s − ak] falls s ≥ ak. (70) Dabei steht ∨ f¨ur das logische ODER zweier Wahrheitswerte x und y (hier: T [k − 1, s] und T [k − 1, s − ak]), das nur dann den Wert “falsch” annimmt, wenn sowohl x als auch y den Wert “falsch” haben. 3) Berechnungsreihenfolge: Die Eintr¨age T [k, s] k¨onnen mit aufsteigendem k und f¨ur gleiches k f¨ur aufsteigendes s berechnet werden. 4) Auslesen der L¨osung: Ob eine Auswahl I ⊆ {1, . . . , n} mit ∑ i∈I ai = z exis- tiert, steht am Ende im Eintrag T [n, z]. Enth¨alt dieser den Wert “wahr”, dann k¨onnen die Elemente einer solchen Auswahl I wie folgt rekonstruiert werden. Wir setzen zun¨achst I ← ∅. Falls T [k, s] = T [k − 1, s] gilt, dann wird der Gegenstand k nicht benutzt, und wir setzen die Rekonstruktion bei T [k − 1, s] fort. Ansonsten muss T [k, s] = T [k − 1, s − ak] gelten, folglich f¨ugen wir I den Gegenstand k hinzu und setzen die Rekonstruktion bei T [k − 1, s − ak] fort. Auf diese Weise verfahren wir weiter, bis schlussendlich k = 0 gilt. Der Algorithmus benutzt eine Tabelle der Gr¨osse (n + 1) · (z + 1), die Berechnung Laufzeit eines jeden Eintrags ben¨otigt nur konstante Zeit, und auch die L¨osung kann in Zeit O(n) ausgelesen werden. Die Gesamtlaufzeit betr¨agt also O(nz). 64 Dynamische Programmierung H¨arte von Problemen Eine Laufzeit von O(nz) wirkt zun¨achst polynomiell. Jetzt m¨ussen wir aber gut aufpassen: Anders als sonst ist z eine Zahl, und diese kann durch ⌈log2(z + 1)⌉ viele Bits repr¨asentiert werden. Die Eingabel¨ange des ProblemsEingabel¨ange ist also in O(n log z). Ist z selbst polynomiell in n, dann ist auch n · z polynomiell in der Eingabel¨ange. Ist dagegen z nicht polynomiell in n (z.B., wenn z = 2n ist), dann ist auch n · z nicht polynomiell in der Eingabel¨ange. Solch einen Algorithmus nennt man pseudopolynomiell. Seine Laufzeit ist genau dann polynomiell, wenn derPseudo- polynomiell Wert aller in der Eingabe vorkommenden Zahlen polynomiell in der Eingabel¨ange beschr¨ankt ist. Es ist nicht bekannt, ob f¨ur das Subset Sum Problem ein Algorithmus mit echt polynomieller Laufzeit existiert. Um dies n¨aher zu erl¨autern, m¨ussen wir kurz aus- holen und zwei Klassen von Problemen deﬁnieren. Die Klasse P ist als Menge aller in Polynomialzeit l¨osbarer Probleme deﬁniert. F¨ur jedes Problem in P gibt es also einen Algorithmus, der in polynomieller Zeit (in der L¨ange der Eingabe) eine L¨osung f¨ur das Problem berechnet. Die Klasse NP ist als Menge aller nichtdeterministischNichtdeter- ministisch polynomiell polynomiell l¨osbarer Probleme deﬁniert.1 Das sind alle Probleme, f¨ur die man eine L¨osung in polynomieller Zeit veriﬁzieren kann. Angenommen, wir betrachten das Subset Sum Problem f¨ur die Eingabe n = 3, a1 = 8, a2 = 9, a3 = 17. H¨atten wir ein gutartiges Orakel, das auf irgendeine Art die L¨osung {1, 2} ermittelt und uns mit-Orakel teilt, dann k¨onnen wir in Polynomialzeit pr¨ufen, dass diese wirklich eine gleichm¨assi- ge Aufteilung der Werte {a1, . . . , an} darstellt (indem wir die Werte der Auswahl der vorgegebenen L¨osung aufsummieren und pr¨ufen, ob diese Summe exakt halb so gross wie die Summe aller Werte a1, . . . , an ist). Nat¨urlich ist P eine Teilmenge von NP, denn k¨onnen wir eine L¨osung selbst in Polynomialzeit ermitteln, dann k¨onnen wir f¨ur eine gegebene L¨osung auch in Polynomialzeit pr¨ufen, ob sie das Problem l¨ost oder nicht. Die Frage, ob P = NP gilt, ist die bedeutendste unl¨oste Frage in der theoretischen Informatik. Oftmals wird vermutet, dass die Gleichheit nicht gilt. F¨ur das Subset Sum Problem ist bekannt, dass es in NP liegt. Es ist aber nicht bekannt, ob es auch in P liegt. Unter der Annahme P ̸= NP gibt es also f¨ur dieses Problem keinen Algorithmus mit einer echt polynomiellen Laufzeit; auf viel mehr als einen pseudopolynomiellen Algorithmus k¨onnen wir im Moment nicht hoﬀen. 3.7 Rucksackproblem Ein Tierarzt f¨ahrt zu seinen Patienten und hat eine Menge von n Gegenst¨andenProblem- definition {1, . . . , n} zur Verf¨ugung, die bei einer Behandlung n¨utzlich sein k¨onnten. Jeder Gegenstand i hat den Nutzwert (engl. value) vi und das Gewicht (engl. weight) wi. Leider erlaubt das benutzte Fahrzeug nur eine Zuladung des Gewichts W .2 Daher wollen wir eine Auswahl I ⊆ {1, . . . , n} der Gegenst¨ande berechnen, deren Summe der Gewichte ∑ i∈I wi h¨ochstens W betr¨agt, und deren gesamter Nutzen ∑i∈I vi maximal ist. Dieses Problem ist unter dem Namen Rucksackproblem bekannt. Eine gierige Heuristik Eine naheliegende Idee zur L¨osung besteht darin, die Ge- genstande zun¨achst absteigend nach Nutzen pro Gewichtseinheit vi/wi zu sortieren und die Gegenst¨ande in der entsprechenden Reihenfolge zu betrachten. Kann der 1Der Buchstabe “N” in NP steht f¨ur “nichtdeterministisch”, und nicht f¨ur das Wort “nicht”! 2Wir k¨onnen o.B.d.A. annehmen, dass der Fahrer Gewicht 0 hat, indem wir sein Gewicht von der maximal erlaubten Zuladung subtrahieren. 3.7 Rucksackproblem 65 aktuell betrachtete Gegenstand i zur aktuellen Auswahl I (initial, I = ∅) hinzu- gef¨ugt werden, ohne dass das Gesamtgewicht von W ¨uberschritten wird, dann setzen wir I ← I ∪ {i}. W¨urde das Hinzuf¨ugen des aktuellen Gegenstands i dagegen dazu f¨uhren, dass das maximal zul¨assige Gesamtgewicht W ¨uberschritten wird, dann wird der Gegenstand einfach nicht hinzugef¨ugt. Eine solche Strategie wird “gierig” (engl. greedy strategy) genannt, da sie stets die Entscheidung triﬀt, die im Moment die beste zu sein scheint. Der Algorithmus ist Laufzeit oﬀenbar sehr schnell, da f¨ur das Sortieren Zeit Θ(n log n) und f¨ur die anschliessende Berechnung der Auswahl lediglich Zeit Θ(n) gebraucht werden. Leider kann dieser Algorithmus L¨osungen berechnen, die beliebig viel schlechter Qualit¨at der L¨osungals die optimale L¨osung sind. Dazu betrachten wir zwei Gegenst¨ande mit den Nutz- werten v1 = 1 und v2 = W − 1 und den Gewichten w1 = 1 und w2 = W , und setzen das maximal zul¨assige Gewicht auf W . Eine optimale Auswahl Iopt besteht oﬀenbar nur aus dem zweiten Gegenstand (mit einem Nutzen von W − 1), die obige gierige Heuristik w¨urde aber stets die Auswahl zur¨uckliefern, die nur den ersten Gegenstand enth¨alt (denn v1/w1 = 1 > 1 − 1 W = v2/w2). Diese Auswahl hat lediglich den Nutzen 1, was W − 1 Mal schlechter als der Wert der besten Auswahl ist. Eine erste DP-L¨osung Analog zum zuvor besprochenen Subset Sum Problem wol- len wir nun dynamische Programmierung zur L¨osung des Rucksackproblems benut- zen. Dazu nehmen wir an, dass wir uns eine kleinere Gewichtsgrenze vorgeben und dann schauen, ob wir mit den ersten i Gegenst¨anden einen Mindestwert erreichen k¨onnen. Formaler benutzen wir eine dreidimensionale DP-Tabelle machbar(i, w, v), DP-Tabelle die Wahrheitswerte (also entweder “wahr” oder “falsch”) enth¨alt, und wir setzen machbar(i, w, v) ist genau dann “wahr”, wenn es eine Auswahl (also eine Teilmen- ge) der ersten i Gegenst¨ande gibt, deren Gesamtgewicht h¨ochstens w und deren Nutzen mindestens v ist. Initial setzen wir machbar[i, w, 0] ← “wahr” f¨ur alle i ≥ 0 Berechnung eines Eintragsund alle w ≥ 0 und machbar[0, w, v] ← “false” f¨ur alle w ≥ 0 und alle v > 0. Einen Eintrag der Tabelle berechnen wir nun durch machbar[i, w, v] ← machbar[i − 1, w, v] ∨ machbar[i − 1, w − wi, v − vi], (71) falls w ≥ wi und v ≥ vi gilt, und ansonsten entsprechend durch machbar[i, w, v] ← machbar[i − 1, w, v]. (72) Wir berechnen die Eintr¨age nach aufsteigendem i (f¨ur i = 0, . . . , n), Eintr¨age mit Berechnungs- reihenfolgegleichem i nach aufsteigendem w (f¨ur w = 0, . . . , W ) und Eintr¨age mit gleichem i und w nach aufsteigendem v (f¨ur v = 0, . . . , ∑n i=1 vi). Der maximal erreichbare Wert Auslesen der L¨osungeiner Auswahl ist der gr¨osste Index v, f¨ur den Indizes i und w mit machbar[i, w, v] = “true” existieren. Die Berechnung der entsprechenden Gegenst¨ande einer besten Auswahl erfolgt analog zum dynamischen Programm f¨ur das Subset Sum Problem. Insgesamt hat unser dynamisches Programm eine Laufzeit von O(n · W · ∑n i=1 vi). Verbesserung Betrachten wir die soeben deﬁnierte DP-Tabelle genauer, dann stel- len wir Folgendes fest: • Ist machbar(i, v, w) = “true”, dann ist auch machbar(i′, v′, w′) = “true” f¨ur alle i′ ≥ i, alle v′ ≤ v und alle w′ ≥ w, und analog 66 Dynamische Programmierung • Ist machbar(i, v, w) = “false”, dann ist auch machbar(i′, v′, w′) = “false” f¨ur alle i′ ≤ i, alle v′ ≥ v und alle w′ ≤ w. Folglich ist braucht die DP-Tabelle keine drei Dimensionen. Stattdessen k¨onnten wir auch eine zweidimensionale Tabelle maxWert benutzen, die in der ersten DimensionDP-Tabelle von 0 bis n und in der zweiten Dimension von 0 bis W indiziert ist, und in der ein Eintrag maxWert[i, w] den maximal erreichbaren Nutzen angibt, wenn nur aus den Gegenst¨anden {1, . . . , i} ausgew¨ahlt werden darf, und das Gewicht der Auswahl maximal w betragen darf. Zur Initialisierung setzen wir maxWert[0, w] ← 0 (wirdBerechnung eines Eintrags kein Gegenstand benutzt, dann ist der maximal erreichbare Nutzen 0). F¨ur i > 0 berechnen wir dann maxWert[i, w] ← max { maxWert[i − 1, w], maxWert[i − 1, w − wi] + vi} , (73) falls w ≥ wi ist (wie im dynamischen Programm f¨ur das Subset Sum Problem kann der i-te Gegenstand entweder genommen werden, oder nicht), und ansonsten wird maxWert[i, w] ← maxWert[i − 1, w] (74) gesetzt. Der maximal erreichbare Nutzen einer Auswahl ist am Ende im EintragAuslesen der L¨osung maxWert[n, W ] gespeichert, und von diesem Eintrag aus k¨onnen die Gegenst¨ande einer Auswahl mit diesem Nutzen genau wie im dynamischen Programm f¨ur das Sub- set Sum Problem rekonstruiert werden. Die Laufzeit dieses dynamischen ProgrammsLaufzeit ist in Θ(nW ). Eine Polynomialzeitapproximation f¨ur das Rucksackproblem F¨ur das Rucksack- problem haben wir im Wesentlichen drei Algorithmen kennengelernt: Eine Greedy- Heuristik, die sehr schnell ist, aber sehr schlechte Ergebnisse liefern kann, sowie zwei dynamische Programme, die eine exakte L¨osung bestimmen, daf¨ur aber pseudopoly- nomielle Zeit ben¨otigen. Im Folgenden wollen wir versuchen, eine N¨aherungsl¨osung zu berechnen. Wir geben uns damit zufrieden, eine sehr gute, ggf. aber nicht optimale, L¨osung zu ﬁnden. Daf¨ur m¨ochten wir aber auch eine Garantie haben, dass die berechnete L¨osung nicht wesentlich schlechter als die optimale L¨osung ist. Ist eine Zahl ε ∈ (0, 1) gegeben, dann suchen wir eine Auswahl I mit ∑ i∈I vi ≥ (1 − ε) ∑ i∈OP T vi, (75) wobei OP T eine optimale Auswahl f¨ur die entsprechende Eingabe bezeichnet. Wir m¨ochten also, dass der Nutzen unserer L¨osung garantiert nur um einen vorgegebe- nen Faktor ε von der optimalen L¨osung abweicht. Beim Gewicht der Auswahl d¨urfen nat¨urlich keine Kompromisse gemacht werden: Die Summe der Gewichte aller Ge- genst¨ande in I darf W niemals ¨ubersteigen. Zum Entwurf eines solchen Approximationsalgorithmus ¨uberlegen wir zun¨achst, dass wir das soeben vorgestellte dynamische Programm auch anders h¨atten formulie- ren k¨onnen. Statt f¨ur eine gegebene Gewichtsschranke w den maximal erreichbaren Nutzen zu ermitteln, k¨onnten wir f¨ur einen gegebenen Nutzen v auch fragen, wie viel Gewicht eine Auswahl mit diesem Nutzen mindestens haben muss. Dieses al- ternative dynamische Programm benutzt also wieder eine zweidimensionale Tabelle,DP-Tabelle diesmal minGew genannt, und ein Eintrag minGew[i, v] gibt das minimale Gewicht 3.7 Rucksackproblem 67 einer Auswahl an, die eine Teilmenge der ersten i Gegenst¨ande ist und einen Nutzen von exakt v hat. Dabei sind 0 ≤ i ≤ n und 0 ≤ v ≤ ∑n i=1 vi (diese Summe ist der theoretisch maximal erreichbare Nutzen, wenn alle Gegenst¨ande in der Auswahl enthalten w¨aren). Aufgrund der ge¨anderten Bedeutung eines Eintrags brauchen wir Berechnung eines Eintragsnat¨urlich auch eine andere Initialisierung. Wir setzen also minGew[0, 0] ← 0 (um den Nutzen 0 unter Verwendung keinerlei Gegenst¨ande zu erzielen, braucht es Gewicht 0), und minGew[0, v] ← ∞ f¨ur alle v > 0 (da mit keinen Gegenst¨anden kein strikt positiver Nutzen erzielt werden kann, wird das Gewicht einer potentiellen Auswahl auf ∞ gesetzt). Einen Eintrag minGew[i, v] berechnen wir mit minGew[i, v] ← min { minGew[i − 1, v], minGew[i − 1, v − vi] + wi} , (76) falls v ≥ vi ist, und ansonsten setzen wir minGew[i, v] ← minGew[i − 1, v]. (77) Der maximal erreichbare Nutzen ist der gr¨osste Index v mit minGew[n, v] ≤ W . Das Auslesen der L¨osungAuslesen der L¨osung erfolgt dann analog zum direkt zuvor diskutierten dynamischen Programm. Die Laufzeit dieses dynamischen Programms ist in Θ(n ∑n i=1 vi), ist also Laufzeit nach wie vor pseudopolynomiell. Eine pseudopolynomielle Laufzeit wird polynomiell, wenn alle vorkommenden Werte durch ein Polynom in der Eingabel¨ange beschr¨ankt werden k¨onnen. K¨onnen wir die Nutzwerte vi also so verkleinern, sodass die Laufzeit polynomiell wird, und die Werte trotzdem noch hinreichend genau sind, um eine gute L¨osung zu ﬁnden? Dazu nehmen wir an, es g¨abe eine geeignet gew¨ahlte Zahl K und ersetzen die Nutz- werte vi durch die gerundeten Nutzwerte ˜vi := ⌊vi/K⌋. W¨are also etwa K = 1000, dann w¨urden von jedem Nutzwert die letzten drei Ziﬀern in einer Dezimaldarstel- lung abgeschnitten. Wie K “geeignet gew¨ahlt” werden kann, wird in K¨urze erl¨autert. Wir lassen dann das soeben beschriebene dynamische Programm auf einer ge¨ander- ten Eingabe (im Folgenden Eingabe∼) mit n Gegenst¨anden laufen, wobei der i-te Gegenstand wie zuvor das Gewicht wi, aber einen ge¨anderten Nutzen ˜vi hat. Als Gewichtsschranke benutzen wir wieder W . Nun beobachten wir: 1) Jede Auswahl von Gegenst¨anden in Eingabe∼ ist auch in der urspr¨unglichen Eingabe g¨ultig, denn jeder Gegenstand in Eingabe∼ hat genau das gleiche Ge- wicht wie in der urspr¨unglichen Eingabe, und das Maximalgewicht der Auswahl betr¨agt noch immer W . 2) Die Laufzeit des Algorithmus ist durch O(n2vmax/K) nach oben beschr¨ankt (wobei vmax = max{vi | i ∈ {1, . . . , n}} der maximale Nutzen eines Gegen- stands in der urspr¨unglichen Eingabe ist), denn ∑n i=1 ˜vi = ∑n i=1⌊vi/K⌋ ≤∑n i=1 vi/K = 1 K ∑n i=1 vi ≤ n K vmax. Wie schlecht kann die L¨osung dieser Approximation werden? Beim Abrunden der Nutzwerte verlieren wir h¨ochstens K, d.h. es gilt vi − K ≤ K · ⌊ vi K ⌋ = K · ˜vi ≤ vi. (78) Wir bezeichnen nun mit OP T ist eine exakte optimale L¨osung f¨ur die urspr¨ungliche 68 Dynamische Programmierung Eingabe, und mit OP T ∼ eine exakte optimale L¨osung f¨ur Eingabe∼. Dann gilt ( ∑ i∈OP T vi) − n · K (∗) ≤ ∑ i∈OP T vi − ∑ i∈OP T K ≤ ∑ i∈OP T (vi − K) (79) ≤ ∑ i∈OP T K · ˜vi = K · ∑ i∈OP T ˜vi (∗∗) ≤ K · ∑ i∈OP T ∼ ˜vi (80) = ∑ i∈OP T ∼ K · ˜vi ≤ ∑ i∈OP T ∼ vi. (81) Die Ungleichung (∗) gilt aufgrund der Tatsache, dass OP T h¨ochstens n Gegenst¨ande enthalten kann, folglich also |OP T | ≤ n gilt. Die Ungleichung (∗∗) gilt, da OP T ∼ optimal bez¨uglich Eingabe∼ ist, folglich muss die Summe der Nutzwerte aller Ge- genst¨ande in OP T ∼ mindestens so gross wie die Summe der Nutzwerte aller Ge- genst¨ande in OP T sein. Wir hatten fr¨uher gefordert, dass der Gesamtnutzen der von unserem Approxi- mationsalgorithmus berechneten Auswahl h¨ochstens um einen Faktor ε vom Opti- mum abweicht. Dies kann erreicht werden, indem K so gew¨ahlt wird, dass nK = ε ∑ i∈OP T vi gilt. Eine optimale Auswahl f¨ur die urspr¨unglichen Nutzwerte kennen wir nat¨urlich nicht. Wir wissen aber bereits, dass der maximal erreichbare Nutzen mindestens vmax ist, denn unter der sinnvollen Annahme, dass jeder Gegenstand ein Gewicht hat, das die Gewichtsschranke nicht ¨ubersteigt (sonst kann er einfach aus der Eingabe verworfen werden), k¨onnen wir den Gegenstand mit Nutzen vmax immer w¨ahlen und haben eine Auswahl mit diesem Wert. Also ist ∑ i∈OP T vi ≥ vmax, und wir w¨ahlen K nun so, dass nK = ε · vmax gilt, also K = ε · vmax n . (82) Da K etwas kleiner als der urspr¨ungliche Wert (ε ∑i∈OP T vi)/n ist, wird die Appro- ximation etwas besser, und die Laufzeit geringf¨ugig schlechter. Wir haben also einen Algorithmus gefunden, der eine (1 − ε)-Approximation f¨ur eine Eingabe des Ruck- sackproblems in Zeit O(n2 · vmax K ) = O( n3 ε ) berechnet. Die Laufzeit h¨angt also ledig-Laufzeit lich noch von der Anzahl der gegebenen Gegenst¨ande und der Approximationsg¨ute ε ab und ist v¨ollig unabh¨angig von den konkreten Gewichten und Nutzwerten. Solch einen Algorithmus nennt man ein Approximationsschema: Sobald wir ein εApproximations- schema gew¨ahlt haben, ist ε quasi eine Konstante und der Algorithmus hat dann polynomi- elle Laufzeit. Die Laufzeit ist also ein Polynom in n und in 1 ε . In diesem Fall nennt man das Approximationsschema dann ein voll-polynomielles Approximationsschema (engl. FPTAS – fully polynomial-time approximation scheme). Man kann zeigen, dass das Rucksackproblem wie das Subset Sum Problem nicht in Polynomialzeit l¨osbar ist, wenn P ̸= NP gilt. Die Existenz eines FPTAS ist al- so das Beste, was wir f¨ur ein solches Problem erwarten k¨onnen, denn es erlaubt die Berechnung einer beliebig guten Approximation in Polynomialzeit. Viele andere Probleme haben kein FPTAS. Manchmal haben sie aber Approximationsalgorith- men, bei deren Laufzeit der Faktor 1 ε nicht als multiplikativer Faktor, sondern als Exponent auftaucht, z.B. wie in O(n 1 ε ). F¨ur ein ﬁxes ε ist dies dann zwar immer noch polynomiell, aber die Potenz h¨angt nun von ε ab. Kapitel 4 Datenstrukturen f¨ur W¨orterb¨ucher 4.1 Abstrakte Datentypen Der bisherige Fokus der Vorlesung lag besonders auf dem Entwurf eﬃzienter Al- gorithmen f¨ur gegebene Problemstellungen (z.B. die Sortierung eines Arrays). Wir wollen heute Datenstrukturen und Algorithmen f¨ur abstrakte Datentypen (ADT) Abstrakter Datentypentwerfen. Abstrakte Datentypen dienen der Verwaltung einer Menge von Objek- ten (z.B. Zahlen, Zeichenketten, Datens¨atzen, usw.). Dazu stellt jeder ADT einige Operationen zur Verf¨ugung, die die Menge der verwalteten Objekte ver¨andern oder Objekte mit gewissen Eigenschaften zur¨uckliefern k¨onnen. Ein ADT beschreibt al- so nur die grunds¨atzliche Funktionalit¨at, aber keine konkrete Implementierung. F¨ur eine Implementierung eines ADT werden Datenstrukturen und Algorithmen gemein- sam entworfen: W¨ahrend Datenstrukturen beschreiben, wie die Daten systematisch gespeichert werden k¨onnen, beschreiben Algorithmen die Implementierung der ein- zelnen Operationen. Wir werden im Folgenden einige abstrakte Datentypen ken- nenlernen und erl¨autern, wie sie durch geeignete Datenstrukturen und Algorithmen implementiert werden k¨onnen. Stapel (Stack) Ein Stack ist ein ADT, der die folgenden Operationen unterst¨utzt: Operationen • Push(x, S): Legt das Objekt x oben auf den Stack S. • Pop(S): Entfernt das oberste Objekt vom Stack S und liefert es zur¨uck. Enth¨alt S keine Objekte, soll null zur¨uckgeliefert werden. • Top(S): Liefert das oberste Objekt vom Stack S zur¨uck, entfernt es aber nicht aus S. Enth¨alt S keine Objekte, soll null zur¨uckgeliefert werden. • isEmpty(S): Liefert genau dann “true” zur¨uck, wenn der Stack S leer ist, d.h. keine Objekte mehr enth¨alt, und “false” ansonsten. • EmptyStack: Liefert einen leeren Stack zur¨uck. Man beachte, dass sowohl Pop(S) als auch Top(S) auch dann noch funktionieren, wenn der Stack leer ist (sie liefern dann einfach null zur¨uck). In einer Implementie- rung in einer echten Programmiersprache m¨usste man entsprechend ¨uberlegen, wie mit einer derartigen Situation umgegangen werden sollte. Einen Stack kann man sich anschaulich wie einen Stapel von (Porzellan)tellern Anschauliche Vorstellungvorstellen: Zum Essen nimmt man den obersten Teller weg und legt ihn nach dem Sp¨ulen wieder ganz oben auf den Stapel zur¨uck. 69 70 Datenstrukturen f¨ur W¨orterb¨ucher Abb. 4.1 Ein durch eine lineare Liste implementierter Stack, auf dem die Operationen EmptyStack, Push(x1), Push(x2), . . . , Push(xn) in genau dieser Reihenfolge ausgef¨uhrt wurden. Abb. 4.2 Hinzuf¨ugen des Objekts x zu einem Stack, der die Objekte x1, . . . , xn verwaltet. Implementieren kann man einen Stack durch eine einfach verkettete Liste, wobeiDatenstruktur jedes Listenelement genau ein Objekt x speichert, und zwar in umgekehrter Reihen- folge, in der die Objekte mittels Push hinzugef¨ugt wurden (siehe Abbildung 4.1). Wir verwalten also einen Anfangszeiger ⃗pA, der auf das Listenelement zeigt, das das zuletzt hinzugef¨ugte Objekt speichert, und jedes Listenelement zeigt auf das Listen- element, das das zeitlich direkt vorher hinzugef¨ugte Objekt enth¨alt. Das Listenele- ment, das das am fr¨uhesten hinzugef¨ugte Objekt speichert, hat einen Nullzeiger, um das Ende der Liste anzuzeigen. Die Operationen des Stacks k¨onnen nun wie folgt implementiert werden: • Push(x, S): Erzeuge ein neues Listenelement, das x enth¨alt, und das auf dasImplementierung der Operationen Listenelement zeigt, auf das momentan ⃗pA zeigt. Modiﬁziere den Anfangszei- ger ⃗pA so, dass er auf das soeben erzeugte Listenelement zeigt (siehe Abbil- dung 4.2). • Pop(S): Ist l = null, dann gib null zur¨uck. Merke ansonsten das Objekt x, das in dem Listenelement l gespeichert ist auf das ⃗pA derzeit zeigt. Sei l′ das nachfolgende Listenelement von l (auf das l zeigt, l′ kann also auch null sein). Modiﬁziere den Anfangszeiger ⃗pA so, dass er auf l′ zeigt, entferne l aus dem Speicher und gib x zur¨uck. • Top(S): Ist l = null, dann gib null zur¨uck. Gib ansonsten das Objekt x, das in dem Listenelement gespeichert ist auf das ⃗pA derzeit zeigt, zur¨uck. • isEmpty(S): Liefere “true” genau dann zur¨uck, wenn ⃗pA = null ist. • EmptyStack: Setze ⃗pA ← null und gib ⃗pA zur¨uck. Jede dieser Operationen ist in Zeit O(1) durchf¨uhrbar. Wenn im Vorfeld bereitsLaufzeit die maximale Anzahl zu verwaltender Objekte bekannt ist, kann man einen Stack auch leicht unter Verwendung eines Arrays anstelle einer einfach verketteten ListeImplementierung mit Arrays implementieren, was die asymptotische Laufzeit der Operationen nicht ¨andert. Die Details auszuarbeiten bleibt als ¨Ubung dem Leser ¨uberlassen. Schlange (Queue) Eine Queue ist ein ADT, der die folgenden Operationen un-Operationen terst¨utzt: • Enqueue(x, Q): F¨ugt das Objekt x hinten an die Queue Q an. 4.1 Abstrakte Datentypen 71 Abb. 4.3 Eine durch eine lineare Liste implementierter Queue, auf der die Operationen EmptyQueue, Enqueue(x1), Enqueue(x2), . . . , Enqueue(xn) in genau dieser Reihenfol- ge ausgef¨uhrt wurden. • Dequeue(Q): Entfernt das am weitesten vorn stehende Objekt aus der Queue Q und liefert es zur¨uck. Enth¨alt Q keine Objekte, soll null zur¨uckgeliefert werden. • Front(Q): Liefert das am weitesten vorn stehende Objekt aus der Queue Q zur¨uck, entfernt es aber nicht aus Q. Enth¨alt Q keine Objekte, soll null zur¨uckgeliefert werden. • isEmpty(Q): Liefert genau dann “true” zur¨uck, wenn die Queue Q leer ist, d.h. keine Objekte mehr enth¨alt, und “false” ansonsten. • EmptyQueue: Liefert eine leere Queue zur¨uck. Der Unterschied zu einem Stack ist also, dass Stacks Objekte immer vorn anf¨ugen Vergleich mit Stacksund auch vorn wieder wegnehmen, w¨ahrend Queues Objekte hinten anf¨ugen und vorn wegnehmen. W¨ahrend Pop(S) also das zuletzt hinzugef¨ugte Objekt zur¨ucklie- fert, liefert Dequeue(Q) das am l¨angsten in der Queue gespeicherte Objekt zur¨uck. Eine Queue kann man sich anschaulich wie eine (idealisierte) Schlange im Super- Anschauliche Vorstellungmarkt vorstellen, in der sich niemand vordr¨angelt. Queues k¨onnen analog zu Stacks durch einfach verkettete Listen implementiert Datenstruktur werden (siehe Abbildung 4.3). Anders als bei Stacks werden die Objekte aber in genau der Reihenfolge gespeichert, in der sie eingef¨ugt wurden (und nicht in umge- kehrter Reihenfolge). Zudem verwalten wir nicht nur einen Zeiger ⃗pA auf das erste Listenelement, sondern auch noch einen Zeiger ⃗pE auf das letzte Listenelement. Auf Implementierung diese Art kann Enqueue(x, Q) in Zeit O(1) implementiert werden, indem zun¨achst ein neues Listenelement l erzeugt wird, das x speichert. Ist ⃗pE ̸= null, dann folgt man ⃗pE, legt l als Nachfolger dieses Listenelements fest und l¨asst ⃗pE auf l zeigen. Waren vorher ⃗pA = ⃗pE = null, dann l¨asst man diese direkt auf das neue Listenele- ment l zeigen lassen. Dequeue(Q), Front(Q), isEmpty(Q) sowie EmptyQueue k¨onnen analog zu den entsprechenden Operationen f¨ur Stacks implementiert wer- den, man muss nur ⃗pE ggf. anpassen (der Zeiger muss u.U. auf null gesetzt werden). Arbeitet man alle Implementierungsdetails gr¨undlich aus, wird man feststellen, dass Laufzeit wie bei Stacks alle Operationen in Zeit O(1) durchf¨uhrbar sind. Ist die maximale Anzahl zu verwaltender Objekte im Voraus bekannt, k¨onnen Queues auch durch Arrays implementiert werden. Priorit¨atswarteschlange (Priority Queue) Eine Priority Queue funktioniert ¨ahn- Operationen lich wie eine Queue, wir k¨onnen Objekte nun aber mit einer Priorit¨at einf¨ugen. Enqueue(x, Q) wird dann von einer Operation Insert(x, p, Q) ersetzt, wobei x das einzuf¨ugende Objekt, p ∈ N die Priorit¨at von x und Q die Priority Queue darstel- len. Analog wird Dequeue(Q) durch eine Operation Extract-Max(Q) ersetzt, die das Objekt mit der h¨ochsten Priorit¨at aus der Priority Queue Q entfernt und zur¨uckliefert. Der Einfachheit halber verbieten wir, dass zwei verschiedene Objekte 72 Datenstrukturen f¨ur W¨orterb¨ucher x und x′ die gleiche Priorit¨at haben, sodass die Ausgabe von Extract-Max(Q) immer wohldeﬁniert ist. Schon fr¨uher haben wir eine Implementierung f¨ur Prio-Implementierung rity Queues kennengelernt, n¨amlich Heaps (siehe Abschnitt 2.4). Wir k¨onnen die Priorit¨aten als Schl¨ussel benutzen und die Objekte selbst in einem zweiten Ar- ray speichern (dessen Elemente beim Bewegen von Schl¨usseln entsprechend mit- bewegt werden m¨ussen). Wie man bei einem Heap das Maximum extrahiert, haben wir bereits fr¨uher gesehen. Man ¨uberlege sich als Hausaufgabe, wie die Operation Insert(x, p, Q) durch Heaps implementiert werden kann. Ebenso ¨uberlege man sich, dass sowohl Extract-Max(Q) als auch Insert(x, p, Q) nur Zeit O(log n) ben¨oti- gen, wenn die Priority Queue n Objekte verwaltet. Multistapel (Multistack) Ein Multistack unterst¨utzt neben allen Operationen, dieOperationen ein herk¨ommlicher Stack unterst¨utzt, noch eine weitere: • Multipop(k, S): Entfernt die k zuletzt hinzugef¨ugten Objekte aus S und lie- fert sie (nach Zeitpunkt der Hinzuf¨ugung absteigend sortiert) zur¨uck. Enth¨alt S weniger als k Elemente, werden entsprechend weniger Elemente entfernt und zur¨uckgeliefert. Insbesondere wird null zur¨uckgeliefert wenn S vor Aufruf der Operation keine Elemente enthielt. Ein Multistack kann genau wie herk¨ommliche Stacks durch einfach verkettete ListenDatenstruktur Implementierung implementiert werden; die Implementierung von Multipop(k, S) erfolgt analog zur Implementierung von Pop(S). Einzig die Laufzeit von Multipop(k, S) betr¨agt jetztLaufzeit O(k) statt O(1) wie die von Pop(S), denn es werden ja k Objekte entfernt und zur¨uckgegeben. Die obere Schranke von O(k) ist auch tats¨achlich exakt, denn wenn S mindes- tens k Elemente enth¨alt, wird wirklich Zeit Θ(k) ben¨otigt, um alle diese Elemente von S zu entfernen. Das heisst: F¨uhren wir auf einem Stack S, der n Objekte ver- waltet, n Mal Multipop(k, S) aus, dann kostet dies Zeit O(n2) (denn jeder Aufruf von Multipop(k, S) kann Zeit O(n) brauchen, wenn k ∈ O(n) ist). Andererseits k¨onnen wir keine Folge von Multistack-Operationen angeben, die tats¨achlich qua- dratische Kosten hat, denn jeder teure (langwierige) Aufruf von Multipop entfernt gleichzeitig viele Elemente vom Stack. Zuk¨unftige Aufrufe von Multipop sind daher m¨oglicherweise nicht mehr ganz so teuer (langwierig). F¨ur eine genauere Analyse nehmen wir vereinfachend an, dass sowohl Push(x, S)Bessere Analyse (anschaulich) als auch Pop(S) Kosten 1 haben (der Liste muss genau ein Element hinzugef¨ugt oder entfernt werden), w¨ahrend Multipop(k, S) Kosten k hat (der Liste m¨ussen k Ele- mente entfernt werden). Gedanklich k¨onnen wir uns nun vorstellen, dass wir bei je- dem Aufruf von Push(x, S) einen Schweizer Franken auf ein Bankkonto legen. Wird ein Objekt irgendwann von S entfernt (entweder durch Pop oder durch Multipop), dann zahlen wir die Entfernung dieses Objekts vom Bankkonto. Da die Kosten zur Entfernung pro Objekt sowohl in Pop als auch in Multipop exakt 1 sind, wir pro Objekt genau einen Schweizer Franken auf das Bankkonto eingezahlt haben und ein Objekt nur dann entfernen, wenn es zuvor irgendwann eingef¨ugt wurde, wird der Kontostand auch niemals negativ. Mit dieser alternativen Sichtweise hat Push also Kosten 2, w¨ahrend sowohl Pop als auch Multipop Kosten 0 haben. Folglich sind die durchschnittlichen Kosten f¨ur jede dieser drei Operationen noch immer in O(1). Diese Analysetechnik wollen wir nun noch ein wenig formalisieren. Dazu nehmenAmortisierte Analyse wir an, wir haben eine Datenstruktur, auf der n Operationen O1, . . . , On in dieser Reihenfolge ausgef¨uhrt werden (z.B. die n = 7 Operationen O1 = EmptyStack, 4.1 Abstrakte Datentypen 73 O2 = Push(15, S), O3 = Push(7, S), O4 = Push(200, S), O5 = Pop(S), O6 = Push(2, S) sowie O7 = Multipop(3, S)). Manche dieser Operationen (im vorigen Beispiel alle) ver¨andern die Datenstruktur. Die i-te Operation habe reale Kosten ti (im vorigen Beispiel haben alle Operationen i reale Kosten ti = 1, mit Ausnahme der letzten Operation, die reale Kosten t7 = 3 hat). Wir modellieren den Stand unseres Bankkontos durch eine Potentialfunktion Φi, die den Kontostand nach Durchf¨uhrung der ersten i Operationen angibt. Da wir annehmen, dass das Bankkonto zu Beginn leer ist, setzen wir Φ0 := 0. Die Potentialfunktion muss so gew¨ahlt werden, dass stets Φi ≥ 0 gilt. Anders als im echten Leben darf das Bankkonto also nicht ¨uberzogen werden! Nun deﬁnieren wir die amortisierten Kosten der i-ten Operation als Amortisierte Kosten ai := ti + Φi − Φi−1. (83) Was hilft uns dies nun? Da Φ0 = 0 und Φi ≥ 0 f¨ur alle i ≥ 0 gelten, erhalten wir n∑ i=1 ai = n∑ i=1(ti + Φi − Φi−1) = ( n∑ i=1 ti) + Φn − Φ0 ≥ n∑ i=1 ti. (84) Die Summe aller amortisierten Kosten bildet also eine obere Schranke f¨ur die Summe aller realen Kosten, oder anders ausgedr¨uckt, die durchschnittlichen realen Kosten aller Operationen sind h¨ochstens so gross wie die durchschnittlichen amortisierten Kosten aller Operationen. H¨auﬁg ist es so, dass die durchschnittlichen realen Kosten schwer abzusch¨atzen sind. Die Kunst bei der amortisierten Analyse liegt darin, eine Wahl der Po- tentialfunktiongeeignete Potentialfunktion zu ﬁnden, sodass die durchschnittlichen amortisierten Kosten leichter berechnet werden k¨onnen. ¨Ublicherweise m¨ochte man die Potential- funktion Φ so w¨ahlen, dass Φi gegen¨uber Φi−1 leicht anw¨achst, wenn die realen Kosten ti klein sind, und dass Φi gegen¨uber Φi−1 stark abf¨allt, wenn die realen Kosten ti sehr gross sind. F¨ur den zuvor diskutierten Multistack k¨onnen wir als Potentialfunktion die An- zahl der Elemente auf dem Stack benutzen. Konkret gibt Φi also die Anzahl der vorhandenen Listenelemente an, nachdem die ersten i Operationen durchgef¨uhrt wurden. Wir betrachten jetzt alle m¨oglichen Operationen, die im i-ten Schritt auf- treten k¨onnen, und zeigen, dass sie alle konstante amortisierte Kosten haben. • Push(x, S): Die realen Kosten sind ti = 1, und da S exakt ein Element hin- zugef¨ugt wurde, ist Φi − Φi−1 = 1. Folglich sind die amortisierten Kosten ai = 1 + 1 = 2. • Pop(S): Die realen Kosten sind ti = 1, und da von S exakt ein Element entfernt wurde, ist Φi − Φi−1 = −1. Folglich sind die amortisierten Kosten ai = 1 − 1 = 0. • Multipop(k, S): Die realen Kosten sind ti = k, denn es werden k Elemente von S entfernt. Aus dem gleichen Grund f¨allt die Potentialfunktion um k ab, wir haben also Φi − Φi−1 = −k. Folglich sind die amortisierten Kosten erneut ai = k − k = 0. Die amortisierten Kosten von Top(S), isEmpty(S) sowie EmptyStack k¨onnen analog bestimmt werden. Wir sehen also wie zuvor, dass alle Operationen nur ko- stante amortisierte Kosten haben. Insbesondere braucht auch Multipop(k, S) im Durchschnitt ¨uber alle Operationen nur konstante Zeit. 74 Datenstrukturen f¨ur W¨orterb¨ucher W¨orterbuch (Dictionary) In dieser und der folgenden Vorlesung werden wir Daten- strukturen und Algorithmen zur Implementierung eines W¨orterbuchs kennenlernen. Dieser ADT dient zur Verwaltung von Schl¨usseln, die aus einem geordneten Univer- sum K (z.B. der Menge der nat¨urlichen Zahlen) stammen und stellt drei wesentliche Operationen zur Verf¨ugung:Operationen • Insert(k, D): F¨ugt den neuen Schl¨ussel k ∈ K in das W¨orterbuch D ein. Falls k in D bereits vorhanden ist, wird eine Fehlermeldung ausgegeben. • Delete(k, D): L¨oscht den Schl¨ussel k ∈ K aus dem W¨orterbuch D. Falls k in D nicht vorhanden ist, wird eine Fehlermeldung ausgegeben. • Search(k, D): Liefert genau dann “true” zur¨uck, wenn das W¨orterbuch D den Schl¨ussel k ∈ K enth¨alt, und “false” ansonsten. In dieser Deﬁnition erfolgt also vor jeder Einf¨ugeoperation eine erfolglose Suche, und vor jeder L¨oschoperation eine erfolgreiche Suche nach dem entsprechenden Schl¨ussel. W¨orterb¨ucher haben sehr viele Anwendungen in vielen praktisch relevanten Be-Praktische ¨Uberlegungen reichen, z.B. in Datenbanken und Dateisystemen. In realen Situationen w¨urden die obigen Operationen vermutlich leicht angepasst: So m¨ochte man ¨ublicherweise nicht nur einen Schl¨ussel (z.B. den Namen einer Person) speichern, sondern auch einen mit ihm verkn¨upften Datensatz (der etwa das Geburtsdatum oder die Anschrift der entsprechenden Person enth¨alt). Auch m¨ochte man beim Suchen oftmals den Da- tensatz selbst zur¨uckgeben lassen, und nicht allein eine Information ob unter dem gegebenen Schl¨ussel ein entsprechender Datensatz gespeichert ist. Der Einfachheit halber ersparen wir uns im Folgenden diese technischen Details und betrachten vor allen Dingen die drei zuvor genannten Operationen. Reale Implementierungen von W¨orterb¨uchern unterst¨utzen dar¨uber hinaus oftmals eine Vielzahl weiterer Opera- tionen, etwa die Ausgabe aller Schl¨ussel in alphabetisch aufsteigender Reihenfolge, die Vereinigung zweier W¨orterb¨ucher, usw. Wir haben bereits einfache Datenstrukturen kennengelernt, die zur Implemen-Naive Realisierungen tierung eines W¨orterbuchs benutzt werden k¨onnen. So k¨onnte man z.B. eine einfach verkettete Liste benutzen. Eine erfolglose Suche dauert allerdings Zeit Θ(n), wenn die Liste n Elemente speichert; Einf¨ugen ist daher nur in Zeit Θ(n) m¨oglich. Das gleiche Problem tritt bei der Verwendung eines (hinreichend grossen) Arrays auf, in das je- weils an eine freie Position eingef¨ugt wird. Schneller suchen, n¨amlich in Zeit O(log n), k¨onnen wir in sortierten Arrays. Wollen wir allerdings einen Schl¨ussel einf¨ugen, der kleiner als alle bisher gespeicherten Schl¨ussel ist, m¨ussen aufgrund der starren Struk- tur eines Arrays alle Schl¨ussel um eine Position nach hinten verschoben werden. Die Einf¨ugung eines Schl¨ussels kann also im schlechtesten Fall erneut Zeit Θ(n) in An- spruch nehmen. Wir werden nun Implementierungen kennenlernen, bei denen die W¨orterbuchoperationen wesentlich schneller ausgef¨uhrt werden k¨onnen. 4.2 Hashing Bei der Deﬁnition des ADT W¨orterbuch hatten wir gefordert, dass die Menge derSchl¨ussel- universum zu verwaltenden Schl¨ussel aus einem geordneten Universum K stammen. In jedem Rechner k¨onnen beliebige Objekte durch eine Folge von Bits codiert werden, die wiederum als Bin¨arzahl interpretiert werden k¨onnen. Es ist also keine wesentliche Einschr¨ankung, wenn wir in diesem Abschnitt annehmen, dass K ⊆ N0 gilt, wir also nur nat¨urliche Zahlen als Schl¨ussel zulassen. 4.2 Hashing 75 Abb. 4.4 Eine Hashtabelle T mit m = 5 Pl¨atzen, in der bereits die Schl¨ussel 11 und 17 gespeichert sind (blau), und in die k = 14 eingef¨ugt werden soll. Wir legen gedanklich zwei Kopien von T (schwarz) an T , f¨ugen k an Position 14 ein und rechnen dies auf die Positionen 0, . . . , m − 1 zur¨uck, was 14 mod 5 = 4 ergibt. Wenn der gr¨osste zu verwaltende Schl¨ussel kmax im Vorfeld bekannt w¨are, k¨onn- Speicherung im Arrayten wir ein Array T benutzen, das von 0 bis kmax indiziert ist, und k¨onnten je- den Schl¨ussel k einfach an Position T [k] speichern. Auf diese Art w¨aren alle drei W¨orterbuchoperationen in konstanter Zeit durchf¨uhrbar. Allerdings ist diese Idee wenig praktikabel, denn sie ben¨otigt u.U. sehr viel Platz. Zudem kann kmax unbe- kannt sein. Hashing wandelt diese Idee nun ab, indem die Gr¨osse des Arrays T auf Hashing m Pl¨atze (f¨ur eine geeignet gew¨ahlte Zahl m) beschr¨ankt wird. Die Positionen von T seien von 0 bis m − 1 nummeriert. Das Array T wird als Hashtabelle bezeich- Hashtabelle net. Ein Schl¨ussel k ∈ {0, . . . , m − 1} kann wie vorher an Position k gespeichert werden. Was k¨onnen wir aber mit Schl¨usseln k ≥ m tun? Dazu k¨onnen wir uns gedanklich vorstellen, identisch gef¨ullte Kopien von T zu erzeugen und nebenein- ander zu legen. Die Positionen von T selbst sind dann 0, . . . , m − 1, die der ersten Kopie sind m, . . . , 2m − 1, die der zweiten Kopie 2m, . . . , 3m − 1, usw. Wir speichern dann gedanklich den Schl¨ussel k an der Position k und rechnen die Position auf die entsprechende Position in T selbst zur¨uck (siehe Abbildung 4.4). Wir beobachten, dass k an der Position k mod m gespeichert wird. Allgemein haben wir also eine Hashfunktion h : K → {0, 1, . . . , m − 1}, die dem Schl¨ussel k seine Hashadresse h(k) Hashfunktion Hashadressezuweist. Man beachte, dass im Allgemeinen |K| ≫ m ist. Wir m¨ussen also damit rechnen, dass es verschiedene Schl¨ussel k, k′ ∈ K mit h(k) = h(k′) gibt, d.h., dass Kollisionen auftreten. Leider sind Kollisionen sogar recht wahrscheinlich, wie das Kollision folgende Theorem zeigt. Theorem 4.1 (Geburtstagsparadoxon). In einem Raum mit 23 Personen ist die Geburtstags- paradoxonWahrscheinlichkeit, dass mindestens zwei dieser Personen am gleichen Tag Geburts- tag haben, gr¨osser als 50%. In Bezug auf Hashing l¨asst sich das Geburtstagsparadoxon wie folgt interpretie- Wahl der Hashfunktionren: Ist eine Hashtabelle der Gr¨osse m = 365 gegeben und verteilen sich die Schl¨ussel aus K gleichm¨assig auf die Positionen 0, 1, . . . , 364, dann ist es schon bei 23 zuf¨allig ausgew¨ahlten Schl¨usseln wahrscheinlicher, dass eine Kollision auftritt, als dass keine auftritt. Eine Hashfunktion sollte daher die Schl¨ussel aus K m¨oglichst gleichm¨assig auf die Positionen der Hashtabelle verteilen. Gl¨ucklicherweise ist dies f¨ur die zuvorge- Divisions-Rest- Methodenannte Hashfunktion h(k) = k mod m der Fall, wenn m als Primzahl gew¨ahlt wird. Man spricht dann auch von der Divisions-Rest-Methode. Eine weitere M¨oglichkeit besteht in der multiplikativen Methode mit der Hashfunktion Multiplikative Methode h(k) = ⌊ m(kϕ−1 − ⌊kϕ−1⌋ )⌋, (85) wobei ϕ−1 = √5−1 2 ≈ 0.61803 das Inverse des goldenen Schnitts darstellt. Da die 76 Datenstrukturen f¨ur W¨orterb¨ucher Divisions-Rest-Methode aber gute Ergebnisse liefert und zudem leicht berechenbar ist, werden wir im Folgenden immer die Hashfunktion h(k) = k mod m benutzen; dabei werde die Gr¨osse m der Hashtabelle als Primzahl gew¨ahlt. 4.2.1 Universelles Hashing In praktischen Anwendungen muss leider bef¨urchtet werden, dass viele Schl¨ussel auf die gleiche Hashadresse abgebildet werden, selbst wenn bei die Gr¨osse m der Hashtabelle als Primzahl gew¨ahlt und die Divisions-Rest-Methode benutzt wird. Andererseits tritt diese Situation nur bei ungl¨ucklicher Wahl der Hashfunktion auf. H¨atten wir eine Menge H m¨oglicher Hashfunktionen zur Verf¨ugung und w¨ahlen wir zu Beginn des Einf¨ugevorgangs einmalig eine Hashfunktion zuf¨allig aus H (die dann im Folgenden f¨ur alle Einf¨ugevorg¨ange stets gleich bleibt), dann f¨uhrt eine “schlecht” gew¨ahlte Schl¨usselmenge nicht notwendigerweise zu vielen Kollisionen. Eine sogenannte universelle Hashklasse ist eine Menge H ⊆ {h : K → {0, . . . , m−1}}Universelles Hashing von Hashfunktionen, sodass ∀k1, k2 ∈ K mit k1 ̸= k2 : |{h ∈ H : h(k1) = h(k2)}| |H| ≤ 1 m (86) gilt. Wird nun f¨ur feste Schl¨ussel k1, k2 ∈ K die Hashfunktion h zuf¨allig aus H gew¨ahlt (und bleibt ¨uber alle Einf¨ugevorg¨ange gleich), dann ist die Wahrscheinlich- keit f¨ur eine Kollision nicht gr¨osser als wenn die Hashfunktion fest und die Schl¨ussel k1 und k2 zuf¨allig gew¨ahlt w¨urden. Von einer Klasse von Hashfunktionen k¨onnen wir also nicht mehr erwarten! Man kann nun zeigen, dass universelle Hashklassen nicht nur existieren, sondern dar¨uber hinaus auch noch einfach konstruierbar sind: Theorem 4.2. Seien p eine Primzahl und K = {0, . . . , p − 1}. Deﬁnieren wir f¨urExistenz perfekter Hashklassen a ∈ {1, . . . , p − 1} und b ∈ {0, . . . , p − 1} die Hashfunktion hab : K → {0, . . . , m − 1} (87) k 7→ ((ak + b) mod p) mod m, dann ist H = {hab | 1 ≤ a ≤ p − 1, 0 ≤ b ≤ p − 1} eine universelle Hashklasse. 4.2.2 Hashverfahren mit Verkettung der ¨Uberl¨aufer Wir haben bereits argumentiert, dass wir stets mit Kollisionen rechnen m¨ussen. Es gibt nun verschiedene Strategien zur Kollisionsbehandlung. Eine naheliegende Variante besteht darin, an jeder Tabellenposition nicht einen einzigen Schl¨ussel, sondern eine Liste von Schl¨usseln zu speichern, die alle die gleiche Hashadresse besitzen. Man spricht dann auch von einer direkten Verkettung der ¨Uberl¨aufer. DieDirekte Verkettung W¨orterbuchoperationen k¨onnen nun sehr leicht wie folgt implementiert werden. Search(k, D). Durchlaufe die an Tabellenposition h(k) gespeicherte Liste und gibSuchen “true” zur¨uck, falls sie ein Listenelement enth¨alt, das k speichert. Wird das Ende der Liste erreicht, ohne dass k gefunden wird, dann ist k nicht in der Hashtabelle vorhanden, also gib “false” zur¨uck. Insert(k, D). Pr¨ufe, ob die an der Tabellenposition h(k) gespeicherte Liste denEinf¨ugen Schl¨ussel k enth¨alt. Falls nein, f¨uge k am Ende dieser Liste ein. 4.2 Hashing 77 Abb. 4.5 Eine Hashtabelle T mit m = 11 Pl¨atzen und direkter Verkettung der ¨Uberl¨aufer. Eine Einf¨ugung der Schl¨ussel 8, 11, 24, 2, 35 in dieser Reihenfolge f¨uhrt (neben weiteren Reihenfolgen) zur dieser Tabelle. Delete(k, D). Durchlaufe die an der Tabellenposition h(k) gespeicherte Liste. Wird L¨oschen dabei ein Listenelement gefunden, das k speichert, dann entferne dieses Lis- tenelement. Die Laufzeit der Operationen h¨angt oﬀenbar von der Gr¨osse der Hashtabelle und der Anzahl der gespeicherten Schl¨ussel ab. Hat eine Hashtabelle Gr¨osse m und werden derzeit n Schl¨ussel verwaltet, dann wird α = n/m als Belegungsfaktor bezeichnet. Belegungs- faktorF¨ur eine genaue Laufzeitabsch¨atzung beobachten wir, dass die Laufzeit des Einf¨ugens und des L¨oschens durch die Zeit zur erfolglosen bzw. erfolgreichen Suche nach einem Schl¨ussel dominiert werden. Daher gen¨ugt es, die erwartete Anzahl betrachteter Listeneintr¨age • C′ n bei erfolgloser Suche, sowie • Cn bei erfolgreicher Suche zu analysieren. Bei einer erfolglosen Suche nach einem Schl¨ussel k m¨ussen alle Ele- Erfolglose Suchemente der an Position h(k) gespeicherten Liste betrachtet werden. Die Anzahl be- trachteter Elemente ist gleich der L¨ange der entsprechenden Liste. Da die durch- schnittliche Listenl¨ange α = n/m betr¨agt, erhalten wir C′ n = α. (88) Ist die Suche dagegen erfolgreich und beﬁndet sich der gesuchte Schl¨ussel k im i-ten Erfolgreiche SucheEintrag in der entsprechenden Liste, dann werden genau i Listeneintr¨age betrachtet. Um den Erwartungswert von i zu bestimmen, analysieren wir die Zeit zur erfolg- reichen Suche des j-ten eingef¨ugten Schl¨ussels. Vereinfachend nehmen wir an, dass Schl¨ussel grunds¨atzlich ans Listenende eingef¨ugt werden, und dass niemals Schl¨ussel gel¨oscht wurden. Vor dem Einf¨ugen des j-ten Schl¨ussels betrug die durchschnittliche Listenl¨ange (j − 1)/m. Also betrachtet die erfolgreiche Suche nach diesem Schl¨ussel im Erwartungswert 1 + (j − 1)/m Listeneintr¨age. F¨ur jedes j ∈ {1, . . . , n} betr¨agt die Wahrscheinlichkeit, dass k als j-tes eingef¨ugt wurde, genau 1/n. Also ist Cn = 1 n n∑ j=1 (1 + (j − 1)/m) = 1 + n − 1 2m ≈ 1 + α 2 . (89) 78 Datenstrukturen f¨ur W¨orterb¨ucher Das Verfahren hat noch Potential zur Verbesserung. Wir haben der EinfachheitVerbesserung halber angenommen, dass ein Schl¨ussel immer ans Ende der entsprechenden Liste eingef¨ugt wird. Halten wir dagegen die Listen sortiert (d.h., f¨ugen wir einen Schl¨ussel gleich an der korrekten Position der sortierten Reihenfolge ein), dann verbessert dies die Zeit zur erfolglosen Suche. Die Zeit zur erfolgreichen Suche verschlechtert sich nicht, lediglich ihre Analyse wird komplizierter. Vorteile der Strategie sind, dass Belegungsfaktoren α > 1 problemlos m¨oglichVor- und Nachteile sind, d.h., dass mehr Schl¨ussel verwaltet werden k¨onnen als die Tabelle Pl¨atze hat. Ausserdem ist das Entfernen von Schl¨usseln unkompliziert und ohne negative Kon- sequenzen m¨oglich. Negativ ist der erh¨ohte Speicherplatzbedarf, denn f¨ur jeden Lis- teneintrag muss ein Zeiger auf den nachfolgenden Eintrag gespeichert werden. 4.2.3 Oﬀenes Hashing Anstatt die ¨Uberl¨aufer in einer Liste zu verwalten, k¨onnen wir sie auch direkt in der Hashtabelle speichern. Auf diese Weise entf¨allt der f¨ur die Listenzeiger ben¨otigte Extraplatz. Um bei diesem oﬀenen Hashing die Position der ¨Uberl¨aufer zu ﬁnden, benutzen wir eine Sondierungsfunktion s(j, k), wobei j ∈ {0, . . . , m − 1} und k ∈ KSondierungs- funktion ein Schl¨ussel ist. Zur Bestimmung der Tabellenposition eines Schl¨ussels k betrachten wir die Tabellenpositionen entlang der Sondierungsfolge (h(k) − s(0, k)) mod m, . . . , (h(k) − s(m − 1, k) ) mod m. (90) Speichert ein Eintrag (h(k) − s(j, k) ) mod m den Schl¨ussel k, dann haben wir die Sondierungs- folge Position von k gefunden und sind fertig (die ¨ubrigen Positionen der Folge m¨ussen dann nicht mehr betrachtet werden). Ist der Eintrag frei, dann ist der Schl¨ussel k in der Tabelle nicht vorhanden und wir sind ebenfalls fertig. Weitersuchen m¨ussen wir lediglich, wenn der Eintrag einen Schl¨ussel ungleich k enth¨alt. In diesem Fall fahren wir analog mit dem Tabelleneintrag (h(k) − s(j + 1, k)) mod m fort. Die W¨orterbuchoperationen k¨onnen nun wie folgt implementiert werden. Search(k, D). Betrachte die Tabelleneintr¨age gem¨ass der Sondierungsfolge (90).Suchen Speichert ein Tabelleneintrag den Schl¨ussel k, gib “true” zur¨uck und brich die Suche ab. Wird ein leerer Tabelleneintrag gefunden oder ist k in der gesamten Sondierungsfolge nicht vorhanden, gib “false” zur¨uck. Insert(k, D). F¨uhre eine Suche nach dem Schl¨ussel k durch. Ist der Schl¨ussel kEinf¨ugen nicht vorhanden, f¨uge k an die erste freie Position der Sondierungsfolge ein. Delete(k, D). F¨uhre eine Suche nach dem Schl¨ussel k durch. Falls k gefunden wird,L¨oschen markiere die Position von k mit einem speziellen Gel¨oscht-Flag. Die Position darf nicht einfach als frei markiert werden, da ansonsten die Suche nach einem Schl¨ussel nicht mehr funktioniert (werden z.B. viele Schl¨ussel k1, . . . , kl mit der gleichen Hashadresse eingef¨ugt und wird dann k1 gel¨oscht, dann w¨are die erste Position der Sondierungsfolge ein freier Tabellenplatz und die Suche w¨urde di- rekt terminieren). Das Gel¨oscht-Flag kann z.B. durch einen speziellen Schl¨ussel repr¨asentiert werden, der dann nat¨urlich nicht mehr regul¨ar eingef¨ugt werden darf. Wird bei der Suche ein als gel¨oscht markiertes Feld gefunden, muss die Suche regul¨ar mit der n¨achsten Position der Sondierungsfolge fortgesetzt wer- den. Neue Schl¨ussel d¨urfen aber nat¨urlich auf Positionen eingef¨ugt werden, die als gel¨oscht markiert sind. 4.2 Hashing 79 Abb. 4.6 Eine oﬀene Hashtabelle T mit m = 11 Pl¨atzen, bei der lineares Sondieren zur Kollisionsauﬂ¨osung benutzt wird. Die Schl¨ussel 8, 11, 24, 2, 35 wurden in dieser Reihenfolge eingef¨ugt. Nachdem wir die Realisierung der W¨orterbuchoperationen beschrieben haben, m¨us- sen wir nun ¨uberlegen, was geeignete Sondierungsfunktionen sind. Auf jeden Fall sollte die Sondierungsfolge (90) alle Tabellenpositionen ber¨ucksichtigen, d.h., sie sollte eine Permutation von {0, . . . , m − 1} sein. Wir beschreiben nun einige Sondie- rungsstrategien, die diese Eigenschaft besitzen. Lineares Sondieren: s(j, k) = j. Die zugeh¨orige Sondierungsfolge ist Lineares Sondieren h(k) mod m, (h(k) − 1) mod m, . . . , (h(k) − m + 1) ≡ (h(k) + 1) mod m, (91) d.h., ausgehend von der Position h(k) laufen wir in der Tabelle so lange nach links, bis eine freie Position gefunden wird. Wird die Position ganz links (mit Index 0) erreicht, fahren wir bei der Position ganz rechts (mit Index m − 1) fort. Diese Sondierungsstrategie hat den Nachteil, dass auch bei geringen Belegunsfaktoren α schnell lange zusammenh¨angende Bl¨ocke von belegten Tabellenpl¨atzen entstehen. Um dies einzusehen, nehmen wir an, alle Tabellenpositionen i innerhalb eines In- tervalls [il, iu] ⊆ {0, . . . , m} w¨aren bereits belegt. Wird nun ein Schl¨ussel k mit Hashadresse h(k) ∈ [il, iu] eingef¨ugt, dann wird dieser direkt links vom genann- ten Bereich gespeichert (wenn il > 0 ist; f¨ur il = 0 wird der Schl¨ussel entsprechend m¨oglichst weit rechts in der Tabelle gespeichert). Aus diesem Grund wachsen bereits bestehende lange Bl¨ocke schneller als kurze Bl¨ocke. Diese Eigenschaft f¨uhrt auch zu langen Suchzeiten: Man kann zeigen, dass die erfolglose bzw. erfolgreiche Suche C′ n ≈ 1 2 (1 + 1 (1 − α)2 ) bzw. Cn ≈ 1 2 (1 + 1 1 − α ) (92) viele Tabellenpositionen betrachten. Dies zeigt, wie ineﬃzient lineares Sondieren bei hohen Belegungsfaktoren ist: F¨ur α = 0.95 betrachtet eine erfolglose Suche im Durchschnitt mehr als 200 Tabelleneintr¨age! Quadratisches Sondieren: s(j, k) = (⌈j/2⌉)2(−1)j+1. Ein Problem beim linearen Quadratisches SondierenSondieren besteht darin, dass ¨ahnliche Hashadressen auch ¨ahnliche Sondierungs- folgen besitzen, was wie gesehen schnell zu langen zusammenh¨angenden Bereichen von belegten Positionen f¨uhrt. Quadratisches Sondieren vermeidet dieses Problem, indem die Abst¨ande zwischen der urspr¨unglichen Hashadresse und der entsprechen- den Adresse in der Sondierungsfolge quadratisch wachsen. Zur oben angegebenen Sondierungsfunktion geh¨ort die Sondierungsfolge h(k) mod m, (h(k) − 1) mod m, (h(k) + 1) mod m, (93) (h(k) − 4 ) mod m, (h(k) + 4) mod m, (h(k) − 9 ) mod m, . . . Man kann zeigen, dass (93) eine Permutation aller Tabellenpositionen {0, . . . , m−1} 80 Datenstrukturen f¨ur W¨orterb¨ucher Abb. 4.7 Eine oﬀene Hashtabelle T mit m = 11 Pl¨atzen, bei der quadratisches Son- dieren zur Kollisionsauﬂ¨osung benutzt wird. Die Schl¨ussel 8, 11, 24, 2, 35 wurden in dieser Reihenfolge eingef¨ugt. Abb. 4.8 Eine oﬀene Hashtabelle T mit m = 11 Pl¨atzen, bei der Double Hashing zur Kollisionsauﬂ¨osung benutzt wird. Die Schl¨ussel 8, 11, 24, 2, 35 wurden in dieser Reihenfolge eingef¨ugt. bildet, wenn m eine Primzahl ist und m ≡ 3 mod 4 erf¨ullt. Die erfolglose bzw. erfolgreiche Suche betrachten C′ n ≈ 1 1 − α − α + ln ( 1 1 − α ) bzw. Cn ≈ 1 + ln ( 1 1 − α ) − α 2 (94) viele Tabellenpositionen. Insbesondere betrachtet die erfolglose Suche bei einem Be- legungsfaktor von α = 0.95 nur ca. 22 Tabelleneintr¨age, was eine enorme Verbesse- rung gegen¨uber linearem Sondieren darstellt. Trotzdem hat diese Sondierungsstra- tegie einen Nachteil: Alle Schl¨ussel mit gleichen Hashadressen besitzen die gleiche Sondierungsfolge. Werden nun viele Schl¨ussel mit der gleichen Hashadresse eingef¨ugt, dann f¨uhrt dies zu vielen sogenannten Sekund¨arkollisionen entlang der Sondierungs-Sekund¨ar- kollision folge. Wir werden im Folgenden eine Strategie kennenlernen, bei der auch Schl¨ussel mit gleichen Hashadressen unterschiedliche Sondierungsfolgen haben k¨onnen. Double Hashing Sei h′(k) eine zweite, von h(k) unabh¨angige Hashfunktion. Dou-Double Hashing ble Hashing besitzt die Sondierungsfunktion s(j, k) = j · h′(k) mit der zugeh¨origen Sondierungsfolge h(k) mod m, (h(k) − h′(k) ) mod m, (h(k) − 2h ′(k)) mod m, . . . (95) Die Wahl der zweiten Hashfunktion h′(k) ist nicht trivial. Oﬀenbar darf sie m nicht teilen und muss f¨ur alle Schl¨ussel k ungleich 0 sein. Man kann aber zeigen, dass alle genannten Anforderungen erf¨ullt werden, wenn m eine Primzahl ist und h(k) = k mod m sowie h′(k) = 1 + (k mod (m − 2)) gew¨ahlt werden. In diesem Fall betrachten die erfolglose bzw. erfolgreiche Suche C′ n ≈ 1 1 − α bzw. Cn ≈ 1 + α 2 + α3 4 + α4 15 − α5 18 + . . . < 2.5 (96) viele Tabellenpositionen. Cuckoo Hashing Kuckucks-Hashing (engl. Cuckoo Hashing) benutzt zwei Hashta-Cuckoo Hashing bellen T1 und T2 mit zwei Hashfunktionen h1(k) und h2(k). Um nach einem Schl¨ussel k zu suchen, schauen wir zun¨achst an Position h1(k) in T1 nach. Ist k dort nicht gespeichert, dann pr¨ufen wir, ob k an der Position h2(k) in T2 gespeichert ist. Ist dies ebenfalls nicht der Fall, dann ist k nicht vorhanden. 4.3 Selbstanordnung 81 Das Einf¨ugen wird jetzt aber komplizierter. Wir f¨ugen einen Schl¨ussel k an die Einf¨ugen Position h1(k) in T1 ein. War dort vorher kein Schl¨ussel gespeichert, dann sind wir fertig. Ansonsten wird der vorher dort gespeicherte Schl¨ussel k1 verdr¨angt. Konkret f¨ugen wir k1 (nicht k!) mit h2 in T2 ein. War dort vorher ein Schl¨ussel k2 gespeichert, dann wird dieser mit h1 in T1 eingef¨ugt. Der ggf. dort gespeicherte Schl¨ussel k3 wird dann mit h2 in T2 eingef¨ugt. Auf diese Art verf¨ahrt man weiter, bis entweder eine freie Position gefunden wird, oder man einen Kreis erh¨alt (wenn der urspr¨unglich ein- zuf¨ugende Schl¨ussel k aus T2 verdr¨angt wird und in T1 eingef¨ugt werden soll). Wenn ein solcher Kreis entsteht, dann erzeugt man zwei neue, gr¨ossere Hashtabellen, w¨ahlt zwei neue Hashfunktionen, f¨ugt alle vorher gespeicherten Schl¨ussel (zuz¨uglich k) auf genau die gleiche Art und Weise in die neuen Hashtabellen ein und verwirft die alten Hashtabellen. Man kann zeigen, dass dies im Erwartungswert auch nur konstante Zeit ben¨otigt. 4.3 Selbstanordnung Wir haben bereits ¨uberlegt, wie einfach verkettete Listen zur Realisierung von W¨orterb¨uchern benutzt werden k¨onnen. Problematisch war hier vor allen Dingen eine im schlechtesten Fall lineare Suchzeit. Angenommen, die Liste speicherte die Schl¨ussel k1, . . . , kn, und f¨ur jeden Schl¨ussel ki w¨ussten wir bereits, mit welcher H¨auﬁgkeit Hi auf ihn zugegriﬀen wird. In diesem Fall k¨onnten wir die Schl¨ussel ab- steigend nach ihrer H¨auﬁgkeit Hi sortieren, im ersten Element der Liste den Schl¨ussel mit der gr¨ossten H¨auﬁgkeit speichern, im zweiten Element den Schl¨ussel mit der zweitgr¨ossten H¨auﬁgkeit, usw. Auf diese Art w¨urde sich zwar die lineare Laufzeit f¨ur die Suche im schlechtesten Fall nicht ¨andern, zumindest die Suche nach den h¨auﬁgsten Elementen w¨are aber u.U. wesentlich schneller. In der Realit¨at sind die Suchh¨auﬁgkeiten oftmals im Vorfeld nicht bekannt. In diesem Fall gibt es verschiedene M¨oglichkeiten, die Liste dynamisch so umzuordnen, dass sp¨atere Zugriﬀe auf Elemente hoﬀentlich schneller m¨oglich sind. 1) Frequency Count: Wir z¨ahlen f¨ur jeden Schl¨ussel ki die bisher beobachteten Frequency CountH¨auﬁgkeiten H ′ i mit (initial H ′ i = 0), und erh¨ohen bei jeder Suche nach ki die entsprechende H¨auﬁgkeit H ′ i um 1. Die Listenelemente werden dann nach jeder Suche nach H¨auﬁgkeit absteigend sortiert angeordnet. 2) Transpose: Bei jedem Zugriﬀ auf einen Schl¨ussel ki bewegen wir ihn genau eine Transpose Position nach vorn (sofern er nicht bereits am Listenanfang stand). 3) Move-to-Front: Bei jedem Zugriﬀ auf einen Schl¨ussel ki bewegen wir ihn an Move-to-Front den Anfang der Liste. Wie gut sind diese Strategien? Man sieht leicht, dass Transpose nur ungen¨ugende Analyse TransposeErgebnisse liefert: Angenommen, eine Liste speichert die Schl¨ussel k1, k2, . . . , kn in exakt dieser Reihenfolge und wir greifen abwechselnd auf kn und auf kn−1 zu. Jeder Zugriﬀ auf kn verschiebt dieses Element um eine Position nach vorn, w¨ahrend der nachfolgende Zugriﬀ auf kn−1 die urspr¨ungliche Ordnung der Liste wiederherstellt. Hat die Liste also n Elemente und f¨uhren wir n Zugriﬀe wie soeben beschrieben durch, f¨uhrt dies zu einer Laufzeit von Θ(n2). Move-to-Front dagegen w¨are in dieser Situation wesentlich besser, da nur der erste Zugriﬀ auf kn und auf kn−1 jeweils Zeit Θ(n) brauchen; jeder weitere Zugriﬀ ist dann in konstanter Zeit m¨oglich, da sich das gesuchte Element stets an der zweiten Stelle der Liste beﬁndet. 82 Datenstrukturen f¨ur W¨orterb¨ucher Abb. 4.9 Zwei Listen mit jeweils f¨unf Elementen. Gedanklich k¨onnen die Elemente in der Liste von A in 1, . . . , 5 umbezeichnet werden; werden die Elemente von der Liste von MTF entsprechend umbezeichnet, l¨asst dies die Anzahl der Inversionen unver¨andert. Im obigen Beispiel gibt es genau vier Inversionen. Nat¨urlich k¨onnen wir auch f¨ur Move-to-Front (im Folgenden MTF genannt) eineAnalyse Move-to-Front Folge angeben, die quadratische Zugriﬀszeiten ben¨otigt. Dazu greifen wir stets auf das aktuell letzte Listenelement zu. Andererseits ist bei so einer Folge von Zugrif- fen nicht klar, wie eine geeignete Strategie aussehen k¨onnte, die mit viel weniger Zugriﬀen auskommt. Daher vergleichen jetzt MTF mit einem idealen Konkurrenten (Algorithmus) A, um zu untersuchen, wie viel besser A werden kann. Dabei nehmen wir an, dass unser Konkurrent A so wie MTF nur das Element x bewegen darf, auf das gerade zugegriﬀen wurde, die anderen Elemente also nicht vertauscht. Die kon- kurrierende Strategie A k¨onnte x aber an eine v¨ollig andere Stelle als MTF bewegen. Wir wollen jetzt argumentieren, dass dies nicht (viel) besser als MTF sein kann. Greift ein Algorithmus (entweder MTF oder A) auf ein Element x zu, das sich an der i-ten Position beﬁndet, dann fallen allein f¨ur den Zugriﬀ Kosten i an (denn es m¨ussen i Listenelemente angeschaut werden). Wenn die entsprechende Strategie das Element x jetzt nach vorn bewegt, fallen keine weiteren Kosten an (denn auf die Elemente vor x wurde bereits zuvor zugegriﬀen). Bewegt die Strategie das Element x aber nach hinten, dann verursacht dies zus¨atzliche Kosten 1 f¨ur jede Position, um die x weiter nach hinten bewegt wird. Sowohl MTF als auch die optimale Strategie A starten beide mit der selben Liste, und es folgen m Zugriﬀe auf irgendwelche Elemente. Bei jedem dieser Zugriﬀe k¨onnen sowohl MTF als auch A die Liste umordnen. Wir betrachten jetzt den l-ten Zugriﬀ auf ein Element x, und wollen zun¨achst die amortisierten Kosten aM T F l f¨ur MTF bestimmen. Die Potentialfunktion misst nach jedem Schritt die Anzahl der Inversionen von A gegen MTF. Dies sind die Anzahl der Paare zweier Elemente x und y, deren Reihenfolgen sich in den Listen von MTF und A unterscheiden (d.h., entweder kommt x in der Liste von A vor y und in der Liste von MTF hinter y, oder umgekehrt). Schreiben wir die Elemente der Listen von MTF und A von links nach rechts auf und verbinden wir die entsprechenden Elemente durch eine Linie, dann ist die Anzahl der Inversionen exakt die Anzahl der Kreuzungspunkte zweier Linien. Abbildung 4.9 zeigt ein Beispiel. Die Abbildung zeigt auch, dass wir die Elemente der Liste von A gedanklich in 1, . . . , n umbenennen k¨onnen, wobei das i-te Element die Nummer i bekomme. Bezeichnen wir das jeweils entsprechende Element in der Liste von MTF gleich um, dann erh¨oht dies die Anzahl der Inversionen nat¨urlich nicht, denn wir haben ja nur die Elemente umbezeichnet, nicht umgeordnet. Angenommen, im l-ten Schritt wird nun auf das Element i zugegriﬀen. Dieses beﬁndet sich aufgrund der soeben vorgenommenen Umbezeichnung der Elemente an der Position i in der Liste von A, folglich kostet A der Zugriﬀ auf i genau CA l = i. Sei nun k die Position, an der sich i in der Liste von MTF beﬁndet. Die Zugriﬀskosten 4.3 Selbstanordnung 83 Abb. 4.10 Zugriﬀ auf das Element i = 8 (schwarz), was in A Kosten C A l = 8 und in MTF Kosten C M T F l = k = 6 verursacht. Es gibt xi = 3 Elemente, die in der Liste von MTF vor i und in der Liste von A hinter i stehen (rot eingezeichnet). Also gibt es k − 1 − xi=2 Elemente, die sowohl in der Liste von A als auch in der Liste von MTF vor i stehen (gr¨un eingezeichnet). Abb. 4.11 Wird i an den Beginn der Liste von MTF bewegt, dann l¨osen sich die xi Inversionen mit den roten Elementen auf, daf¨ur kommen k − 1 − xi viele Inversionen mit den gr¨unen Elementen neu hinzu. f¨ur MTF auf das Element i sind dann CM T F l = k. Wie ver¨andert sich nun die Potentialfunktion, wenn sowohl MTF als auch A auf i zugreifen? Es sei xi die Anzahl der Elemente, die in der Liste von MTF vor i und in der Liste von A hinter i liegen. Da in der Liste von MTF genau k − 1 Elemente vor i liegen, muss es also genau k − 1 − xi viele Elemente geben, die sowohl in der Liste von MTF als auch in der Liste von A vor i liegen (siehe Abbildung 4.10). F¨uhren wir gedanklich zuerst den Zugriﬀ auf i in MTF durch, dann ziehen wir i an den Beginn der Liste. Dadurch verlieren wir xi Inversionen mit den Elementen, die in der Liste von A hinter i liegen, gewinnen aber k − 1 − xi neue Inversionen mit den Elementen, die in der Liste von A vor i liegen, hinzu (siehe Abbildung 4.11). Jetzt f¨uhrt A den Zugriﬀ auf i durch. Wir beobachten nun, dass f¨ur jede Position, um die i nach vorne bewegt wird, eine Inversion wegf¨allt. Analog erhalten wir pro Position, um die i nach hinten bewegt wird, eine neue Inversion hinzu. Die Anzahl der Inversionen steigt also nur dann, wenn A das Element i nach hinten bewegt. Sei X A l die Anzahl der kostenpﬂichtigen Vertauschungen, d.h., die Anzahl der Stellen, um die A das Element im l-ten Schritt nach hinten bewegt (wird das Element im l-ten Schritt nach vorne bewegt, dann ist X A l = 0). Wir sch¨atzen die Potentialdiﬀerenz zwischen dem l-ten und dem (l−1)-ten Schritt durch Φl − Φl−1 ≤ −xi + (k − 1 − xi) + X A l , (97) nach oben ab, d.h., Φl ist gegen¨uber Φl−1 um h¨ochstens diesen Wert gewachsen. F¨ur die amortisierten Kosten von MTF im l-ten Schritt ergibt sich damit a M T F l = CM T F l + Φl − Φl−1 (98) ≤ k − xi + (k − 1 − xi) + X A l (99) = (k − xi) + (k − xi − 1) + X A l ≤ CA l + CA l − 1 + X A l , (100) 84 Datenstrukturen f¨ur W¨orterb¨ucher denn die realen Kosten CA l von A beim Zugriﬀ auf i sind mindestens k − xi (da mindestens so viele Elemente in der Liste von A vor i kommen). Haben wir nun eine Folge von m Zugriﬀen, dann hat MTF Kosten ∑n l=1 CM T F l und A Kosten∑n l=1(CA l + X A l ). Der Summand X M T F l entf¨allt in der Summe der Kosten von MTF, da er stets 0 ist (MTF bewegt ein Element stets nach vorne, niemals nach hinten). Da nun die realen Kosten von MTF durch die amortisierten Kosten nach oben abgesch¨atzt werden k¨onnen (die Potentialfunktion ist initial 0, da die Listen gleich sind, und wird niemals negativ), folgt n∑ l=1 CM T F l ≤ n∑ l=1 a M T F l ≤ n∑ l=1 (2CA l − 1 + X A l ) (101) ≤ n∑ l=1 2(CA l + X A l ) ≤ 2 n∑ l=1 (CA l + X A l ). (102) Move-to-Front f¨uhrt damit also selbst im schlechtesten Fall h¨ochstens doppelt so viele Operationen wie eine optimale Strategie aus. 4.4 Nat¨urliche Suchb¨aume Wir haben mit Hashing bereits eine Implementierung von W¨orterb¨uchern kennenge-Motivation lernt, die im besten sowie im durchschnittlichen Fall sehr schnelle Zugriﬀszeiten hat. Auch haben wir ¨uberlegt, wie man erreichen kann, dass man den schlechtesten Fall mit hoher Wahrscheinlichkeit umgehen kann. Schlimmer als eine lineare Suchzeit im schlechtesten Fall ist jedoch, dass Hashing manche Anfragen ¨uberhaupt nicht un- terst¨utzt. Bisher haben wir nur das Suchen, Einf¨ugen und Entfernen von Schl¨usseln diskutiert. In vielen realen Anwendungen m¨ochte man aber beispielsweise auch die gespeicherten Schl¨ussel in aufsteigend sortierter Reihenfolge ausgeben k¨onnen. Eben- so m¨ochte man vielleicht f¨ur einen Schl¨ussel k, der nicht im W¨orterbuch enthalten ist, den n¨achstkleineren Schl¨ussel k′ ﬁnden, der im W¨orterbuch enthalten ist. Beide Operationen k¨onnen mit Hashing nicht implementiert werden. Wir haben bereits fr¨uher das Konzept eines bin¨aren Baums kennengelernt (z.B. bei der unteren Schranke f¨ur allgemeine Sortierverfahren und bei Heaps). Ein bin¨arerBin¨arer Baum Baum • ist entweder ein Blatt, d.h. der Baum ist leer, oder er • besteht aus einem innerer Knoten v mit zwei B¨aumen Tl(v) und Tr(v) als linkem bzw. rechtem Nachfolger. Der Baum Tl(v) heisst linker Teilbaum von v, Tr(v) heisst rechter Teilbaum von v. Jeder Baum besitzt genau einen Knoten ohne Vorg¨anger, die sog. Wurzel, die inWurzel den folgenden Algorithmenbeschreibungen Root genannt wird. In jedem inneren Knoten v speichern wir • einen Schl¨ussel v.Key, • einen Zeiger v.Left auf den linken Nachfolgerknoten (also auf die Wurzel des linken Teilbaums Tl(v) und nicht auf den Teilbaum als ganzes), sowie • einen Zeiger v.Right auf den rechten Nachfolgerknoten (also auf die Wurzel des rechten Teilbaums Tr(v)). 4.4 Nat¨urliche Suchb¨aume 85 Abb. 4.12 Ein m¨oglicher bin¨arer Suchbaum zur Schl¨usselmenge {5, 7, 8, 10, 11, 15}. In- nere Knoten werden durch Kreise, Bl¨atter durch Rechtecke dargestellt. Die Wurzel ist der Knoten 7 mit den Nachfolgerknoten 5 und 10. Ist der linke (bzw. rechte) Nachfolger eines inneren Knotens ein Blatt, dann setzen wir v.Left (bzw. v.Right) auf null. Ein Zeiger auf die Wurzel gen¨ugt dann zur Repr¨asentation des gesamten Baums. Der Baum wird also vollst¨andig durch Zeiger auf die entsprechenden Nachfolger repr¨asentiert, und nicht z.B. als Array (wie bei Heaps). Trotzdem ist noch nicht klar, wie dies bei der Suche nach einem gegebenen Schl¨ussel hilft. Ein Heap k¨onnte z.B. auch durch entsprechende Zeiger repr¨asentiert werden, aber es ist unklar, wie man dort eﬃzient suchen kann. Daher f¨uhren wir Bin¨arer Suchbaumnun ein weiteres Kriterium ein: Ein bin¨arer Suchbaum ist ein bin¨arer Baum, der die Suchbaumeigenschaft erf¨ullt: Jeder innere Knoten v speichert einen Schl¨ussel k, alle Suchbaum- eigenschaftim linken Teilbaum Tl(v) von v gespeicherten Schl¨ussel sind kleiner als k und alle im rechten Teilbaum Tr(v) von v gespeicherten Schl¨ussel sind gr¨osser als k. Suchen eines Schl¨ussels Abbildung 4.12 zeigt einen m¨oglichen bin¨aren Suchbaum zur Schl¨usselmenge {5, 7, 8, 10, 11, 15}. Man beachte, dass es im Allgemeinen sehr viele verschiedene Suchb¨aume gibt, die die gleiche Schl¨usselmenge repr¨asentieren. So kann etwa jeder Schl¨ussel an der Wurzel stehen. Da aber alle Suchb¨aume die Suchbaumeigenschaft erf¨ullen, k¨onnen wir eine bin¨are Suche simulieren, um nach einem gegebenen Schl¨ussel k zu suchen. Dazu starten wir an der Wurzel und pr¨ufen, ob k dort gespeichert ist. Falls ja, dann haben wir k gefunden und beenden das Verfahren. Falls nein, dann fahren wir im linken Teilbaum von v fort, falls k kleiner als der Schl¨ussel der Wurzel ist, und ansonsten im rechten Teilbaum. Stossen wir auf ein Blatt, dann ist der Schl¨ussel k nicht vorhanden. Search(k) Schl¨ussel suchen 1 v ← Root 2 while v ist kein Blatt do 3 if k = v.Key then return true ▷ Element gefunden 4 else if k < v.Key then v ← v.Left ▷ Suche links weiter 6 else v ← v.Right ▷ Suche rechts weiter 7 return false ▷ k nicht gefunden Zur Analyse der Laufzeit deﬁnieren wir die H¨ohe eines Baums T . Ist T ein Blatt, H¨ohe 86 Datenstrukturen f¨ur W¨orterb¨ucher Abb. 4.13 Der Suchbaum aus Abbildung 4.12 nach der Einf¨ugung des Schl¨ussels 9. dann ist die H¨ohe h(T ) = 0. Ist T ein Baum mit Wurzel v und den Teilb¨aumen Tl(v) bzw. Tr(v), dann ist h(T ) = 1 + max{h(Tl(v)), h(Tr(v))}. (103) Die H¨ohe gibt anschaulich an, aus wie vielen Ebenen der Baum besteht. Der in Abbildung 4.12 dargestellte Baum etwa hat H¨ohe 4. Es ist nun leicht zu sehen, dass die zuvor vorgestellte Suche im schlechtestenLaufzeit Fall Zeit O(h) braucht, wenn h die H¨ohe des bin¨aren Suchbaums ist: Die Schritte 1 sowie 3–7 ben¨otigen nur konstante Zeit. Jeder Weg von der Wurzel zu einem Blatt hat maximal L¨ange h, also wird die Schleife im zweiten Schritt maximal h Mal durchlaufen. Einf¨ugen eines Schl¨ussels Beim Einf¨ugen eines Schl¨ussels k f¨uhren wir zun¨achst eine Suche nach k durch. Wird k gefunden, dann wird der Schl¨ussel nicht erneut eingef¨ugt und eine Fehlermeldung ausgegeben. Ansonsten endet die Suche erfolglos in einem Blatt. Dieses wird durch einen inneren Knoten mit dem Schl¨ussel k und zwei Bl¨attern ersetzt. F¨ugen wir beispielsweise den Schl¨ussel 9 in den Suchbaum aus Abbildung 4.12 ein, dann besuchen wir die Schl¨ussel 7, 10 und 8, und f¨ugen 9 als rechten Nachfolgerknoten von 8 ein. Da zum Einf¨ugen im Wesentlichen nur eine Suche durchgef¨uhrt wird und die an- schliessende Ersetzung eines Knotens nur Zeit O(1) kostet, kann in einen Suchbaum der H¨ohe h in Zeit O(h) eingef¨ugt werden. Entfernen eines Schl¨ussels Es verbleibt zu zeigen, wie ein Schl¨ussel k aus einem bin¨aren Suchbaum entfernt werden kann. Sei dazu v der Knoten, in dem k gespeichert ist. O.B.d.A. sei v nicht die Wurzel des Baums und u der Vorg¨anger von v. Wir unterscheiden drei F¨alle. 1. Fall: Beide Nachfolger von v sind Bl¨atter. Dann kann der Knoten v direkt ge- l¨oscht werden, d.h. der entsprechende Nachfolger von u wird durch ein Blatt ersetzt (siehe Abbildung 4.14). 2. Fall: Genau ein Nachfolger von v ist ein Blatt. Sei w der innere Knoten, der der Nachfolger von v ist. Der entsprechende Nachfolger von u wird durch w ersetzt und v gel¨oscht (siehe Abbildung 4.15). 4.4 Nat¨urliche Suchb¨aume 87 Abb. 4.14 Entfernen, Fall 1 (beide Nachfolger von v sind Bl¨atter). Abb. 4.15 Entfernen, Fall 2 (genau ein Nachfolger von v ist ein Blatt). Der Fall, in dem w der linke Nachfolger von v ist, wird analog aufgel¨ost. Abb. 4.16 Entfernen, Fall 3 (kein Nachfolger von v ist ein Blatt). 3. Fall: Kein Nachfolger von v ist ein Blatt. Dann enthalten sowohl der linke Teil- baum Tl(v) als auch der rechte Teilbaum Tr(v) mindestens einen inneren Kno- ten. Sei w der Knoten mit minimalem Schl¨ussel in Tr(v) (dieser heisst symme- Symmetrischer Nachfolgertrischer Nachfolger von v). Wird der in v gespeicherte Schl¨ussel durch den in w gespeicherten Schl¨ussel ersetzt und anschliessend w gel¨oscht (siehe Abbil- dung 4.16), dann bleibt die Suchbaumeigenschaft erhalten (denn der Schl¨ussel in w ist minimal unter allen in Tr(v) gespeicherten Schl¨usseln). Der Knoten w hat keinen linken Nachfolgerknoten, denn dort m¨usste ein Schl¨ussel von klei- nerem Wert gespeichert sein (und der Schl¨ussel von w w¨are nicht minimal in Tr(v)). Also tritt beim L¨oschen von w nur einer der beiden erstgenannten F¨alle auf. Zu einem gegebenen Knoten v kann der symmetrische Nachfolger gefunden wer- den, indem man genau einmal nach rechts l¨auft und danach so lange dem linken Nachfolger folgt, bis dieser ein Blatt als linken Nachfolger besitzt. Dies f¨uhrt zu folgendem Algorithmus. 88 Datenstrukturen f¨ur W¨orterb¨ucher SymmetricSuccessor(v) 1 w ← v.Right ▷ Gehe genau einmal nach rechts 2 x ← w.Left ▷ Folge danach dem linken Nachfolger 3 while x ist kein Blatt do w ← x; x ← w.Left 4 return w ▷ w ist symmetrischer Nachfolger von v Nat¨urlich k¨onnte auch der symmetrische Vorg¨anger (der Knoten mit gr¨osstem Schl¨us-Symmetrischer Vorg¨anger sel in Tl(v)) gew¨ahlt werden. Die vorigen ¨Uberlegungen gelten dann analog. Theorem 4.3 (Laufzeit des Entfernens). Sei T ein bin¨arer Suchbaum der H¨ohe h.Laufzeit des Entfernens Das Entfernen eines Schl¨ussels in T erfordert im schlechtesten Fall Zeit O(h). Beweis. Der zu entfernende Knoten muss zun¨achst gefunden werden, was in Zeit O(h) m¨oglich ist. Danach tritt einer der F¨alle 1 bis 3 auf. In den ersten beiden F¨allen werden lediglich Zeiger ver¨andert und Speicher freigegeben. Daher f¨allt f¨ur sie nur Zeit O(1) an. Im dritten Fall muss der zun¨achst mithilfe des Algorithmus SymmetricSuccessor der sym- metrische Nachfolger gefunden werden. Dies kostet maximal Zeit O(h), da die Pfadl¨ange von der Wurzel bis zu einem Blatt h¨ochstens h betr¨agt. Danach werden lediglich die Schl¨ussel vertauscht und der symmetrische Nachfolger gel¨oscht, was in Zeit O(1) m¨oglich ist. Damit wird im dritten Fall maximal Zeit O(h) ben¨otigt. Durchlaufordnungen f¨ur B¨aume Sei T ein bin¨arer Suchbaum mit der Wurzel v, dem linken Teilbaum Tl(v) und dem rechten Teilbaum Tr(v). Wir k¨onnen die Knoten von T auf verschiedene Arten durchlaufen: • In der Hauptreihenfolge (engl. Preorder) wird zun¨achst der in v gespeicherteHaupt- reihenfolge Preorder Schl¨ussel ausgegeben. Danach wird zuerst rekursiv mit Tl(v) fortgefahren und anschliessend rekursiv Tr(v) verarbeitet. • In der Nebenreihenfolge (engl. Postorder) wird zun¨achst Tl(v) rekursiv ver-Neben- reihenfolge Postorder arbeitet und danach Tr(v). Schliesslich wird der in v gespeicherte Schl¨ussel ausgegeben. • In der symmetrischen Reihenfolge (engl. Inorder) wird zun¨achst Tl(v) rekursivSymmetrische Reihenfolge Inorder besucht, danach der in v gespeicherte Schl¨ussel ausgegeben und schliesslich Tr(v) rekursiv besucht. Da alle Schl¨ussel in Tl(v) kleiner und alle Schl¨ussel in Tr(v) gr¨osser sind als der in v gespeicherte Schl¨ussel, gibt die symmetrische Reihenfolge die in T gespeicherten Schl¨ussel in sortierter Reihenfolge aus. Beispiel Die Knoten des bin¨aren Suchbaums aus Abbildung 4.13 werden in den folgenden Reihenfolgen durchlaufen: • 7, 5, 10, 8, 9, 11, 15 bei Verwendung der Hauptreihenfolge, • 5, 9, 8, 15, 11, 10, 7 bei Verwendung der Nebenreihenfolge, • 5, 7, 8, 9, 10, 11, 15 bei Verwendung der symmetrischen Reihenfolge. 4.5 AVL-B¨aume 89 Zusammenfassung und Ausblick Sei T ein bin¨arer Suchbaum mit H¨ohe h, der n Schl¨ussel verwaltet. Bin¨are Suchb¨aume implementieren die W¨orterbuchoperationen in Zeit O(h). Ausserdem werden eine Reihe weiterer Operationen unterst¨utzt, zum Beispiel: • Min(T ): Liefert den Schl¨ussel aus T mit minimalem Wert zur¨uck. Diese Ope- Minimaler Schl¨usselration kann in Zeit O(h) realisiert werden, indem ausgehend von der Wurzel von T so lange dem linken Nachfolgerknoten gefolgt wird, bis dieser ein Blatt als linken Nachfolger besitzt. • Extract-Min(T ): Sucht und entfernt den Schl¨ussel mit minimalem Wert Minimum extrahierenaus T . Auch diese Operation kann in Zeit O(h) durchgef¨uhrt werden. • List(T ): Liefert eine sortierte Liste der in T gespeicherten Schl¨ussel zur¨uck. Schl¨ussel ausgebenDiese Funktion wird von einem Durchlauf in symmetrischer Reihenfolge in Zeit O(n) realisiert. • Join(T1, T2): Seien T1 und T2 zwei Suchb¨aume zu den disjunkten Schl¨ussel- Vereinigung mengen K1 und K2, und zus¨atzlich der maximale Wert eines Schl¨ussels in K1 kleiner als der minimale Wert eines Schl¨ussels in K2. Join(T1, T2) berech- net einen bin¨aren Suchbaum zur Schl¨usselmenge K1 ∪ K2. Dazu f¨uhren wir zun¨achst Extract-Min(T2) aus, erhalten einen Schl¨ussel k sowie den aus T2 resultierenden Baum T ′ 2. Dann erzeugen wir einen neuen Baum, dessen Wurzel den Schl¨ussel k speichert und die Teilb¨aume T1 sowie T ′ 2 besitzt. Die Laufzeit betr¨agt O(h). Die soeben diskutierten nat¨urlichen bin¨aren Suchb¨aume sind problematisch, wenn Verhalten im schlechtesten Fall die Schl¨ussel (gr¨osstenteils) in geordneter Reihenfolge eingef¨ugt werden. Im schlech- testen Fall degenerieren sie zu einer linearen Liste, und die Laufzeiten f¨ur die W¨orter- buchoperationen sind dann linear in der Anzahl der gespeicherten Schl¨ussel. 4.5 AVL-B¨aume Da die Laufzeit der W¨orterbuchoperationen linear in der Baumh¨ohe sein kann, w¨are es gut, wenn wir sicherstellen k¨onnten, dass die H¨ohe stets sublinear oder besser noch in O(log n) ist (wobei n wie zuvor die Anzahl der verwalteten Schl¨ussel bezeich- net). Wir haben bereits Baumstrukturen mit logarithmischer H¨ohe kennengelernt, n¨amlich Heaps. Leider sind diese viel zu unﬂexibel um dort dynamisch Schl¨ussel einzuf¨ugen und zu l¨oschen, denn pro Anzahl verwalteter Schl¨ussel gibt es nur genau eine m¨ogliche Struktur. Adelson-Velskii und Landis schlugen nun 1962 vor, dass sich in jedem Knoten eines bin¨aren Suchbaums die H¨ohen des links und des rechts ge- speicherten Teilbaums um maximal 1 unterscheiden sollten (siehe Abbildung 4.17). Sei nun T ein Baum mit der Wurzel v, der linke Teilbaum von v sei Tl(v), und Struktur- bedingungTr(v) der rechte (man beachte, dass sowohl Tl(v) als auch Tr(v) ein Blatt, d.h. ein Nullzeiger, sein k¨onnen). Wir deﬁnieren die Balance des Knotens v als bal(v) := h(Tr(v)) − h(Tl(v)), (104) wobei h(Tl(v)) bzw. h(Tr(v)) die H¨ohe von Tl(v) bzw. Tr(v) angeben. Die AVL- AVL-Bedingung Bedingung besagt nun, dass f¨ur alle Knoten v des Baums bal(v) ∈ {−1, 0, 1} gilt. Ab- bildung 4.18 zeigt Beispiele f¨ur AVL-B¨aume. Um zu zeigen, dass die AVL-Bedingung 90 Datenstrukturen f¨ur W¨orterb¨ucher Abb. 4.17 Ein bin¨arer Suchbaum mit der Wurzel v. Damit die AVL-Bedingung erf¨ullt ist, d¨urfen sich die H¨ohen hl und hr des linken bzw. des rechten Teilbaums von v maximal um 1 unterscheiden. Zudem muss diese Bedingung auch f¨ur alle Knoten gelten, die sich in Tl(v) oder Tr(v) beﬁnden. (a) (b) (c) Abb. 4.18 Da sich bei AVL-B¨aumen die H¨ohen der Teilb¨aume um maximal 1 unterschei- den d¨urfen, sind (a) und (b) Beispiele f¨ur AVL-B¨aume, (c) hingegen nicht. tats¨achlich sinnvoll ist, zeigen wir zun¨achst, dass sie tats¨achlich eine logarithmische Baumh¨ohe garantiert. Danach zeigen wir, wie in einen bestehenden AVL-Baum ein- gef¨ugt werden kann, ohne die AVL-Eigenschaft zu verletzen. Logarithmische H¨ohe Wir wollen f¨ur einen AVL-Baum mit n Schl¨usseln zeigen, dass seine H¨ohe stets durch O(log n) nach oben beschr¨ankt ist. Leider ist ein direk- ter Nachweis dieser Aussage aber nicht so einfach, da es sehr viele m¨ogliche AVL- Baumstrukturen zur Verwaltung von n Schl¨usseln gibt. Daher bedienen wir uns eines Tricks: Statt f¨ur eine gegebene Schl¨usselanzahl n zu untersuchen, welche H¨ohe einTrick AVL-Baum h¨ochstens hat, untersuchen wir, wie viele Bl¨atter ein AVL-Baum f¨ur ei- ne gegebene H¨ohe h mindestens hat. Man kann leicht durch vollst¨andige Induktion nachweisen, dass jeder bin¨are Suchbaum (und damit auch jeder AVL-Baum), der n Schl¨ussel speichert, genau n + 1 Bl¨atter hat. Deswegen liefert eine solche unte- re Schranke f¨ur die Anzahl der Bl¨atter in einem AVL-Baum mit einer gegebenen H¨ohe h automatisch eine obere Schranke f¨ur die H¨ohe eines AVL-Baums mit einer gegebenen Anzahl von Schl¨usseln n. Verankerung I (AVL-B¨aume mit H¨ohe h = 1): Es gibt nur einen AVL-Baum mit H¨o-Mindest- blattzahl he 1, n¨amlich denjenigen, der genau einen Schl¨ussel speichert und zwei Bl¨atter besitzt (siehe Abbildung 4.18(a)). Die Mindestblattzahl eines AVL-Baums mit H¨ohe 1 betr¨agt daher M B(1) = 2. Verankerung II (AVL-B¨aume mit H¨ohe h = 2): Es gibt genau drei AVL-B¨aume mit H¨ohe 2. Zwei davon verwalten genau zwei Schl¨ussel, von denen einer in der Wurzel des Baums und der andere im linken bzw. im rechten Nachfolger der 4.5 AVL-B¨aume 91 Wurzel gespeichert ist (siehe Abbildung 4.18(b)). Ausserdem gibt es noch einen Baum mit einer Wurzel und jeweils genau einem linken und einem rechten Nachfolger. Da jeder dieser B¨aume mindestens drei Bl¨atter hat, betr¨agt die Mindestblattzahl eines AVL-Baums mit H¨ohe 2 genau M B(2) = 3. Rekursion (AVL-B¨aume mit H¨ohe h ≥ 3): Betrachte einen beliebigen AVL-Baum mit H¨ohe h. Dieser besteht aus einem Wurzelknoten v mit einem linken Teilbaum Tl(v) und einem rechten Teilbaum Tr(v) (siehe Abbildung 4.17). Die H¨ohe dieser Teilb¨aume ist h¨ochstens h − 1. Mindestens einer der Teilb¨aume muss H¨ohe h − 1 haben (h¨atten beide eine H¨ohe strikt kleiner als h − 1, dann w¨are die H¨ohe des gesamten Baums strikt kleiner als h). Der andere Teilbaum hat entweder H¨ohe h − 1, oder H¨ohe h − 2, denn gem¨ass AVL-Bedingung d¨urfen sich die H¨ohen der Teilb¨aume h¨ochstens um 1 unterscheiden. Da wir die Min- destblattzahl untersuchen, nehmen wir an, der andere Teilbaum h¨atte H¨ohe h − 2 (denn ein Baum mit H¨ohe h − 1 hat mit Sicherheit nicht weniger Bl¨atter als ein Baum mit H¨ohe h − 2). Die Anzahl der Bl¨atter des gesamten Baums ist nun die Summe der Blattanzahlen in den beiden Teilb¨aumen. Es gilt also M B(h) = M B(h − 1) + M B(h − 2). Die Rekursionsformel f¨ur die Mindestblattzahl erinnert an die der Fibonacci-Zahlen. Diese waren als F1 := 1, F2 := 1, Fh := Fh−1 + Fh−2 f¨ur h ≥ 3 (105) deﬁniert. Damit gilt oﬀenbar die Beziehung M B(h) = Fh+2, und man kann zeigen, dass M B(h) ∈ Θ (( 1+ √5 2 )h) ⊆ Ω(1.6h) gilt. Ein AVL-Baum mit H¨ohe h hat also mindestens 1.6h viele Bl¨atter, d.h., mindestens 1.6h − 1 viele Schl¨ussel. Im Um- kehrschluss bedeutet dies, dass die H¨ohe eines AVL-Baums mit n Schl¨usseln durch 1.44 log2 n nach oben beschr¨ankt ist, also wie gehoﬀt tats¨achlich nur logarithmisch in der Anzahl der Schl¨ussel n ist. Das heisst also, ein AVL-Baum ist nur h¨ochstens 44% h¨oher als ein perfekt balancierter Bin¨arbaum! Einf¨ugen in einen AVL-Baum Ein Schl¨ussel wird in einen AVL-Baum zun¨achst wie in einen nat¨urlichen Suchbaum eingef¨ugt. Danach testen wir, ob die AVL-Bedingung noch immer an allen Knoten gilt, und rebalancieren ansonsten den Baum. Wir beob- achten zun¨achst, dass die AVL-Bedingung h¨ochstens bei den Knoten auf dem Weg von der Wurzel zum neu eingef¨ugten Schl¨ussel verletzt sein kann. Bei allen anderen Knoten ist die Balance unver¨andert, folglich gilt die AVL-Bedingung nach wie vor. Wir laufen also vom neu eingef¨ugten Knoten zur Wurzel hoch und pr¨ufen, ob die AVL-Bedingung noch immer gilt. Um eﬃzient pr¨ufen zu k¨onnen, ob die AVL-Bedingung f¨ur einen Knoten erf¨ullt Speicherung der Balanceist, k¨onnten wir pro Knoten die H¨ohe des dort repr¨asentierten Teilbaums speichern. Das w¨urde aber zu viel Platz brauchen, und es ausreichend, einfach nur die ak- tuelle Balance zu speichern, also −1 (linker Teilbaum h¨oher), 0 (beide Teilb¨aume gleich hoch) oder +1 (rechter Teilbaum h¨oher). Da man weiss, in welchen Teilbaum eingef¨ugt wurde, weiss man auch, welcher Teilbaum ggf. gewachsen ist. Wir nehmen im Folgenden an, dass der neue Schl¨ussel in einen Knoten r eingef¨ugt Balance pr¨ufen wurde, der der linke Nachfolger eines Knotens u ist. Der Fall, in dem r der rechte Nachfolger von u ist, kann v¨ollig analog abgehandelt werden. Nun betrachten wir die bisherige Balance von u und unterscheiden drei (bzw. eigentlich nur zwei) F¨alle. 92 Datenstrukturen f¨ur W¨orterb¨ucher (a) (b) Abb. 4.19 Die Situation, in der u vor Einf¨ugung des neuen Schl¨ussels in r (a) Balance 0, und (b) Balance 1 hatte. 1. Fall: bal(u) = −1. Solch ein Fall kann nicht auftreten, da u dann vor Einf¨ugung des Schl¨ussels genau einen linken Nachfolger und keinen rechten Nachfolger gehabt h¨atte. Dann aber h¨atte r nicht linker Nachfolger von u werden k¨onnen. 2. Fall: bal(u) = 0. Da r der linke Nachfolger von u ist, kann u vor der Einf¨ugung des neuen Schl¨ussels keinen linken Nachfolger gehabt haben. Da die Balance von u vorher 0 war, kann u folglich auch keinen rechten Nachfolger gehabt haben. Der neue Knoten r ist der linke Nachfolger von u, also setzen wir bal(u) ← −1 und bal(r) ← 0 (siehe Abbildung 4.19(a)). Nun ist aber die H¨ohe des Teilbaums mit der Wurzel u um 1 gewachsen. Daher muss f¨ur die Vorg¨anger von r gepr¨uft werden, ob die AVL-Bedingung noch gilt. Dazu rufen wir eine Methode upin(u) auf, deren Funktionsweise gleich erl¨autert wird. 3. Fall: bal(u) = 1. In diesem Fall hatte u vorher genau einen rechten Nachfolger. Da v der linke Nachfolger von u ist, setzen wir bal(u) ← 0 und bal(r) ← 0 (siehe Abbildung 4.19(b)). In diesem Fall ist die H¨ohe des Teilbaums mit der Wurzel u nicht gewachsen, also muss die AVL-Bedingung f¨ur alle Knoten des Baums nach wie vor gelten, und wir sind fertig. Wir m¨ussen uns also nur noch um den Fall k¨ummern, dass die AVL-Bedingung f¨ur einen Knoten auf dem Weg von u zur Wurzel des Baums verletzt ist. Dazu rufen wir, wie soeben erw¨ahnt, eine Methode upin(u) auf. Diese Methode wird nur aufgerufen, wenn die folgenden drei Invarianten gelten: Invarianten f¨ur upin 1) Der neu eingef¨ugte Schl¨ussel beﬁndet sich im Teilbaum mit der Wurzel u, und durch die Einf¨ugung ist die H¨ohe des Teilbaums mit der Wurzel u um 1 gewachsen, 2) u hat eine von Null verschiedene Balance, und 3) u hat einen Vorg¨anger w. Man beachte, dass die Balance von u bereits im vorigen Schritt korrekt berechnetBeschreibung von upin wurde, die Balance des Vorg¨angers w von u aber noch aktualisiert werden muss. Dazu nehmen wir o.B.d.A. an, dass u der linke Nachfolger von w ist (der Fall, dass u der rechte Nachfolger von w ist, wird analog abgehandelt), und unterscheiden wie zuvor drei F¨alle: 1. Fall: bal(w) = 1. Dann war bisher der rechte Teilbaum von w um 1 h¨oher als der linke Teilbaum mit der Wurzel u. Da dessen H¨ohe um 1 gewachsen ist, haben jetzt beide Teilb¨aume von w die gleiche H¨ohe, und wir setzen bal(w) ← 0 (siehe Abbildung 4.20(a)). Da sich die H¨ohe des Teilbaums mit der Wurzel w nicht ver¨andert hat, sind wir fertig. 4.5 AVL-B¨aume 93 (a) (b) Abb. 4.20 Situation beim Rebalancieren, wenn w vorher (a) Balance 1 hatte, und (b) Balance 0 hatte. Der gestrichelte Teil zeigt die Situation nach Einf¨ugung des neuen Schl¨ussels in den Knoten r. Der Einfachheit halber wurden die Bl¨atter von r nicht eingezeichnet. 2. Fall: bal(w) = 0. Dann hatten bisher beide Teilb¨aume von w die gleiche H¨ohe. Da wir in den Teilbaum mit der Wurzel u eingef¨ugt haben und dessen H¨ohe um 1 gewachsen ist, setzen wir bal(w) ← −1 (siehe Abbildung 4.20(b)). Jetzt ist aber die H¨ohe des Teilbaums mit der Wurzel w um 1 gewachsen, also rufen wir upin(w) rekursiv auf (sofern auch w noch einen Vorg¨anger hat und nicht die Wurzel des gesamten Baums ist). Wir beobachten, dass der neue Schl¨ussel in den Teilbaum mit der Wurzel w eingef¨ugt wurde und w eine von 0 verschiedene Balance hat, also sind die Invarianten f¨ur den Aufruf von upin(w) wieder erf¨ullt. 3. Fall: bal(w) = −1. Dann war der linke Teilbaum (mit der Wurzel u) bereits vor Einf¨ugung des neuen Schl¨ussels um 1 h¨oher als der rechte Teilbaum. Da die H¨ohe des linken Teilbaums durch die Einf¨ugung des neuen Schl¨ussels erneut um 1 gewachsen ist, betr¨agt die Balance von w damit aktuell -2; damit ist die AVL-Bedingung bei w derzeit also verletzt. Zur Reparatur unterscheiden wir noch einmal zwei F¨alle: • Ist bal(u) = −1, dann wurde der neue Schl¨ussel in den linken Teilbaum von u eingef¨ugt. Wir f¨uhren nun eine Rechtsrotation um w durch, bei der u Einfache Rotationdie neue Wurzel des aktuellen Teilbaums wird, w rechter Nachfolger von u, und die Teilb¨aume von u und w entsprechend umgeh¨angt werden (siehe Abbildung 4.21). Die H¨ohe des so erhaltenen Teilbaums mit der Wurzel u entspricht exakt der H¨ohe des fr¨uheren Teilbaums mit der Wurzel w vor der Einf¨ugung des neuen Schl¨ussels, also sind wir fertig. • Ist dagegen bal(u) = 1, dann wurde der neue Schl¨ussel in den rechten Teilbaum von u eingef¨ugt. Sei v der rechte Nachfolger von u. Wir neh- men o.B.d.A. an, dass der neue Schl¨ussel in den linken Teilbaum von v eingef¨ugt wurde (der Fall, in dem der neue Schl¨ussel in den rechten Teil- baum von v eingef¨ugt wurde, wird absolut identisch gehandhabt). Man beachte, dass v nicht den neu eingef¨ugten Schl¨ussel enth¨alt, denn dann h¨atte w¨are der linke Nachfolger von w ein Blatt, und dieser Fall wurde bereits fr¨uher abgehandelt. Zur Wiederherstellung der AVL-Bedingung wird eine Doppelrotation er- Doppelrotation forderlich. Dazu f¨uhren wir zun¨achst eine einfache Linksrotation um u 94 Datenstrukturen f¨ur W¨orterb¨ucher Abb. 4.21 Wurde der neue Schl¨ussel in den linken Teilbaum von u eingef¨ugt, dann gen¨ugt eine einfache Rechtsrotation um den Knoten w zur Wiederherstellung der AVL-Bedingung bei w. Wie zuvor sind die Bl¨atter von r nicht eingezeichnet. Abb. 4.22 Wurde der neue Schl¨ussel in den rechten Teilbaum von u eingef¨ugt, dann wird eine Doppelrotation zur Rebalancierung benutzt. Dazu wird zun¨achst eine einfache Linksrotation um u und direkt danach eine einfache Rechtsrotation um w durchgef¨uhrt, sodass sich der rechts dargestellte Baum ergibt. Der Fall, in dem der neue Schl¨ussel in C (statt in B) eingef¨ugt wurde, wird identisch gehandhabt. durch, sodass u der linke Nachfolger von v und v der linke Nachfolger von w wird. Direkt danach f¨uhren wir eine einfache Rechtsrotation um w durch, sodass v die neue Wurzel des Teilbaums wird (siehe Abbil- dung 4.22). Wie bei der einfachen Rotation hat der so erhaltene Teilbaum mit der Wurzel v die gleiche H¨ohe wie der fr¨uhere Teilbaum mit der Wurzel w vor der Einf¨ugung des neuen Schl¨ussels, also sind wir fertig. Wir sehen also, dass beim Einf¨ugen nur eine einzige einfache oder Doppelrotation n¨otig ist, um die AVL-Bedingung bei allen Knoten wiederherzustellen. AVL-B¨aume wurden eingef¨uhrt, damit die W¨orterbuchoperationen bessere Lauf-Laufzeit zeiten im schlechtesten Fall haben. Um diese zu bestimmen, muss der Einf¨ugevorgang und insbesondere die zum Rebalancieren ben¨otigte Zeit genauer analysiert werden. Das Einf¨ugen selbst (ohne Rebalancierung) hat eine in der H¨ohe des Baums be- schr¨ankte Laufzeit, und da die H¨ohe in O(log n) liegt, folgt die gleiche obere Schran- 4.5 AVL-B¨aume 95 ke f¨ur die Laufzeit des Einf¨ugens (ohne Rebalancierung). Die Methode upin f¨uhrt (ohne den ggf. durchgef¨uhrten rekursiven Aufruf) nur konstant viele Operationen durch. Man beachte, dass auch Rotationen in konstanter Zeit durchgef¨uhrt werden kann, da bei ihnen nur konstant viele Vergleiche und Umh¨angungen von Zeigern anfallen. Bei jedem rekursiven Aufruf verringert sich der Abstand zur Wurzel um 1. Da die H¨ohe stets in O(log n) liegt, gibt es also h¨ochstens so viele rekursive Aufrufe, und da jeder nur konstante Zeit ben¨otigt, l¨auft upin in Zeit O(log n). Damit kann in einem AVL-Baum tats¨achlich in Zeit O(log n) gesucht und eingef¨ugt werden. Die gleiche Laufzeit ergibt sich auch f¨ur das L¨oschen eines Schl¨ussels, das ¨ahnlich L¨oschen zum Einf¨ugen durchgef¨uhrt wird. Dort ist allerdings zu beachten, dass u.U. Θ(log n) viele Rotationen zur Wiederherstellung der AVL-Bedingung ben¨otigt werden. 96 Datenstrukturen f¨ur W¨orterb¨ucher Kapitel 5 Graphenalgorithmen 5.1 Grundlagen Im historischen K¨onigsberg (heute Kaliningrad) gab es sieben Br¨ucken ¨uber den Fluss, den Pregel, die verschiedene Teile der Stadt miteinander verbanden. Abbil- dung 5.1 skizziert die Situation zu Beginn des 18. Jahrhunderts. Wir wollen nun ¨uberlegen, ob es einen Rundweg durch die Stadt gibt, die jede Br¨ucke genau einmal ¨uberquert und am Ende zum Ausgangspunkt zur¨uckkehrt. Abb. 5.1 Situation in K¨onigsberg zu Beginn des 18. Jahrhunderts. Rot eingezeichnet sind die Br¨ucken, die den Fluss (den Pregel) ¨uberqueren. Wie immer abstrahieren wir zun¨achst. Wir erzeugen f¨ur jeden der vier Teile der Stadt einen Knoten und verbinden zwei Knoten durch eine Kante, wenn eine Br¨ucke Knoten Kantezwischen den entsprechenden Teilen besteht. Je mehr Br¨ucken zwischen zwei Teilen existieren, umso mehr Kanten zwischen den entsprechen Knoten erzeugen wir. Eine solche Struktur nennt man einen Graphen. Abbildung 5.2 zeigt einen Graphen, der Graph die in Abbildung 5.1 dargestellte Situation modelliert. Wir wollen jetzt untersuchen, ob es einen Rundweg (einen sog. Zyklus) durch den Graphen gibt, der jede Kante Zyklus genau einmal benutzt. Ein solcher Zyklus wird Eulerscher Zyklus genannt (zu Ehren Eulerscher Zyklusvon Leonhard Euler, der 1736 nachwies, dass ein solcher Rundweg in K¨onigsberg nicht existiert). Abb. 5.2 Ein Graph, der die Situation aus Abbildung 5.1 modelliert. Die blauen Kreise stellen die Knoten da, die Linien die Kanten. 97 98 Graphenalgorithmen (a) (b) Abb. 5.3 Beispiele f¨ur Graphen: Gerichteter Graph mit f¨unf Knoten und einer Schleife um den Knoten 5 (a), ungerichteter vollst¨andiger Graph mit f¨unf Knoten (b). Wir beobachten nun: Falls ein Graph einen Eulerzyklus hat, dann gibt es an jedem Knoten eine gerade Anzahl Kanten (wir sagen dann auch, dass jeder Knoten einen geraden Grad) hat. Tats¨achlich kann man sogar die ¨Aquivalenz beweisen (was wir jetzt nicht tun): Ein Graph hat genau dann einen Eulerzyklus, wenn jeder Kno- ten einen geraden Grad hat. Bevor wir Beispiele f¨ur andere Probleme anschauen, deﬁnieren wir zun¨achst Graphen und die zugeh¨origen Konzepte formal. 5.1.1 Graphentheorische Grundlagen und Begriﬀe Deﬁnition 5.1 (Gerichteter Graph). Ein gerichteter Graph besteht aus einer MengeGerichteter Graph V = {v1, . . . , vn} von Knoten (engl. vertices) und einer Menge E ⊆ V × V von Kanten (engl. edges). Deﬁnition 5.2 (Ungerichteter Graph). Ein ungerichteter Graph besteht aus einerUngerichteter Graph Menge V = {v1, . . . , vn} von Knoten und einer Menge E ⊆ {{u, v} | u, v ∈ V } von Kanten. In gerichteten Graphen hat also jede Kante (u, v) eine Richtung; sie verl¨auft von u nach v. Eine Kante ist formal ein Paar von Knoten. In ungerichteten Graphen hat eine Kante keine Richtung. Sie ist formal eine Menge mit h¨ochstens zwei Elemen- ten. Kanten (v, v) (im Falle gerichteter Graphen) bzw. {v} (im Falle ungerichteter Graphen) heissen Schleifen. Manchmal erlaubt man, dass E eine Multimenge ist,Schleife gleiche Kanten also mehrfach enthalten darf (dies ist z.B. bei dem in Abbildung 5.2 dargestellten Graph der Fall). Man spricht dann von einem Multigraphen. F¨ur dieseMultigraph Vorlesung nehmen wir jedoch an, dass jeder Graph jede m¨ogliche Kante h¨ochstens einmal enth¨alt, E also niemals eine Multimenge ist. Ein Graph G = (V, E), in dem E jede Kante zwischen zwei verschiedenen KnotenVollst¨andiger Graph v und w enth¨alt, heisst vollst¨andig (siehe Abbildung 5.3(b)). Ein Graph G = (V, E), dessen Knotenmenge V in zwei disjunkte Mengen U und W aufgeteilt werden, so-Bipartiter Graph dass alle Kanten genau einen Knoten in U und einen Knoten und W haben, heisst bipartit. Ein gewichteter Graph G = (V, E, c) ist ein Graph G = (V, E) mit einerGewichteter Graph Kantengewichtsfunktion c : E → R. Der Wert c(e) heisst dann Gewicht der Kante e, und ist oftmals nicht-negativ. Ein Knoten w heisst adjazent zu einem Knoten v, falls E die Kante (v, w) (imAdjazenz Falle gerichteter Graphen) bzw. {v, w} (im Falle ungerichteter Graphen) enth¨alt. F¨ur gerichtete Graphen G = (V, E) ist die Vorg¨angermenge eines Knotens v alsVorg¨anger N −(v) := {u ∈ V | (u, v) ∈ E} deﬁniert. Analog ist N +(v) := {w ∈ V | (v, w) ∈ E}Nachfolger die Nachfolgermenge eines Knotens v. Der Eingangsgrad eines Knotens v ist dieEingangsgrad Kardinalit¨at der Vorg¨angermenge und wird mit deg−(v) bezeichnet. Analog ist 5.1 Grundlagen 99 (a) (b) Abb. 5.4 Im gerichteten Graphen links (a) sind deg−(v) = 3, deg+(v) = 2, deg−(w) = 1 und deg+(w) = 1. Im ungerichteten Graphen rechts (b) sind deg(v) = 5 und deg(w) = 2. der Ausgangsgrad eines Knotens v die Kardinalit¨at der Nachfolgermenge und wird Ausgangsgrad mit deg+(v) bezeichnet. Das Analogon f¨ur ungerichtete Graphen ist die Menge N (v) := {w ∈ V | {v, w} ∈ E}, die als Nachbarschaft von v bezeichnet wird. Da in Nachbarschaft ungerichteten Graphen der Eingangs- und der Ausgangsgrad eines jeden Knotens v ¨ubereinstimmen, spricht man hier einfach nur vom Grad von v, und bezeichnet ihn Grad mit deg(v). Hier muss allerdings ein Spezialfall beachtet werden: Eine Schleife um einen Knoten v erh¨oht den Grad in ungerichteten Graphen um 2 (und nicht um 1) erh¨oht; in gerichteten Graphen dagegen werden Schleifen nur einfach gez¨ahlt und erh¨ohen den Eingangs- und Ausgangsgrad eines Knotens lediglich um 1. Zwischen den Knotengraden und der Kantenanzahl bestehen nun die folgenden Beziehungen: Lemma 5.3. In jedem Graphen G = (V, E) gilt (i) ∑ v∈V deg−(v) = ∑ v∈V deg+(v) = |E|, falls G gerichtet ist, und (ii) ∑ v∈V deg(v) = 2|E|, falls G ungerichtet ist. Eine Sequenz von Knoten ⟨v1, . . . , vk+1⟩ heisst Weg, wenn f¨ur jedes i ∈ {1, . . . , k} Weg eine Kante von vi nach vi+1 existiert. Die L¨ange eines Weges ist k, die Anzahl der enthaltenen Kanten. In einem gewichteten Graphen ist das Gewicht eines Weges deﬁniert als die Summe der Gewichte aller im Weg enthaltenen Kanten (vi, vi+1) (bzw. {vi, vi+1} bei ungerichteten Graphen). Ein Weg, der keinen Knoten mehrfach benutzt, heisst Pfad. Ein Pfad, der in einem Knoten s startet und in einem Knoten t Pfad endet, heisst st-Pfad. Ein ungerichteter Graph G = (V, E), in dem zwischen jedem Paar zweier Knoten v und w ein Weg existiert, heisst zusammenh¨angend. Zusammenhang Ein Weg ⟨v1, . . . , vk, vk+1⟩ mit v1 = vk+1 heisst Zyklus. In einem Zyklus stimmen Zyklus also Start- und Endknoten ¨uberein. Ein Zyklus heisst Kreis, falls er kein Knoten Kreis (mit Ausnahme des ersten und des letzten Knotens) und keine Kante mehr als einmal benutzt. Insbesondere ist eine Schleife ein Kreis der L¨ange 1. Man beachte, dass ungerichtete Graphen mit dieser Deﬁnition niemals Kreise der L¨ange 2 haben k¨onnen. Ein Graph ohne jegliche Kreise heisst kreisfrei. Kreisfreier Graph 5.1.2 Beispiele f¨ur Graphen und Graphprobleme Soziale Netzwerke Soziale Netzwerke wie et- wa Facebook k¨onnen durch Graphen beschrieben werden, in denen ein Knoten pro Account er- zeugt wird und zwei Knoten miteinander verbun- den werden, wenn die entsprechenden Accounts miteinander befreundet sind. Sind Freundschaf- ten symmetrisch (wie z.B. bei Facebook), dann ist der Graph ungerichtet, ansonsten (wie z.B. bei Twitter) gerichtet. F¨ur solche 100 Graphenalgorithmen Graphen kann man zum Beispiel fragen, wie weit (also ¨uber wie viele Klicks) Xin von Peter entfernt ist. Das entsprechende graphentheoretische Problem besteht dann in der Berechnung der L¨ange eines k¨urzesten Weges von einem gegebenen Startkno- ten s zu einem gegebenen Zielknoten t. Strassennetze Strassennetze k¨onnen durch gewichtete Graphen modelliert werden, in- dem man f¨ur jede Kreuzung einen Knoten er- zeugt und zwei Knoten miteinander verbun- den werden, wenn es zwischen den Kreuzun- gen eine direkte Verbindung (d.h. ohne wei- tere Zwischenkreuzungen) gibt. Das Gewicht einer Kante gibt dann z.B. an, wie lange die Traversierung der entsprechenden Kante durchschnittlich ben¨otigt. Oftmals werden gerichtete Graphen benutzt, damit auch Einbahnstrassen (und manchmal sogar ei- gene Spuren) modelliert werden k¨onnen. Das graphentheoretische Problem besteht nun darin, f¨ur zwei gegebene Knoten s und t einen Weg zu berechnen, dessen Kan- tenkosten minimal unter allen Wegen von s nach t ist. Bewertungen Bei Streamingdiensten wie Net- ﬂix k¨onnen Benutzer gesehene Filme bewerten. Auch solche Zusammenh¨ange k¨onnen mit gewich- teten Graphen modelliert werden, indem man zum Beispiel einen Knoten f¨ur jeden Benutzer und einen Knoten f¨ur jeden Film erzeugt. Der Graph enth¨alt eine Kante f¨ur jede Wertung, die ein Zuschauer einem Film gibt, und das Gewicht dieser Kante spiegelt die numeri- sche Bewertung wieder. Dieser Graph hat die Eigenschaft, dass er bipartit ist, denn Knotenmenge V kann so in zwei disjunkte Mengen U (hier: Benutzer) und W (hier: Filme) aufgeteilt werden, dass Kanten stets zwischen einem Knoten aus U und einem Knoten aus W verlaufen. B¨aume Auch B¨aume k¨onnen durch Graphen re- pr¨asentiert werden. Ein Baum ist ein ungerichte- ter Graph, der zusammenh¨angend und kreisfrei ist. Diese Deﬁnition weicht zun¨achst von der bisherigen Deﬁnition von B¨aumen ab. Sobald man aber einen Knoten des hier deﬁnierten Baums als Wurzel fest- legt und die Kanten von der Wurzel abw¨arts richtet, erh¨alt man einen gewurzelten Baum, f¨ur den z.B. untersucht werden kann, ob er die AVL-Bedingung erf¨ullt. Auch kann man z.B. zeigen, dass jeder Baum mit n Knoten genau n − 1 Kanten hat. 5.1.3 Datenstrukturen f¨ur Graphen Im Folgenden sei G = (V, E) ein gerichteter Graph mit der Knotenmenge V = {v1, . . . , vn}. G kann durch seine sog. Adjazenzmatrix AG = (aij)1≤i,j≤n repr¨asen-Adjazenzmatrix tiert werden, die die Gr¨osse n × n hat und deren Eintr¨age aus {0, 1} stammen. F¨ur i, j ∈ {1, . . . , n} ist der Eintrag aij genau dann 1, wenn E die Kante (vi, vj) enth¨alt. Ungerichtete Graphen k¨onnen nat¨urlich analog repr¨asentiert werden: Enth¨alt E eine 5.1 Grundlagen 101      0 1 1 1 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 1 0 1  | | |  Abb. 5.5 Ein gerichteter Graph mit n = 5 Knoten (links), sowie seine Darstellung als Adjazenzliste (Mitte) und als Adjazenzmatrix (rechts). Die Knoten in den einzelnen Listen k¨onnen, m¨ussen aber nicht nach dem Index der Nachfolgerknoten aufsteigend sortiert sein. Kante {vi, vj}, dann haben in der Adjazenzmatrix beide Eintr¨age aij und aji den Wert 1, sonst 0. Hat ein Graph (gerichtet oder ungerichtet) eine Schleife um einen Knoten vi, dann enth¨alt der i-te Diagonaleintrag (also aii) der Adjazenzmatrix ei- ne 1. Die Adjazenzmatrix ben¨otigt oﬀenbar Platz Θ(|V |2), da sie |V |2 Eintr¨age hat Platzbedarf und pro Eintrag genau ein Bit ben¨otigt wird. Wir haben bereits fr¨uher die Berechnung von k¨urzesten Wegen in Strassennet- zen als Anwendung f¨ur Graphen genannt. Strassennetze haben aber die Eigenschaft, dass zu einer Kreuzung (Knoten) oftmals verh¨altnism¨assig wenige Strassen (Kanten) f¨uhren, meist vier oder weniger. Reale Strassennetze (etwa von Kontinentaleuropa) haben aber oft mehrere Millionen Knoten. Das bedeutet also: Wird ein Strassennetz durch eine Adjazenzmatrix repr¨asentiert, dann hat jede Zeile (die die Nachbarn des entsprechenden Knotens codiert) h¨ochstens vier oder f¨unf Einsen, aber mehrere Mil- lionen Nullen. Oﬀenbar wird hier also sehr viel Platz verschenkt. Zum Gl¨uck gibt es eine weitere Art, Graphen zu repr¨asentieren, n¨amlich die sog. Adjazenzlisten- Adjazenzliste darstellung. Eine Adjazenzliste besteht aus einem Array (A[1], . . . , A[n]), wobei der Eintrag A[i] eine einfach verkettete Liste aller Knoten in N +(v) (bzw. deren Indizes) enth¨alt. Die Reihenfolge, in der die in A[i] gespeicherte Liste die Nachfolger von vi (bzw. deren Indizes) enth¨alt, ist beliebig. Sie muss also insbesondere nicht nach Index aufsteigend sortiert sein. Die Adjazenzlistendarstellung ben¨otigt Platz Θ(|V | + |E|), Platzbedarf denn das Array besitzt |V | Pl¨atze, und die die Listen enthalten insgesamt |E| Listen- elemente. Ist der Graph nur d¨unn besetzt, zum Beispiel wenn |E| ∈ O(|V |) ist (was zum Beispiel f¨ur Graphen zur Modellierung von Strassennetzen erf¨ullt ist), dann ben¨otigt die Adjazenzliste deutlich weniger Platz als die Adjazenzmatrix. Adjazenzmatrizen und -listen unterst¨utzen verschiedene Operationen unterschied- lich gut. Tabelle 5.6 zeigt eine ¨Ubersicht. Alle Nachbarn von v ∈ V ermitteln Θ(n) Θ(deg+(v)) Finde v ∈ V ohne Nachbar O(n2) O(n) Ist (u, v) ∈ E? O(1) O(deg+(v)) Kante einf¨ugen O(1) O(1) Kante l¨oschen O(1) O(deg+(v)) Abb. 5.6 Operationen und ihre Laufzeiten auf Adjazenzmatrizen und -listen. 102 Graphenalgorithmen 5.1.4 Beziehung zur Linearen Algebra Betrachten wir noch einmal die Adjazenzmatrix des in Abbildung 5.5 dargestellten Graphen und quadrieren wir sie, dann erhalten wir die Matrix B := A2 G =       0 1 0 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 1 1 2  | | | |  (106) Wie kann diese anschaulich interpretiert werden? Ein Eintrag bij dieser Matrix wird durch bij = ∑n k=1 aik · akj berechnet. Wir beobachten nun, dass das Produkt aik · akj entweder 0 oder 1 ist, und es ist genau dann 1, wenn sowohl (vi, vk) ∈ E als auch (vk, vj) ∈ E sind. Das heisst also, bij z¨ahlt die Anzahl der Wege der L¨ange 2 von i nach j. Wir k¨onnen die Aussage sogar auf At G f¨ur beliebige t ∈ N verallgemeinern, wie das folgende Theorem zeigt: Theorem 5.4. Sei G ein Graph (gerichtet oder ungerichtet) und t ∈ N beliebig.Anzahl Wege der L¨ange t Das Element an der Position (i, j) in der Matrix At G gibt die Anzahl der Wege der L¨ange t von vi nach vj an. Beweis. Wir beweisen die Aussage durch vollst¨andige Induktion ¨uber t. Induktionsanfang (t = 1): Die Adjazenzmatrix AG = A1 G enth¨alt die An- zahl der Wege der L¨ange 1. Zwischen zwei Knoten gibt es entweder einen Weg der L¨ange 1 (wenn die entsprechende Kante existiert), und keinen sonst. Induktionshypothese: Angenommen, in At G gibt jeder Eintrag (i, j) die Anzahl der Wege der L¨ange t von vi nach vj an. Induktionsschritt (t → t + 1): Sei B = (bij)1≤i,j≤n := At G. Betrachte nun C = (cij)1≤i,j≤n := At+1 G = B × AG. F¨ur einen Eintrag cij gilt cij = n∑ k=1 bik · akj. (107) Dabei z¨ahlt bik gem¨ass Induktionshypothese die Anzahl der Wege von vi nach vk der L¨ange t. Ausserdem ist akj entweder 0 oder 1, und 1 genau dann, wenn eine Kante (also ein Weg der L¨ange 1) von vk nach vj existiert. Das heisst, die Anzahl der Wege von vi nach vj ¨uber den Zwischenknoten vk ist genau bik, falls (vk, vj) existiert, und 0 sonst. Da die Summe ¨uber alle m¨oglichen Zwischenknoten vk gebildet wird, gibt cij also korrekt die Anzahl der Wege von vi nach vj der L¨ange t + 1 an. Um in einem Graphen den k¨urzesten Weg (mit einer minimalen Anzahl von Kanten)Anwendungen zwischen zwei gegebenen Knoten vi und vj zu bestimmen, gen¨ugt es also oﬀenbar, AG zu potenzieren, bis zum ersten Mal der Eintrag an der Position (i, j) ungleich Null ist. Da ein k¨urzester Weg oﬀenbar keinen Knoten mehrfach benutzt und damit h¨ochstens L¨ange n − 1 hat, reicht eine Potenzierung bis n aus; enth¨alt die Position (i, j) dann noch immer keine Eins, dann gibt es keinen Weg von vi nach vj. 5.1 Grundlagen 103 Eine andere Anwendung besteht in der Berechnung der Anzahl von Dreiecken in ungerichteten Graphen. Ein Dreieck ist eine Menge D von drei Knoten, wobei Dreieck zwischen jedem Paar zweier Knoten in D eine Kante verl¨auft. Um f¨ur einen gegebe- nen ungerichteten Graphen G die Anzahl der Dreiecke zu bestimmen, entfernen wir zun¨achst alle Schleifen von G, indem wir die Diagonaleintr¨age in AG auf 0 setzen. Danach berechnen wir die Matrix B = (bij)1≤i,j≤n := A3 G (dazu gen¨ugen zwei Ma- trixmultiplikationen). Ein Eintrag bii gibt nun an, wie viele Wege der L¨ange 3 von vi nach vi existieren, d.h., er z¨ahlt die Anzahl der Dreiecke in denen vi enthalten ist. Da jedes Dreieck irgendeinen Knoten des Graphen enth¨alt und auf sechs ver- schiedene Arten gez¨ahlt werden wird (⟨x, y, z, x⟩, ⟨x, z, y, x⟩, ⟨y, z, x, y⟩, ⟨y, x, z, y⟩, ⟨z, x, y, z⟩, ⟨z, y, x, z⟩), betr¨agt die Anzahl der Dreiecke exakt (∑n i=1 bii)/6. Als Bei- spiel betrachten wir den folgenden Graph: AG =     0 1 1 0 1 0 1 0 1 1 1 1 0 0 1 0  | |  Nach Entfernung der Schleifen ergeben sich die neue Adjazenzmatrix bzw. ihre dritte Potenz ¯AG =     0 1 1 0 1 0 1 0 1 1 0 1 0 0 1 0  | |  bzw. B = ¯A3 G =     2 3 4 1 2 2 4 1 4 4 2 3 1 1 3 0  | |  . Oﬀenbar hat G genau ein Dreieck (n¨amlich die Menge {v1, v2, v3}), und die Summe der Diagonaleintr¨age in B ist genau 6. 5.1.5 Beziehung zu Relationen Einen Graphen G = (V, E) k¨onnen wir auch als Relation E ⊆ V × V auf V auf- fassen, und umgekehrt. Sei wie zuvor AG = (aij)1≤i,j≤n die Adjazenzmatrix von G. Konzepte von Relationen k¨onnen wie folgt auf Graphen ¨ubertragen werden: • E ist genau dann reﬂexiv, wenn E jede Kante (v, v) mit v ∈ V enth¨alt, G also Reflexivit¨at eine Schleife um jeden Knoten v ∈ V hat. Dies ist genau dann der Fall, wenn aii = 1 f¨ur alle i ∈ {1, . . . , n} ist. • E ist genau dann symmetrisch, wenn f¨ur alle (v, w) ∈ E auch (w, v) ∈ E gilt, Symmetrie d.h. G ungerichtet ist. • E ist genau dann transitiv, wenn f¨ur jedes Paar zweier Kanten (u, v) ∈ E und Transitivit¨at (v, w) ∈ E auch (u, w) ∈ E ist. Eine ¨Aquivalenzrelation erf¨ullt bekanntermassen alle drei obigen Eigenschaften. Folg- lich ist der Graph zu einer ¨Aquivalenzrelation eine Kollektion vollst¨andiger, unge- richteter Graphen, wobei jeder Knoten eine Schleife hat. Die reﬂexive und transitive H¨ulle eines Graphens G = (V, E) beschreibt die sog. Erreichbarkeitsrelation E∗. Dies ist eine zweistellige Relation, die ein Paar (v, w) Erreichbarkeits- relationgenau dann enth¨alt, wenn es in G einen Weg vom Knoten v zum Knoten w gibt. 104 Graphenalgorithmen 5.1.6 Berechnung der reﬂexiven und transitiven H¨ulle Gegeben sei ein gerichteter oder ungerichteter Graph G = (V, E) durch seine Ad- jazenzmatrix AG = (aij)1≤i,j≤n. Wir wollen nun die reﬂexive und transitive H¨ulle von G als Matrix berechnen. Das Ziel ist also die Berechnung einer Matrix B = (bij)1≤i,j≤n, wobei bij genau dann den Wert 1 annimmt, wenn (vi, vj) ∈ E∗ ist (und 0 sonst). Unser Algorithmus darf in-place arbeiten, d.h. er darf die Matrix A ¨uber-in-place schreiben, sodass am Ende an ihrer Stelle B steht. Wir beobachten, dass es niemals n¨otig ist, eine 1 zu ¨uberschreiben, da eine 1 an einer Position (i, j) signalisiert, dass es (irgendeinen) Weg von vi nach vj gibt. Nur Nullen m¨ussen ¨uberschrieben wer- den, und zwar genau dann, wenn ein Weg zwischen zwei Knoten gefunden wird und bisher nicht bekannt war, dass zwischen ihnen ein Weg verl¨auft. Um nun Wege der L¨ange 2 zu ﬁnden, k¨onnen wir ¨uber alle i, j, k ∈ {1, . . . , n}Erste Idee iterieren und aij ← 1 setzen, wenn sowohl aik = 1 als auch akj = 1 sind. Zus¨atzlich setzen wir nat¨urlich aii ← 1 f¨ur alle i ∈ {1, . . . , n}, da die H¨ulle ja auch reﬂexiv sein soll. Nach diesen Schritten codiert die Matrix bereits alle Wege der L¨angen 1 und 2. F¨uhren wir dieses Verfahren erneut aus, wurden alle Wege der L¨ange h¨ochstens 4 gefunden, bei einer weiteren Ausf¨uhrung alle Wege der L¨ange h¨ochstens 8, usw. Daher reichen ⌈log2 n⌉ viele Ausf¨uhrungen, um alle Wege zu ﬁnden. Tats¨achlich reicht sogar eine einzige Ausf¨uhrung, wenn wir sicherstellen k¨onnen,Verbesserung dass sowohl aik als auch akj bereits ihren entg¨ultigen Wert enthalten (also 1, falls es irgendeinen Weg von vi nach vk bzw. von vk nach vj gibt, und 0 sonst). Wars- hall beobachtete nun, dass es ausreicht, die Wege in der Reihenfolge des gr¨ossten Zwischenknotens vk zu berechnen, was der folgende Algorithmus tut: ReflexiveTransitiveHull(A)Reflexive und transitive H¨ulle 1 for k ← 1, . . . , n do 2 akk ← 1 ▷ Reﬂexive H¨ulle 3 for i ← 1, . . . , n do 4 for j ← 1, . . . , n do 5 if aik = 1 and akj = 1 then aij ← 1 ▷ Berechne Weg ¨uber vk Die Laufzeit dieses Algorithmus ist oﬀenbar in Θ(n3). Die Korrektheit weisen wirLaufzeit induktiv nach, dass in der ¨ausseren Schleife die folgende Invariante stets erf¨ullt bleibt: Alle Wege, bei denen der gr¨osste Zwischenknoten (und damit alle Zwischenknoten) einen Index < k hat, wurden ber¨ucksichtigt. Induktionsanfang (k = 1): Alle direkten Wege ohne Zwischenknoten (dies entspricht allen Kanten) sind bereits in AG enthalten. Induktionshypothese: Sei die obige Invariante vor dem k-ten Schleifendurchlauf wahr, d.h. alle Wege, bei denen der gr¨osste Zwischenknoten einen Index < k hat, wurden ber¨ucksichtigt. Induktionsschritt (k → k + 1): Betrachte nun den k-ten Schleifendurchlauf sowie ei- nen beliebigen Weg von einem Knoten vi zu einem Knoten vj, dessen gr¨osster Zwischenknoten den Index k hat. Wir m¨ussen zeigen, dass der Algorithmus dann tats¨achlich aij ← 1 setzt. Dies ist der Fall, denn nach Induktionshypo- these haben sowohl aik als auch akj den Wert 1 (da k der gr¨osste Index eines 5.2 Durchlaufen von Graphen 105 Zwischenknotens auf einem Weg von vi nach vj ist, m¨ussen die Zwischenknoten auf den Wegen von vi nach vk bzw. von vk nach vj entsprechend kleinere Indizes haben). Daher setzt der Algorithmus in Schritt 5 auch tats¨achlich aij ← 1, und da auf diese Weise alle Wege gefunden werden, deren gr¨osster Zwischenknoten den Index k hat, bleibt die Invariante erhalten. 5.2 Durchlaufen von Graphen Wir untersuchen jetzt, wie die Knoten eines Graphen in systematischer Art und Weise besucht werden k¨onnen. Obwohl die Fragestellung vielleicht k¨unstlich erschei- nen mag, so hat sie dennoch viele Anwendungen, zum Beispiel, aus einem gegebenen Labyrinth herauszuﬁnden; oftmals werden solche Knotendurchl¨aufe auch als Teilrou- tine zum Erkundschaften der Struktur eines Graphen benutzt. Wir werden sp¨ater auch noch sehen, wie einer beiden im Folgenden vorgestellten Algorithmen erweitert werden kann, um einen Weg mit minimalem Gesamtgewicht in einem gewichteten Graphen (der z.B. ein Strassennetz o.¨a. modellieren k¨onnte) zu berechnen. F¨ur dieses und die folgenden Abschnitte nehmen wir an, dass der Graph als eine Adjazenzliste und nicht als Adjazenzmatrix gespeichert ist. 5.2.1 Tiefensuche Rekursiver Algorithmus Die Idee bei der Tiefensuche ist es, bei einem Knoten zu Idee starten und dann so lange einem dort startenden Pfad zu folgen, bis man nur noch bereits besuchte Knoten ﬁndet. Erst dann geht man einen Schritt (d.h., eine Kante) zur¨uck und versucht dort, den Pfad zu erweitern. Ist dies ebenfalls nicht m¨oglich, weil man alle m¨oglichen Knoten ebenfalls bereits fr¨uher besucht hat, dann geht man einen weiteren Schritt zur¨uck. Aus diesem Vorgehen resultiert auch der Name Tiefensuche (engl. Depth First Search, kurz DFS): Man verfolgt einen Pfad in die Tiefe, bis er nicht mehr erweitert werden kann. Wir markieren also stets den aktuell besuchten Knoten als besucht, iterieren ¨uber alle Nachfolger und setzen die Tiefensuche rekursiv bei genau den Nachfolgerknoten fort, die noch nie besucht wurden. Eine Tiefensuche in einem Graphen G = (V, E), die bei einem Knoten v ∈ V startet, kann wie folgt formuliert werden. DFS-Visit(G, v) Tiefensuche 1 Markiere v als besucht 2 for each (v, w) ∈ E do 3 if w ist noch nicht besucht then 4 DFS-Visit(G, w) Oﬀenbar besucht dieser Algorithmus u.U. nicht alle Knoten des Graphen, n¨amlich genau dann, wenn nicht jeder Knoten von v aus erreichbar ist. Wenn so etwas pas- siert, dann starten wir die Suche einfach bei einem noch nie besuchten Knoten neu. Wir erhalten also folgendes Rahmenprogramm. 106 Graphenalgorithmen DFS(G)Rahmen- programm 1 for each v ∈ V do 2 if v ist noch nicht besucht then 3 DFS-Visit(G, v) Man beachte, dass die Reihenfolge, in der die Algorithmen die Knoten aus V (in DFS) bzw. die Nachfolger von v (in DFS-Visit) nicht festgelegt ist. ¨Ublicherweise wird die von der Adjazenzlistendarstellung implizit vorgegebene Reihenfolge be- nutzt. Dies bedeutet insbesondere, dass die Nachfolger eines Knotens genau dann in alphabetischer Reihenfolge abgearbeitet werden, wenn sie in der Adjazenzliste in alphabetischer Reihenfolge vorkommen, was aber nicht unbedingt der Fall sein muss. Laufzeit Um die Laufzeit der Tiefensuche zu bestimmen, beobachten wir zun¨achst,Laufzeit dass DFS-Visit f¨ur jeden Knoten v ∈ V genau einmal aufgerufen wird, denn jeder Knoten v wird beim ersten Aufruf von DFS-Visit(G, v) als besucht markiert, und vor jedem Aufruf von DFS-Visit (Schritt 3 in DFS-Visit bzw. Schritt 2 im DFS- Rahmenprogramm) wird gepr¨uft, ob der entsprechende Knoten schon fr¨uher besucht wurde. Also braucht DFS(G) ohne die Aufrufe von DFS-Visit(G, v) Zeit Θ(n). InRahmen programm DFS-Visit(G, v) f¨allt ohne die rekursiven Aufrufe Zeit a deg+(v) + c (f¨ur geeignet gew¨ahlte Konstanten a, c ∈ R+) an, denn das Markieren kostet konstante Zeit und danach wird f¨ur alle Nachfolger w von v in konstanter Zeit gepr¨uft, ob w schon fr¨uher besucht wurde. Damit betr¨agt die Gesamtlaufzeit einer Tiefensuche genauGesamtlaufzeit Θ(|V | + ∑ v∈V (deg+(v) + 1)) = Θ(|V | + |E| + |V |) = Θ(|V | + |E|), was linear in der Eingabegr¨osse ist. Beispiel Abbildung 5.7 zeigt das Ergebnis einer Tiefensuche auf einem Beispiel- graphen. F¨ur unser Beispiel nehmen wir an, dass alle Schleifen die entsprechenden Knoten stets in alphabetisch aufsteigender Reihenfolge betrachten. Der erste be- trachtete Knoten ist damit a, und von dort ausgehend werden zun¨achst b, c und f entdeckt. Von f gibt es keine ausgehenden Kanten, also wird die Tiefensuche bei c fortgesetzt. Dort gibt es ebenfalls keine weiteren unentdeckten Nachbarn, weswegen die Tiefensuche zuerst bei b und dann bei a fortgesetzt wird. Von dort aus werden noch die Knoten d und e entdeckt, danach gibt es keine Knoten mehr, die von a aus erreichbar sind. Daher wird die Tiefensuche bei g neu gestartet (g ist der alphabe- tisch kleinste Knoten, der noch nicht besucht wurde), und von dort aus werden noch die Knoten h und i entdeckt. Iterativer Algorithmus Die zuvor gezeigte rekursive Formulierung der Tiefensuche wird in einer praktischen Implementierung schnell an ihre Grenzen stossen, wenn sie auf einem sehr grossen Graphen (mit mehreren Millionen Knoten) eingesetzt werden soll. Wir k¨onnen die Rekursion aber vermeiden, indem wir einen Stapel benutzen. In jedem Schritt nehmen wir den obersten Knoten v vom Stapel und gehen wie zuvor die Nachfolger von v durch (diesmal aber in umgekehrter Reihenfolge); wurde ein Nachfolger noch nie besucht, wird er auf den Stapel gelegt. Damit erhalten wir den folgenden Algorithmus. 5.2 Durchlaufen von Graphen 107 Abb. 5.7 Eine Tiefensuche auf dem dargestellten Graphen. Die blauen Zahlen neben jedem Knoten geben an, zu welchem Zeitpunkt ein Knoten erstmals entdeckt wird. Die Reihenfolge, in der die Knoten entdeckt werden, ist also a, b, c, f, d, e, g, h, i. Bei g ﬁndet ein Neustart statt, da dieser Knoten von a aus nicht erreicht werden kann. DFS-Visit-Iterative(G, v) Iterative Tiefensuche 1 S ← ∅ ▷ Initialisiere leeren Stapel S 2 Push(v, S) ▷ Leg v oben auf S 3 while S ̸= ∅ do 4 w ← Pop(S) ▷ Aktueller Knoten 5 if w noch nicht besucht then 6 Markiere w als besucht 7 for each (w, x) ∈ E in reverse order do 8 if x noch nicht besucht then 9 Push(x, S) ▷ Leg x oben auf S Man sieht leicht, dass die Laufzeit noch immer in Θ(|V | + |E|) liegt: Jeder Knoten w Laufzeit wird h¨ochstens einmal als besucht markiert (genau dann, wenn er vom Startknoten v aus erreichbar ist), und nur dann, wenn er besucht wird, f¨allt ein Extraaufwand von Θ(deg+(w) + 1) an. Der Stapel kann insgesamt bis zu |E| viele Elemente enthalten, also ist die Gesamtlaufzeit in O(|V | + |E| + ∑ w∈V (deg+(w) + 1)) = O(|V | + |E|). Wird die Methode DFS-Visit-Iterative aus dem DFS-Rahmenprogramm heraus aufgerufen (anstelle von DFS-Visit), dann ist die Laufzeit insgesamt wieder in Θ(|V | + |E|). Ein Wermutstropfen der obigen iterativen Formulierung ist, dass im Extraplatz schlimmsten Fall tats¨achlich Platz Θ(|E|) ben¨otigt wird. Ein solcher Fall tritt zum Beispiel dann ein, wenn der Algorithmus auf einem vollst¨andigen Graphen aufgerufen wird. Die rekursive Formulierung ben¨otigt niemals mehr als Θ(|V |) viel Extraplatz, da die Rekursionstiefe durch |V | nach oben beschr¨ankt ist und pro rekursivem Auf- ruf nur konstant viel Extraplatz ben¨otigt wird. Der obige Algorithmus kann aber Verbesserung so modiﬁziert werden, dass der Extraspeicher nur h¨ochstens Θ(|V |) statt Θ(|E|) betr¨agt. Dazu legen wir nicht die entsprechenden Nachfolgerknoten auf den Spei- cher, sondern nur diejenigen Knoten, die bereits besucht aber noch nicht komplett abgearbeitet wurden, und speichern f¨ur jeden solchen Knoten auch einen Verweis auf den n¨achsten dort zu besuchenden Nachfolger (z.B. durch einen Zeiger auf den entsprechenden Knoten in der Adjazenzliste). Diese Modiﬁkation ist nicht schwierig, aber recht technisch, weswegen sie im Folgenden nicht weiter diskutiert wird. 108 Graphenalgorithmen Abb. 5.8 Eine Breitensuche auf dem dargestellten Graphen. Die blauen Zahlen neben jedem Knoten geben an, zu welchem Zeitpunkt ein Knoten erstmals entdeckt wird. Die Reihenfolge, in der die Knoten entdeckt werden, ist also a, b, d, e, c, f, g, h, i. Bei g ﬁndet ein Neustart statt, da dieser Knoten von a aus nicht erreicht werden kann. 5.2.2 Breitensuche Anstatt einen Pfad in die Tiefe zu verfolgen, k¨onnten wir auch zuerst alle Nachfolger eines Knotens abarbeiten, dann alle Nachfolger dieser Nachfolger usw. Diese Idee wird von der Breitensuche aufgegriﬀen. Abbildung 5.8 zeigt noch einmal den zuvorBreitensuche gezeigten Graphen und zeigt auch, in welcher Reihenfolge eine Breitensuche die Knoten betrachtet, wenn (wie zuvor) die Nachfolger eines Knotens in alphabetisch aufsteigender Reihenfolge bearbeitet werden. Algorithmisch k¨onnen wir analog zur iterativen Tiefensuche vorgehen. Wir stellen jetzt aber direkt eine Variante vor, die mit O(|V |) Extraplatz auskommt. Dazu wird der Stapel durch eine Schlange ersetzt, und damit ein Knoten nicht mehrfach in die Schlange aufgenommen wird, markieren wir ihn als “aktiv”, sobald er das erste Mal aufgenommen wurde. Ist ein Knoten abgearbeitet, wird er wie bisher als “besucht” markiert (die Markierung ist nicht unbedingt notwendig und dient nur der besseren Unterscheidbarkeit zu aktiven Knoten). Man ¨uberlege sich als Hausaufgabe, warum ein solcher einfacher Trick bei der iterativen Tiefensuche nicht funktioniert. BFS-Visit-Iterative(G, v)Iterative Breitensuche 1 Q ← ∅ ▷ Initialisiere leere Schlange Q 2 Markiere v als aktiv 3 Enqueue(v, Q) ▷ F¨uge v zur Schlange Q hinzu 4 while Q ̸= ∅ do 5 w ← Dequeue(Q) ▷ Aktueller Knoten 6 Markiere w als besucht 7 for each (w, x) ∈ E do 8 if x nicht aktiv und x noch nicht besucht then 9 Markiere x als aktiv 10 Enqueue(x, Q) ▷ F¨uge x zur Schlange Q hinzu 5.3 Zusammenhangskomponenten 109 Abb. 5.9 Ein ungerichteter Graph mit zwei Zusammenhangskomponenten. Diese k¨onnen durch die Knotenmengen V1 = {a, b, c, d} und V2 = {e, f } eindeutig beschrieben werden. Als Rahmenprogramm f¨ur die Breitensuche kann das gleiche wie das zur Tiefen- Rahmen- programmsuche benutzt werden, lediglich der Aufruf DFS-Visit(G, v) muss durch BFS-Visit- Iterative(G, v) ersetzt werden. Die Laufzeit der Breitensuche ist in Θ(|V | + |E|), Laufzeit denn jeder Knoten wird genau einmal als aktiv markiert und in die Schlange aufge- nommen, und wird er der Schlange entnommen, werden genau Θ(deg+(v) + 1) viele Operationen ausgef¨uhrt. Da jeder Knoten niemals mehr als einmal in die Schlange Extraplatz aufgenommen wird, ist der Platzbedarf durch O(|V |) nach oben beschr¨ankt. 5.3 Zusammenhangskomponenten Gegeben sei ein ungerichteter Graph G = (V, E). Das Ziel dieses Abschnitts besteht in der Berechnung der Zusammenhangskomponenten von G. Diese sind genau die Zusammenhangs- komponente¨Aquivalenzklassen der reﬂexiven und transitiven H¨ulle von G (siehe Abbildung 5.9). Eine Zusammenhangskomponente ist damit ein Teilgraph G′ = (V ′, E′) von G, wo- bei E′ = {{v, w} ∈ E | v, w ∈ V ′} ist, und in E (also im gegebenen Graphen) keine Kante existiert, die genau einen Knoten in V ′ und einen Knoten in V \\V ′ hat. Eine Zusammenhangskomponente mit der Knotenmenge V ′ enth¨alt also alle Kan- ten zwischen zwei Knoten aus V ′, die auch der gegebene Graph G enth¨alt, und von einer Zusammenhangskomponente f¨uhrt keine Kante zu irgendeiner anderen Zu- sammenhangskomponente. Folglich ist eine Zusammenhangskomponente eindeutig Charakteri- sierungdurch ihre Knoten v ∈ V ′ festgelegt. Sollen alle Zusammenhangskomponenten eines gegebenen ungerichteten Graphen G = (V, E) bestimmt werden, dann gen¨ugt es, ei- ne Partitionierung von V (also eine Zerlegung von V in paarweise disjunkte Mengen V1, . . . , Vk) zu berechnen, wobei Vi die Knoten einer Zusammenhangskomponente enth¨alt (und f¨ur jede Kante in E beide Knoten in der gleichen Menge Vi liegen). Um eine solche Partitionierung zu berechnen, kann einfach der Algorithmus Berechnung zur Tiefensuche modiﬁziert werden. Ein Knoten kommt in die gleiche Zusammen- hangskomponente wie sein Vorg¨anger; jedes Mal, wenn die Tiefensuche neu beginnt (im Rahmenprogramm) wird eine neue, leere Zusammenhangskomponente erzeugt. Nat¨urlich kann auch eine Breitensuche zur Berechnung der Zusammenhangskompo- nenten benutzt werden. Die Laufzeit des so erhaltenen Verfahrens ist in Θ(|V |+|E|). Wir beobachten, dass die Anzahl der ¨Aquivalenzklassen exakt der Anzahl der Neustarts im DFS- oder BFS-Rahmenprogramm entspricht. Ebenso h¨atten wir statt einer Tiefen- oder Breitensuche auch Warshalls Algorithmus benutzen k¨onnen, dieser hat aber eine erheblich schlechtere Laufzeit von Θ(|V |3). 110 Graphenalgorithmen (a) (b) Abb. 5.10 Der Graph K6 auf der linken Seite (a) kann nicht topologisch sortiert werden. Dagegen ist der Graph auf der rechten Seite (b) kreisfrei und besitzt daher eine topologische Sortierung. 5.4 Topologische Sortierung Gegeben seien eine Menge von Aufgaben A1, . . . , An, von denen einige bereits er-Motivation ledigt sein m¨ussen, bevor andere Aufgaben begonnen werden k¨onnen. Sind etwa Ai = “Socken anziehen” und Aj = “Schuhe anziehen”, dann muss oﬀenbar Ai vor Aj erledigt werden. Gesucht ist eine Reihenfolge, in der die Aufgaben abgearbeitet werden k¨onnen, sodass jedes Mal, wenn eine Aufgabe Aj begonnen wird, alle f¨ur diese Aufgabe vorausgesetzten Aufgaben Ai bereits erledigt wurden. Das Problem kann formal durch einen gerichteten Graphen G = (V, E) mo-Modellierung delliert werden, der f¨ur jede Aufgabe Ai genau einen Knoten enth¨alt, und f¨ur jede Aufgabe Ai, die vor einer Aufgabe Aj erledigt sein muss, eine Kante (Ai, Aj) enth¨alt. Gesucht wird eine bijektive Abbildung ord : V → {1, . . . , |V |} mit ord(v) < ord(w)Topologische Sortierung f¨ur alle (v, w) ∈ E. Eine solche Abbildung heisst topologische Sortierung von G. Setzen wir vi = ord −1(i) f¨ur i = 1, . . . , |V |, dann k¨onnen wir eine topologische Sortierung auch kompakter durch die Sequenz ⟨v1, . . . , v|V |⟩ repr¨asentieren. Man be- achte, dass die Berechnung einer topologischen Sortierung trotz des gleichen Namens ein anderes Problem als die Sortierung einer Menge von Zahlen ist. Beispiel. Nicht f¨ur jeden Graphen kann eine topologische Sortierung angegeben wer-Beispiel den, wie etwa der Graph mit den Knoten v1 und v2 sowie den Kanten (v1, v2) und (v2, v1) zeigt. Das Beispiel kann auf Kreise beliebiger Gr¨osse verallgemeinert werden. Seien Vn = {v1, . . . , vn} und En = {(vi, vi+1) | i ∈ {1, . . . , n − 1}} ∪ {(vn, v1)}. Der Graph Kn = (Vn, En) (siehe Abbildung 5.10(a)) besitzt keine topologische Sortierung. Sei o.B.d.A. v1 der Knoten mit ord(v1) = 1. Damit ord eine g¨ultige topologische Sor- tierung ist, muss der Wert von ord entlang des Pfades ⟨v1, . . . , vn⟩ wachsen. Folglich ist ord(vn) > 1. Nun ist aber (vn, v1) ∈ En mit ord(vn) ̸< ord(v1), also besitzt Kn keine topologische Sortierung. Der in Abbildung 5.10(b) dargestellte Graph dagegen ist topologisch sortierbar. Er besitzt sogar zwei topologische Sortierungen, denn sowohl ⟨v1, v2, v3, v4, v6, v5⟩ als auch ⟨v1, v3, v2, v4, v6, v5⟩ sind topologische Sortierungen dieses Graphen. Das vorige Beispiel zeigte bereits, dass eine topologische Sortierung weder f¨ur jeden Graphen existiert, noch eindeutig bestimmt ist. Zur Charakterisierung topo- logisch sortierbarer Graphen zeigen wir nun das folgende Theorem. 5.4 Topologische Sortierung 111 Theorem 5.5. Ein gerichteter Graph G = (V, E) besitzt genau dann eine topologische Existenz einer topologischer Sortierung Sortierung, wenn er kreisfrei ist. Beweis. Enth¨alt G einen Kreis, dann besitzt er oﬀenbar keine topolo- gische Sortierung. Wir zeigen nun durch Induktion ¨uber die Knotenan- zahl n, dass ein Graph topologisch sortiert kann, wenn er kreisfrei ist. Induktionsanfang (n = 1): Ein Graph mit genau einem Knoten v ist to- pologisch sortierbar, wenn er kreisfrei ist, d.h., keine Schleife besitzt. Setzt man ord(v) ← 1, dann erh¨alt man eine topologische Sortie- rung f¨ur einen kreisfreien Graphen mit einem Knoten. Induktionshypothese: Angenommen, jeder kreisfreier Graph mit n Kno- ten besitzt eine topologische Sortierung. Induktionsschritt (n → n + 1): Sei G ein Graph mit n + 1 Knoten. Wir ¨uberlegen zun¨achst, dass G mindestens einen Knoten v0 mit Ein- gangsgrad 0 besitzt. W¨are dies n¨amlich nicht der Fall, dann k¨onnten wir bei einem Knoten starten und r¨uckw¨arts laufen (indem wir ei- ner eingehenden Kante zum Vorg¨anger folgen), und nach sp¨atestens n + 1 Schritten h¨atten wir einen Knoten gefunden, den wir schon fr¨uher besucht haben. Damit w¨are der Graph also nicht kreisfrei. Wir entfernen nun v0 sowie alle von v0 ausgehenden Kanten aus G. Der so entstandene Graph G′ = (V ′, E′) hat |V ′| = n Knoten, ist noch immer kreisfrei (denn durch die Entfernung eines Knotens k¨onnen keine Kreise entstehen) und besitzt daher gem¨ass Indukti- onshypothese eine topologische Sortierung ord′ : V ′ → {1, . . . , n}. Setzen wir nun ord(v0) ← 1 sowie ord(v) ← ord ′(v) + 1 f¨ur alle v ∈ V ′, dann ist ord eine topologische Sortierung f¨ur G, denn f¨ur alle Kanten (v0, w) ist ord(v0) = 1 < ord(w), und f¨ur alle Kanten (v, w) mit v ̸= v0 ist nach Induktionshypothese ord ′(v) < ord ′(w), folglich also auch ord(v) < ord(w). Der Beweis des vorigen Theorems liefert eine Idee f¨ur einen Algorithmus zur Be- Idee f¨ur Algorithmusrechnung einer topologischen Sortierung eines gerichteten kreisfreien Graphen G: Wir suchen einen Knoten v0 mit Eingangsgrad 0 und geben v0 aus. Danach entfer- nen wir v0 sowie alle von v0 ausgehenden Kanten aus G und wenden das Verfahren rekursiv auf dem verbleibenden Graphen an, bis dieser entweder ¨uberhaupt keine oder keine Knoten mit Eingangsgrad 0 mehr besitzt. Im ersten Fall h¨atten wir eine topologische Sortierung gefunden, im zweiten Fall h¨atten wir einen Kreis gefunden und es g¨abe keine topologische Sortierung. Das Problem dieses Algorithmus besteht in der Laufzeit: Zum Finden eines Knotens mit Eingangsgrad 0 k¨onnen wir bei einem beliebigen Knoten von G starten und jeweils den eingehenden Kanten r¨uckw¨arts fol- gen, bis ein geeigneter Kandidat gefunden wird. Im schlimmsten Fall m¨ussen wir aber den ganzen Graphen r¨uckw¨arts entlanglaufen und ben¨otigen Ω(|V |) Schritte, was zu einem Algorithmus mit Laufzeit Ω(|V |2) f¨uhrt. Die Idee zur Verbesserung besteht nun darin, die Eingangsgrade aller Knoten Verbesserte Ideeim Voraus zu berechnen und in einem Array A zu speichern, und alle Knoten mit Eingangsgrad 0 auf einen Stapel S zu legen. Danach entfernen wir den obersten Knoten v von S, geben v aus (bzw. ordnen v seine korrekte Position in der topo- logischen Sortierung zu) und dekrementieren den Eingangsgrad aller Knoten w mit 112 Graphenalgorithmen (v, w) ∈ E. Falls dabei ein Knoten mit einem neuen Eingangsgrad von 0 entdeckt wird, so wird dieser auf S gelegt. Dieses Verfahren wird wiederholt, bis S leer ist. Toplogical-Sort(V, E)Algorithmus 1 S ← EmptyStack ▷ Stapel S initialisieren 2 for each v ∈ V do A[v] ← 0 3 for each (v, w) ∈ E do A[w] ← A[w] + 1 ▷ Berechne Eingangsgrade 4 for each v ∈ V do ▷ Lege Knoten mit Eingangs- 5 if A[v] = 0 then Push(v, S) ▷ grad 0 auf den Stapel S 6 i ← 1 7 while S not empty do 8 v ← Pop(S) ▷ Knoten mit Eingangsgrad 0 9 ord[v] ← i; i ← i + 1 ▷ Weise korrekte Position zu 10 for each (v, w) ∈ E do ▷ Verringere Eingangsgrad 11 A[w] ← A[w] − 1 ▷ der Nachfolger 12 if A[w] = 0 then Push(w, S) 13 if i = |V | + 1 then return ord else “Graph enth¨alt einen Kreis” Theorem 5.6. Sei G = (V, E) ein gerichteter kreisfreier Graph. Der AlgorithmusLaufzeit und Korrektheit, Teil I Topological-Sort(V, E) berechnet in Zeit Θ(|V | + |E|) eine topologische Sortie- rung ord f¨ur G. Beweis. Die Korrektheit des Vorgehens folgt im Wesentlichen aus Theo- rem 5.5 zusammen mit der Beobachtung, dass f¨ur kreisfreie Graphen das Dekrementieren der Knotengrade aller Nachbarknoten von v in den Schritten 10–11 exakt der Entfernung von v entspricht. Es verbleibt zu zeigen, dass am Ende eine topologische Sortierung ord zur¨uckgegeben wird. Ein Knoten v wird nur dann in S eingef¨ugt, wenn er entweder in G einen Eingangsgrad von 0 hat, oder wenn allen Knoten u ∈ V mit (u, v) ∈ E bereits fr¨uher ein Wert ord[u] > 0 zugewiesen wurde. Wird also ein Knoten v aus S entfernt, dann wird ord[v] auf einen Wert ge- setzt, der gr¨osser als alle ord[u], (u, v) ∈ E, ist. Ausserdem wird v kein weiteres Mal in S eingef¨ugt. Folglich ist ord eine topologische Sortierung, und nach Terminierung der Schleife in Schritt 6 ist i = |V |. Somit wird ord zur¨uckgegeben. Die Schleifen in den Schritten 2 und 4 haben eine Laufzeit von exakt Θ(|V |), die Schleife in Schritt 3 hat eine Laufzeit von Θ(|E|). Wir haben bereits gesehen, dass die Schleife in Schritt 7 genau |V | Mal durchlaufen wird. Ausserdem wird in den Schritten 7–12 jede Kante (v, w) ∈ E nur genau einmal betrachtet. Also betr¨agt die Laufzeit der Schritte 7–12 genau Θ(|V | + |E|), was somit der gesamten Laufzeit des Algorithmus entspricht. Theorem 5.7. Sei G = (V, E) ein gerichteter, nicht kreisfreier Graph. Der Algo-Laufzeit und Korrektheit, Teil II rithmus Topological-Sort(V, E) terminiert nach Θ(|V | + |E|) Schritten und gibt “Graph enth¨alt einen Kreis” zur¨uck. 5.5 K¨urzeste Wege 113 Beweis. Sei K = ⟨v1, . . . , vk, v1⟩ ein in G enthaltener Kreis. In jedem Durchlauf der Schleife in Schritt 7 bleibt A[vi] ≥ 1 f¨ur alle i ∈ {1, . . . , k}, folglich wird keiner der Knoten v1, . . . , vk jemals in S eingef¨ugt. Somit wird die Schleife in Schritt 7 maximal |V | − k < |V | Mal durchlaufen, am Ende ist i < |V | + 1 und es wird in Schritt 13 keine topologische Sortierung zur¨uckgegeben. Der Beweis der Laufzeit verl¨auft analog zu Theorem 5.6 mit der ¨Anderung, dass die Schleife in Schritt 7 nicht exakt |V | Mal, sondern h¨ochstens |V | − 2 Mal durchlaufen wird. Man beachte, dass die Gesamtlaufzeit in Θ(|V | + |E|) bleibt, da die Schritte 2–5 immer so viel Zeit ben¨otigen. 5.5 K¨urzeste Wege Bereits zu Beginn des Kapitels wurde die Berechnung einer schnellsten Route in Motivation einem gegebenen Strassennetz als Beispiel f¨ur ein Problem genannt, das mithilfe der Graphentheorie gel¨ost werden kann. Zur Berechnung einer schnellsten Zugver- bindung zwischen zwei gegebenen St¨adten kommen zus¨atzlich noch Abfahrtszeiten hinzu, was das Problem etwas komplexer macht, aber dennoch kann auch dieses Problem als graphentheoretisches Problem formuliert werden. Beim K¨urzeste-Wege- K¨urzeste-Wege- ProblemProblem ist als Eingabe ein gerichteter, gewichter Graph G = (V, E, w) gegeben, wobei wie zuvor w : E → R die Kantengewichtungsfunktion ist. Weiterhin sind zwei Knoten s, t ∈ V gegeben. Gesucht ist ein Weg W = ⟨s = v0, . . . , vk = t⟩ von s nach t, dessen Kosten c(W ) = ∑k i=1 w((vi−1, vi)) minimal unter allen Wegen von s nach t ist. Wir nennen W dann vereinfachend auch einen k¨urzesten Weg, wobei sich diese Bezeichnung auf die Kantengewichte und im Allgemeinen nicht auf die Anzahl der Kanten auf dem Weg bezieht. Vereinfachend nehmen wir an, dass es mindestens Vereinfachung einen Weg gibt, der in s startet und in t endet. Ob dies der Fall ist, kann im Vorfeld leicht mit einer in s startenden Breitensuche festgestellt werden. Falls kein einziger st-Weg existiert, geben wir eine Fehlermeldung aus und sind fertig. Wir m¨ussen zun¨achst ¨uberlegen, ob das soeben formulierte K¨urzeste-Wege-Pro- Existenz von k¨urzesten Wegen blem ¨uberhaupt sinnvoll ist. Es kann n¨amlich unendlich viele Wege von s nach t geben, und es kann sogar passieren dass man zu jedem solchen st-Weg einen weiteren, k¨urzeren st-Weg ﬁndet (vgl. Abbildung 5.11). Solch eine Situation kann auftreten, wenn es Kreise mit negativem Gewicht gibt. Unproblematisch dagegen ist es, wenn alle Kantengewichte nicht-negativ (also gr¨osser oder gleich Null) sind, denn dann hat jeder Kreis ein nicht-negatives Gewicht. Es gibt also auf jeden Fall einen k¨urzesten Weg, der keinen Knoten mehrfach besucht, und der folglich ein Pfad ist. Ein Pfad hat h¨ochstens |V | viele Knoten, also gibt es f¨ur einen festen Graphen nur endlich Abb. 5.11 Am Knoten u gibt es einen Kreis, also gibt es unendlich viele Wege von s nach t. Wenn die Summe der Kantengewichte auf dem Kreis ⟨u, v, w, u⟩ negativ ist, gibt es keinen k¨urzesten st-Weg, denn zu jedem solchen Weg ﬁndet man einen k¨urzeren st-Weg, indem der Kreis einmal mehr durchlaufen wird. 114 Graphenalgorithmen Abb. 5.12 Eine Breitensuche auf einem Beispielgraphen. Die dick gestrichelten Linien unterteilen den Graphen in Schichten, und alle Knoten einer Schicht sind gleich weit von s entfernt: Ein k¨urzester Weg von s zu s hat L¨ange 0, ein k¨urzester Weg von s zu v1, v2 und v3 hat L¨ange 1, und ein k¨urzester Weg von s zu v4, v5, v6 und v7 hat L¨ange 2. viele Pfade. Unter diesen muss einer k¨urzestm¨oglich (in Hinblick auf sein Gewicht) sein. Wir werden jetzt zuerst ¨uberlegen, wie ein k¨urzester Weg in einem Graphen mit nicht-negativen Kantengewichten berechnet werden kann. Danach diskutieren wir, wie man auch negative Kantengewichte zulassen kann, und wie Kreise mit negativem Gewicht behandelt werden k¨onnen. 5.5.1 K¨urzeste Wege in Graphen mit uniformen Kantengewichten Wenn alle Kanten die gleichen Kosten (z.B. 1) haben, dann k¨onnen wir einen k¨urzes- ten Weg einfach mit einer modiﬁzierten Breitensuche von s aus ﬁnden. Dazu spei- chern wir f¨ur jeden Knoten v ∈ V , von welchem Knoten p[v] aus der Knoten v entdeckt wurde. Der Wert p[v] gibt also den Vorg¨anger (engl. predecessor) von v auf einem k¨urzesten Weg von s nach v an, und wird f¨ur alle v ∈ V mit null initiali- siert (zu Beginn wurde noch kein Knoten entdeckt). Damit ergibt sich der folgende Algorithmus: BFS-Visit-Iterative(G, v)Iterative Breitensuche 1 for each v ∈ V do p[v] = null ▷ Initialisiere Vorg¨anger 2 Q ← ∅ ▷ Initialisiere leere Schlange Q 3 Enqueue(s, Q) ▷ F¨uge s zur Schlange Q hinzu 4 while Q ̸= ∅ do 5 u ← Dequeue(Q) ▷ Aktueller Knoten 6 for each (u, v) ∈ E do 7 if p[v] ̸= null then ▷ Falls v noch nicht entdeckt wurde 8 p[v] ← u ▷ Speichere u als Vorg¨anger von v 9 Enqueue(v, Q) ▷ F¨uge v zur Schlange Q hinzu Die Laufzeit ist nat¨urlich noch immer in Θ(|V | + |E|), da pro Knoten und proLaufzeit Kante nur ein konstanter Extraaufwand betrieben wird. Um nun den k¨urzesten Weg von s zu t zu rekonstruieren, setzen wir zun¨achst v ← t und geben v aus. DanachRekonstruktion des Weges setzen wir v ← p[v] und geben v aus, bis v = s gilt. Auf diese Art wird ein k¨urzes- ter Weg von s nach t r¨uckw¨arts rekonstruiert (wir ﬁnden also zuerst den letzten Knoten auf diesem Weg, dann den vorletzten, usw). Man beachte, dass dieser Weg 5.5 K¨urzeste Wege 115 Abb. 5.13 Unter allen Kanten (u, v), die von S zu V \\S verlaufen, wird diejenige gew¨ahlt, f¨ur die d[u]+w((u, v)) minimal ist. Die blauen Zahlen neben einem Knoten geben d[u] (links) bzw. d[u] + w((u, v)) (rechts) an, die schwarzen Zahlen oberhalb bzw. unterhalb der Kanten die entsprechenden Gewichte w((u, v)). Gew¨ahlt wird die Kante mit Gewicht 9. kreisfrei ist, also aus h¨ochstens |V | Knoten besteht. Damit ist die f¨ur die Rekon- struktion ben¨otigte Zeit in O(|V |) und im Vergleich zur Laufzeit der Breitensuche selbst vernachl¨assigbar. Das urspr¨ungliche Ziel war die Berechnung eines k¨urzesten Weges von s nach t. Tats¨achlich macht die Breitensuche aber etwas mehr, denn sie berechnet die k¨urzes- ten Wege vom Startknoten s zu allen Knoten des Graphen! Ausserdem k¨onnen wir mit nur einem Durchlauf feststellen, welche Knoten nicht von s aus erreicht werden k¨onnen. Das sind genau die Knoten v mit p[v] = null. 5.5.2 K¨urzeste Wege in Graphen mit nicht-negativen Kantengewichten Die im vorigen Unterabschnitt vorgestellte Breitensuche kann nun verallgemeinert werden, um alle k¨urzesten Wege (bzw. ihre L¨angen) vom Startknoten s zu allen Knoten v ∈ V in einem Graphen mit allgemeinen, nicht-negativen Kantengewich- ten zu berechnen. Wir erlauben zun¨achst die vereinfachende Annahme, dass von s Vereinfachung aus jeder Knoten v ∈ V erreicht werden kann. Diese Annahme vereinfacht sp¨ater die Analyse und stellt keine Einschr¨ankung dar, denn wie gesehen k¨onnen wir eine Breitensuche von s aus starten um alle von dort aus erreichbaren Knoten zu ﬁnden; alle ¨ubrigen Knoten werden entsprechend als “unerreichbar” markiert. Algorithmenger¨ust Unsere verallgemeinerte Breitensuche arbeitet induktiv und verwaltet f¨ur jeden Knoten v ∈ V einen Wert d[v], der angibt, wie lang ein k¨urzes- ter Weg von s zu v h¨ochstens ist. Initial setzen wir d[s] ← 0, und f¨ur alle anderen v ∈ V \\{s} setzen wir d[v] ← ∞. Bei der Terminierung des Algorithmus soll d[v] genau die L¨ange eines k¨urzesten Weges von s nach v angeben (und nicht nur eine Absch¨atzung). Der Algorithmus verwaltet ausserdem eine Menge von Knoten S, f¨ur die bereits bekannt ist, dass d[v] genau der L¨ange eines k¨urzesten Weges von s nach v entspricht. Initial enth¨alt S nur s mit d[s] = 0. Nun wird S in jedem Schritt um genau einen Knoten erweitert. Dazu w¨ahlen wir unter allen Kanten (u, v) ∈ (S ×(V \\S))∩E (also allen Kanten (u, v), die von einem Knoten in S zu einem Knoten in V \\S ver- laufen) diejenige, f¨ur die d[u] + w((u, v)) minimal ist (siehe Abbildung 5.13). Dann setzen wir d[v] ← d[u] + w((u, v)) und f¨ugen S den Knoten v hinzu. Der Algorithmus endet, sobald S alle Knoten enth¨alt. 116 Graphenalgorithmen Abb. 5.14 Der k¨urzeste Weg von s nach x ist mindestens so lang wie ein k¨urzester Weg von s nach v ¨uber u. Ein sv-Weg, der zus¨atzlich noch x′ und x besucht, ist daher nicht k¨urzer als der k¨urzeste Weg von s nach v ¨uber u. Korrektheit Zum Nachweis der Korrektheit f¨uhren wir eine vollst¨andige Induktion ¨uber die Anzahl der Knoten in S aus, um zu zeigen, dass d[v] f¨ur alle v ∈ S stets genau die L¨ange eines k¨urzesten Weges von s nach v angibt. Induktionsanfang (|S| = 1): Zu Beginn enth¨alt S nur den Startknoten s mit d[s] = 0, folglich ist die Aussage wahr. Induktionshypothese: Angenommen, f¨ur jeden Knoten v ∈ S entspricht d[v] der L¨ange eines k¨urzesten Weges von s nach v. Induktionsschritt (|S| → |S| + 1): Der Algorithmus w¨ahlt eine Kante (u, v) ∈ (S × (V \\S)) ∩ E, f¨ur die d[u] + w((u, v)) minimal ist, setzt d[v] ← d[u] + w((u, v)) und f¨ugt v der Menge S hinzu. Wir argumentieren jetzt, dass d[v] tats¨achlich die L¨ange eines k¨urzesten Weges von s nach v angibt. Dazu betrachten wir einen k¨urzesten Weg von s nach v. Sei nun x der Knoten, den dieser Weg direkt vor v besucht. Liegt x in S, dann gilt d[v] = d[u] + w((u, v)) ≤ d[x] + w((x, v)) = L¨ange eines k¨urzesten Weges von s nach v. (108) Man beachte, dass sowohl x als auch u in S liegen, folglich geben d[u] bzw. d[x] die L¨angen der k¨urzesten Wege von s nach u bzw. x an. Die Ungleichung gilt, weil sowohl (u, v) als auch (x, v) von S nach V \\S verlaufen und unter all diesen Kanten (u, v) diejenige ist, f¨ur die d[u] + w((u, v)) minimal ist. Da es ausserdem einen Pfad von s nach u sowie eine Kante von u nach v gibt, gilt sogar Gleichheit. Liegt dagegen x nicht in S, dann enth¨alt jeder Weg von s nach v mindestens eine Kante, die von einem Knoten in S zu einem Knoten x′ ∈ V \\S verl¨auft. Also hat (wie zuvor) jeder Weg von s nach x′ mindestens L¨ange d[u]+w((u, v)), und jeder Weg von s nach x nat¨urlich erst recht (da es keine Kanten mit strikt negativem Gewicht gibt). Daher muss auch der Weg von s nach v ¨uber x mindestens L¨ange d[u] + w((u, v)) haben (siehe Abbildung 5.14). Andererseits hat der Weg von s nach v ¨uber u genau die L¨ange d[u] + w((u, v)). Daher kann kein Weg ¨uber einen Knoten x ∈ V \\S k¨urzer sein als der Weg ¨uber u, also gibt d[v] = d[u] + w((u, v)) wie gew¨unscht die L¨ange eines k¨urzesten Weges von s nach v an. 5.5 K¨urzeste Wege 117 Pr¨azisierung des Algorithmus Es verbleibt zu ¨uberlegen, wie die Auswahl einer geeigneten Kante von S nach V \\S realisiert werden kann. Wir k¨onnten zum Beispiel Triviale Varianteeinfach ¨uber alle Kanten (u, v) ∈ E des Graphen iterieren und pr¨ufen, ob u ∈ S und v ̸∈ S gilt. Unter allen Kanten mit dieser Eigenschaft merken wir uns diejenige, f¨ur die d[u] + w((u, v)) minimal ist. In dieser einfachen Realisierung ben¨otigt jeder Schritt Zeit O(|E|), da ¨uber alle Kanten iteriert wird. Da in jedem Schritt |S| um 1 w¨achst (und niemals gr¨osser als |V | wird), erhalten wir insgesamt einen Algorithmus mit Laufzeit O(|V ||E|). Der niederl¨andische Informatiker Dijkstra beobachtete, dass es nicht notwendig Dijkstras Algorithmus (original) ist, in jedem Schritt alle Kanten zu betrachten. Stattdessen gen¨ugt es, sich f¨ur je- den Knoten v eine vorl¨auﬁge obere Schranke d[v] zu merken und entsprechend zu aktualisieren, sobald eine neue Kante zu v gefunden wird. Sobald also ein Knoten u der Menge S hinzugef¨ugt wird, iterieren wir ¨uber alle von u ausgehenden Kan- ten (u, v) ∈ E, pr¨ufen ob d[u] + w((u, v)) < d[v] gilt, und setzen in dem Fall d[v] auf d[u] + w((u, v)) (denn wir haben einen k¨urzeren Weg zu v entdeckt). Gilt da- gegen d[u] + w((u, v)) ≥ d[v], dann ist der Weg von s zu v ¨uber u nicht k¨urzer als der bisher beste gefundene Weg von s zu v. In jedem Schritt w¨ahlen wir dann als n¨achstes den Knoten v ∈ V \\S, f¨ur den d[v] minimal ist, f¨ugen ihn S hinzu und verfahren wie soeben beschrieben. In dieser Realisierung wird jede Kante (u, v) ∈ E insgesamt genau einmal angeschaut (genau dann, wenn u der Menge S hinzugef¨ugt wird), und die Auswahl eines geeigneten Knotens v kann in Zeit O(|V |) gesche- hen, da die Menge V \\S h¨ochstens so viele Knoten hat. Da dieser Auswahlschritt |V | Mal ausgef¨uhrt wird, erhalten wir insgesamt einen Algorithmus mit Laufzeit Laufzeit O(|V |2 + |E|) = O(|V |2), was gegen¨uber der trivialen Variante schon eine Verbesse- rung darstellt. Die Laufzeit der zuvor beschriebenen urspr¨unglichen Variante von Dijkstras Al- Dijkstras Algorithmus mit Heaps gorithmus ist quadratisch in der Anzahl der Knoten, da in jedem Schritt ¨uber alle Knoten in V \\S iteriert wird, um den Knoten v zu ﬁnden, f¨ur den d[v] minimal ist. Eine Verbesserung besteht nun darin, die Knoten in V \\S mit einer Priorit¨atswar- teschlange zu verwalten (siehe Abschnitt 4.1) und als Priorit¨at eines Knotens den aktuellen Wert d[v] zu verwenden. Mit einer geeigneten Datenstruktur kann dann der Knoten v mit minimalem Wert d[v] schneller gefunden werden. Anders als fr¨uher wollen wir jetzt aber einen Knoten mit minimaler Priorit¨at ﬁnden. Ausserdem er- lauben wir, dass die Priorit¨atswarteschlange mehrere Knoten mit gleicher Priorit¨at enth¨alt, denn es kann ja zwei verschiedene Knoten v, w ∈ V \\S mit d[v] = d[w] geben. Da der Wert d[v] auch nachtr¨aglich noch absinken kann, ben¨otigen wir weiterhin ei- ne Operation, die dies umsetzt. Konkret muss unsere Priorit¨atswarteschlange Q also die folgenden drei Operationen unterst¨utzen: Operationen • Extract-Min(Q): Liefert irgendeinen Knoten v zur¨uck, dessen Priorit¨at un- ter allen in Q verwalteten Knoten minimal ist, und entfernt ihn aus Q. Die Operation darf nur dann aufgerufen werden, wenn Q nicht leer ist. • Insert(v, π, Q): F¨ugt den Knoten v mit Priorit¨at π ∈ Q + 0 in Q ein. Die Ope- ration darf nur aufgerufen werden, wenn Q den Knoten v noch nicht enth¨alt. • Decrease-Key(v, π, Q): Setzt die Priorit¨at des Knotens v auf π herab. Die Operation darf nur aufgerufen werden, wenn Q den Knoten v enth¨alt und die Priorit¨at von v vor Aufruf der Operation gr¨osser oder gleich π ist. Der Algorithmus kann nun wie folgt formuliert werden: 118 Graphenalgorithmen Dijkstra(G = (V, E), s)Dijkstras Algorithmus 1 for each v ∈ V \\{s} do ▷ Initialisiere f¨ur alle Knoten die 2 d[v] ← ∞; p[v] ← null ▷ Distanz zu s sowie Vorg¨anger 3 d[s] ← 0; p[s] ← null ▷ Initialisierung des Startknotens 4 Q ← ∅ ▷ Leere Priorit¨atswarteschlange Q 5 Insert(s, 0, Q) ▷ F¨uge s zu Q hinzu 6 while Q ̸= ∅ do 7 u ← Extract-Min(Q) ▷ Aktueller Knoten 8 for each (u, v) ∈ E do ▷ Inspiziere Nachfolger 9 if p[v] = null then ▷ v wurde noch nicht entdeckt 10 d[v] ← d[u] + w((u, v)) ▷ Berechne obere Schranke 11 p[v] ← u ▷ Speichere u als Vorg¨anger von v 12 Enqueue(v, d[v], Q) ▷ F¨uge v zu Q hinzu 13 else if d[u] + w((u, v)) < d[v] then ▷ K¨urzerer Weg zu v entdeckt 14 d[v] ← d[u] + w((u, v)) ▷ Aktualisiere obere Schranke 15 p[v] ← u ▷ Speichere u als Vorg¨anger von v 16 Decrease-Key(v, d[v], Q) ▷ Setze Priorit¨at von v herab Wie bei der Breitensuche im vorigen Unterabschnitt 5.5.1 bezeichnet p[v] den Vorg¨an-Rekonstruktion des Weges gerknoten von v auf einem k¨urzesten Weg von s nach v. Dieser Vorg¨angerknoten kann auch benutzt werden, um festzustellen, ob ein Knoten v ∈ V \\S bereits in Q gespeichert ist: Wenn p[v] = null ist, dann wurde v noch nie in Q eingef¨ugt. Der Algorithmus berechnet f¨ur einen gegebenen Startknoten s die L¨angen der k¨urzesten Wege zu allen Knoten des Graphen sowie die entsprechenden Vorg¨angerknoten. Der k¨urzeste Weg selbst von s zu einem beliebigen Knoten t kann wieder genau wie im vorigen Unterabschnitt beschrieben rekonstruiert werden. Theorem 5.8. Wird Dijkstras Algorithmus mit Heaps implementiert, dann ist dieLaufzeit Laufzeit in O((|V | + |E|) log |V |). Beweis. Der in Abschnitt 2.4 vorgestellte Heap kann so modiﬁziert wer- den, dass alle drei Operationen Extract-Min, Insert und Decrease- Key unterst¨utzt werden und nur Zeit O(log n) ben¨otigen, wobei n die Anzahl der von Q verwalteten Schl¨ussel angibt. Da Q jeden Knoten aus V h¨ochstens einmal enth¨alt, ist die Laufzeit aller drei Operationen also stets in O(log |V |). Die Schritte 1–5 des Algorithmus laufen in Zeit O(|V |). Die Schrit- te 9–16 brauchen insgesamt Zeit h¨ochstens O(log |V |). Zentral f¨ur die Laufzeitanalyse ist die Beobachtung, dass jeder Knoten genau einmal in Q eingef¨ugt und genau einmal aus Q entfernt wird. Wurde ein Knoten u aus Q entfernt, dann wird er niemals wieder in Q eingef¨ugt, und sein Wert d[u] wird niemals wieder ver¨andert. Der Grund ist, dass f¨ur alle sp¨ater aus Q entfernten Knoten x der Wert d[x] mindestens so gross wie d[u] ist; folglich ist der Vergleich in Schritt 13 niemals erf¨ullt. Da jeder Knoten nur genau einmal aus Q entfernt wird, wird jede von u ausge- hende Kante (u, v) ∈ E im Verlauf des Algorithmus nur genau einmal angeschaut. Die Gesamtlaufzeit betr¨agt damit O((|V | + |E|) log |V |). 5.5 K¨urzeste Wege 119 Der soeben vorgestellte Algorithmus kann noch ein wenig verbessert werden. Dijkstras Algorithmus mit Fibonacci-Heaps Dazu wird die Priorit¨atswarteschlange Q durch einen sogenannten Fibonacci-Heap (ohne weitere Erkl¨arung) implementiert. Dieser erlaubt die Hinzuf¨ugung eines neuen Knotens in Zeit O(1), die Absenkung der Priorit¨at eines Knotens in amortisierter Zeit O(1) sowie die Extraktion eines Knotens mit minimaler Priorit¨at in amortisier- ter Zeit O(log n) (wobei wie zuvor n die Anzahl der in Q gespeicherten Knoten an- gibt). Da jeder Knoten genau einmal in Q eingef¨ugt und genau einmal aus Q entfernt wird, f¨allt f¨ur diese beiden Operationen insgesamt Zeit O(|V | log |V |) an. Zus¨atz- lich m¨ussen insgesamt h¨ochstens |E| viele Priorit¨aten abgesenkt werden, was in Zeit O(|E|) realisiert werden kann. Wird also Dijkstras Algorithmus mit einem Fibonacci- Heap implementiert, dann betr¨agt die Laufzeit nur noch O(|V | log |V |+|E|). Dies ist auch die Algorithmenvariante, die ¨ublicherweise als Dijkstras Algorithmus bezeich- net wird (auch wenn der urspr¨unglich von Dijkstra vorgeschlagene Algorithmus keine Fibonacci-Heaps verwendete und daher eine schlechtere Laufzeit aufwies). In prakti- Praktische Relevanzschen Anwendungen spielen Fibonacci-Heaps allerdings keine grosse Rolle, da die in der O-Notation seiner Laufzeit versteckten Konstanten recht gross sind. Herk¨omm- liche Heaps stellen daher oftmals eine bessere Wahl dar. 5.5.3 K¨urzeste Wege in Graphen mit allgemeinen Kantengewichten Wir haben bereits ¨uberlegt, dass die Situation in Graphen mit allgemeinen Kan- Problem tengewichten schwieriger ist, da es Kreise mit negativem Gewicht geben kann (vgl. Abbildung 5.11). Bevor wir einen Algorithmus f¨ur dieses allgemeine K¨urzeste-Wege- Problem angeben, ¨uberlegen wir zun¨achst, welche der bisherigen Erkenntnisse wei- terverwendet werden k¨onnen. Wie zuvor sei s der Startknoten, von dem ausgehend die k¨urzesten Wege zu allen anderen Knoten des Graphen berechnet werden sollen. F¨ur jede Kante (u, v) ∈ E gilt nach wie vor d[v] ≤ d[u] + w((u, v)), denn ein k¨urzester sv-Weg ist h¨ochstens so lang wie ein k¨urzester su-Weg und dem Gewicht (bzw. der L¨ange) der Kante (u, v) zusammen. Wenn wir also auf eine Kante (u, v) mit d[v] > d[u] + w((u, v)) treﬀen, k¨onnen wir wie zuvor d[v] ← d[u] + w((u, v)) setzen. Wir sagen dann auch, die Kante (u, v) werde relaxiert. Wird eine Kante (u, v) mit Relaxierung d[v] ≤ d[u] + w((u, v)) relaxiert, dann bleibt d[v] nat¨urlich unver¨andert, da der sv- Weg ¨uber u keine Verbesserung gegen¨uber dem bisher besten Weg darstellt. Fords Fords AlgorithmusAlgorithmus relaxiert in jedem Schritt jede Kante des Graphen genau einmal und beginnt dann wieder von vorn, bis sich in einem Schritt kein Wert d[v] mehr ¨andert. Das Problem dieses Verfahrens ist, dass es niemals endet, wenn der Graph Kreise mit negativem Gewicht hat. Wir haben bereits fr¨uher ¨uberlegt, dass jeder k¨urzeste Weg, sofern existent, ein Pfad sein muss. Ein k¨urzester Weg besucht also keinen Knoten mehr als einmal. Dies gilt nat¨urlich auch dann noch, wenn ein Graph Kanten mit negativen Gewichten hat. Der US-amerikanische Mathematiker Bellman schlug ein dynamisches Programm Algorithmus von Bellmanzur Berechnung aller k¨urzesten Wege von einem gegebenen Startknoten aus vor. Dazu wird eine |V | × |V |-Tabelle benutzt, und ein Eintrag T [v, i] (mit v ∈ V und i ∈ {0, . . . , |V |−1}) gibt die L¨ange eines k¨urzesten Weges von s nach v mit h¨ochstens i Kanten an. Initial setzen wir T [s, 0] ← 0 und T [v, 0] ← ∞ f¨ur alle v ∈ V \\{s}. Im i-ten Schritt rechnen wir T [v, i] ← min (T [v][i − 1], min (u,v)∈E (T [u][i − 1] + w((u, v)) )), (109) 120 Graphenalgorithmen denn ein k¨urzester sv-Weg mit h¨ochstens i Kanten wurde entweder bereits im (i−1)- ten Schritt gefunden, oder es gibt einen k¨urzesten Weg mit h¨ochstens i − 1 Kanten zu einem Knoten u sowie eine Kante von u nach v. Nachdem die gesamte Tabelle ausgef¨ullt wurde, setzen wir d[v] ← T [v, n − 1], iterieren ¨uber alle Kanten (u, v) ∈ E und pr¨ufen, ob noch eine Kante relaxiert werden kann. Falls ja, dann gibt es einen Kreis mit negativem Gewicht. Ansonsten k¨onnen die k¨urzesten Wege einfach aus der DP-Tabelle abgelesen werden. Ein Tabelleneintrag kann in Zeit O(|V |) berech-Laufzeit net werden (denn er h¨angt von h¨ochstens |V | anderen Tabelleneintr¨agen ab), und die Tabelle hat |V |2 viele Eintr¨age. Nach der Berechnung der Tabelle kann in Zeit O(|E|) festgestellt werden, ob es einen Kreis mit negativem Gewicht gibt. Die Ge- samtlaufzeit von Bellmans Algorithmus ist also in O(|V |3 + |E|) = O(|V |3). Man kann die Algorithmen von Ford und Bellman kombinieren und sich ¨uberle- gen, dass jede Kante (u, v) ∈ E niemals mehr als |V | − 1 Mal relaxiert werden muss. F¨uhrt eine weitere Relaxierung von (u, v) dann dazu, dass sich der Wert d[v] ¨andert, dann enth¨alt der Graph einen Kreis mit negativem Gewicht. Diese Idee macht sich der Algorithmus von Bellman und Ford zunutze, der wie folgt funktioniert. Bellman-Ford(G = (V, E), s)Algorithmus von Bellman und Ford 1 for each v ∈ V \\{s} do ▷ Initialisiere f¨ur alle Knoten die 2 d[v] ← ∞; p[v] ← null ▷ Distanz zu s sowie Vorg¨anger 3 d[s] ← 0; p[s] ← null ▷ Initialisierung des Startknotens 4 for i ← 1, 2, . . . , |V | − 1 do ▷ Wiederhole |V | − 1 Mal 5 for each (u, v) ∈ E do ▷ Iteriere ¨uber alle Kanten (u, v) 6 if d[v] > d[u] + w((u, v)) then ▷ Relaxiere Kante (u, v) 7 d[v] ← d[u] + w((u, v)) ▷ Berechne obere Schranke 8 p[v] ← u ▷ Speichere u als Vorg¨anger von v 9 for each (u, v) ∈ E do ▷ Pr¨ufe, ob eine weitere Kante 10 if d[u] + w((u, v)) < d[v] then ▷ relaxiert werden kann 11 Melde Kreis mit negativem Gewicht Sofern kein Kreis mit negativem Gewicht existiert, kann ein k¨urzester Pfad von s zu einem beliebigen Zielknoten t wie in den vorigen Unterabschnitten beschrieben rekonstruiert werden, indem man dem Vorg¨anger p[v] beginnend mit v = t folgt, bis der Startknoten erreicht wurde. Die Initialisierung (Schritte 1–3) l¨auft in Zeit O(|V |).Laufzeit Die Berechnung der Werte d[v] (Schritte 4–8) l¨auft in Zeit O(|V ||E), und wie zuvor kann in Zeit O(|E|) festgestellt werden, ob ein Kreis mit negativem Gewicht existiert (Schritte 9–11). Die Gesamtlaufzeit des Algorithmus von Bellman und Ford ist also in O(|V ||E|), was eine Verbesserung gegen¨ubers Bellmanns originalem dynamischen Programm darstellt. 5.5.4 K¨urzeste Wege zwischen allen Paaren von Knoten In einem gewichteten Graphen G = (V, E, w) k¨onnen wir f¨ur jeden Knoten messen, wie oft er auf einem k¨urzesten Weg zwischen zwei Knoten vorkommt. Knoten, die auf vielen k¨urzesten Wegen vorkommen, kommt oftmals eine herausragende Bedeutung zu. Dieses Mass ist unter dem Namen Betweenness Centrality bekannt. Zur Berech-Betweenness Centrality nung ist es erforderlich, alle k¨urzesten Pfade zwischen allen Knoten des Graphen 5.5 K¨urzeste Wege 121 zu berechnen. Zur L¨osung dieses Problems k¨onnte zum Beispiel Dijkstras Algorith- mus verwendet werden, der dann von jedem Knoten s ∈ V aus gestartet wird. Dies ben¨otigt insgesamt Zeit O(|V |2 log |V |+|V ||E|) und funktioniert nat¨urlich nur, wenn alle Kantengewichte nicht-negativ sind. Im Falle allgemeiner Kantengewichtsfunktio- nen kann der Algorithmus von Bellman und Ford anstelle von Dijkstras Algorithmus verwendet werden, was zu einer Gesamtlaufzeit in O(|V |2|E|) f¨uhrt. Wir werden im Folgenden untersuchen, wie f¨ur einen Graphen mit allgemeinen Kantengewichten die k¨urzesten Pfade zwischen allen Paaren zweier Knoten schneller berechnet wer- den k¨onnen. Algorithmus von Floyd und Warshall Wir haben bereits in Abschnitt 5.1.6 einen Algorithmus zur Berechnung der transitiven H¨ulle eines Graphen G = (V, E) mit V = {v1, . . . , vn} gesehen. Dieser berechnet eine Matrix A = (aij), in der ein Eintrag aij genau dann den Wert 1 hat, wenn es einen Weg vom Knoten vi zum Knoten vj gibt, und 0 sonst. Der Algorithmus iteriert ¨uber m¨oglichen Zwischenknoten vi und pr¨uft f¨ur alle u, v ∈ V , ob es einen Weg von u nach vi sowie einen Weg von vi nach v gibt. In diesem Fall h¨atten wir auch einen Weg von u nach v gefunden. Der Algorithmus von Floyd und Warshall greift diese Idee wieder auf, nur dass Algorithmus von Floyd und Warshall diesmal die L¨ange eines k¨urzesten Weges zwischen zwei Knoten (statt eines bin¨aren Werts) verwaltet wird. Konkret sei di uv mit u, v ∈ V und i ∈ {0, . . . , n} die L¨ange eines k¨urzesten Weges von u nach v, auf dem alle Knoten vk zwischen u und v einen Index k ≤ i haben. Initial (i = 0) sind keine Zwischenknoten erlaubt, also Initialisierung setzen wir d0 uu = 0. F¨ur u ̸= v setzen wir d0 uv = w((u, v)), falls der Graph die Kante (u, v) enth¨alt, und ansonsten d0 uv = ∞ (da keine direkte Verbindung von u nach v existiert). Im Berechnungsschritt iterieren wir ¨uber alle i ∈ {1, 2, . . . , n}, und f¨ur jedes i ¨uber alle u ∈ V und alle v ∈ V . Wir setzen dann Berechnungs- schritt d i uv = min (d i−1 uv , d i−1 uvi + d i−1 viv ), (110) denn entweder wird vi auf einem k¨urzesten Weg nicht benutzt (dann ist di uv = di−1 uv ), oder die Benutzung von vi f¨uhrt zu einem k¨urzeren als dem bisher gefundenen uv- Weg (dann ist di uv = di−1 uvi + di−1 viv ). Nach Ende der Berechnung enth¨alt dn uv die L¨ange eines k¨urzesten Weges von u nach v, sofern ein solcher existiert. Wir m¨ussen dann Negative Kreise erkennenaber noch pr¨ufen, ob es einen Kreis mit negativem Gewicht gibt. Dies ist genau dann der Fall, wenn es einen negativen Eintrag dn uu gibt. Der Algorithmus von Floyd und Warshall berechnet insgesamt O(|V |3) viele Laufzeit Eintr¨age di uv, und jeder Eintrag kann in konstanter Zeit aus fr¨uher berechneten Ein- tr¨agen berechnet werden. Die Zeit zur Pr¨ufung, ob ein Kreis mit negativem Gewicht existiert, liegt in O(|V |). Damit berechnet der Algorithmus in Zeit O(|V |3) die Di- stanzen zwischen allen Paaren zweier Knoten des Graphen. Man beachte, dass der Berechnungsschritt (110) in-place ausgef¨uhrt werden kann. Der obige Algorithmus berechnet nur die Abst¨ande zwischen zwei Knoten, nicht Rekonstruktion der Wegedie k¨urzesten Wege selbst. Dies kann aber leicht erg¨anzt werden, indem zu jedem Paar zweier Knoten (u, v) der Nachfolger succ[u, v] von u auf einem k¨urzesten Weg von u nach v gespeichert wird. Initial setzen wir succ[u, v] ← v f¨ur alle u, v ∈ V mit (u, v) ∈ E, und succ[u, v] ← null f¨ur alle u, v ∈ V mit (u, v) ̸∈ E. Wird dann im Berechnungsschritt di uv ← di−1 uvi + di−1 viv gesetzt, muss succ[u, v] ← succ[u, vi] gesetzt werden. Um den k¨urzesten Weg von einem Knoten s zu einem Knoten t zu berechnen, setzen wir initial u ← s. Dann gibt succ[u, t] den n¨achsten Knoten auf dem Weg zu t an. Wir setzen u ← succ[u, t] und fahren auf die gleiche Art fort, bis t erreicht wird 122 Graphenalgorithmen Abb. 5.15 Konstruktion des neuen Graphen. (d.h., bis u = t gilt). Die Zeit zur Rekonstruktion des Weges ist dann nur linear in der Wegl¨ange, und auch die asymptotische Laufzeit des Algorithmus bleibt gleich. Algorithmus von Johnson Der Algorithmus von Floyd und Warshall berechnet die k¨urzesten Wege zwischen allen Paaren zweier Knoten in Zeit O(|V |3) und funk- tioniert auch dann, wenn Kanten mit negativem Gewicht existieren. F¨ur Graphen, deren Kantengewichte stets nicht-negativ sind, k¨onnen alle k¨urzesten Wege durch |V |-malige Ausf¨uhrung von Dijkstras Algorithmus berechnet werden, was insgesamt Zeit O(|V |2 log |V | + |V ||E|) kostet und damit im besten Fall schneller als der Al- gorithmus von Floyd und Warshall ist (und niemals schlechter). Wir werden jetzt den Algorithmus von Johnson beschreiben, der genau die gleiche Laufzeit hat, aber auch dann noch funktioniert, wenn es Kanten mit negativem Gewicht gibt. Dazu f¨ugen wir zun¨achst einen neuen N EU in V ein und erzeugen |V |−1 KantenVorbereitung von N EU zu jedem v ∈ V \\{N EU }. Das Gewicht dieser Kanten ist 0. Zus¨atzlich f¨uhren wir f¨ur jeden Knoten v ∈ V eine H¨ohe h(v) ein und deﬁnieren eine neue Kantengewichtsfunktion ˆw((u, v)) := w((u, v)) + h(u) − h(v). Das Ziel ist es nun, die H¨ohen h(v) so zu w¨ahlen, dass die Kantengewichtsfunktion ˆw stets nicht-negativ ist. Unabh¨angig von der Wahl der H¨ohen h(v) beobachten wir, dass in dem GraphenNutzen der H¨ohen mit den neuen Kantengewichten ˆw((u, v)) folgende zwei Eigenschaften gelten: • Ein k¨urzester st-Pfad P = ⟨s, u1, . . . , uk, t⟩ in G = (V, E, w) ist auch ein k¨urzes- ter st-Pfad in G = (V, E, ˆw) (also in Bezug auf die neuen Kantengewichte). Es gilt n¨amlich ˆw(P ) = w(P ) + h(s) − h(t) (wobei wir vereinfachend ˆw(P ) und w(P ) schreiben, um die Gewichte von P bez¨uglich ˆw bzw. w anzugeben), da sich die H¨ohen der Zwischenknoten gegeneinander aufheben. Der Term ˆw(P ) h¨angt also nur von den H¨ohen des Start- und Zielknotens ab, und diese sind f¨ur alle st-Wege gleich. • Die Kosten eines Kreises K = ⟨u1, u2, . . . , uk, u1⟩ bleibt bez¨uglich w und ˆw gleich, es gilt also ˆw(K) = w(K). Als H¨ohe eines Knotens v w¨ahlen wir jetzt die L¨ange eines k¨urzesten Pfades vomWahl der H¨ohen neu eingef¨ugten Knoten N EU zu v. Dann n¨amlich ist h(v) ≤ h(u) + w((u, v)) (siehe Abbildung 5.15), und es gilt ˆw((u, v)) = w((u, v)) + h(u) − h(v) ≥ w((u, v)) + h(u) − (h(u) + w((u, v))) = 0. Folglich sind alle Kantengewichte ˆw((u, v)) nicht-negativ. 5.5 K¨urzeste Wege 123 Johnsons Algorithmus funktioniert also wie folgt: Algorithmus 1) F¨uge dem Graphen einen neuen Knoten N EU sowie Kanten (N EU, v) zu allen anderen Knoten v ∈ V \\{N EU } mit Gewicht 0 ein. 2) Benutze den Algorithmus von Bellman und Ford ausgehend von N EU zur Berechnung aller H¨ohen h(v). Falls dabei ein Kreis mit negativem Gewicht gefunden wird, melde dies und brich ab. 3) Berechne die neuen Kantengewichte ˆw((u, v)) = w((u, v)) + h(s) − h(t). 4) F¨ur jeden Knoten u ∈ V \\{N EU }, starte Dijkstras Algorithmus von u aus, um die Wege zu allen Knoten v ∈ V des Graphen zu berechnen. Danach m¨ussen nur noch die gefundenen Distanzen um h(u) − h(v) reduziert werden. Schritt 1 kostet Zeit O(|V |). Die Ausf¨uhrung des Algorithmus von Bellman und Ford Laufzeit kostet Zeit O(|V ||E|). Die neuen Kantengewichte ˆw((u, v)) k¨onnen in Zeit O(|E|) berechnet werden. In Schritt 4 wird Dijkstras Algorithmus |V | − 1 Mal ausgef¨uhrt, was insgesamt Zeit O(|V |2 log |V | + |V ||E|) dauert. Dies ist auch der dominierende Term in der Gesamtlaufzeit von Johnsons Algorithmus. Falls |E| ∈ o(|V |2) gilt, ist er damit also schneller als der Algorithmus von Floyd und Warshall.","libVersion":"0.3.1","langs":""}
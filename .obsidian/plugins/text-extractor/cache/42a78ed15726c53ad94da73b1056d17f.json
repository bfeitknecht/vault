{"path":"sem4/W&S/PV/summaries/W&S-pvw-script.pdf","text":"Wahrscheinlichkeit und Statistik PVW Script Last Updated: June, 2023 Authors: Jonathan Steffani luk@vis.ethz.ch Disclaimer: This script only serves as additional material for practice purposes and should not serve as a substitute for the lecture material. We neither guarantee that this script covers all relevant topics for the exam, nor that it is correct. If an attentive reader finds any mistakes or has any suggestions on how to improve the script, they are encouraged to contact the authors under the indicated email address or, preferably, through a gitlab issue https://gitlab.ethz. ch/vis/luk/pvw_script_wus. Inhaltsverzeichnis I Wahrscheinlichkeitstheorie 3 1 Grundbegriffe 3 2 Bedingte Wahrscheinlichkeiten 5 3 Unabh¨angigkeit 6 4 Zufallsvariablen und Verteilungsfunktionen 7 5 Typen von Verteilungen 7 5.1 Diskrete Verteilungen . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7 5.2 Stetige Verteilungen . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8 6 Der Erwartungswert 9 6.1 Der Erwartungswert einer diskreten Zufallsvariablen . . . . . . . . . . . . 9 6.2 Der Erwartungswert einer stetigen Zufallsvariablen . . . . . . . . . . . . . 10 6.3 Eigenschaften des Erwartungswertes . . . . . . . . . . . . . . . . . . . . 10 7 Varianz, Kovarianz und Korrelation 11 7.1 Die Varianz . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11 7.2 Die Kovarianz . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12 7.3 Die Korrelation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12 8 Gemeinsame Verteilungen 12 8.1 Gemeinsame Verteilungen von diskreten Zufallsvariablen . . . . . . . . . . 13 8.2 Gemeinsame Verteilungen von stetigen Zufallsvariablen . . . . . . . . . . 14 9 Das Gesetz der grossen Zahlen und der zentrale Grenzwertsatz 15 9.1 Das Gesetz der grossen Zahlen . . . . . . . . . . . . . . . . . . . . . . . 15 9.2 Der zentrale Grenzwertsatz . . . . . . . . . . . . . . . . . . . . . . . . . 16 II Statistik 17 10 Sch¨atzer 17 11 Die Maximum-Likelihood-Methode 19 12 Konfidenzintervalle 21 13 Approximative Konfidenzintervalle 23 14 Statistische Tests 24 14.1 Grundbegriffe . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24 14.2 Konstruktion von Tests: Das Neyman-Pearson-Lemma . . . . . . . . . . . 25 14.3 Der Binomialtest . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26 14.4 Der z-Test . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27 14.5 Der t-Test . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28 14.6 Der Vorzeichentest . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28 1 Wozu brauch ich das ganze? Das Ziel der Wahrscheinlichkeitstheorie ist, Zufallsexperimente mathematisch zu beschreiben, also Experimente, deren Ausgang nicht vorhersehbar ist (zum Beispiel M ¨unz- oder W ¨urfelw ¨urfe, die Ziehung der Lottozahlen, etc.). F ¨ur Informatiker besonders interessant sind randomisierte Algorithmen, also Algorithmen, die zuf¨allige Entscheidungen treffen und, bei geringer Fehler- wahrscheinlichkeit, eine gegen ¨uber deterministischen Algorithmen stark verbesserte Laufzeit haben. In der Statistik betrachten wir konkrete Zahlen (der Fachbegriff ist ”Daten”) und wir m¨ochten herausfinden, welcher zahlengenerierende Zufallsprozess uns diese Zahlen gegeben hat. Die statistischen Methoden finden Verwendung im Bereich Machine Learning. 2 I Wahrscheinlichkeitstheorie 1 Grundbegriffe Um ein Zufallsexperiment modellieren zu k¨onnen brauchen wir einen Wahrscheinlichkeit- sraum (Ω, F, P): • Ω ̸= ∅ ist eine Menge, genannt Grundraum. Ein Element ω ∈ Ω heisst Elementar- ereignis ”Ω = Menge aller m¨oglichen Ausg¨ange des Experiments” • F ⊆ P(Ω) ist eine Sigma-Algebra. Ein Element A ∈ F heisst Ereignis. ”F = Menge aller beobachtbaren Ausg¨ange des Experiments” Eine Sigma-Algebra erf ¨ullt die folgenden Eigenschaften: ⋆ Ω ∈ F ”Wir k¨onnen beobachten, ob irgendeiner der m¨oglichen Ausg¨ange des Experi- ments eingetreten ist” ⋆ A ∈ F =⇒ Ac ∈ F ”Wenn wir beobachten k¨onnen, ob das Ereignis A eingetreten ist, dann k¨onnen wir auch beobachten, ob das Ereignis A nicht eingetreten ist” ⋆ (Ai)i⩾1 ∈ F =⇒ ⋃ i⩾1 Ai ∈ F ”Wenn wir beobachten k¨onnen, ob das Ereignis A1, A2, ... jeweils eingetreten ist, dann k¨onnen wir auch beobachten, ob irgendeines der Ai, i ⩾ 1 eingetreten ist” • P : F → [0, 1] ist eine Abbildung, genannt Wahrscheinlichkeitsmass ”F ¨ur A ∈ F ist P[A] die Wahrscheinlichkeit daf ¨ur, dass das Ereignis A eintritt” Ein Wahrscheinlichkeitsmass erf ¨ullt folgende Eigenschaften: ⋆ P[Ω] = 1 ”Mit 100%-iger Wahrscheinlichkeit passiert irgendwas” ⋆ Wenn A = ⋃ i⩾1 Ai und Ai ∩Aj = ∅ f ¨ur alle i ̸= j, dann gilt P[A] = ∑ i⩾1 P[Ai] Was bedeutet es zu sagen, ”das Ereignis A ist eingetreten”? Wir f ¨uhren das Zufallsexperiment durch und bekommen ein zuf¨alliges Elementarereignis ω ∈ Ω. Die Wahrscheinlichkeit, ω zu erhalten, betr¨agt P[{ω}]. Wir unterscheiden die fol- genden F¨alle: • Wenn ω ∈ A, dann sagen wir ”das Ereignis A tritt ein” • Wenn ω /∈ A, dann sagen wir ”das Ereignis A tritt nicht ein” Ein besonders einfacher Wahrscheinlichkeitsraum ist das Laplace-Modell: • Ω ist endlich, das heisst |Ω| < ∞ 3 • F = P(Ω) • P : F → [0, 1], A ↦→ |A| |Ω| ”Alle Elementarereignisse ω ∈ Ω haben die gleiche Wahrscheinlichkeit P[{ω}] = 1 |Ω| ” Wir werfen zwei faire W ¨urfel, einen roten und einen gr ¨unen, und notieren jeweils das Ergeb- nis. (a) Gib einen geeigneten Wahrscheinlichkeitsraum (Ω, F, P) an. • Ω = {1, . . . , 6} 2 = {1, . . . , 6} ︸ ︷︷ ︸ roter W ¨urfel × {1, . . . , 6} ︸ ︷︷ ︸ gr ¨uner W ¨urfel = {(r, g) : r, g ∈ {1, . . . , 6}} • F = P(Ω) = {∅, {(1, 1)}, {(1, 5), (2, 4)}, {(1, 1), (2, 2), ..., (6, 6)} ︸ ︷︷ ︸ Ereignis ”Beide W ¨urfel zeigen gleiche Zahl” , ..., Ω} • P : F → [0, 1], A ↦→ |A| |Ω| = |A| 36 (b) Welches Element von F entspricht dem Ereignis A = ”Die Zahl auf dem gr ¨unen W ¨urfel ist um genau 3 gr¨osser als die Zahl auf dem roten W ¨urfel”? A = {(1, 4), (2, 5), (3, 6)} (c) Welches Element von F entspricht dem Ereignis B = ”Die Summe beider Augenzahlen ist gleich 6”? B = {(1, 5), (2, 4), (3, 3), (4, 2), (5, 1)} (d) Wir f ¨uhren das Experiment durch und erhalten das Elementarereignis (4, 4). Nenne drei Ereignisse, die eingetreten sind (also A ∈ F so dass (4, 4) ∈ A). • A = ”Beide W ¨urfel zeigen die gleiche Zahl” • B = {(4, 4)} • C = ”Die Summe der Augenzahlen ist gerade” (e) Wir nehmen nun an, dass eine Person mit rot-gr ¨un-Schw¨ache das Experiment durchf ¨uhrt. Wie lautet die Sigma-Algebra F ′, die alle f ¨ur diese Person beobachtbaren Ereignisse enth¨alt? Die Person kann Elementarereignisse wie zum Beispiel (1, 6) und (6, 1) nicht voneinander unterscheiden. Also muss f ¨ur A ∈ F ′ gelten: (r, g) ∈ A =⇒ (g, r) ∈ A. Wenn zum Beispiel (1, 2) ∈ A, dann muss auch (2, 1) ∈ A gelten. Also bekommen wir F ′ = {A ∈ F : (r, g) ∈ A ⇐⇒ (g, r) ∈ A}. Zum Beispiel gilt A = ”Die Augensumme beider W ¨urfel ist gleich 3” = {(1, 2), (2, 1)} ∈ F ′ 4 2 Bedingte Wahrscheinlichkeiten F ¨ur einen Wahrscheinlichkeitsraum (Ω, F, P) und zwei Ereignisse A und B mit P[B] > 0 ist P[A|B] = P[A∩B] P[B] die bedingte Wahrscheinlichkeit von A gegeben B. ”P[A|B] = Wahrscheinlichkeit, dass A eintritt wenn wir wissen, dass B eingetreten ist.” Im Allgemeinen gilt: P[A|B] ̸= P[B|A] und P[A|Bc] ̸= 1 − P[A|B]. Wir haben eine faire M ¨unze und zwei faire W ¨urfel. Ein W ¨urfel ist normal, der andere W ¨urfel ist speziell. Der spezielle W ¨urfel hat anstatt der ”6” eine ”7”. Wir werfen die M ¨unze. Zeigt sie Kopf, so werfen wir den normalen W ¨urfel, zeigt sie Zahl, so werfen wir den speziellen W ¨urfel. (a) Gib einen geeigneten Wahrscheinlichkeitsraum (Ω, F, P) an. Da sowohl die M ¨unze als auch die W ¨urfel fair sind ist jedes Elementarereignis gleich wahrscheinlich und wir k¨onnen das Laplace-Modell hernehmen: • Ω = {(K, 1), . . . , (K, 6), (Z, 1), . . . , (Z, 5), (Z, 7)} • F = P(Ω) • P : F → [0, 1], A ↦→ |A| |Ω| = |A| 12 (b) Definiere A = ”Der W ¨urfel zeigt eine 7” = {(Z, 7)} und B = ”Die M ¨unze zeigt Kopf” = {(K, 1), . . . , (K, 6)}. Vergleiche P[A] und P[A|B]. • P[A] = 1 12 • P[A|B] = P[A∩B] P[B] = 0 ”Die Information, dass B eingetreten ist, hat Auswirkungen auf die Wahrscheinlichkeit, dass A eintritt.” Der Satz der totalen Wahrscheinlichkeit Seien B1, ..., Bk disjunkte Ereignisse mit Ω = k⋃ i=1 Bi (B1, ..., Bk heisst auch Partition von Ω) und sei A ∈ F. Dann gilt P[A] = P [ k⋃ i=1 (A ∩ Bi) ] = k∑ i=1 P[A ∩ Bi] = k∑ i=1 P[A|Bi] · P[Bi] Meistens wird der Satz der totalen Wahrscheinlichkeit angewendet mit k = 2 und der Zer- legung Ω = B ∪ Bc f ¨ur ein Ereignis B ∈ F: P[A] = P[(A∩B)∪(A∩Bc)] = P[A∩B]+P[A∩Bc] = P[A|B]·P[B]+P[A|Bc]·P[Bc] Der Satz von Bayes Seien A und B zwei Ereignisse mit P[A], P[B] > 0. Dann gilt P[B|A] = P[B ∩ A] P[A] = P[A ∩ B] P[A] = P[A|B] · P[B] P[A] 5 3 Unabh¨angigkeit Zwei Ereignisse A und B sind unabh¨angig, falls P[A ∩ B] = P[A] · P[B]. Wenn A und B unabh¨angig sind, dann gilt P[A|B] = P[A ∩ B] P[B] = P[A] · P[B] P[B] = P[A] und P[B|A] = P[B] ”Ob A eintritt oder nicht hat keine Auswirkung auf die Wahrscheinlichkeit, dass B eintritt und umgekehrt.” [Fortsetzung von Beispiel 2] Wir betrachten dasselbe Beispiel wie in Kapitel 2. (c) Sind die Ereignisse A = ”Der W ¨urfel zeigt eine 7” = {(Z, 7)} und B = ”Die M ¨unze zeigt Kopf” = {(K, 1), . . . , (K, 6)} unabh¨angig? • P[A ∩ B] = 0 • P[A] · P[B] = 1 12 · 6 12 ̸= 0 Somit sind die Ereignisse nicht unabh¨angig. (d) Sind die Ereignisse C = ”Der W ¨urfel zeigt eine 5” = {(K, 5), (Z, 5)} und B unabh¨angig? • P[C ∩ B] = P[{(K, 5)}] = 1 12 • P[C] · P[B] = 2 12 · 6 12 = 1 12 Somit sind die Ereignisse unabh¨angig. Die Definition der Unabh¨angigkeit bei mehr als zwei Ereignissen ist etwas komplizierter. Sei (Ω, F, P) ein Wahrscheinlichkeitsraum. Eine Menge (Ai)1⩽i⩽n von Ereignissen heisst unabh¨angig wenn f ¨ur jedes Tupel (i1, . . . , ik) ⊆ {1, . . . , n} mit k ⩽ n und 1 ⩽ i1 < i2 < . . . < ik ⩽ n gilt P[Ai1 ∩ . . . ∩ Aik ] = P[Ai1] · . . . · P[Aik ]. Paarweise unabh¨angigkeit impliziert im Allgemeinen nicht Unabh¨angigkeit. Wir werfen einen fairen Tetraeder. Dieser hat vier Seitenfl¨achen. Jeweils eine Seite ist rot, gr ¨un und blau. Die vierte Seite zeigt alle drei Farben. Wir definieren die folgenden Ereignisse: • A1 = ”Der Tetraeder f¨allt auf eine Seite mit roter Farbe” • A2 = ”Der Tetraeder f¨allt auf eine Seite mit gr ¨uner Farbe” 6 • A3 = ”Der Tetraeder f¨allt auf eine Seite mit blauer Farbe” Es gilt P[A1] = P[A2] = P[A3] = 1 2 . Ausserdem gilt • P[A1 ∩ A2] = 1 4 = P[A1] · P[A2] • P[A1 ∩ A3] = 1 4 = P[A1] · P[A3] • P[A2 ∩ A3] = 1 4 = P[A2] · P[A3] und somit sind die Ereignisse paarweise unabh¨angig. Sie sind jedoch nicht unabh¨angig, denn es gilt P[A1 ∩ A2 ∩ A3] = 1 4 ̸= 1 8 = P[A1] · P[A2] · P[A3]. 4 Zufallsvariablen und Verteilungsfunktionen Eine Zufallsvariable X auf einem Wahrscheinlichkeitsraum (Ω, F, P) ist eine Abbildung X : Ω → R, die messbar ist, das heisst f ¨ur alle a ∈ R gilt {ω ∈ Ω : X(ω) ⩽ a} ∈ F. ”X(ω) ∈ R ist eine zuf¨allige Zahl. Ihr Wert h¨angt davon ab, welches Elementarereignis ω ∈ Ω realisiert wurde.” Die Messbarkeitsbedingung brauchen wir, weil wir sp¨ater Wahrscheinlichkeiten wie zum Beispiel P[X ⩽ a] = P[{ω ∈ Ω : X(ω) ⩽ a}] berechnen wollen. F ¨ur eine Zufallsvariable X auf einem Wahrscheinlichkeitsraum (Ω, F, P) definieren wir die Verteilungsfunktion von X als FX : R → [0, 1], FX (a) := P[X ⩽ a]. Die Verteilungsfunktion FX erf ¨ullt folgende Eigenschaften: • FX ist monoton steigend ”y1 ⩽ y2 =⇒ P[X ⩽ y1] ⩽ P[X ⩽ y2]” • FX ist rechtsstetig ”f ¨ur alle y ∈ R gilt lim ϵ↘0 P[X ⩽ y + ϵ] = P[X ⩽ y]” • lim y→−∞ FX (y) = 0, lim y→+∞ FX (y) = 1 ”P[X ⩽ −∞] = 0, P[X ⩽ +∞] = 1” Ausserdem sind die folgenden Rechenregeln sehr n ¨utzlich (a, b ∈ R mit a < b): • P[a < X ⩽ b] = P[X ⩽ b] − P[X ⩽ a] = F (b) − F (a) • P[X > b] = 1 − P[X ⩽ b] = 1 − F (b) Der Begriff der Unabh¨angigkeit l¨asst sich auch auf Zufallsvariablen ¨ubertragen. Zufallsvariablen X1, . . . , Xn auf einem Wahrscheinlichkeitsraum (Ω, F, P) heissen unabh¨angig, falls f ¨ur alle x1, . . . , xn ∈ R gilt P[X1 ⩽ x1, . . . , Xn ⩽ xn] = P[X1 ⩽ x1] · . . . · P[Xn ⩽ xn]. Wenn alle Zufallsvariablen zudem noch die gleiche Verteilungsfunktion haben, also FXi = FX f ¨ur alle i ∈ {1, . . . , n} gilt, dann heisst die Folge von Zufallsvariablen iid (independent and identically distributed). 5 Typen von Verteilungen 5.1 Diskrete Verteilungen Eine Zufallsvariable X : Ω → R heisst diskret, falls eine endliche oder abz¨ahlbar unendliche Menge W ⊆ R existiert so dass P[X ∈ W ] = 1. ”Wenn X eine diskrete Zufallsvariable ist, 7 dann k¨onnen wir eine (wom¨oglich unendlich lange) Liste schreiben mit allen Werten, die X annehmen kann.” Die Verteilung von X ist dann die Folge von Zahlen (p(x))x∈W mit p(x) = P[X = x] f ¨ur alle x ∈ W . Es gilt ∑ x∈W p(x) = 1 und FX (b) = ∑ x∈W,x⩽b p(x) f ¨ur alle b ∈ R. Beispiele f¨ur diskrete Verteilungen Die Bernoulli-Verteilung Sei p ∈ [0, 1] der Erfolgsparameter. X ∼ Ber(p), wenn W = {0, 1}, P[X = 1] = p und P[X = 0] = 1 − p gilt. ”X ∼ Ber(p) =⇒ X beschreibt den Ausgang eines Experiments mit zwei m¨oglichen Ausg¨angen und ’Erfolgswahrscheinlichkeit’ p”. Die Binomialverteilung Sei wieder p ∈ [0, 1] der Erfolgsparameter und sei n ∈ N. X ∼ Bin(n, p), wenn W = {0, 1, . . . , n} und f ¨ur alle k ∈ W gilt P[X = k] = (n k)p k(1 − p) n−k. (n k) = n! k!(n−k)! = Anzahl M¨oglichkeiten, aus einer Urne mit n Kugeln (= Experimenten) k Kugeln (= Erfolge) zu ziehen, ohne Zur ¨ucklegen und ohne Beachtung der Reihenfolge. X ∼ Bin(n, p) =⇒ X d = X1 + . . . + Xn, wobei X1, . . . , Xn iid ∼ Ber(p). ”X ∼ Bin(n, p) =⇒ X beschreibt die Anzahl Erfolge bei n-maligem Durchf ¨uhren eines Bernoulli-Experiments mit Erfolgswahrscheinlichkeit p.” Die geometrische Verteilung Sei p ∈ [0, 1]. X ∼ Geom(p), wenn W = {1, 2, 3, . . .} und f ¨ur alle k ⩾ 1 gilt P[X = k] = (1 − p)k−1 ︸ ︷︷ ︸ k−1M isserf olge · p ︸︷︷︸ 1Erf olg . ”X ∼ Geom(p) beschreibt die Anzahl Wiederholungen von unabh¨angigen Ber(p)-Experimenten bis zum ersten Erfolg.” Die Poisson-Verteilung Sei λ > 0. X ∼ P oi(λ), wenn W = {0, 1, 2, . . .} und f ¨ur alle k ⩾ 0 gilt P[X = k] = e−λ λk k! Wenn X ∼ P oi(λ1) und Y ∼ P oi(λ2) und X und Y unabh¨angig sind, dann gilt X + Y ∼ P oi(λ1 + λ2) 5.2 Stetige Verteilungen Eine Zufallsvariable X : Ω → R heisst stetig, falls ihre Verteilungsfunktion FX geschrieben werden kann als FX (a) = ∫ a −∞ f (x) dx f ¨ur alle a ∈ R, wobei f : R → R eine nicht- negative Funktion ist, genannt Dichte von X. 8 Mithilfe der Dichtefunktion k¨onnen wir durch Integrieren Wahrscheinlichkeiten berech- nen: P[a ⩽ X ⩽ b] = ∫ b a f (x) dx Wenn X eine stetige Zufallsvariable ist, dann gilt f ¨ur alle a ∈ R: P[X = a] = lim ϵ↘0 P[a ⩽ X ⩽ a + ϵ] = lim ϵ↘0 ∫ a+ϵ a f (z) dz = ∫ a a f (z) dz = 0. Beispiele f¨ur stetige Verteilungen Die Gleichverteilung Sei a < b. X ∼ U([a, b]), wenn f (x) = { 1 b−a ,falls x ∈ [a, b] 0 , sonst die Dichte von X ist. ”f ist auf [a, b] konstant =⇒ Die Gleichverteilung bevorzugt keine Region auf [a, b].” Die Normalverteilung Sei m ∈ R, σ2 > 0. X ∼ N (m, σ2), wenn f (x) = 1√2πσ e− (x−m)2 2σ2 die Dichte von X ist. Seien m0, m1, . . . , mn, λ1, . . . , λn ∈ R und seien σ2 1, . . . , σ2 n > 0. Wenn X1 ∼ N (m1, σ2 1), . . . , Xn ∼ N (mn, σ2 n) unabh¨angig sind, dann gilt: m0 + λ1X1 + . . . + λnXn ∼ N (m0 + λ1m1 + . . . + λnmn, λ 2 1σ2 1 + . . . + λ 2 nσ2 n). Die Exponentialverteilung Sei λ > 0. X ∼ Exp(λ), wenn f (x) = {0 , wenn x < 0 λe−λx , wenn x ⩾ 0 die Dichte von X ist. 6 Der Erwartungswert Wir betrachten das Konzept des Erwartungswertes einer Zufallsvariablen getrennt f ¨ur diskrete und stetige Zufallsvariablen. 6.1 Der Erwartungswert einer diskreten Zufallsvariablen F ¨ur eine diskrete Zufallsvariable X : Ω → R mit Werten in W ist der Erwartungswert von X definiert als E[X] = ∑ x∈W x · P[X = x]. ”E[X] ist der durchschnittliche Wert, den die Zufallsvariable X annimmt, wenn wir das Experiment unendliche oft wiederholen.” Sei X ∼ Ber(p). Dann gilt E[X] = 0 · P[X = 0] + 1 · P[X = 1] = 0 · (1 − p) + 1 · p = p. Sei A ∈ F ein Ereignis. Die Funktion 1 A : Ω → R, 1 A(ω) = { 0 , wenn ω /∈ A 1 , wenn ω ∈ A ist eine Zufallsvariable. ”Es gilt 1 A = 1 genau dann, wenn das Ereignis A eintritt.” Es gilt 9 • P[1 A = 1] = P[A] • P[1 A = 0] = P[Ac] = 1 − P[A] und deshalb 1 A ∼ Ber(P[A]), woraus wir mithilfe von Beispiel 6.1 folgern, dass E[1 A] = P[A]. F ¨ur eine diskrete Zufallsvariable X mit Werten in einer Menge W k¨onnen wir auch Er- wartungswerte der Form zum Beispiel E[X 2] oder E[e−X ] berechnen: • E[X 2] = ∑ x∈W x 2 · P[X = x] • E [ e−X ] = ∑ x∈W e−x · P[X = x] 6.2 Der Erwartungswert einer stetigen Zufallsvariablen F ¨ur eine stetige Zufallsvariable X : Ω → R mit Dichte f ist der Erwartungswert von X definiert als E[X] = ∫ ∞ −∞ xf (x) dx. Analog zu Bemerkung 6.1 gilt: E[X 2] = ∫ ∞ −∞ x2f (x) dx, E [ e−X ] = ∫ ∞ −∞ e−xf (x) dx, . . . 6.3 Eigenschaften des Erwartungswertes Wie berechnet man nun kompliziertere Erwartungswerte wie etwa E[2X 2 + 5Y ]? Das fol- gende Theorem ist daf ¨ur sehr hilfreich. Seien X, Y : Ω → R Zufallsvariablen und sei λ ∈ R. Dann gilt E[λX + Y ] = λE[X] + E[Y ]. Sei n ⩾ 1, sei p ∈ [0, 1] und sei X ∼ Bin(n, p). Was ist E[X]? • Nach Bemerkung 5.1 gilt X d = X1 + . . . + Xn, wobei X1, . . . , Xn iid ∼ Ber(p). • Mit Theorem 6.3 und Beispiel 6.1 gilt nun E[X] = E[X1 + . . . + Xn] = E[X1] + . . . + E[Xn] = p + . . . + p ︸ ︷︷ ︸ n Mal = np. Auch das folgende Theorem ist sehr n ¨utzlich. F ¨ur zwei Zufallsvariablen X : Ω → R und Y : Ω → R, die unabh¨angig sind, gilt E[XY ] = E[X]E[Y ]. Die folgende Gleichung heisst Tailsum-Formel und kann auch n ¨utzlich sein, um Erwartungswerte von bestimmten Zufallsvariablen zu berechnen. [Tailsum-Formel] Sei X : Ω → R eine diskrete Zufallsvariable mit Werten in {0, 1, 2, . . .}. Dann gilt E[X] = ∑ n⩾1 P[X ⩾ n]. 10 7 Varianz, Kovarianz und Korrelation 7.1 Die Varianz Sei X : Ω → R eine Zufallsvariable mit E[X 2] < ∞. Die Varianz von X ist definiert als σ2 X = Var[X] = E[(X − E[X]) 2]. ”X ist im Durchschnitt σ2 X von seinem Erwartungswert entfernt.” Es gilt Var[a + bX] = b2Var[X] f ¨ur alle a, b ∈ R. Die Formel in Definition 7.1 ist eher m ¨uhsam zum Berechnen der Varianz. Daf ¨ur eignet sie sich gut, um eine Intuition zu bekommen, was genau die Varianz eigentlich ist. Die folgende Formel eigenet sich besser f ¨ur konkrete Berechnungen: Var[X] = E[(X−E[X]) 2] = E[X 2−2XE[X]+E[X] 2] = E[X 2]−2E[X]E[X]+E[X] 2 = E[X 2]−E[X] 2 Sei X : Ω → R eine Zufallsvariable mit E[X 2] < ∞. Die Standardabweichung von X ist definiert als σX = √ Var[X]. Erwartungswert und Varianz der wichtigsten Verteilungen X ∼ E[X] Var[X] Ber(p) p p(1 − p) Bin(n, p) np np(1 − p) Geom(p) 1 p 1−p p2 P oi(λ) λ λ U([a, b]) a+b 2 (b−a)2 12 N (m, σ2) m σ2 Exp(λ) 1 λ 1 λ2 Ein paar wichtige Ungleichungen Die Markov-Ungleichung Sei X : Ω → R eine nicht-negative Zufallsvariable (das heisst, P[X ⩾ 0] = 1) und sei a > 0. Dann gilt P[X ⩾ a] ⩽ E[X] a . Die Jensen-Ungleichung Sei X : Ω → R eine Zufallsvariable und sei ϕ : R → R eine konvexe Funktion. Dann gilt ϕ(E[X]) ⩽ E[ϕ(X)]. W¨ahle ϕ : R → R, ϕ(x) = x2 als konvexe Funktion und erhalte E[X] 2 = ϕ(E[X]) ⩽ E[ϕ(X)] = E[X 2]. Wenn ϕ : R → R eine konkave Funktion ist, dann ist −ϕ eine konvexe Funktion und wir erhalten ϕ(E[X]) ⩾ E[ϕ(X)]. 11 Die Cauchy-Schwarz-Ungleichung Seien X, Y : Ω → R Zufallsvariablen mit E[X 2], E[Y 2] < ∞. Dann gilt E[XY ] ⩽ √E[X 2]E[Y 2]. Die Chebychev-Ungleichung Sei X : Ω → R eine Zufallsvariable mit E[X 2] < ∞ und sei a ⩾ 0. Dann gilt P[∣ ∣X − E[X] ∣ ∣ ⩾ a] ⩽ Var[X] a2 . ”Wenn die Varianz klein ist, dann entfernt sich X nur mit geringer Wahrscheinlichkeit weit weg von seinem Erwartungswert.” 7.2 Die Kovarianz Seien X : Ω → R und Y : Ω → R Zufallsvariablen mit E[X 2] < ∞ und E[Y 2] < ∞. Die Kovarianz zwischen X und Y ist definiert als Cov(X, Y ) = E[XY ] − E[X]E[Y ]. ”Cov(X, Y ) beschreibt die Abh¨angigkeit zwischen X und Y .” Es gilt Cov(X, X) = E[X 2] − E[X]2 = Var[X]. Es gilt: X und Y unabh¨angig =⇒ E[XY ] = E[X]E[Y ] =⇒ Cov(X, Y ) = E[XY ]−E[X]E[Y ] = 0 Aber: Cov(X, Y ) = 0 ̸=⇒ X und Y unabh¨angig Zum Beispiel gilt mit X ∼ N (0, 1) und Y = X 2: Cov(X, Y ) = E[XY ] − E[X] ︸ ︷︷ ︸ =0 E[Y ] = E[XY ] = E[X 3] = 0, aber X und Y sind abh¨angig. F ¨ur zwei Zufallsvariablen X und Y gilt Var[X + Y ] = Var[X] + Var[Y ] + 2Cov(X, Y ). 7.3 Die Korrelation F ¨ur zwei Zufallsvariablen X und Y ist die Korrelation von X und Y definiert als ρ(X, Y ) = Corr(X, Y ) = Cov(X, Y ) σX σY . ”ρ(X, Y ) ist ein Mass f ¨ur den linearen Zusammenhang zwischen X und Y .” 8 Gemeinsame Verteilungen Das Ziel von gemeinsamen Verteilungen ist es, das Verhalten von mehreren Zufallsvariablen zusammen zu beschreiben. Wir unterscheiden hierf ¨ur wieder die beiden F¨alle von diskreten und stetigen Zufallsvariablen. 12 8.1 Gemeinsame Verteilungen von diskreten Zufallsvariablen Seien X1, . . . , Xn Zufallsvariablen und seien W1, . . . , Wn ⊆ R abz¨ahlbare Teilmengen so dass f ¨ur alle 1 ⩽ i ⩽ n gilt, P[Xi ∈ Wi] = 1 oder ander gesagt, Xi ∈ Wi fast sicher. Die gemeinsame Verteilung des Zufallsvektors (X1, . . . , Xn) ist definiert als die Menge der Zahlen (p (x1, . . . , xn) ) xi∈Wi, wobei p(x1, . . . , xn) = P[X1 = x1, . . . , Xn = xn]. Es gilt ∑ xi∈Wi p(x1, . . . , xn) = 1. Wenn wir die Verteilung von (X1, . . . , Xn) kennen, dann k¨onnen wir die Randverteilungen der einzelnen Xi berechnen: F ¨ur i ∈ {1, . . . , n}, z ∈ Wi gilt P[X = z] = ∑ x1∈W1,...,xi−1∈Wi−1,xi+1∈Wi+1,...,xn∈Wn p(x1, . . . , xi−1, z, xi+1, . . . , xn) Aus der gemeinsamen Verteilung kann man immer die Randverteilungen bestimmen. Je- doch kann man umgekehrt aus den Randverteilungen im Allgemeinen nicht die gemeinsame Verteilung bestimmen. Das geht nur, wenn die einzelnen Komponenten des Zufallsvektors unabh¨angig sind. Wir k¨onnen aus der gemeinsamen Verteilung von X1, . . . , Xn ablesen, ob die einzelnen Komponenten X1, . . . , Xn des Vektors unabh¨angig sind: X1, . . . , Xn sind unabh¨angig ⇐⇒ p(x1, . . . , xn) = P[X1 = x1] · · · P[Xn = xn] f ¨ur alle x1 ∈ Wi, . . . , xn ∈ Wn Betrachte zwei diskrete Zufallsvariablen X und Y , die nur die Werte 1, 2 und 3 annehmen k¨onnen (das heisst, WX = WY = {1, 2, 3}). Die folgende Tabelle zeigt die gemeinsame Verteilung des Zufallsvektors (X, Y ): X\\Y 1 2 3 1 11.6% 4.5% 7.6% 2 7.1% 46.0% 7.6% 3 4.5% a 9.8% So gilt zum Beispiel p(3, 1) = P[X = 3, Y = 1] = 0.045. (a) Bestimme den Wert von a. 1 = ∑ x,y∈{1,2,3} p(x, y) = 11.6% + 7.1% + 4.5% + 4.5% + 46% + a + 7.6% + 7.6% + 9.8% = 98.7% + a =⇒ a = 1.3% (b) Bestimme die Randverteilungen von X und Y . • P[X = 1] = ∑ y∈{1,2,3} p(1, y) = 11.6% + 4.5% + 7.6% = 23.7% • P[X = 2] = ∑ y∈{1,2,3} p(2, y) = 7.1% + 46% + 7.6% = 60.7% • P[X = 3] = ∑ y∈{1,2,3} p(3, y) = 4.5% + 1.3% + 9.8% = 15.6% • P[Y = 1] = ∑ x∈{1,2,3} p(x, 1) = 11.6% + 7.1% + 4.5% = 23.2% 13 • P[Y = 2] = ∑ x∈{1,2,3} p(x, 2) = 4.5% + 46% + 1.3% = 51.8% • P[Y = 3] = ∑ x∈{1,2,3} p(x, 3) = 7.6% + 7.6% + 9.8% = 25% (c) Sind X und Y unabh¨angig? Nein. p(3, 2) = 1.3%, aber P[X = 3]·P[Y = 2] = 0.156·0.518 ≈ 0.081 = 8.1% 8.2 Gemeinsame Verteilungen von stetigen Zufallsvariablen Zufallsvariablen X1, . . . , Xn haben eine gemeinsame Dichtefunktion, wenn es eine Funk- tion f : Rn → R+ gibt so dass P [X1 ⩽ a1, . . . , Xn ⩽ an] = ∫ a1 −∞ · · · ∫ an −∞ f (x1, . . . , xn) dxn · · · dx1 f ¨ur alle a1, . . . , an ∈ R. Analog zu Bemerkung 8.1 gilt ∫ ∞ −∞ · · · ∫ ∞ −∞ f (x1, . . . , xn) dxn · · · dx1 = 1. Die Dichten der einzelnen Xi heissen Randdichten. Randdichten werden ¨ahnlich berechnet wie im diskreten Fall, die Intuition dahinter ist dieselbe. Wenn X und Y Zufallsvariablen sind mit gemeinsamer Dichte fX,Y , dann gilt f ¨ur die Rand- dichten fX und fY von X und Y : fX (x) = ∫ ∞ −∞ fX,Y (x, y) dy und fX (x) = ∫ ∞ −∞ fX,Y (x, y) dx. Analog zu Bemerkung 8.1 k¨onnen wir aus der gemeinsamen Dichte stets die Randdichten bestimmen, jedoch k¨onnen wir aus den Randdichten die gemeinsame Dichte nur dann bes- timmen, wenn die Komponenten des Zufallsvektors unabh¨angig sind. Auch die Unabh¨angigkeitsbedingung ist sehr ¨ahnlich zum diskreten Fall: X1, . . . , Xn sind unabh¨angig ⇐⇒ Eine gemeinsame Dichte fX1,...,Xn von X1, . . . , Xn existiert und es gilt fX1,...,Xn (x1, . . . , xn) = fX1(x1) · · · fXn (xn) f ¨ur alle x1, . . . , xn ∈ R Die gemeinsame Dichte von zwei Zufallsvariablen X und Y ist konstant gleich c auf dem Dreieck D und gleich 0 ausserhalb: 14 (a) Bestimme die gemeinsame Dichte fX,Y . • fX,Y (x, y) = c1 {(x,y)∈D} • 1 = ∫ D c1 {(x,y)∈D} dx dy = c · Fl¨ache(D) ︸ ︷︷ ︸ =1 = c =⇒ c = 1 (b) Bestimme die Randdichten von X und Y . • Die Randdichte von X ist fX (x) = ∫ ∞ −∞ fX,Y (x, y) dy =    0 f ¨ur x < −1 oder x ⩾ 1 ∫ x+1 0 1 dy = x + 1 f ¨ur − 1 ⩽ x < 0 ∫ −x+1 0 1 dy = 1 − x f ¨ur 0 ⩽ x < 1 • Die Randdichte von Y ist fY (y) = ∫ ∞ −∞ fX,Y (x, y) dx = { 0 f ¨ur y < 0 oder y ⩾ 1 ∫ 1−y y−1 1 dx = 1 − y − (y − 1) = 2(1 − y) f ¨ur 0 ⩽ y < 1 (c) Sind X und Y unabh¨angig? Nein. fX,Y (0, 0) = 1, aber fX (0) · fY (0) = 1 · 2 = 2. 9 Das Gesetz der grossen Zahlen und der zentrale Gren- zwertsatz 9.1 Das Gesetz der grossen Zahlen Gegeben ”zuf¨allige Vorzeichen”, also iid Zufallsvariablen Z1, Z2, . . . mit P[Z1 = 1] = P[Z1 = −1] = 1 2 , was k¨onnen wir ¨uber n∑ k=1 Zk k sagen f ¨ur n → ∞? 15 [Das (starke) Gesetz der grossen Zahlen] Seien X1, X2, . . . iid Zufallsvariablen mit E[|X1|] < ∞. Es gilt: lim n→∞ 1 n n∑ i=1 Xi = E[X1] P-fast-sicher ”E[X] ist der ’Mittelwert’ von unendlich vielen unabh¨angigen Realisierungen von X.” Angewendet auf die Frage am Beginn des Kapitels gibt das starke Gesetz der grossen Zahlen: lim n→∞ n∑ k=1 Zk k = E[Z1] = 1 · 1 2 + (−1) · 1 2 = 0 9.2 Der zentrale Grenzwertsatz Der zentrale Grenzwertsatz zeigt uns, dass die Normalverteilung eine besondere Rolle in der Wahrscheinlichkeitstheorie innehat. [Der zentrale Grenzwertsatz] Seien X1, X2, . . . iid Zufallsvariablen mit E[X 2 1 ] < ∞. Definiere Sn = X1 + . . . + Xn, n ⩾ 1. Es gilt: P [ Sn − n · E[X1] √ n · Var[X1] ⩽ a ] n→∞ −−−−→ Φ(a) = ∫ a −∞ 1 √2π e− x2 2 dx (” = P[N (0, 1) ⩽ a]”) f ¨ur alle a ∈ R ”F ¨ur grosse n ist Sn−n·E[X1]√n·Var[X1] ungef¨ahr N (0, 1)-verteilt.” Auf einen LKW werden 500 Zements¨acke aufgeladen. Die Masse eines Zementsackes ist gleichverteilt zwischen 18kg und 22kg. Sch¨atze die Wahrscheinlichkeit ab, dass der LKW seine maximal zul¨assige Nutzlast von 10.5t ¨uberschreitet. • Sei Xi die Masse des i-ten Sackes (i = 1, . . . , 500). Es gilt X1, . . . , X500 iid ∼ U([18, 22]). • S500 = X1 + . . . + X500 ist das Gesamtgewicht der Zements¨acke. • E[X 2 1 ] = ∫ 22 18 1 22−18 x2 dx = 22 3−18 3 3·(22−18) < ∞ =⇒ Wir d ¨urfen den zentralen Grenzwertsatz anwenden. • E[X1] = 18+22 2 = 20, Var[X1] = (22−18) 2 12 = 4 3 • Mit dem zentralen Grenzwertsatz folgt nun: S500−500·20√500· 4 3 ≈ N (0, 1) • Gesucht ist nun P[S500 > 10′500] = 1 − P[S500 ⩽ 10 ′500]. • P[S500 ⩽ 10 ′500] = P[S500 − 500 · 20 ⩽ 10′500 − 500 · 20] = P [ S500−500·20√500· 4 3 ⩽ 10 ′500−500·20√500· 4 3 ] = P [ S500−500·20√500· 4 3 ⩽ 500√ 2000 3 ] ≈ Φ( 500√ 2000 3 ) = Φ(19.4) ⩾ Φ(3.49) = 0.9997585 • Somit bekommen wir P[S500 > 10 ′500] ⩽ 1 − 0.9997585 = 0.02415%. 16 II Statistik Worin unterscheidet sich die Statistik von der Wahrscheinlichkeits- theorie? In der Wahrscheinlichkeitstheorie haben wir einen bekannten zahlengenerierenden Formal- ismus und m¨ochten untersuchen, wie sich dieser typischerweise verh¨alt, also welche Zahlen der Formalismus typischerweise ausgibt. Wenn wir beispielsweise einen fairen W ¨urfelwurf betrachten, dann haben wir iid Zufallsvariablen X1, X2, . . . mit P[X1 = 1] = . . . = P[X1 = 6] = 1 6 und k¨onnen uns fragen, mit welcher Wahrscheinlichkeit die Augensumme der ersten drei W ¨urfe durch neun teilbar ist, wie oft man im Durchschnitt werfen muss, um zweimal die Zahl sechs zu sehen, etc. In der Statistik bekommen wir Daten x1, . . . , xn, die wir als Realisierungen von Zufallsvari- ablen X1, . . . , Xn auffassen, also als konkrete Zahlen. Wir m¨ochten nun untersuchen, welcher zahlengenerierende Formalismus dahintersteckt. Als Beispiel k¨onnten wir 100 Mal eine M ¨unze werfen, 80 Mal Kopf beobachten und uns fragen, ob die M ¨unze fair ist oder nicht. In diesem Fall bekommen wir die Zahlen und fragen uns, welcher zahlengenerierende Formalismus uns diese Zahlen gegeben hat, der einer fairen M ¨unze oder der einer unfairen M ¨unze. 10 Sch¨atzer F ¨ur das Set-Up brauchen wir Folgendes: • Einen Grundraum mit Sigma-Algebra (Ω, F) • Einen Parameterraum Θ ⊆ R ”Θ gibt an, in welchem Bereich der unbekannte Paremeter, nach dem wir suchen, liegt.” • Eine Familie von Wahrscheinlichkeitsmassen (Pϑ)ϑ∈θ • Zufallsvariablen X1, . . . , Xn Wir haben nun Daten x1 = X1(ω), x2 = X2(ω), . . . , xn = Xn(ω), die von einem unbekannten Parameter ϑ ∈ Θ abh¨angen. Wir betrachten einen M ¨unzwurf mit unbekanntem Erfolgsparameter p ∈ [0, 1]. In diesem Fall haben wir • Θ = [0, 1] • Pϑ = Pp • X1, . . . , Xn iid ∼ Ber(p) unter Pp Unser Ziel ist nun, den unbekannten Parameter ϑ ∈ Θ anhand der Daten x1, . . . , xn zu sch¨atzen. Ein Sch¨atzer ist eine Zufallsvariable ˆϑ : Ω → R. ˆϑ = ˆϑ(x1, . . . , xn) nimmt unsere Daten und liefert eine Ann¨aherung des Parameters ϑ. [Fortsetzung von Beispiel 10] In Beispiel 10 w¨are ˆp = ˆp(X1, . . . , Xn) = 1 n n∑ i=1 Xi 17 ein Sch¨atzer f ¨ur p. Ein Sch¨atzer ˆϑ heisst erwartungstreu f ¨ur den Parameter ϑ, falls Eϑ[ ˆϑ] = ϑ gilt. ”Wenn ˆϑ erwartungstreu ist, dann gibt uns dieser Sch¨atzer nach unendlich vielen Realisierungen von X1, . . . , Xn im Durchschnit den richtigen Parameter ϑ heraus.” Der Ausdruck Eϑ[ ˆϑ] bedeutet, dass wir bei der Berechnung des Erwartungswertes davon ausgehen, dass ϑ ∈ Θ der wahre parameter unseres Modells ist. [Fortsetzung von Beispiel 10] F ¨ur den Sch¨atzer ˆp = ˆp(X1, . . . , Xn) = 1 n n∑ i=1 Xi aus Beispiel 10 gilt Ep[ˆp(X1, . . . , Xn)] = Ep [ 1 n n∑ i=1 Xi ] = 1 n n∑ i=1 Ep[Xi] ︸ ︷︷ ︸ =p = 1 n · n · p = p und deshalb ist ˆp erwartungstreu f ¨ur p. Der Bias von ˆϑ ist gegeben durch Eϑ[ ˆϑ] − ϑ. Wenn ˆϑ erwartungstreu ist, dann ist der Bias gleich null. Der mittlere quadratische Sch¨atzfehler (MSE) von ˆϑ ist gegeben durch M SEϑ[ ˆϑ] = Eϑ[( ˆϑ− ϑ)2]. ”Der M SE gibt an, wie sehr der Sch¨atzer im Durchschnitt danebenliegt.” Wir k¨onnen den M SE darstellen als die Summe der Varianz und des Bias des Sch¨atzers: M SEϑ[ ˆϑ] = Eϑ[( ˆϑ − ϑ)2] = Eϑ[( ˆϑ − Eϑ[ ˆϑ] + Eϑ[ ˆϑ] − ϑ) 2] = Eϑ[( ˆϑ − Eϑ[ ˆϑ]) 2] + 2Eϑ[( ˆϑ − Eϑ[ ˆϑ])(Eϑ[ ˆϑ] − ϑ)] + Eϑ[(Eϑ[ ˆϑ] − ϑ) 2] = Varϑ[ ˆϑ] + (Eϑ[ ˆϑ] − ϑ) 2 ︸ ︷︷ ︸ =Bias2 , wobei wir verwendet haben, dass 2Eϑ[( ˆϑ−Eϑ[ ˆϑ])(Eϑ[ ˆϑ]−ϑ)] = 2(Eϑ[ ˆϑ]−ϑ)Eϑ[ ˆϑ−Eϑ[ ˆϑ]] = 2(Eϑ[ ˆϑ]−ϑ) (Eϑ[ ˆϑ] − Eϑ[ ˆϑ]) ︸ ︷︷ ︸ =0 = 0 gilt. [Fortsetzung von Beispiel 10] F ¨ur unseren Sch¨atzer ˆp bekommen wir: M SEp[ˆp] = Varp[ˆp]+bias 2 ︸ ︷︷ ︸ =0 = Varp [ 1 n n∑ i=1 Xi ] =︸︷︷︸ U nabh¨angigkeit 1 n2 n∑ i=1 Varp[Xi] ︸ ︷︷ ︸ =p(1−p) = p(1 − p) n n→∞ −−−−→ 0 Das bedeutet, je gr¨osser unsere Stichprobe ist, desto genauer ist auch unsere Sch¨atzung. Wir schauen uns nun noch einen zweiten Sch¨atzer f ¨ur p an: p ′(X1, . . . , Xn) = X1 + Xn 2 Ist p ′ erwartungstreu? Ep[p′] = Ep [ X1 + Xn 2 ] = 1 2 ( Ep[X1] ︸ ︷︷ ︸ =p + Ep[Xn] ︸ ︷︷ ︸ =p ) = 1 2 ·2p = p =⇒ p ′ ist erwartungstreu. 18 Wie gross ist M SEp[p′]? M SEp[p′] = Varp[p′]+bias 2 ︸ ︷︷ ︸ =0 = Varp [ X1 + Xn 2 ] =︸︷︷︸ U nabh¨angigkeit 1 4 ( Varp[X1] ︸ ︷︷ ︸ =p(1−p) + Varp[Xn] ︸ ︷︷ ︸ =p(1−p) ) = p(1 − p) 2 . Der Sch¨atzer ˆp ist also ”besser” als der Sch¨atzer p ′ in dem Sinne, dass sein mittlerer quadratis- cher Sch¨atzfehler mit zunehmender Stichprobengr¨osse immer kleiner wird. Der zweite Sch¨atzer nimmt immer nur den ersten und den letzten Datenpunkt f ¨ur seine Sch¨atzung und daher bleibt sein M SE mit zunehmender Stichprobengr¨osse konstant. 11 Die Maximum-Likelihood-Methode In diesem Kapitel lernen wir eine Methode, einen Sch¨atzer zu konstruieren. Wir haben Daten x1, . . . , xn, die wir als Realisierungen von iid Zufallsvariablen X1, . . . , Xn betra- chten. Die Verteilung der Zufallsvariablen h¨angt von einem unbekannten Parameter ϑ ∈ Θ ab. Wir m¨ochten nun einen Sch¨atzer f ¨ur ϑ konstruieren so dass die beobachteten Daten so plausibel wie m¨oglich erscheinen. Dieser Sch¨atzer heisst Maximum-Likelihood-Sch¨atzer. Die Vorgehensweise ist folgende: 1. Bestimme die Likelihood-Funktion: Wenn X1, . . . , Xn diskrete Zufallsvariablen sind: L(x1, . . . , xn; ϑ) = Pϑ[X1 = x1, . . . , Xn = xn] =︸︷︷︸ U nabh¨angigkeit n∏ i=1 Pϑ[Xi = xi] Wenn Xi, . . . , Xn stetige Zufallsvariablen mit Dichte fX sind: L(x1, . . . , xn; ϑ) = f(X1,...,Xn)(x1,...,xn;ϑ) =︸︷︷︸ U nabh¨angigkeit n∏ i=1 fX (xi; ϑ) 2. Finde ˆϑ ∈ Θ so dass L(x1, . . . , xn; ˆϑ) = max ϑ∈Θ L(x1, . . . , xn; ϑ). ˆϑ ist der Maximum- Likelihood-Sch¨atzer (MLE) f ¨ur ϑ. Die Frage ist nun, wie man den Maximierer ˆϑ findet. Oft kann man die Log-Likelihood- Funktion l(x1, . . . , xn; ϑ) = log(L(x1, . . . , xn; ϑ)) nach ϑ ableiten, gleich null setzen und nach ϑ aufl¨osen. Seien X1, . . . , Xn iid ∼ Ber(p) mit p ∈ [0, 1]. Seien x1, . . . , xn Realisierungen von X1, . . . , Xn. Finde den MLE von p. 1. Likelihood-Funktion: L(x1, . . . , xn; p) = n∏ i=1 Pp[Xi = xi] ︸ ︷︷ ︸ =pxi (1−p)1−xi = n∏ i=1 p xi(1−p)1−xi = p n∑ i=1 xi(1−p) n− n∑ i=1 xi 19 2. Likelihood-Funktion bez ¨uglich p maximieren: l(x1, . . . , xn; p) = log(L(x1, . . . , xn; p)) = log (p n∑ i=1 xi(1 − p)n− n∑ i=1 xi) = n∑ i=1 xi · log(p) + ( n − n∑ i=1 xi ) · log(1 − p) d dp l(x1, . . . , xn; p) = n∑ i=1 xi · 1 p − (n − n∑ i=1 xi ) · 1 1 − p = 0 ⇐⇒ n∑ i=1 xi · 1 p = (n − n∑ i=1 xi ) · 1 1 − p ⇐⇒ n∑ i=1 xi · (1 − p) = ( n − n∑ i=1 xi ) · p ⇐⇒ n∑ i=1 xi − p n∑ i=1 xi = np − p n∑ i=1 xi ⇐⇒ p = 1 n n∑ i=1 xi Jetzt m ¨ussen wir noch sicherstellen, dass der Extremwert p = 1 n n∑ i=1 xi ein Maximum ist: d 2 dp2 l(xi, . . . , xn; p) = − 1 p2 n∑ i=1 xi − 1 (1 − p)2 (n − n∑ i=1 xi ) ⩽ 0 und deshalb ist ˆp(X1, . . . , Xn) = 1 n n∑ i=1 Xi der Maximum-Likelihood Sch¨atzer f ¨ur p. Die Strategie, die Log-Likelihood-Funktion abzuleiten und gleich null zu setzen, funktion- iert leider nicht immer, wie das folgende Beispiel zeigt. Seien X1, . . . , Xn iid ∼ U([a, b]) mit a < b unbekannt und seien x1, . . . , xn Realisierungen von X1, . . . , Xn. Bestimme den MLE (ˆa, ˆb) von (a, b). 1. Likelihood-Funktion: L(x1, . . . , xn; (a, b)) = n∏ i=1 f (xi; (a, b)) ︸ ︷︷ ︸ = 1 b−a 1 xi∈[a,b] = n∏ i=1 1 b − a 1 xi∈[a,b] = ( 1 b − a )n1 x1,...,xn∈[a,b] 2. Maximiere L(x1, . . . , xn; (a, b)): Ableiten und gleich null setzen funktioniert hier nicht. Die folgenden ¨Uberlegungen helfen und jedoch, die Funktion zu maximieren: • ( 1 b−a )n ist gr¨osser je kleiner b−a ist. Deshalb w¨ahlen wir a so gross wie m¨oglich und b so klein wie m¨oglich so dass immer noch die Bedingung a < b gilt. • 1 x1,...,xn∈[a,b] ist null sobald irgendein xi ausserhalb von [a, b] liegt und dann ist die Funktion bestimmt nicht maximal. • Daher w¨ahlen wir ˆa = min i=1,...,n xi und ˆb = max i=1,...,n xi. 20 12 Konfidenzintervalle Dieses Kapitel dreht sich, genau wie das vorangehende, um Zufallsvariablen X1, . . . , Xn, deren Verteilung von einem unbekannten Parameter ϑ ∈ Θ abh¨angt, sowie um Realisierun- gen x1, . . . , xn. Anstatt, wie bisher, den Parameter ϑ zu sch¨atzen, wollen wir diesmal ein In- tervall [a, b] ⊆ Θ konstruieren, das den wahren Parameter ϑ mit hoher Wahrscheinlichkeit enth¨alt. Sei α ∈ [0, 1]. Ein Konfidenzintervall f ¨ur ϑ mit Niveau 1 − α ist ein zuf¨alliges Intervall I = [A, B] so dass f ¨ur alle ϑ ∈ Θ gilt: Pϑ[ϑ ∈ [A, B]] ⩾ 1 − α ”Wenn ϑ der wahre Parameter ist, dann ist ϑ mit Wahrscheinlichkeit mindestens 1 − α in I enthalten.” I = R ist ein Konfidenzintervall f ¨ur ϑ mit Niveau 1 (also α = 0), denn f ¨ur alle ϑ ∈ Θ gilt Pϑ[ϑ ∈ R] = 1. I = ∅ ist ein Konfidenzintervall f ¨ur ϑ mit Niveau 0 (also α = 1), denn f ¨ur alle ϑ ∈ Θ gilt Pϑ[ϑ ∈ ∅] = 0. Als erstes nicht-triviales Beispiel betrachten wir den Fall von normalverteilten Daten f ¨ur deren Erwartungswert wir ein Konfidenzintervall konstruieren m¨ochten. Das ist einer der seltenen F¨alle, in denen wir ein Konfidenzintervall analytisch von Hand bestimmen k¨onnen. Seien X1, . . . , Xn µ ∼ N (µ, σ2)iid wobei σ2 > 0 bekannt und µ ∈ R unbekannt ist. Sei α ∈ (0, 1). (a) Bestimme ein (1 − α)-Konfidenzintervall f ¨ur µ. • X1, . . . , Xn µ ∼ N (µ, σ2)iid =⇒ n∑ i=1 Xi µ ∼ N (nµ, nσ2) =⇒ X n = 1 n n∑ i=1 Xi µ ∼ N (µ, σ2 n ) =⇒ X n − µ µ ∼ N (0, σ2 n ) =⇒ X n−µ σ/ √n µ ∼ N (0, 1) • Wir suchen jetzt zwei Zahlen a und b mit a < b so dass Pµ [ a ⩽ X n − µ σ/ √n ⩽ b] = 1 − α. Da die Dichte von N (0, 1) symmetrisch um null ist, k¨onnen wir a und b fol- gendermassen w¨ahlen: a = Φ −1( α 2 ) = −Φ−1(1 − α 2 ) und b = Φ −1(1 − α 2 ), wobei Φ : R → [0, 1] die Verteilungsfunktion der Standardnormalverteilung ist. Wir w¨ahlen also als linke und rechte Grenze jeweils das α 2 - und das 1 − α 2 - Quantil und erhalten Pµ [ − Φ−1(1 − α 2 ) ⩽ X n − µ σ/ √n ⩽ Φ−1(1 − α 2 )] = 1 − α. 21 • Durch Umformen erhalten wir 1 − α = Pµ [ − Φ−1(1 − α 2 ) ⩽ X n−µ σ/ √n ⩽ Φ−1(1 − α 2 ) ] = Pµ [ − Φ−1(1 − α 2 ) σ√n ⩽ X n − µ ⩽ Φ−1(1 − α 2 ) σ√n ] = Pµ [ − X n − Φ−1(1 − α 2 ) σ√n ⩽ −µ ⩽ −X n + Φ−1(1 − α 2 ) σ√n ] = Pµ [ X n − Φ−1(1 − α 2 ) σ√n ⩽ µ ⩽ X n + Φ−1(1 − α 2 ) σ√n ] • Das (1 − α)-Konfidenzintervall f ¨ur µ ist also gegeben durch [ X n − Φ−1(1 − α 2 ) σ √n , X n + Φ−1(1 − α 2 ) σ √n ] . (b) Sei σ2 = 4, α = 5% = 0.05. Wieviele Beobachtungen brauchen wir, damit das 95%-Konfidenzintervall aus Teil (a) h¨ochstens L¨ange 2 hat? • Das Intervall hat die L¨ange X n+Φ−1( 1− α 2 ) σ √n − ( X n−Φ−1(1− α 2 ) σ √n ) = 2·Φ−1(1− α 2 ) σ √n • Somit haben wir die Bedingung 2 · Φ−1(1 − α 2 ) σ √n ⩽ 2 und daraus folgt n ⩾ ( Φ−1( 1 − α 2 )σ)2 ≈ 15.3664 • Wir brauchen also mindestens 16 Beobachtungen. Falls wir σ2 nicht wissen m ¨ussen wir es sch¨atzen. Daf ¨ur verwenden wir den Sch¨atzer S2 = 1 n − 1 n∑ i=1(Xi − X n) 2 sowie das Resultat, dass folgendes gilt: X n − µ S/√n µ ∼ tn−1, wobei tn−1 die t-Verteilung mit n−1 Freiheitsgraden ist. Der Rest funktioniert genau gleich, lediglich das 1 − α 2 -Quantil der Standardnormalverteilung muss ersetzt werden durch das 1 − α 2 -Quantil der tn−1-Verteilung. Das Konfidenzintervall aus Bemerkung 12 ist l¨anger als das Konfidenzintervall aus Beispiel 12 da die Unsicherheit durch die unbekannte Varianz σ2 gr¨osser ist. 22 13 Approximative Konfidenzintervalle Die Idee von approximativen Konfidenzintervallen ist, dass wir die Konstruktion eines Kon- fidenzintervalles auch auf nicht-normalverteilte Zufallsvariablen anwenden wollen. Wir nutzen hierf ¨ur den zentralen Grenzwertsatz. Seien X1, . . . , Xn λ ∼ P oisson(λ)iid mit λ > 0 unbekannt und seien x1, . . . , xn Real- isierungen. (a) Bestimme den Maximum-Likelihood-Sch¨atzer f ¨ur λ. • Die Likelihood-Funktion ist L(x1, . . . , xn; λ) = n∏ i=1 Pλ[Xi = xi] ︸ ︷︷ ︸ =e−λ λxi xi! = e−nλ λ n∑ i=1 xi n∏ i=1 xi! • Maximiere die log-Likelihood-Funktion: l(x1, . . . , xn; λ) = −nλ + log(λ) n∑ i=1 xi − n∑ i=1 log(xi!) =⇒ d dλ l(x1, . . . , xn; λ) = −n + 1 λ n∑ i=1 xi =⇒ d dλ l(x1, . . . , xn; λ) = 0 ⇐⇒ λ = 1 n n∑ i=1 xi Ausserdem gilt d 2 dλ2 l(x1, . . . , xn; λ) = − 1 λ2 n∑ i=1 xi < 0 und daher ist ˆλ = 1 n n∑ i=1 Xi der MLE f ¨ur λ. (b) Bestimme ein approximatives Konfidenzintervall f ¨ur λ mit Niveau 1 − α. • Der zentrale Grenzwertsatz gibt uns n∑ i=1 Xi λ ≈ N (n · Eλ[X1] ︸ ︷︷ ︸ =λ , n · Varλ[X1] ︸ ︷︷ ︸ =λ ) und daher n∑ i=1 Xi − nλ √nλ λ ≈ N (0, 1). • Analog zur Herleitung in Beispiel 12 erhalten wir somit Pλ [ − Φ−1( 1 − α 2 ) ⩽ n∑ i=1 Xi − nλ √nλ ⩽ Φ−1(1 − α 2 )] ≈ 1 − α. 23 • L¨ose die Ungleichung nach λ auf: − Φ−1(1 − α 2 ) ⩽ n∑ i=1 Xi − nλ √nλ ⩽ Φ−1(1 − α 2 ) ⇐⇒ ∣ ∣ ∣ ∣ ∣ n∑ i=1 Xi − nλ √nλ ∣ ∣ ∣ ∣ ∣ ⩽ Φ−1(1 − α 2 ) ⇐⇒ ∣ ∣ ∣ ∣ n∑ i=1 Xi − nλ∣ ∣ ∣ ∣ ⩽ Φ−1(1 − α 2 ) · √nλ ⇐⇒ ( n∑ i=1 Xi − nλ)2 ⩽ (Φ−1(1 − α 2 ))2 · nλ • L¨ose die folgende Gleichung nach λ auf: n2λ2 − ( 2 n∑ i=1 Xi + (Φ−1(1 − α 2 ))2)nλ + ( n∑ i=1 Xi )2 = 0. • Das Konfidenzintervall ist gegeben durch [λ1, λ2], wobei λ1 und λ2 die beiden L¨osungen der Gleichung sind. 14 Statistische Tests 14.1 Grundbegriffe Das Ziel von statistischen Tests ist es, aufgrund von Beobachtungen zu einer Entscheidung zu kommen, in welchem Bereich der unbekannte Parameter eher liegt. Das Set-Up ist genau gleich wie in den vorhergehenden Kapiteln. Wir betrachten Zufallsvariablen X1, . . . , Xn, die iid sind und deren Verteilung von einem unbekannten Parameter ϑ ∈ Θ abh¨angt. Ausserdem haben wir einen Grundraum mit Sigma-Algebra (Ω, F) sowie eine Familie von Wahrscheinlichkeitsmassen (Pϑ)ϑ∈Θ auf diesem Grundraum. Wir betrachten nun zwei dis- junkte Teilmengen Θ0 und ΘA unseres Parameterraums Θ. Am Ende m ¨ussen wir uns entschei- den, ob wir glauben, dass ϑ ∈ Θ0 oder ϑ ∈ ΘA gilt. H0 : ϑ ∈ Θ0 ist die Nullhypothese und HA : ϑ ∈ ΘA ist die Alternativhypothese. Ein statistischer Test sagt uns nun, ob wir an H0 oder an HA glauben sollen. Ein Test ist ein Paar (T, K) wobei T = T (X1, . . . , Xn) eine Zufallsvariable und K ⊆ R eine Teilmenge ist. T ist die Teststatistik und K ist der Verwerfungsbereich. Wie kommen wir nun zu einer Entscheidung? Wir realisieren unsere Zufallsvariablen X1, . . . , Xn und bekommen dadurch Daten x1, . . . , xn. • Wir verwerfen H0 (und glauben an HA), wenn T (x1, . . . , xn) ∈ K • Wir glauben an H0 (und verwerfen HA), wenn T (x1, . . . , xn) /∈ K Jedoch k¨onnen wir bei jeder Entscheidung Fehler machen: • Fehler 1. Art: H0 ist richtig und wird verworfen • Fehler 2. Art: H0 ist falsch und wird nicht verworfen 24 In der Praxis ist H0 das Gegenteil von dem, was wir zeigen wollen, deshalb ist es wichtig, wissenschaftlich sauber zu arbeiten und H0 nicht zu Unrecht abzulehnen. Wenn wir zum Beispiel zeigen wollen, dass der Grenzwert einer Schadstoffemission ¨uberschritten wird, dann wird unsere Nullhypothese sein, dass der Grenzwert eingehalten wird und wir werden es uns sehr schwer machen, diese Nullhypothese zu verwerfen damit wir, wenn wir sie am Ende doch verwerfen, dies mit umso mehr ¨Uberzeugung tun k¨onnen. Unsere Priorit¨aten sehen daher folgendermassen aus: • Priorit¨at 1: Fehler 1. Art klein halten • Priorit¨at 2: Fehler 2. Art klein halten F ¨ur α ∈ (0, 1) sagen wir, ein Test (T, K) hat Signifikanzniveau α, falls f ¨ur alle ϑ ∈ Θ0 gilt: Pϑ[T ∈ K] ⩽ α ”Die Wahrscheinlichkeit f ¨ur einen Fehler 1. Art (H0 stimmt und ϑ ∈ Θ0 gilt, wird aber verworfen weil T ∈ K gilt) betr¨agt h¨ochstens α.” Die Macht eines Tests (T, K) ist die Funktion β : ΘA → [0, 1], ϑ ↦→ Pϑ[T ∈ K]. ”Die Macht beschreibt die Wahrscheinlichkeit, dass wenn die Alternative HA stimmt und ϑ ∈ ΘA gilt, der Test das auch erkennt und H0 ablehnt, also T ∈ K gilt.” In Anerkennung von Bemerkung 14.1 sieht unsere Strategie bei der Konstruktion eines Tests nun folgendermassen aus: • Fixiere ein Signifikanzniveau α • Betrachte alle Tests (T, K) mit Signifikanzniveau α und w¨ahle den Test ”mit der gr¨ossten Macht” aus Der p-Wert ist definiert als: p − W ert = inf{α : Der Test lehnt H0 auf dem Signifikanzniveau α ab} Der p-Wert ist ein Mass daf ¨ur, wie plausibel die Nullhypothese unter Ber ¨ucksichtigung der Daten ist, die wir beobachtet haben. Der p-Wert ist auch gleich der Wahrscheinlichkeit, Daten zu beobachten, die ’extremer’ sind als die Daten, die wir beobachtet haben. Der Begriff ’extremer’ h¨angt dabei von unserer Al- ternativhypothese ab. 14.2 Konstruktion von Tests: Das Neyman-Pearson-Lemma In diesem Unterkapitel nehmen wir ein sehr simplistisches Testszenario an, n¨amlich, dass H0 : ϑ = ϑ0 und HA : ϑ = ϑA. Der Likelihood-Quotient ist gegeben als R(x1, . . . , xn) = L(x1, . . . , xn; ϑA) L(x1, . . . , xn; ϑ0) , wobei L die Likelihood-Funktion ist. ”R(x1, . . . , xn) ’gross’ =⇒ ϑ = ϑA ist plausibler als ϑ = ϑ0 =⇒ W¨ahle K = (c, +∞] mit c ⩾ 0 als Verwerfungsbereich f ¨ur H0.” Wir verwenden hier die Konvention, dass x 0 = +∞ f ¨ur alle x ∈ R gilt. Wir k¨onnen nun den Likelihood-Quotienten benutzen, um einen Test zu konstruieren. Sei c ⩾ 0. Der Likelihood-Quotienten-Test mit Parameter c ist ein Test (T, K) wobei T = R(X1, . . . , Xn) 25 und K = [c, +∞). Das nachfolgende Neyman-Pearson-Lemma besagt nun, dass in diesem Szenario der Likelihood- Quotienten-Test in einem bestimmten Sinn ”optimal” ist. [Neyman-Pearson-Lemma] Sei (T, K) ein Likelihood-Quotienten-Test mit Parameter c ⩾ 0 und Signifikanzniveau α∗ = Pϑ0[T > c]. F ¨ur jeden anderen Test (T ′, K ′) mit Sig- nifikanzniveau α ⩽ α∗ gilt PϑA[T ′ ∈ K ′] ⩽ PϑA[T > c]. ”Unter allen Tests, die das Signifikanzniveau des Likelihood-Quotienten-Tests einhalten, hat dieser die gr¨osste Macht.” 14.3 Der Binomialtest Der Binomialtest heisst so weil die Teststatistik unter der Nullhypothese Binomialverteilt ist. Wir wiederholen also ein Bernoulli-Experiment mehrmals und wollen eine Aussage ¨uber den ”Erfolgsparameter” machen. Wir haben eine M ¨unze auf einer Seite rot und auf der anderen Seite blau eingef¨arbt. Wir vermuten, dass die M ¨unze gezinkt ist und eher auf der blauen Seite landet. Wir werfen die M ¨unze 10 Mal und notieren jeweils, auf welcher Seite sie gelandet ist. Sei Xi = 1 wenn der i-te Wurfd auf blau landet und Xi = 0 sonst. Wurf i 1 2 3 4 5 6 7 8 9 10 xi 0 1 1 1 1 1 0 1 1 1 Teste auf dem Signifikanzniveau α = 5%, ob die M ¨unze gezinkt ist • Modell: X1, . . . , X10 p ∼ Ber(p) sind iid und p ist unbekannt. • Nullhypothese: H0 : p = p0 = 0.5 • Alternativhypothese: HA : p = pA > p0 • Teststatistik: R(X1, . . . , X10; p0, pA) = L(X1,...,X10;pA) L(X1,...,X10;p0) = p 10∑ i=1 Xi A (1−pA) 10− 10∑ i=1 Xi p 10∑ i=1 Xi 0 (1−p0)10− 10∑ i=1 Xi = ( pA(1−p0) p0(1−pA) ) 10∑ i=1 Xi( 1−pA 1−p0 )10 Also wird der Likelihood-Quotient genau dann gross, wenn T = 10∑ i=1 Xi gross wird und wir nehmen T als Teststatistik. Unter der Nullhypothese gilt T ∼ Bin(10, 1 2 ). • Kritischer Bereich: K = [c, +∞) f ¨ur ein c > 0, denn wir zweifeln an der Nullhy- pothese, wenn wir zu oft beobachten, dass die M ¨unze auf der blauen Seite landet. • Bestimmen von c: 0.05 ⩾ P[Fehler 1. Art] = PH0[T ∈ K] = PH0 [T ⩾ c] = 1 − PH0 [T < c] =⇒ PH0 [T < c] ⩾ 0.95 =⇒ c = 9 • Wert der Teststatistik: t = 8 /∈ K =⇒ H0 wird nicht verworfen Bestimme den p-Wert • p-Wert = PH0 [T ∈ ”kleinster Verwerfungsbereich K = [c, +∞), der t = 8 enth¨alt”] = PH0[ T ∈ [8, +∞)] ] = PH0[T ⩾ 8] = 1 − PH0 [Z ⩽ 7] = 1 − 0.945 = 0.055 26 • 5.5% ist also das kleinste Signifikanzniveau, auf dem wir H0 mit den Daten, die wir beobachtet haben, verwerfen k¨onnen. Wir verwerfen H0 also zum Beispiel auf dem 6%-Niveau, nicht aber auf dem 5%-Niveau. 14.4 Der z-Test Der z-Test ist einer der fundamentalsten Tests und fragt nach dem Mittelwert von normalverteil- ten Zufallsvariablen bei bekannter Varianz, ¨ahnlich zu der Konstruktion von Konfidenzin- tervallen aus Kapitel 12. Das Modell, welches wir im Folgenden annehmen, sieht folgender- massen aus: • X1, . . . , Xn µ ∼ N (µ, σ2) sind iid, µ ∈ R ist unbekannt und σ2 > 0 ist bekannt. • Die Nullhypothese ist H0 : µ = µ0. • Die Alternative ist entweder HA : µ < µ0 oder HA : µ > µ0 oder HA : µ ̸= µ0. • Die Teststatistik ist Z = X n−µ0 σ/ √n H0∼ N (0, 1). Was ist die Intuition hinter der Testatistik Z? Nehmen wir mal an, wir haben die Alterna- tivhypothese HA : µ > µ0. Was muss mit unserem Sch¨atzer X n f ¨ur µ passieren, damit wir an der Nullhypothese zugunsten der Alternative zweifeln? Wir zweifeln an H0, wenn X n ’gross’ wird. Wenn X n ’gross’ wird, dann ist Z ’deutlich gr¨osser als 0’ (was auch immer das am Ende heisst). Unser kritische Bereich hat also die Form K = [c, +∞) f ¨ur ein c > 0, das wir noch genauer bestimmen m ¨ussen und das von unserem Signifikanzniveau abh¨angt. Und da wir die Verteilung von Z unter der Nullhypothese kennen (Z H0∼ N (0, 1)) k¨onnen wir dieses c auch bestimmen. Unterhalb einer Kl¨aranlage werden 16 unabh¨angige Wasserproben entnommen und auf ihre Ammoniumkonzentration untersucht. Sei Xi, i = 1, . . . , 16, die Ammoniumkonzentra- tion. Der Mittelwert ist x16 = 204.2, die Standardabweichung betr¨agt σ = 10. F ¨uhre einen Test durch um zu pr ¨ufen, ob eine ¨Uberschreitung des Grenzwerts von 200 auf dem Signifikanzniveau von 5% nachgewiesen werden kann. • Modellannahmen: X1, . . . , X16 µ ∼ N (µ, σ2) sind iid mit σ = 10. • Nullhypothese: H0 : µ = 200 • Alternativhypothese: HA : µ > 200 • Teststatistik: Z = X n−µ0 σ/ √n = X 16−200 10/√16 H0∼ N (0, 1) • Verwerfungsbereich: K = [c, +∞) f ¨ur ein c > 0 • Bestimmen von c: 0.05 ⩾ W’keit f ¨ur Fehler 1. Art = PH0 [Z ∈ K] = PH0[Z ⩾ c] = 1 − PH0[Z ⩽ c] und daher gilt PH0 [Z ⩽ c] = Φ(c) ⩾ 0.95 weil Z ∼ N (0, 1) unter H0. Wir erhalten c ⩾ Φ−1(0.95) ≈ 1.64 und daher K = [1.64, +∞). • Wert der Teststatistik: z = xn−µ0 σ/ √n = 204.2−200 10/√16 = 1.68 ∈ K =⇒ H0 wird verworfen. Angenommen, die wahre Ammoniumkonzentration ist bekannt und betr¨agt 205. Berechne die Macht des Tests 27 • Gesucht ist Pµ=205[Z ∈ K] und wir wissen, dass unter µ = 205 gilt X 16 − 205 σ/ √16 ∼ N (0, 1). • Pµ=205[Z ∈ K] = Pµ=205[ X 16−µ0 σ/ √ 16 ⩾ 1.64] = Pµ=205[ X 16−200 σ/ √16 + 200−205 σ/ √16 ⩾ 1.64 + 200−205 σ/ √16 ] = Pµ=205[ X 16−205 σ/ √16 ⩾ −0.36 ] = 1 − Φ(−0.36) = 1 − (1 − Φ(0.36)) ≈ 64% Berechne den p-Wert. • p-Wert = PH0 [Z ∈ ”kleinster Verwerfungsbereich K = [c, +∞), der z = 1.68 enth¨alt”] = PH0[ Z ∈ [1, 68, +∞)] ] = PH0 [Z ⩾ 1.68] = 1 − PH0 [Z ⩽ 1.68] = 1 − Φ(1.68) ≈ 4.648% • 4.648% ist also das kleinste Signifikanzniveau, auf dem wir H0 mit den Daten, die wir beobachtet haben, verwerfen k¨onnen. Wir verwerfen H0 also zum Beispiel auf dem 5%-Niveau, nicht aber auf dem 1%-Niveau. 14.5 Der t-Test Der t-Test kommt zum Einsatz, wenn wir das gleiche Set-up haben wie beim Z-Test jedoch mit unbekannter Varianz. Wenn die Varianz nicht bekannt ist, dann muss sie gesch¨atzt wer- den. Die Teststatistik ¨andert sich somit und sieht folgendermassen aus: T = T (X1, . . . , Xn) = X n − µ0 Sn/ √n wobei Sn = √ 1 n−1 n∑ i=1(Xi − X n)2 ein Sch¨atzer f ¨ur σ ist. Unter H0 gilt: T ∼ t(n−1). Die Herangehensweise ist daher genau gleich wie beim Z-Test, lediglich die Quantile bei der Bestimmung des kritischen Bereiches ¨andern sich. 14.6 Der Vorzeichentest Bei unseren letzten Testszenarien (Z − T est, t − T est) haben wir angenommen, die Daten seien normalverteilt. Das ist eine sehr starke Annahme. Ein Beispiel f ¨ur einen Test, der diese Annahme nicht macht, ist der Vorzeichentest: Wir haben X1, . . . , Xn iid ∼ F(µ), wobei F eine beliebige, stetige Verteilung mit Median µ ist (das heisst, P[X1 ⩽ µ] = P[X1 ⩾ µ] = 0.5). Wir wollen testen, wie gross der Median µ ist, also wollen wir Hypothesen der Form H0 : µ = µ0 vs. HA : µ ̸= µ0 oder H0 : µ ⩽ µ0 vs. HA : µ > µ0 f ¨ur ein µ0 ∈ R testen. Die Idee ist nun folgende: Wir z¨ahlen, wieviele der Xi gr¨osser als µ0 sind und wieviele kleiner. Wenn H0 : µ = µ0 stimmt, dann m ¨usste ca. die H¨alfte der Xi gr¨osser sein als µ0 und die andere H¨alfte kleiner. Die Zufallsvariable T = ∣ ∣{i : Xi − µ0 > 0} ∣ ∣ ist unter H0 Bin(n, 1 2 )-verteilt. 28 In einem Supermarkt soll die Wartezeit von Kunden an den Kassen untersucht werden. Von der Gesch¨aftsleitung wird angestrebt, dass Kunden im Mittel h¨ochstens drei Minuten an der Kasse warten m ¨ussen. Eine Stichprobe von 12 zuf¨allig ausgesuchten Kunden ergibt folgende Wartezeiten: 5 4.5 3.5 6 1.5 12 15 3.5 5 7.5 2.5 4 F ¨uhre einen Vorzeichentest zum 5%-Niveau durch und berechne den p-Wert. • Modell: X1, . . . , X12 iid Zufallsvariablen mit Median µ. • Nullhypothese: H0 : µ ⩽ 3 • Alternativhypothese: HA : µ > 3 • Teststatistik: T = ∣ ∣{i : Xi − 3 > 0} ∣ ∣ H0∼ Bin(12, 1 2 ) • Kritischer Bereich: K = [c, +∞) f ¨ur ein c > 0 (Wir lehnen H0 ab, wenn zu viele Leute l¨anger als drei Minuten warten mussten) • Wir bestimmen nun c: 0.05 ⩾ P[Fehler 1. Art] = PH0[T ∈ K] = PH0 [T ⩾ c] Unter H0 ist T Bin(12, 1 2 )-verteilt und daher gilt: – PH0[T = 12] = 0.5 12 ≈ 2.4 · 10−4 – PH0[T = 11] = (12 11 )0.5 12 ≈ 2.9 · 10−3 – PH0[T = 10] = (12 10 )0.5 12 ≈ 0.016 – PH0[T = 9] = (12 9 )0.5 12 ≈ 0.054 Wir erhalten: – PH0[T ⩾ 10] = 0.016 + 2.9 · 10 −3 + 2.4 · 10−4 = 0.01914 ⩽ 0.05 – PH0[T ⩾ 9] = PH0 [T = 9] + PH0 [T ⩾ 10] = 0.054 + 0.01914 = 0.07314 > 0.05 Deshalb w¨ahlen wir c = 10 und K = [10, +∞). • Testentscheid: 10 Kunden aus unserer Stichprobe mussten mehr als drei Minuten lange warten =⇒ t = 10 ∈ K =⇒ H0 wird verworfen. • Berechnen von p-Wert: Kleinster Verwerfungsbereich, der t = 10 enth¨alt: [10, +∞) p − W ert = PH0 [T ⩾ 10] = 0.01914 = 1.9% 29","libVersion":"0.5.0","langs":""}
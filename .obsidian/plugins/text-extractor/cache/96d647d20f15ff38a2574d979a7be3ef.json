{"path":"sem2/DDCA/VRL/extra/slides/DDCA-L10a-number-systems.pdf","text":"Carnegie Mellon 1 Digital Design and Computer Architecture Mohammad Sadrosadati Frank K. Gürkaynak Adapted from Digital Design and Computer Architecture, David Money Harris & Sarah L. Harris ©2007 Elsevier http://safari.ethz.ch/ddca Number Systems Carnegie Mellon 2 What will we learn? ¢ How to represent fractions? ¢ Fixed point ¢ Floating point ¢ Briefly: § Adding floating point numbers § Life is a bit more complicated Carnegie Mellon 3 Number Systems ¢ For what kind of numbers do you know binary representations? § Positive integers Unsigned binary § Negative integers Sign/magnitude numbers Two’s complement ¢ What about fractions? Carnegie Mellon 4 Fractions: Two Representations ¢ Fixed-point: binary point is fixed 1101101.0001001 ¢ Floating-point: binary point floats to the right of the most significant 1 and an exponent is used 1.1011010001001 x 26 Carnegie Mellon 5 Fixed-Point Numbers ¢ Fixed-point representation using 4 integer bits and 3 fraction bits: 0110110 0110.110 = ? interpreted as Carnegie Mellon 6 Fixed-Point Numbers ¢ Fixed-point representation using 4 integer bits and 3 fraction bits: ¢ The binary point is not a part of the representation but is implied ¢ The number of integer and fraction bits must be agreed upon by those generating and those reading the number 0110110 0110.110 = 22 + 21 + 2-1 + 2-2 = 6.75 interpreted as Carnegie Mellon 12 Signed Fixed-Point Numbers ¢ Negative fractional numbers can be represented two ways: § Sign/magnitude notation § Two’s complement notation ¢ Represent -7.510 using an 8-bit binary representation with 4 integer bits and 4 fraction bits in Two’s complement: § +7.5: 01111000 § Invert bits: 10000111 § Add 1 to lsb: 10001000 Carnegie Mellon 13 Floating-Point Numbers ¢ The binary point floats to the right of the most significant digit ¢ Similar to decimal scientific notation: § For example, 27310 in scientific notation is 273 = 2.73 × 102 ¢ In general, a number is written in scientific notation as: ± M × BE Where: § M = mantissa § B = base § E = exponent ¢ In the example, M = 2.73, B = 10, and E = 2 Carnegie Mellon 14 Floating-Point Numbers ¢ Example: represent the value 22810 using a 32-bit floating point representation ¢ We show three versions; the final version is used in the IEEE 754 floating-point standard Sign Exponent Mantissa 1 bit 8 bits 23 bits Carnegie Mellon 15 Floating-Point Representation 1 ¢ Convert the decimal number to binary: 22810 = 111001002 = 1.11001 × 27 ¢ Fill in each field of the 32-bit number: § The sign bit is positive (0) § The 8 exponent bits represent the value 7 § The remaining 23 bits are the mantissa 0 00000111 11 1001 0000 0000 0000 0000 Sign Exponent Mantissa 1 bit 8 bits 23 bits Carnegie Mellon 16 Floating-Point Representation 2 ¢ First bit of the mantissa is always 1: 22810 = 111001002 = 1.11001 × 27 § Thus, storing the most significant 1, also called the implicit leading 1, is redundant information ¢ Instead, store just the fraction bits in the 23-bit field The leading 1 is implied 0 00000111 110 0100 0000 0000 0000 0000 Sign Exponent Fraction 1 bit 8 bits 23 bits Carnegie Mellon 17 Floating-Point Representation 3 (IEEE) ¢ Bias for 8 bits = 12710 = 011111112 ¢ Biased exponent = bias + exponent § Exponent of 7 is stored as: 127 + 7 = 134 = 100001102 ¢ The IEEE 754 32-bit floating-point representation of 22810 0 10000110 Sign Biased Exponent Fraction 1 bit 8 bits 23 bits 110 0100 0000 0000 0000 0000 Carnegie Mellon 18 Floating-Point Example Write the value -58.2510 using IEEE 754 32-bit floating-point standard ¢ First, convert the decimal number to binary: 58.2510 = ¢ Next, fill in each field in the 32-bit number: § Sign bit: § 8 exponent bits: § 23 fraction bits: Sign Exponent Fraction 1 bit 8 bits 23 bits Carnegie Mellon 19 Floating-Point Example Write the value -58.2510 using IEEE 754 32-bit floating-point standard ¢ First, convert the decimal number to binary: 58.2510 = 111010.012 = 1.1101001 × 25 ¢ Next, fill in each field in the 32-bit number: § Sign bit: 1 (negative) § 8 exponent bits: (127 + 5) = 13210 = 100001002 § 23 fraction bits: 110 1001 0000 0000 0000 00002 In hexadecimal: 0xC2690000 1 100 0010 0 110 1001 0000 0000 0000 0000 Sign Exponent Fraction 1 bit 8 bits 23 bits Carnegie Mellon 20 Floating-Point Numbers: Special Cases ¢ The IEEE 754 standard includes special cases for numbers that are difficult to represent, such as 0 because it lacks an implicit leading 1 ¢ NaN (= Not a Number) is used for numbers that don’t exist, such as sqrt(-1) or log(-5) Number Sign Exponent Fraction 0 X 00000000 00000000000000000000000 ∞ 0 11111111 00000000000000000000000 - ∞ 1 11111111 00000000000000000000000 NaN X 11111111 non-zero Carnegie Mellon 21 Floating-Point Number Precision ¢ Single-Precision: § 32-bit notation § 1 sign bit, 8 exponent bits, 23 fraction bits § bias = 127 ¢ Double-Precision: § 64-bit notation § 1 sign bit, 11 exponent bits, 52 fraction bits § bias = 1023 Carnegie Mellon 22 Floating-Point Numbers: Rounding ¢ Problems: § Overflow: number is too large to be represented § Underflow: number is too small to be represented ¢ Rounding modes: § Down § Up § Toward zero § To nearest Carnegie Mellon 23 Floating-Point Numbers: Rounding Example ¢ Round 1.100101 (1.578125) so that it uses only 3 fractional bits § Down: § Up: § Toward zero: § To nearest: Carnegie Mellon 24 Floating-Point Numbers: Rounding Example ¢ Round 1.100101 (1.578125) so that it uses only 3 fractional bits § Down: 1.100 § Up: 1.101 § Toward zero: 1.100 § To nearest: 1.101 (1.625 is closer to 1.578125 than 1.5 is) Carnegie Mellon 25 Floating-Point Addition ¢ Steps for floating point addition: 1. Extract exponent and fraction bits 2. Prepend leading 1 to form mantissa 3. Compare exponents 4. Shift smaller mantissa if necessary 5. Add mantissas 6. Normalize mantissa and adjust exponent if necessary 7. Round result 8. Assemble exponent and fraction back into floating-point format ¢ Not so easy as binary addition! Carnegie Mellon 26 Floating-Point Addition: Example ¢ Add the following floating-point numbers: 0x3FC00000 0x40500000 Carnegie Mellon 27 Floating-Point Addition: Example 1. Extract exponent and fraction bits § For first number (N1): S = 0, E = 127, F = .1 § For second number (N2): S = 0, E = 128, F = .101 2. Prepend leading 1 to form mantissa § N1: 1.1 § N2: 1.101 0 01111111 100 0000 0000 0000 0000 0000 Sign Exponent Fraction 1 bit 8 bits 23 bits 0 10000000 101 0000 0000 0000 0000 0000 1 bit 8 bits 23 bits Sign Exponent Fraction Carnegie Mellon 28 Floating-Point Addition: Example 3. Compare exponents 127 – 128 = -1 so shift N1 right by 1 bit 4. Shift smaller mantissa if necessary shift N1’s mantissa: 1.1 >> 1 = 0.11 (× 21) 5. Add mantissas 0.11 × 21 + 1.101 × 21 10.011 × 21 Carnegie Mellon 29 Floating-Point Addition: Example 6. Normalize mantissa and adjust exponent if necessary 10.011 × 21 = 1.0011 × 22 7. Round result No need (fits in 23 bits) 8. Assemble exponent and fraction back into floating-point format S = 0, E = 2 + 127 = 129 = 100000012, F = 001100.. Written in hexadecimal: 0x40980000 0 10000001 001 1000 0000 0000 0000 0000 Sign Exponent Fraction 1 bit 8 bits 23 bits Carnegie Mellon 30 Floating-Point Unit of ARM Carnegie Mellon 35 What did we learn ¢ How to express real numbers in binary § Fixed point § Floating point ¢ IEEE Standard to express floating point numbers § Sign § Exponent (biased) § Mantissa ¢ Briefly § Adding floating point numbers","libVersion":"0.3.2","langs":""}
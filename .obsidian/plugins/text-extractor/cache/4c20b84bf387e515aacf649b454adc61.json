{"path":"sem4/W&S/PV/cheatsheets/W&S-cheatsheet-BF.pdf","text":"1. Probability 1.1. Prerequisites Sigma AlgebraFor some non-empty set Î© â‰  âŒ€ , ğœ -algebra is Î£ âŠ† ğ’« ( Î© ) containing Î© , is closed under complement and countable union for â„ âŠ† â„• . âŒ€ , Î© âˆˆ Î£ ğ´ âˆˆ Î£ âŸº ğ´ âˆ âˆˆ Î£ ğ’œ = { ğ´ ğ‘– } â„ âŠ† Î£ âŸ¹ â‹ƒ ğ´ âˆˆ ğ’œ ğ´ âˆˆ Î£ It follows that ğœ -algebras are also closed under intersection. Easily checked examples of ğœ -algebras include the trivial case { âŒ€ , Î© } , the simple case { âŒ€ , ğ´ , ğ´ âˆ , Î© } , and the complete case ğ’« ( Î© ) . Probability MeasureFunction Pr : Î© â†’ [ 0 , 1 ] on measurable space ( Î© , Î£ ) which satisfies totality and countable additivity of disjoint union for â„ âŠ† â„• . Pr [ Î© ] = 1 ğ´ = âˆ ğ‘– âˆˆ â„ ğ´ ğ‘– âŸ¹ Pr [ ğ´ ] = âˆ‘ ğ‘– âˆˆ â„ Pr [ ğ´ ğ‘– ] Monotonicity follows, ğ´ âŠ‚ ğµ âŸ¹ Pr [ ğ´ ] â‰¤ Pr [ ğµ ] . The following equalities hold for Pr [ ğµ ] > 0 . â€¢ Pr [ ğ´ âˆª ğµ ] = Pr [ ğ´ ] + Pr [ ğµ ] âˆ’ Pr [ ğ´ âˆ© ğµ ] â€¢ Pr [ ğ´ âˆ© ğµ ] = Pr [ ğ´ | ğµ ] Pr [ ğµ ] Probability SpaceTriple ( Î© , Î£ , Pr ) of sample space, ğœ -algebra event space and probability measure. An outcome ğœ” âˆˆ Î© is element of the sample space. An event ğ´ âˆˆ Î£ is set of outcomes. For some finite sample space the Laplace model is ( Î© , ğ’« ( Î© ) , ğ´ â†¦ | ğ´ | | Î© | ) . Independent Eventsğ´ , ğµ âˆˆ Î£ are independent, ğ´ âŠ¥ ğµ âŸº Pr [ ğ´ âˆ© ğµ ] = Pr [ ğ´ ] Pr [ ğµ ] . Some (infinite) family of events ( ğ´ ğ‘– ) â„ is independent, if every finite subset is independent. âˆ€ ğ’¥ âŠ† â„ . | ğ’¥ | âˆˆ â„• âŸ¹ Pr [ â‹‚ ğ‘— âˆˆ ğ’¥ ğ´ ğ‘— ] = âˆ ğ‘— âˆˆ ğ’¥ Pr [ ğ´ ğ‘— ] Conditional ProbabilityFor ğ´ , ğµ âˆˆ Î£ , probability of ğ´ given ğµ defined below. Pr [ ğ´ | ğµ ] = Pr [ ğ´ âˆ© ğµ ] Pr [ ğµ ] = Bayes â´ â´ â´ â´ â´ â´Pr [ ğµ | ğ´ ] Pr [ ğ´ ] Pr [ ğµ ] The fixed conditional Pr [ â€Š Â· | ğµ ] is a probability measure. Note that Pr [ ğ´ | ğ´ ] = Pr [ ğ´ | Î© ] = 1 . 1.2. Functions Random VariableFunction ğ‘‹ : Î© â†’ â„ such that the following holds (ensures CDF). âˆ€ ğ‘ âˆˆ â„ . { ğœ” âˆˆ Î© | ğ‘‹ ( ğœ” ) â‰¤ ğ‘ } âˆˆ Î£ Indicator r.v. encodes the occurrence of an event, ğŸ ğ´ ( ğœ” ) = âŸ¦ ğœ” âˆˆ ğ´ âŸ§ . Independent Random VariablesThe sequence of r.v.â€˜s ğ— = ( ğ‘‹ ğ‘– ) ğ‘› is independent if the joint CDF equals the product of marginal CDFs. Abusive, but write ğ‘‹ âŠ¥ ğ‘Œ . âˆ€ ğ± âˆˆ â„ ğ‘› . ğ¹ ğ— ( ğ± ) = âˆ ğ‘– âˆˆ [ ğ‘› ] âˆ— ğ¹ ğ‘‹ ğ‘– ( ğ‘¥ ğ‘– ) Infinite sequence ( ğ‘‹ ğ‘– ) â„• of r.v.â€˜s independent if âˆ€ ğ‘› . ( ğ‘‹ ğ‘– ) ğ‘› independent. Identically distributed if âˆ€ ğ‘– , ğ‘— . ğ¹ ğ‘‹ ğ‘– = ğ¹ ğ‘‹ ğ‘— . If both, ( ğ‘‹ ğ‘– ) â„• i.i.d. . Probability Mass Function PMF of discrete r.v. ğ‘‹ is function ğ‘“ ğ‘‹ : â„ â†’ [ 0 , 1 ] that yields probability of specific value such that the below holds. ğ‘“ ğ‘‹ ( ğ‘¥ ) = Pr [ ğ‘‹ = ğ‘¥ ] âˆ‘ ğ‘¥ âˆˆ ğ‘Š ğ‘“ ğ‘‹ ( ğ‘¥ ) = 1 Probability Density Function PDF of continuous r.v. ğ‘‹ is non-negative function ğ‘“ ğ‘‹ : â„ â†’ â„ + . Intuitively, ğ‘“ ğ‘‹ ( ğ‘¥ ) d ğ‘¥ is the probability that ğ‘‹ falls in [ ğ‘¥ , ğ‘¥ + d ğ‘¥ ] . Pr [ ğ‘ â‰¤ ğ‘‹ â‰¤ ğ‘ ] = Pr [ ğ‘‹ â‰¤ ğ‘ ] âˆ’ Pr [ ğ‘‹ < ğ‘ ] = âˆ« ğ‘ ğ‘ ğ‘“ ğ‘‹ ( ğ‘¥ ) d ğ‘¥ âˆ« + âˆ âˆ’ âˆ ğ‘“ ğ‘‹ ( ğ‘¥ ) d ğ‘¥ = 1 If ğ‘“ ğ‘‹ continuous at ğ‘¥ , then PDF is derivative of CDF ğ‘“ ğ‘‹ ( ğ‘¥ ) = ğ¹ â€² ğ‘‹ ( ğ‘¥ ) . Cumulative Distribution Function CDF of r.v. ğ‘‹ is function ğ¹ ğ‘‹ : â„ â†’ [ 0 , 1 ] defined as below. ğ¹ ğ‘‹ ( ğ‘¥ ) = Pr [ ğ‘‹ â‰¤ ğ‘¥ ] = Pr [ { ğœ” âˆˆ Î© | ğ‘‹ ( ğœ” ) â‰¤ ğ‘¥ } ] Some function ğ‘“ is CDF if and only if it is non-decreasing , right continuous and from zero to one . âˆ€ ğ‘¥ , ğ‘¥ â€² . ğ‘¥ â‰¤ ğ‘¥ â€² âŸ¹ ğ‘“ ( ğ‘¥ ) â‰¤ ğ‘“ ( ğ‘¥ â€² ) âˆ€ ğ‘¥ . ğ‘“ ( ğ‘¥ ) = lim â„ â†’ 0 + ğ‘“ ( ğ‘¥ + â„ ) lim ğ‘¥ â†’ âˆ’ âˆ ğ‘“ ( ğ‘¥ ) = 0 , lim ğ‘¥ â†’ + âˆ ğ‘“ ( ğ‘¥ ) = 1 General inverse distribution is ğ¹ âˆ’ 1 ğ‘‹ ( ğ‘ ) = inf { ğ‘¥ âˆˆ â„ | ğ¹ ğ‘‹ ( ğ‘¥ ) â‰¥ ğ‘ } . Continuous r.v. has continuous CDF. Joint DistributionJoint CDF of ğ— = ( ğ‘‹ ğ‘– ) ğ‘› defines probability that every r.v. falls into specific discrete set or continuous range. ğ¹ ğ— ( ğ± ) = Pr [ ğ‘‹ 1 â‰¤ ğ‘¥ 1 , â€¦ ğ‘‹ ğ‘› â‰¤ ğ‘¥ ğ‘› ] Joint PMF for discrete r.v.â€˜s s.t. âˆ€ ğ‘‹ ğ‘– . Pr [ ğ‘‹ ğ‘– âˆˆ ğ‘Š ğ‘– ] = 1 with ğ‘Š ğ‘– âŠ‚ â„ countable, then let ğ± âˆˆ â¨‰ ğ‘– âˆˆ [ ğ‘› ] âˆ— ğ‘Š ğ‘– . ğ‘“ ğ— ( ğ± ) = Pr [ ğ‘‹ 1 = ğ‘¥ 1 , â€¦ ğ‘‹ ğ‘› = ğ‘¥ ğ‘› ] Joint PDF for continuous ğ— exists if it yields joint CDF. ğ‘“ ğ— ( ğ± ) = ğœ• ğ‘› ğ¹ ğ— ( ğ± ) âˆ ğ‘– âˆˆ [ ğ‘› ] âˆ— ğœ• ğ‘¥ ğ‘– = ! âˆ« ğ± âˆˆ â„ ğ‘› ğ‘“ ğ— ( ğ± ) âˆ ğ‘– âˆˆ [ ğ‘› ] âˆ— d ğ‘¥ ğ‘– Always possible to recover marginal density from joint density but only the other way if r.v.â€˜s are i.i.d.. Marginal DistributionFor r.v.â€˜s ğ— = ( ğ‘‹ ğ‘– ) ğ‘› with joint PMF / joint PDF ğ‘“ ğ— , the marginal distribution of ğ‘‹ ğ‘– is given below. ğ‘“ ğ‘‹ ğ‘– ( ğ‘¥ ) = {{{{{ âˆ‘ ğ± âˆˆ â„ ğ‘› , ğ‘¥ ğ‘– = ğ‘¥ ğ‘“ ğ— ( ğ± ) ğ‘‹ ğ‘– discrete âˆ« ğ± âˆˆ â„ ğ‘› , ğ‘¥ ğ‘– = ğ‘¥ ğ‘“ ğ— ( ğ± ) âˆ ğ‘— âˆˆ [ ğ‘› ] âˆ— âˆ– { ğ‘– } d ğ‘¥ ğ‘— ğ‘‹ ğ‘– continuous Expectation For r.v. ğ‘‹ with PMF / PDF ğ‘“ ğ‘‹ , expectation ğœ‡ ğ‘‹ defines the mean as weighted average of possible outcomes. E [ ğ‘‹ ] = {{{{{ âˆ‘ ğ‘¥ âˆˆ ğ‘Š ğ‘¥ ğ‘“ ğ‘‹ ( ğ‘¥ ) ğ‘‹ discrete âˆ« + âˆ âˆ’ âˆ ğ‘¥ ğ‘“ ğ‘‹ ( ğ‘¥ ) d ğ‘¥ ğ‘‹ continuous â€¢ E [ ğ‘ ğ‘‹ + ğ‘Œ ] = ğ‘ E [ ğ‘‹ ] + E [ ğ‘Œ ] , linearity â€¢ E [ ğ‘‹ ğ‘Œ ] = E [ ğ‘‹ ] E [ ğ‘Œ ] + Cov [ ğ‘‹ , ğ‘Œ ] , multiplicity â€¢ Pr [ ğ‘‹ â‰¤ ğ‘Œ ] = 1 âŸ¹ E [ ğ‘‹ ] â‰¤ E [ ğ‘Œ ] , monotonicity For function ğœ‘ : â„ â†’ â„ the following holds. E [ ğœ‘ ( ğ‘‹ ) ] = { âˆ‘ ğ‘¥ âˆˆ ğ‘Š ğœ‘ ( ğ‘¥ ) ğ‘“ ğ‘‹ ( ğ‘¥ ) ğ‘‹ discrete âˆ« âˆ âˆ’ âˆ ğœ‘ ( ğ‘¥ ) ğ‘“ ğ‘‹ ( ğ‘¥ ) d ğ‘¥ ğ‘‹ continuous VarianceFor r.v. ğ‘‹ with E [ ğ‘‹ 2 ] < + âˆ , variance ğœ 2 ğ‘‹ defines the spread around the mean ğœ‡ ğ‘‹ as positive function Var : Î£ â†’ â„ + . Var [ ğ‘‹ ] = E [ ( ğ‘‹ âˆ’ ğœ‡ ğ‘‹ ) 2 ] = E [ ğ‘‹ 2 ] âˆ’ E [ ğ‘‹ ] 2 â€¢ Var [ ğ‘‹ + ğ‘ ] = Var [ ğ‘‹ ] , translation invariant â€¢ Var [ ğ‘ ğ‘‹ ] = ğ‘ 2 Var [ ğ‘‹ ] , quadraticity â€¢ Var [ ğ‘ ğ‘‹ Â± ğ‘ ğ‘Œ ] = ğ‘ 2 Var [ ğ‘‹ ] + ğ‘ 2 Var [ ğ‘Œ ] Â± 2 ğ‘ ğ‘ Cov [ ğ‘‹ , ğ‘Œ ] , multiplicity â€¢ For ( ğ‘‹ ğ‘– ) ğ‘› pairwise independent, Var [ âˆ‘ ğ‘– âˆˆ [ ğ‘› ] âˆ— ğ‘‹ ğ‘– ] = âˆ‘ ğ‘– âˆˆ [ ğ‘› ] âˆ— Var [ ğ‘‹ ğ‘– ] 1 CovarianceFor r.v.â€˜s ğ‘‹ , ğ‘Œ with ğœ‡ ğ‘‹ , ğœ‡ ğ‘Œ the covariance measures co-movement. Cov [ ğ‘‹ , ğ‘Œ ] = E [ ( ğ‘‹ âˆ’ ğœ‡ ğ‘‹ ) ( ğ‘Œ âˆ’ ğœ‡ ğ‘Œ ) ] = E [ ğ‘‹ ğ‘Œ ] âˆ’ E [ ğ‘‹ ] E [ ğ‘Œ ] Reflexive covariance equals variance, Cov [ ğ‘‹ , ğ‘‹ ] = Var [ ğ‘‹ ] . Exhibits bilinearity, Cov [ ğ‘ ğ‘‹ + ğ‘ ğ‘Œ , ğ‘ ] = ğ‘ Cov [ ğ‘‹ , ğ‘ ] + ğ‘ Cov [ ğ‘Œ , ğ‘ ] . ğ‘‹ âŠ¥ ğ‘Œ âŸ¹ Cov [ ğ‘‹ , ğ‘Œ ] = 0 but not the other way. 1.3. Asymptotic Behavior Let ( ğ‘‹ ğ‘– ) â„• i.i.d. . Then define ğ‘† ğ‘› = âˆ‘ ğ‘– âˆˆ [ ğ‘› ] âˆ— ğ‘‹ ğ‘– and ğ‘‹ ğ‘› = ğ‘† ğ‘› ğ‘› . Law of Large NumbersAssume E [ ğ‘‹ ğ‘– ] < + âˆ . The LLN states that in the limit the sample mean equals the true mean almost surely . Pr [ lim ğ‘› â†’ + âˆ ğ‘‹ ğ‘› = ğœ‡ ğ‘‹ ğ‘– ] = 1 Central Limit TheoremAssume E [ ğ‘‹ 2 ğ‘– ] < + âˆ . Note that E [ ğ‘† ğ‘› ] = ğ‘› ğœ‡ and Var [ ğ‘† ğ‘› ] = ğ‘› ğœ 2 . The CLT states that in the limit the sum of normalized samplesresembles the standard normal distribution. Pr [ lim ğ‘› â†’ + âˆ ğ‘† ğ‘› âˆ’ ğ‘› ğœ‡ âˆš ğ‘› ğœ 2 â‰¤ ğ‘¥ ] = Î¦ ( ğ‘¥ ) 1.4. Distributions 1.4.1. Discrete BernoulliExperiment with single binary outcome and parameter ğ‘ . Notation ğ‘‹ âˆ¼ Ber ( ğ‘ ) Parameters ğ‘ âˆˆ [ 0 , 1 ] Support ğ‘˜ âˆˆ { 0 , 1 } PMF ğ‘“ ğ‘‹ ( ğ‘˜ ) = { ğ‘ ğ‘˜ = 1 1 âˆ’ ğ‘ ğ‘˜ = 0 CDF ğ¹ ğ‘‹ ( ğ‘˜ ) = {{{{{ 0 ğ‘˜ < 0 1 âˆ’ ğ‘ 0 â‰¤ ğ‘˜ < 1 1 ğ‘˜ â‰¥ 1 Mean E [ ğ‘‹ ] = ğ‘ Variance Var [ ğ‘‹ ] = ğ‘ ( 1 âˆ’ ğ‘ ) BinomialRepeat Bernoulli ğ‘› times with same parameter ğ‘ . Notation ğ‘‹ âˆ¼ Bin ( ğ‘› , ğ‘ ) Parameters ğ‘› âˆˆ â„• , ğ‘ âˆˆ [ 0 , 1 ] Support ğ‘˜ âˆˆ [ ğ‘› ] PMF ğ‘“ ğ‘‹ ( ğ‘˜ ) = ( ğ‘›ğ‘˜ ) ğ‘ ğ‘˜ ( 1 âˆ’ ğ‘ ) ğ‘˜ âˆ’ 1 CDF ğ¹ ğ‘‹ ( ğ‘˜ ) = âˆ‘ ğ‘– âˆˆ [ ğ‘˜ ] ( ğ‘› ğ‘– ) ğ‘ ğ‘– ( 1 âˆ’ ğ‘ ) ğ‘– âˆ’ 1 Mean E [ ğ‘‹ ] = ğ‘› ğ‘ Variance Var [ ğ‘‹ ] = ğ‘› ğ‘ ( 1 âˆ’ ğ‘ ) GeometricNumber of failures until success with parameter ğ‘ . Notation ğ‘‹ âˆ¼ Geom ( ğ‘ ) Parameters ğ‘ âˆˆ [ 0 , 1 ] Support ğ‘˜ âˆˆ â„• âˆ— PMF ğ‘“ ğ‘‹ ( ğ‘˜ ) = ğ‘ ( 1 âˆ’ ğ‘ ) ğ‘˜ âˆ’ 1 CDF ğ¹ ğ‘‹ ( ğ‘˜ ) = { 1 âˆ’ ( 1 âˆ’ ğ‘ ) ğ‘˜ ğ‘˜ â‰¥ 1 0 ğ‘˜ < 1 Mean E [ ğ‘‹ ] = 1 ğ‘ Variance Var [ ğ‘‹ ] = 1 âˆ’ ğ‘ ğ‘ 2 For ( ğ‘‹ ğ‘– ) ğ‘› âˆ¼ i.i.d. Ber ( ğ‘ ) r.v. min { ğ‘– âˆˆ â„• | ğ‘‹ ğ‘– = 1 } = ğ‘‡ âˆ¼ Geom ( ğ‘ ) . PoissonHigh number of unlikely outcomes at rate parameter ğœ† . Notation ğ‘‹ âˆ¼ Pois ( ğœ† ) Parameters ğœ† âˆˆ ( 0 , + âˆ ) Support ğ‘˜ âˆˆ â„• PMF ğ‘“ ğ‘‹ ( ğ‘˜ ) = ğœ† ğ‘˜ ğ‘’ âˆ’ ğœ† ğ‘˜ ! CDF ğ¹ ğ‘‹ ( ğ‘˜ ) = ğ‘’ âˆ’ ğœ† âˆ‘ ğ‘– âˆˆ [ ğ‘˜ ] ğœ† ğ‘– ğ‘– ! Mean E [ ğ‘‹ ] = ğœ† Variance Var [ ğ‘‹ ] = ğœ† Equals the limit of Binomial with fixed scaled parameter. lim ğ‘› â†’ + âˆ Bin ( ğ‘› , ğœ† ğ‘› ) = Pois ( ğœ† ) 1.4.2. Continuous UniformEverything is equally likely Notation ğ‘‹ âˆ¼ ğ’° ( [ ğ‘ , ğ‘ ] ) Parameters ğ‘ âˆˆ â„ , ğ‘ âˆˆ â„ > ğ‘ Support ğ‘¥ âˆˆ â„ PDF ğ‘“ ğ‘‹ ( ğ‘¥ ) = { 1 ğ‘ âˆ’ ğ‘ ğ‘¥ âˆˆ [ ğ‘ , ğ‘ ] 0 ğ‘¥ âˆ‰ [ ğ‘ , ğ‘ ] CDF ğ¹ ğ‘‹ ( ğ‘¥ ) = {{{{{ 0 ğ‘¥ < ğ‘ ğ‘¥ âˆ’ ğ‘ ğ‘ âˆ’ ğ‘ ğ‘ â‰¤ ğ‘¥ < ğ‘ 1 ğ‘¥ â‰¥ ğ‘ Mean E [ ğ‘‹ ] = ğ‘ + ğ‘ 2 Variance Var [ ğ‘‹ ] = ( ğ‘ âˆ’ ğ‘ ) 2 1 2 NormalEverything is normal. Notation ğ‘‹ âˆ¼ ğ’© ( ğœ‡ , ğœ 2 ) Parameters ğœ‡ âˆˆ â„ , ğœ 2 âˆˆ â„ + Support ğ‘¥ âˆˆ â„ PDF ğ‘“ ğ‘‹ ( ğ‘¥ ) = ğ‘’ âˆ’ ( ğ‘¥ âˆ’ ğœ‡ ) 2 2 ğœ 2 âˆš 2 ğœ‹ ğœ 2 CDF ğ¹ ğ‘‹ ( ğ‘¥ ) = Î¦ ( ğ‘¥ ) if ğ‘‹ âˆ¼ ğ’© ( 0 , 1 ) Mean E [ ğ‘‹ ] = ğœ‡ Variance Var [ ğ‘‹ ] = ğœ 2 ExponentialWaiting time between Poisson events. Notation ğ‘‹ âˆ¼ Exp ( ğœ† ) Parameters ğœ† âˆˆ â„ âˆ—+ Support ğ‘¥ âˆˆ [ 0 , + âˆ ) PDF ğ‘“ ğ‘‹ ( ğ‘¥ ) = ğœ† ğ‘’ âˆ’ ğœ† ğ‘¥ CDF ğ¹ ğ‘‹ ( ğ‘¥ ) = 1 âˆ’ ğ‘’ âˆ’ ğœ† ğ‘¥ Mean E [ ğ‘‹ ] = 1 ğœ† Variance Var [ ğ‘‹ ] = 1 ğœ† 2 2 2. Statistics 2.1. Estimation Let ğ— = ( ğ‘‹ ğ‘– ) ğ‘› be the (i.i.d.) r.v.â€˜s describing some underlying model. Then ğ± = ğ— ( ğœ” ) = ( ğ‘‹ ğ‘– ( ğœ” ) ) ğ‘› denotes an observation, i.e. its realization. EstimatorIs r.v. ğ‘‡ : Î© â†’ â„ for some measurable function ğ‘¡ : â„ ğ‘› â†’ â„ which yields estimate for parameter ğœƒ âˆˆ Î˜ based the sample ğ± . ğ‘‡ = ğ‘¡ ( ğ— ) ğ‘‡ ( ğœ” ) = ğ‘¡ ( ğ± ) BiasFor estimator ğ‘‡ of parameter ğœƒ âˆˆ Î˜ , bias is as defined below. Bias ğœƒ [ ğ‘‡ ] = E ğœƒ [ ğ‘‡ ] âˆ’ ğœƒ An estimator ğ‘‡ is unbiased if and only if âˆ€ ğœƒ âˆˆ Î˜ . Bias ğœƒ [ ğ‘‡ ] = 0 . Mean Square ErrorFor estimator ğ‘‡ of parameter ğœƒ âˆˆ Î˜ , MSE is as defined below. MSE ğœƒ [ ğ‘‡ ] = E ğœƒ [ ( ğ‘‡ âˆ’ ğœƒ ) 2 ] = Var ğœƒ [ ğ‘‡ ] âˆ’ ( Bias ğœƒ [ ğ‘‡ ] ) 2 For unbiased estimators, the MSE is equal to the variance. Likelihood For ğ— i.i.d. , likelihood of sample ğ± with parameter ğœƒ as below. ğ¿ ( ğ± ; ğœƒ ) = âˆ ğ‘– âˆˆ [ ğ‘› ] âˆ— ğ‘“ ğ‘‹ ğ‘– ( ğ‘¥ ğ‘– ; ğœƒ ) Logarithm of likelihood transforms product to sum, ğ‘™ = ln ğ¿ . Maximum Likelihood EstimatorFor ğ— i.i.d. , MLE of ğœƒ âˆˆ Î˜ for sample ğ± is defined as follows. Ì‚ğœƒ ML = arg max ğœƒ âˆˆ Î˜ ğ¿ ( ğ± ; ğœƒ ) = arg max ğœƒ âˆˆ Î˜ ğ‘™ ( ğ± ; ğœƒ ) 2.2. Testing Confidence IntervalFor some parameter ğœƒ and confidence level ğ›¾ = 1 âˆ’ ğ›¼ with ğ›¼ âˆˆ [ 0 , 1 ] , confidence interval for ğ— = ( ğ‘‹ ğ‘– ) ğ‘› is defined as the random interval ğ¼ = [ ğ´ , ğµ ] with endpoints defined by functions ğ‘ , ğ‘ : â„ ğ‘› â†’ â„ such that the following holds. âˆ€ ğœƒ âˆˆ Î˜ . Pr ğœƒ [ ğ´ â‰¤ ğœƒ â‰¤ ğµ ] â‰¥ ğ›¾ Hypothesis For parameter space Î˜ , hypothesis forms two exclusive classes of the underlying model. Î˜ 0 , Î˜ A âŠ‚ Î˜ Î˜ 0 âˆ© Î˜ A = âŒ€ The null hypothesis ğ» 0 states that ğœƒ âˆˆ Î˜ 0 . The alternative hypothesis ğ» A states that ğœƒ âˆˆ Î˜ A . Simple hypothesis has cardinality one, otherwise composite hypothesis.Typically, it holds that Î˜ A = Î˜ âˆ– Î˜ 0 . Statistical TestPair ( ğ‘‡ , ğ¾ ) of statistic ğ‘‡ = ğ‘¡ ( ğ— ) and critical region ğ¾ âŠ‚ â„ . For the observation ğœ” the test then rejects or accepts ğ» 0 . ğ‘‡ ( ğœ” ) âˆˆ ğ¾ âŸ¹ reject ğ» 0 ğ‘‡ ( ğœ” ) âˆ‰ ğ¾ âŸ¹ accept ğ» 0 Type 1 error falsely rejects ğ» 0 with Pr ğœƒ [ ğ‘‡ âˆˆ ğ¾ ] . Type 2 error falsely accepts ğ» 0 with Pr [ ğ‘‡ âˆ‰ ğ¾ ] = 1 âˆ’ Pr ğœƒ [ ğ‘‡ âˆˆ ğ¾ ] . Significance LevelTest ( ğ‘‡ , ğ¾ ) has significance level ğ›¼ âˆˆ [ 0 , 1 ] if the following holds. âˆ€ ğœƒ âˆˆ Î˜ 0 . Pr ğœƒ [ ğ‘‡ âˆˆ ğ¾ ] â‰¤ ğ›¼ Here ğ›¼ is upper bound on probability of type 1 error, minimize . PowerTest ( ğ‘¡ , ğ¾ ) has power ğ›½ : Î˜ A â†’ [ 0 , 1 ] as defined below. ğ›½ ( ğœƒ ) = Pr ğœƒ [ ğ‘‡ âˆˆ ğ¾ ] Here 1 âˆ’ ğ›½ ( Î˜ A ) is the probability of type 2 error, try to maximize . This asymmetry makes it harder to reject ğ» 0 , than fail to reject it. Thus, choose ğ» 0 as the negation of the statement to prove. Likelihood Ratio For Î˜ 0 = { ğœƒ 0 } , Î˜ A = { ğœƒ A } the likelihood ratio is defined as below. ğ‘… ( ğ± ) = ğ¿ ( ğ± , ğœƒ A ) ğ¿ ( ğ± , ğœƒ 0 ) Likelihood Ratio TestAs ğ‘… ( ğ— ) grows, ğ» A is increasingly likely compared to ğ» 0 . ğ‘‡ = ğ‘… ( ğ— ) ğ¾ = ( ğ‘ , + âˆ ) For significance level ğ›¼ = Pr ğœƒ 0 [ ğ‘‡ > ğ‘ ] determine suitable ğ‘ â‰¥ 0 . This method is optimal in power for deciding between two cases ğœƒ 0 , ğœƒ A with given significance level ğ›¼ by the Neyman-Pearson-Lemma. Ordered Family of Tests Family of tests ( ğ‘‡ , ( ğ¾ ğ‘¡ ) ğ‘˜ â‰¥ 0 ) can be ordered with respect to ğ‘‡ . âˆ€ ğ‘– , ğ‘— âˆˆ â„ + . ğ‘– â‰¤ ğ‘— âŸ¹ ğ¾ ğ‘– âŠƒ . ğ¾ ğ‘— If the ğ‘¡ -th test rejects ğ» 0 , then all previous tests also reject it. p-valueFor simple null hypothesis ğ» 0 : ğœƒ = ğœƒ 0 the p-value is r.v. as below. p-value = ğº ( ğ‘‡ ) For ğ‘¡ = ğ‘‡ ( ğœ” ) the p-value ğº ( ğ‘¡ ) = Pr ğœƒ 0 [ ğ‘‡ âˆˆ ğ¾ ğ‘¡ ] is probability of observing result at least as extreme as sample, provided ğ» 0 holds. Alternatively, lowest significance level that allows rejection of ğ» 0 . Chi-Squared DistributionThe r.v. ğ‘‹ âˆ¼ ğœ’ 2ğ‘š in ğ‘š degrees of freedom with density given below. ğ‘“ ğ‘‹ ( ğ‘¥ ) = ğ‘¥ ğ‘š 2 âˆ’ 1 ğ‘’ âˆ’ ğ‘¥2 2 ğ‘š 2 Î“ ( ğ‘š 2 ) âˆ€ ğ‘› âˆˆ â„• . Î“ ( ğ‘› ) = ( ğ‘› âˆ’ 1 ) ! . If you are using this, good luck! Sum of SquaresLet ( ğ‘‹ ğ‘– ) ğ‘š âˆ¼ i.i.d. ğ’© ( 0 , 1 ) then their squared sum is chi-squared. âˆ‘ ğ‘– âˆˆ [ ğ‘š ] ğ‘‹ 2 ğ‘– = ğ‘Œ âˆ¼ ğœ’ 2ğ‘š t-distributionThe r.v. ğ‘‹ âˆ¼ ğ‘¡ ğ‘š in ğ‘š degrees of freedom with density given below. ğ‘“ ğ‘‹ ( ğ‘¥ ) = Î“ ( ğ‘š + 1 2 ) âˆš ğ‘š ğœ‹ Î“ ( ğ‘š 2 ) ( 1 + ğ‘¥ 2 ğ‘š ) âˆ’ ğ‘š + 1 2 3 3. Utility 3.1. Notational Conventions â€¢ â„ + = [ 0 , + âˆ ) â€¢ â„ âˆ—+ = ( 0 , + âˆ ) â€¢ â„• = { 0 , 1 , â€¦ } â€¢ â„• âˆ— = â„• âˆ– { 0 } â€¢ [ ğ‘› ] = { ğ‘˜ âˆˆ â„• âˆ— | ğ‘˜ â‰¤ ğ‘› } = { 1 , â€¦ , ğ‘› } â€¢ [ ğ‘› ] âˆ— = [ ğ‘› ] âˆ– { 0 } 3.2. Tables â€¢ âˆ‘ ğ‘– âˆˆ [ ğ‘› ] âˆ— ğ‘– = ğ‘› ğ‘› + 1 2 â€¢ âˆ‘ ğ‘– âˆˆ [ ğ‘› ] âˆ— ğ‘– 2 = ğ‘› ( ğ‘› + 1 ) ( 2 ğ‘› + 1 ) 6 â€¢ âˆ‘ ğ‘– âˆˆ [ ğ‘› ] âˆ— ğ‘– 3 = ğ‘› 2 ( ğ‘› + 1 ) 2 4 From ğ‘› take ğ‘˜ With Repetition Without Repetition With Order ğ‘› ğ‘˜ ğ‘› ! ( ğ‘› âˆ’ ğ‘˜ ) ! Without Order ( ğ‘› + ğ‘˜ âˆ’ 1 ğ‘˜ ) ( ğ‘›ğ‘˜ ) = ğ‘› ! ğ‘› ! ( ğ‘› âˆ’ ğ‘˜ ) ! ğ¹ ( ğ‘¥ ) ğ¹ â€² ( ğ‘¥ ) ğ¶ 0 ğ‘¥ ğ‘› , ğ‘› â‰  âˆ’ 1 ğ‘› ğ‘¥ ğ‘› âˆ’ 1 ğ‘¥ ğ‘› + 1 ğ‘› + 1 ğ‘¥ ğ‘› , ğ‘› â‰  âˆ’ 1 ( ğ‘ ğ‘¥ + ğ‘ ) ğ‘› + 1 ğ‘ ( ğ‘› + 1 ) ( ğ‘ ğ‘¥ + ğ‘ ) ğ‘› âˆš ğ‘¥ 1 2 âˆš ğ‘¥ ğ‘›âˆš ğ‘¥ = ğ‘¥ 1 ğ‘› ğ‘¥ 1 ğ‘› âˆ’ 1 ğ‘› 2 ğ‘¥ 32 3 âˆš ğ‘¥ ğ‘› ğ‘¥ 1 ğ‘› + 1 ğ‘› + 1 ğ‘›âˆš ğ‘¥ ğ‘’ ğ‘¥ ğ‘’ ğ‘¥ ğ‘ ğ‘ ğ‘¥ ğ‘ ğ‘ ğ‘¥ ğ‘ ln ğ‘ ğ‘ ğ‘ ğ‘¥ ğ‘ ln ğ‘ ğ‘ ğ‘ ğ‘¥ ln | ğ‘¥ | 1 ğ‘¥ ğ‘¥ ln | ğ‘¥ | âˆ’ ğ‘¥ ln | ğ‘¥ | log ğ‘ | ğ‘¥ | 1 ğ‘¥ ln ğ‘ = log ğ‘ ğ‘’ ğ‘¥ sin ğ‘¥ cos ğ‘¥ cos ğ‘¥ âˆ’ sin ğ‘¥ ğ‘ ğ‘“ ( ğ‘¥ ) ğ‘ ğ‘“ â€² ( ğ‘¥ ) ğ‘“ ( ğ‘¥ ) + ğ‘” ( ğ‘¥ ) ğ‘“ â€² ( ğ‘¥ ) + ğ‘” ( ğ‘¥ ) â€² ğ‘“ ( ğ‘¥ ) ğ‘” ( ğ‘¥ ) ğ‘“ â€² ( ğ‘¥ ) ğ‘” ( ğ‘¥ ) + ğ‘“ ( ğ‘¥ ) ğ‘” â€² ( ğ‘¥ ) â€² ğ‘“ ( ğ‘¥ ) ğ‘” ( ğ‘¥ ) ğ‘“ â€² ( ğ‘¥ ) ğ‘” ( ğ‘¥ ) âˆ’ ğ‘“ ( ğ‘¥ ) ğ‘” â€² ( ğ‘¥ ) â€² ğ‘” ( ğ‘¥ ) 2 ğ‘“ ( ğ‘” ( ğ‘¥ ) ) ğ‘“ â€² ( ğ‘” ( ğ‘¥ ) ) ğ‘” â€² ( ğ‘¥ ) Integration by Substitutionğ‘¢ = ğ‘” ( ğ‘¥ ) âŸ¹ d ğ‘¢ = ğ‘” â€² ( ğ‘¥ ) d ğ‘¥ âˆ« ğ‘ ğ‘ ğ‘“ ( ğ‘” ( ğ‘¥ ) ) ğ‘” â€² ( ğ‘¥ ) d ğ‘¥ = âˆ« ğ‘” ( ğ‘ ) ğ‘” ( ğ‘ ) ğ‘“ ( ğ‘¢ ) d ğ‘¢ Integration by Parts âˆ« ğ‘“ ( ğ‘¥ ) ğ‘” â€² ( ğ‘¥ ) d ğ‘¥ = ğ‘“ ( ğ‘¥ ) ğ‘” ( ğ‘¥ ) âˆ’ âˆ« ğ‘“ â€² ( ğ‘¥ ) ğ‘” ( ğ‘¥ ) d ğ‘¥ DI Method Compute âˆ« ğ‘ ( ğ‘¥ ) ğ‘ ( ğ‘¥ ) d ğ‘¥ . 1. Choose functions ğ‘“ ( ğ‘¥ ) , ğ‘” ( ğ‘¥ ) for differentiation and integration â€¢ âˆ« ğ‘“ ( ğ‘¥ ) ğ‘” ( ğ‘¥ ) d ğ‘¥ = âˆ« ğ‘ ( ğ‘¥ ) ğ‘ ( ğ‘¥ ) d ğ‘¥ 2. Construct DI table Â± D I 0 ğ‘“ ( ğ‘¥ ) ğ‘” ( ğ‘¥ ) 1 ğ‘“ â€² ( ğ‘¥ ) âˆ« ğ‘” ( ğ‘¥ ) d ğ‘¥ 2 ğ‘“ â€³ ( ğ‘¥ ) âˆ¬ ğ‘” ( ğ‘¥ ) d ğ‘¥ d ğ‘¥ ğ‘– â€¦ â€¦ ğ‘ ğ· ğ‘ ğ¼ ğ‘ 3. Stop at ğ‘– = ğ‘ if any condition holds â€¢ ğ· ğ‘ = 0 â€¢ âˆ« ğ· ğ‘ ğ¼ ğ‘ d ğ‘¥ is easy â€¢ âˆ« ğ· ğ‘ ğ¼ ğ‘ d ğ‘¥ = âˆ« ğ‘ ( ğ‘¥ ) ğ‘ ( ğ‘¥ ) d ğ‘¥ 4. Result is telescope sum of diagonals ( â†˜ ), plus final row âˆ« ğ‘ ( ğ‘¥ ) ğ‘ ( ğ‘¥ ) d ğ‘¥ = âˆ‘ ğ‘– âˆˆ [ ğ‘ âˆ’ 1 ] ( âˆ’ 1 ) ğ‘– ğ· ğ‘– ğ¼ ğ‘– + 1 + âˆ« ğ· ğ‘ ğ¼ ğ‘ d ğ‘¥ Independent Distributions Approaches ğ‘‹ ğ‘– âˆ¼ Pois ( ğœ† ğ‘– ) âˆ‘ ğ‘– âˆˆ [ ğ‘› ] âˆ— ğ‘‹ ğ‘– âˆ¼ Pois ((( âˆ‘ ğ‘– âˆˆ [ ğ‘› ] âˆ— ğœ† ğ‘– ))) ğ‘‹ ğ‘– âˆ¼ Bin ( ğ‘› ğ‘– , ğ‘ ) âˆ‘ ğ‘– âˆˆ [ ğ‘› ] âˆ— ğ‘‹ ğ‘– âˆ¼ Bin ((( âˆ‘ ğ‘– âˆˆ [ ğ‘› ] âˆ— ğ‘› ğ‘– , ğ‘ ))) ğ‘‹ ğ‘– âˆ¼ ğ’© ( ğœ‡ ğ‘– , ğœ 2 ğ‘– ) ğœ‡ ğ‘ = ğ‘ + âˆ‘ ğ‘– âˆˆ [ ğ‘› ] âˆ— ğ‘ ğ‘– ğœ‡ ğ‘– ğœ ğ‘ = âˆ‘ ğ‘– âˆˆ [ ğ‘› ] âˆ— ğ‘ 2ğ‘– ğœ 2 ğ‘– ğ‘ + âˆ‘ ğ‘– âˆˆ [ ğ‘› ] âˆ— ğ‘ ğ‘– ğ‘‹ ğ‘– = ğ‘ âˆ¼ ğ’© ( ğœ‡ ğ‘ , ğœ ğ‘ ) 3.3. Inequalities MarkovLet ğ‘‹ be non-negative and ğ‘ âˆˆ â„ . Pr [ ğ‘‹ â‰¥ ğ‘ ] â‰¤ E [ ğ‘‹ ] ğ‘ ChebyshevLet E [ ğ‘‹ 2 ] < + âˆ and ğ‘ âˆˆ â„ + . Pr [ | ğ‘‹ âˆ’ ğœ‡ ğ‘‹ | â‰¥ ğ‘ ] â‰¤ Var [ ğ‘‹ ] ğ‘ 2 JensenLet ğ‘‹ be r.v. and ğœ‘ : â„ â†’ â„ convex . The inequality holds if defined. ğœ‘ ( E [ ğ‘‹ ] ) â‰¤ E [ ğœ‘ ( ğ‘‹ ) ] 3.4. Miscellaneous Just in case, ğ‘ = 2 9 9 â€² 7 9 2 â€² 4 5 8 ğ‘š ğ‘  . Inclusion Exclusion Principle Pr [ â‹ƒ ğ‘– âˆˆ [ ğ‘› ] âˆ— ğ´ ğ‘– ] = âˆ‘ ğ½ âŠ† [ ğ‘› ] âˆ— ( âˆ’ 1 ) | ğ½ | + 1 Pr [ â‹‚ ğ‘— âˆˆ ğ½ ğ´ ğ‘— ] Binomial Theorem ( ğ‘¥ + ğ‘¦ ) ğ‘› = âˆ‘ ğ‘– âˆˆ [ ğ‘› ] ( ğ‘› ğ‘– ) ğ‘¥ ğ‘– ğ‘¦ ğ‘› âˆ’ ğ‘– = âˆ‘ ğ‘– âˆˆ [ ğ‘› ] ( ğ‘› ğ‘– ) ğ‘¥ ğ‘› âˆ’ ğ‘– ğ‘¦ ğ‘– Gamma FunctionExtension of the factorial to the reals, Î“ : â„ â†’ â„ as defined below. Î“ ( ğ‘¥ ) = âˆ« + âˆ 0 ğ‘¡ ğ‘¥ âˆ’ 1 ğ‘’ âˆ’ ğ‘¥ d ğ‘¡ Polar CoordinatesFor bivariate ğ‘¥ = ğ‘Ÿ cos ( ğœƒ ) , ğ‘¦ = ğ‘Ÿ sin ( ğœƒ ) substitution below is useful. â€¢ ğ‘¥ 2 + ğ‘¦ 2 = ğ‘Ÿ 2 â€¢ d ğ‘¥ d ğ‘¦ = ğ‘Ÿ d ğ‘Ÿ d ğœƒ rad sin cos tan 0 0 1 0 ğœ‹6 12 âˆš 3 2 âˆš 3 3 ğœ‹4 âˆš 2 2 âˆš 2 2 1 ğœ‹3 âˆš 3 2 12 âˆš 3 ğœ‹2 1 0 N/A logarithm rules log ğ‘ ( 1 ) = 0 log ğ‘ ( ğ‘¥ ğ‘¦ ) = log ğ‘ ( ğ‘¥ ) + log ğ‘ ( ğ‘¦ ) log ğ‘ ( ğ‘¥ğ‘¦ ) = log ğ‘ ( ğ‘¥ ) âˆ’ log ğ‘ ( ğ‘¦ ) log ğ‘ ( ğ‘¥ ğ‘Ÿ ) = ğ‘Ÿ Â· log ğ‘ ( ğ‘¥ ) log ğ‘ ( ğ‘ ) = log ğ‘ ( ğ‘ ) log ğ‘ ( ğ‘ ) 4 4. Appendix 4.1. Recipes Standardize Normal DistributionLet ğ‘‹ âˆ¼ ğ’© ( ğœ‡ , ğœ 2 ) . Normalization yields standard normal. ğ‘‹ âˆ’ ğœ‡ ğœ âˆ¼ ğ’© ( 0 , 1 ) Maximum Likelihood EstimatorFind Ì‚ğœƒ ML for ğ— = ( ğ‘‹ ğ‘– ) ğ‘› i.i.d. . 1. ğ¿ ( ğ± ; ğœƒ ) = âˆ ğ‘– âˆˆ [ ğ‘› ] âˆ— ğ‘“ ğ‘‹ ğ‘– ( ğ‘¥ ğ‘– ; ğœƒ ) 2. ğ‘™ ( ğ± ; ğœƒ ) = ln âˆ‘ ğ‘– âˆˆ [ ğ‘› ] âˆ— ğ‘“ ğ‘‹ ğ‘– ( ğ‘¥ ğ‘– ; ğœƒ ) = âˆ‘ ğ‘– âˆˆ [ ğ‘› ] âˆ— ln ğ‘“ ğ‘‹ ğ‘– ( ğ‘¥ ğ‘– ; ğœƒ ) 3. Differentiate with respect to ğœƒ 4. Solve ğ‘™ â€² ( ğœƒ ) = 0 for ğœƒ 5. Check local maximum with ğ‘™ â€³ ( ğœƒ ) < 0 Confidence IntervalFind interval ğ¼ with confidence level ğ›¾ = 1 âˆ’ ğ›¼ . 1. For symmetric distribution define ğ¼ around MLE, ğ‘‡ = Ì‚ğœƒ ML â€¢ ğ¼ = [ ğ‘‡ âˆ’ ğ‘ , ğ‘‡ + ğ‘ ] â€¢ ğ›¾ = Pr ğœƒ [ ğ‘‡ âˆ’ ğ‘ â‰¤ ğœƒ â‰¤ ğ‘‡ + ğ‘ ] 2. Rewrite to single instance of estimator ğ‘‡ â€¢ Pr ğœƒ [ ğœƒ âˆ’ ğ‘ â‰¤ ğ‘‡ â‰¤ ğœƒ + ğ‘ ] 3. Convert ğ‘‡ to known distribution, e.g. Î¦ 4. Use CDF to calculate probability w.r.t. ğ‘ and set equal to ğ›¾ 5. Invert CDF and solve for ğ‘ Define TestFor given probability model. 1. Form hypotheses ğ» 0 , ğ» A , with aim to disprove the ğ» 0 2. Calculate statistic ğ‘‡ (e.g. MLE) and determine form of ğ¾ 3. Set significance level ğ›¾ = 1 âˆ’ ğ›¼ 4. Solve ğ›¼ = Pr ğœƒ 0 [ ğ‘‡ âˆˆ ğ¾ ] for ğ¾ â€¢ Choose ğœƒ 0 âˆˆ Î˜ 0 s.t. âˆ€ ğœƒ âˆˆ Î˜ 0 . Pr ğœƒ [ ğ‘‡ âˆˆ ğ¾ ] â‰¤ Pr ğœƒ 0 [ ğ‘‡ âˆˆ ğ¾ ] 5. Perform the test, i.e. insert data into ğ‘‡ 6. Decide on hypothesis and optionally determine p-value 4.1.1. Suitable Tests for Hypotheses at Significance Level ğ›¼ Let ğ— = ( ğ‘‹ ğ‘– ) ğ‘› i.i.d. with E [ ğ‘‹ ğ‘– ] < + âˆ and ğœ‡ = E [ ğ‘‹ ğ‘– ] , ğœ 2 = Var [ ğ‘‹ ğ‘– ] . Let ğ‘† 2 = 1 ğ‘› âˆ’ 1 âˆ‘ ğ‘– âˆˆ [ ğ‘› ] âˆ— ( ğ‘‹ ğ‘– âˆ’ ğ‘‹ ) 2 . Test Mean, Known Variance, Normal Distribution ğ— âˆ¼ i.i.d. ğ’© ( ğœƒ , ğœ 2 ) , ğœ 2 known. ğ» 0 : ğœƒ = ğœƒ 0 ğ‘‡ = ğ‘† ğ‘› âˆ’ ğ‘› ğœƒ 0âˆš ğ‘› ğœ 2 âˆ¼ Pr ğœƒ 0 ğ’© ( 0 , 1 ) ğ» A : ğœƒ A > ğœƒ 0 âŸ¹ ğ¾ = ( ğ‘ â† , + âˆ ) , ğ‘ â† = Î¦ âˆ’ 1 ( 1 âˆ’ ğ›¼ ) = ğ‘§ 1 âˆ’ ğ›¼ ğ» A : ğœƒ A < ğœƒ 0 âŸ¹ ğ¾ = ( âˆ’ âˆ , ğ‘ â†’ ) , ğ‘ â†’ = Î¦ âˆ’ 1 ( ğ›¼ ) ğ» A : ğœƒ A â‰  ğœƒ 0 âŸ¹ ğ¾ = ( âˆ’ âˆ , âˆ’ ğ‘ â†” ) âˆª ( ğ‘ â†” , + âˆ ) , ğ‘ â†” = Î¦ âˆ’ 1 ( 1 âˆ’ ğ›¼2 ) Test Mean, Unknown Variance, Normal Distribution ğ— âˆ¼ i.i.d. ğ’© ( ğœ‡ , ğœ 2 ) . ğ» 0 : ğœƒ = ğœƒ 0 âˆˆ { ğœ‡ 0 } Ã— â„ âˆ—+ ğ‘‡ = ğ‘† ğ‘› âˆ’ ğ‘› ğœ‡ 0âˆš ğ‘› ğ‘† 2 âˆ¼ ğ‘ƒ ğœƒ 0 ğ‘¡ ğ‘› âˆ’ 1 ğ» A : ğœ‡ A > ğœ‡ 0 âŸ¹ ğ¾ = ( ğ‘ â† , + âˆ ) , ğ‘ â† = ğ‘¡ ğ‘› âˆ’ 1 , 1 âˆ’ ğ›¼ ğ» A : ğœ‡ A < ğœ‡ 0 âŸ¹ ğ¾ = ( âˆ’ âˆ , ğ‘ â†’ ) , ğ‘ â†’ = ğ‘¡ ğ‘› âˆ’ 1 , ğ›¼ ğ» A : ğœ‡ A â‰  ğœ‡ 0 âŸ¹ ğ¾ = ( âˆ’ âˆ , âˆ’ ğ‘ â†” ) âˆª ( ğ‘ â†” , + âˆ ) , ğ‘ â†” = ğ‘¡ ğ‘› âˆ’ 1 , 1 âˆ’ ğ›¼ 2 Test Variance, Unknown Mean, Normal Distribution ğ— âˆ¼ i.i.d. ğ’© ( ğœ‡ , ğœ 2 ) . ğ» 0 : ğœ 2 = ğœ 2 0 ğ‘‡ = ( ğ‘› âˆ’ 1 ) ğ‘† 2 ğ‘› ğœ 2 0 âˆ¼ ğœ’ 2ğ‘› âˆ’ 1 ğ» A : ğœ‡ A > ğœ‡ 0 âŸ¹ ğ¾ = ( ğ‘ â† , + âˆ ) , ğ‘ â† = ğœ’ 2ğ‘› âˆ’ 1 , 1 âˆ’ ğ›¼ ğ» A : ğœ‡ A < ğœ‡ 0 âŸ¹ ğ¾ = ( âˆ’ âˆ , ğ‘ â†’ ) , ğ‘ â†’ = ğœ’ 2ğ‘› âˆ’ 1 , ğ›¼ ğ» A : ğœ‡ A â‰  ğœ‡ 0 âŸ¹ ğ¾ = ( âˆ’ âˆ , âˆ’ ğ‘ â†” ) âˆª ( ğ‘ â†” , + âˆ ) , ğ‘ â†” = ğœ’ 2ğ‘› âˆ’ 1 , 1 âˆ’ ğ›¼ 2 Test Mean, Known Variance, Unknown Distribution ğ— i.i.d. , ğœ 2 known. ğ» 0 : ğœƒ = ğœƒ 0 ğ‘‡ = ğ‘† ğ‘› âˆ’ ğ‘› ğœƒ 0âˆš ğ‘› ğœ 2 âˆ¼ ğ‘ƒ ğœƒ 0 ğ’© ( 0 , 1 ) by the CLT ğ» A : ğœ‡ A > ğœ‡ 0 âŸ¹ ğ¾ = ( ğ‘ â† , + âˆ ) , ğ‘ â† = ğ‘§ 1 âˆ’ ğ›¼ ğ» A : ğœ‡ A < ğœ‡ 0 âŸ¹ ğ¾ = ( âˆ’ âˆ , ğ‘ â†’ ) , ğ‘ â†’ = ğ‘§ ğ›¼ ğ» A : ğœ‡ A â‰  ğœ‡ 0 âŸ¹ ğ¾ = ( âˆ’ âˆ , âˆ’ ğ‘ â†” ) âˆª ( ğ‘ â†” , + âˆ ) , ğ‘ â†” = ğ‘§ 1 âˆ’ ğ›¼ 2 Test Mean, Unknown Variance, Unknown Distribution ğ— i.i.d. , ğœ 2 unknown. ğ» 0 : ğœƒ = ğœƒ 0 âˆˆ { ğœ‡ 0 } Ã— â„ âˆ—+ ğ‘‡ = ğ‘† ğ‘› âˆ’ ğ‘› ğœ‡ 0âˆš ğ‘› ğ‘† 2 âˆ¼ ğ‘ƒ ğœƒ 0 ğ’© ( 0 , 1 ) by CLT ğ» A : ğœ‡ A > ğœ‡ 0 âŸ¹ ğ¾ = ( ğ‘ â† , + âˆ ) , ğ‘ â† = ğ‘§ 1 âˆ’ ğ›¼ ğ» A : ğœ‡ A < ğœ‡ 0 âŸ¹ ğ¾ = ( âˆ’ âˆ , ğ‘ â†’ ) , ğ‘ â†’ = ğ‘§ ğ›¼ ğ» A : ğœ‡ A â‰  ğœ‡ 0 âŸ¹ ğ¾ = ( âˆ’ âˆ , âˆ’ ğ‘ â†” ) âˆª ( ğ‘ â†” , + âˆ ) , ğ‘ â†” = ğ‘§ 1 âˆ’ ğ›¼ 2 4.2. Examples Common EstimatorsLet ğ— = ( ğ‘‹ ğ‘– ) ğ‘› and ğ‘‹ = 1 ğ‘› âˆ‘ ğ‘– âˆˆ [ ğ‘› ] âˆ— ğ‘‹ ğ‘– . Bernoulli Ì‚ğ‘ = ğ‘‹ Binomial Ì‚ğ‘ = ğ‘‹ ğ‘š for ğ— âˆ¼ i.i.d. Bin ( ğ‘ , ğ‘š ) with ğ‘š known Poisson Ì‚ğœ† = ğ‘‹ Normal Ì‚ğœ‡ = ğ‘‹ Ì‚ğœ 2 = {{{{{ 1 ğ‘› âˆ‘ ğ‘– âˆˆ [ ğ‘› ] âˆ— ( ğ‘‹ ğ‘– âˆ’ Ì‚ğœ‡ ) 2 biased MLE 1 ğ‘› âˆ’ 1 âˆ‘ ğ‘– âˆˆ [ ğ‘› ] âˆ— ( ğ‘‹ ğ‘– âˆ’ Ì‚ğœ‡ ) 2 unbiased Exponential Ì‚ğœ† = 1 ğ‘‹ Uniform Ì‚ğ‘ = min ( ğ— ) Ì‚ğ‘ = max ( ğ— ) 56","libVersion":"0.5.0","langs":""}
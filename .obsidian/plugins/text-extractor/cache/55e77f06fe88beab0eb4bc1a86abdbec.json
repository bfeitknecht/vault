{"path":"sem4/CN/VRL/extra/slides/CN-s06-UDP-TCP.pdf","text":"Computer Networks: UDP and TCP Simon Scherrer Slides adapted from Ankit Singla, Jennifer Rexford, Scott Shenker, Laurent Vanbever Photo: ETH Zürich / Gian Marco Castelberg Where we are in the course … Part 1: Overview & Principles Part 2: Applications Part 3: Transport Part 4: Algorithms 2 Last Lecture Quick recap Application multiplexing, bytestream abstractions, reliability, flow & congestion control Desired functionality of transport layer Goals of reliable transport Timers, ACKs, sliding-window algorithm Design primitives for reliable transport Go-Back-N vs Selective Repeat vs TCP Retransmission Retransmission algorithms 3 Correctness, timeliness, efficiency, fairness Computer Networks What should the transport layer provide? How do we build reliable transport? How does the Internet’s transport work? Sockets: the application ⟷ transport interface #1 #2 #3 #4 Part 3: Transport 4 Reliable Internet transport Data delivery to the correct application IP just targets network interfaces, not individual applications using the same interface Files or byte-streams abstractions for applications Network deals with packets Transport layer needs to turn packets into streams Reliable transfer Not overloading the receiver Not overloading the network 5 Two Major Internet Transport Protocols User Datagram Protocol (UDP) Absolute basic transport-layer functionality Transmission Control Protocol (TCP) Full-fledged transport-layer functionality including reliability, flow control, and congestion control 6 User Datagram Protocol (UDP) Absolute basic transport-layer functionality 7 UDP: “User Datagram Protocol” Data delivery to the correct application Demultiplexing using application identifiers (ports) Files or byte-streams abstractions for applications Do segmentation and reassembly Reliable transfer: ACKs, checksums (optionally) No-frills, simple extension of IP 9 This is all UDP is SRC port DST port checksum length DATA \"I'd tell you a joke on UDP, but you might not get it...\" 10 Why would anyone want UDP? • Avoids overhead and delays of ordered, reliable delivery • No delay for connection establishment • Finer control by application over what data is sent and when • No connection state, buffers, timers, leading to greater scalability • Small per-packet overhead, as headers are minimal DNS Gaming VoIP 11 Two Major Internet Transport Protocols User Datagram Protocol (UDP) Absolute basic transport-layer functionality Transmission Control Protocol (TCP) Full-fledged transport-layer functionality including reliability, flow control, and congestion control 17 Transmission Control Protocol (TCP) Full-fledged transport-layer functionality including reliability, flow control, and congestion control 18 TCP: “Transmission Control Protocol” Data delivery to the correct application Demultiplexing using application identifiers (ports) Files or byte-streams abstractions for applications Do segmentation and reassembly Reliable transfer: ACKs, checksums Not overloading the receiver: “Flow control” via receiver window Not overloading the network: “Congestion control” via sender window 19 Connections (or sessions) Reliability requires keeping state Sender: packets sent but not ACKed, and related timers Receiver: non-contiguous packets Each bytestream is called a connection or session Each with their own connection state State is in hosts, not network! 20 What transport protocols do not provide Delay and/or bandwidth guarantees This cannot be offered by transport Would require support at IP level Sessions that survive change-of-IP-address This is an artifact of current implementations (cf. lecture on sockets) 21 Transmission Control Protocol (TCP) Reliable, in-order delivery • ACKs — carry byte sequence numbers, cumulative • Timer — resend on timeout, double the timer value • “Fast retransmit” — on three duplicate ACKs • Requires “connections” and associated state at end hosts Flow control • Sliding window of size no larger than receiver wants Congestion control • Dynamic adaptation to network-path capacity 23 TCP Header Source port Destination port Sequence number Acknowledgment Advertised windowHdrLen Flags0 Checksum Urgent pointer Options (variable) Data 27 TCP Header Let's look at sequence numbers first Source port Destination port Sequence number Acknowledgment Advertised windowHdrLen Flags0 Checksum Urgent pointer Options (variable) Data 28 Segments and Sequence Numbers TCP “Stream of Bytes” Service… Application @ Host A Application @ Host B 30 … Provided Using TCP “Segments” Application @ Host A Application @ Host B TCP Data TCP Data Transmitted when: Segment full (Max Segment Size) Not full, but times out 31 TCP Segment IP packet • No bigger than Maximum Transmission Unit (MTU) • E.g., up to 1500 bytes with Ethernet TCP packet • IP packet with a TCP header and data inside • TCP header is 20 bytes long TCP segment • No more than Maximum Segment Size (MSS) bytes • E.g., up to 1460 consecutive bytes from the stream • MSS = MTU – (IP header) – (TCP header) IP Data IP Hdr TCP HdrTCP Data (segment) 32 Sequence Numbers ISN (initial sequence number) ISN + n 33 Sequence Numbers ISN (initial sequence number) ISN + n ACK sequence number = next expected byte 34 ACKing and Sequence Numbers Sender sends packet • Data starts with sequence number X • Packet contains B bytes • X, X+1, X+2, ….X+B-1 Upon receipt of packet, receiver sends an ACK • If all data prior to X already received: • ACK acknowledges X+B (because that is next expected byte) • If highest contiguous byte received is smaller value Y • ACK acknowledges Y+1 • Even if this has been ACKed before (causing duplicate ACKs) 35 Normal Pattern Sender: seqno=X, length=B Receiver: ACK=X+B Sender: seqno=X+B, length=B Receiver: ACK=X+2B Sender: seqno=X+2B, length=B … Seqno of next packet is same as last ACK field 36 Source port Destination port Sequence number Acknowledgment Advertised windowFlags Checksum Urgent pointer Options (variable) Data HdrLen 0 TCP Header Starting byte offset of data carried in this segment 37 TCP Header “What Byte is Next” Source port Destination port Sequence number Acknowledgment Advertised windowFlags Checksum Urgent pointer Options (variable) Data HdrLen 0 38 TCP Header How much the sender can send Source port Destination port Sequence number Acknowledgment Advertised windowFlags Checksum Urgent pointer Options (variable) Data HdrLen 0 40 Sliding Window Flow Control Advertised Window, W Can send W bytes beyond the next expected byte Receiver uses W to prevent sender from overflowing receiver buffer Limits number of bytes sender can have in flight 41 Filling the Pipe Simple example: Window W (in bytes), which we assume is constant RTT (in sec), which we assume is constant Bandwidth B (in bytes/sec) How fast will data be transferred? If W/RTT < B, the transfer has speed W/RTT If W/RTT > B, the transfer has speed B 42 Advertised Window Limits Rate Sender can send no faster than W/RTT bytes/sec Receiver only advertises more space when it has consumed old arriving data In original design, sole protocol mechanism controlling sender’s rate! What’s missing? 43 Implementing Sliding Window Both sender & receiver maintain a window Sender: not yet ACKed Receiver: not yet delivered to application Left edge of window: Sender: beginning of unacknowledged data Receiver: beginning of undelivered data For the sender: Window size = maximum amount of data in flight For the receiver: Window size = maximum amount of undelivered data 44 Sliding Window Allow a larger amount of data “in flight” • Allow sender to get ahead of the receiver • … though not too far ahead Sending process Receiving process Last byte ACKed Last byte can send TCP Next byte needed Last byte written Last byte read Last byte received Sender Window Receiver Window 45 Sliding Window When sender receives a new ACK, send window advances (slides forward) Sending process Last byte ACKed Last byte can send TCP Last byte written 46 Sliding Window When sender receives a new ACK, send window advances (slides forward) Sending process Last byte ACKed Last byte can send TCP Last byte written 47 Sliding Window When the receiving process consumes data, receive window advances Receiving process Next byte needed Last byte read Last byte received 48 Sliding Window When the receiving process consumes data, receive window advances Receiving process Next byte needed Last byte received 49 Sliding Window Summary Sender: window advances when new data ACKed Receiver: window advances as receiving process consumes data Receiver advertises to the sender where the receiver window currently ends (“righthand edge”) • Sender agrees not to exceed this amount • It makes sure by setting its own window size to a value that can’t send beyond the receiver’s righthand edge 50 Source port Destination port Sequence number Acknowledgment Advertised windowFlags Checksum Urgent pointer Options (variable) Data HdrLen 0 TCP Header: What’s left? Number of 4-byte words in TCP header; 5 ⇒ no options “Must Be Zero” 6 reserved bits Used with URG flag to indicate urgent data (not discussed further) 51 Source port Destination port Sequence number Acknowledgment Advertised windowFlags Checksum Urgent pointer Options (variable) Data HdrLen 0 TCP Header: What’s left? We’ll come to this one shortly 52 TCP Connection Establishment and Initial Sequence Numbers Initial Sequence Number (ISN) Sequence number for the very first byte • E.g., why not just use ISN = 0? Practical issue • IP addresses and port #s uniquely identify a connection • Eventually, though, these port #s do get used again • Small chance an old packet is still in flight Security issue • Off-path attacker could inject packets into existing connection by using the predictable sequence numbers TCP therefore requires changing ISN • Drawn from a pseudo random number generator To establish a connection, hosts exchange ISNs 54 Connection establishment: 3-way handshake Host A sends a SYN (open; “synchronize sequence numbers”) Host B returns a SYN acknowledgment (SYN ACK) Host A sends an ACK to acknowledge the SYN ACK A B Data Data Each host tells its ISN to the other 55 Source port Destination port Sequence number Acknowledgment Advertised windowHdrLen Flags0 Checksum Urgent pointer Options (variable) Data TCP Header SYN ACK FIN RST PSH URG See /usr/include/netinet/tcp.h on Unix Systems 56 Step 1: A’s Initial SYN Packet (Irrelevant since ACK not set) Advertised window5 0 Flags Checksum Urgent pointer Options (variable) SYN ACK FIN RST PSH URG A’s Initial Sequence Number A’s port B’s port A tells B it wants to open a connection… 57 Step 2: B’s SYN-ACK Packet ACK = A’s ISN plus 1 Advertised window5 0 Flags Checksum Urgent pointer Options (variable) SYN ACK FIN RST PSH URG B’s Initial Sequence Number B’s port A’s port B tells A it accepts, and is ready to hear the next byte… … upon receiving this packet, A can start sending data 58 Step 3: A’s ACK of the SYN-ACK ACK = B’s ISN plus 1 Advertised window5 0 Flags Checksum Urgent pointer Options (variable) SYN ACK FIN RST PSH URG A’s Initial Sequence Number A’s port B’s port A tells B it’s likewise okay to start sending … upon receiving this packet, B can start sending data 59 Timing Diagram: 3-Way Handshaking Client (initiator) Server SYN + ACK, SeqNum = y, Ack = x + 1 “Active open” connect() listen() accept() “Passive open” 60 SYN, SeqNum = x What if the SYN Packet Gets Lost? Suppose the SYN packet gets lost • Packet is lost inside the network, or: • Server discards the packet (e.g., listen queue is full) Eventually, no SYN-ACK arrives • Sender sets a timer and waits for the SYN-ACK • … and retransmits the SYN if needed How should the TCP sender set the timer? • Sender has no idea how far away the receiver is • Hard to guess a reasonable length of time to wait • Should (RFCs 1122 & 2988) use default of 3 seconds 61 SYN Loss and Web Downloads User clicks on a hypertext link • Browser creates a socket and does a “connect” • The “connect” triggers the OS to transmit a SYN If the SYN is lost… • 3 seconds of delay can be very long • User may become impatient • … and click the hyperlink again, or click “reload” User triggers an “abort” of the “connect” • Browser creates a new socket and another “connect” • Essentially, forces a faster send of a new SYN packet! • Sometimes very effective, and the page comes quickly 62 3-Way Handshaking: Security issue Server needs to save mapping (client, y) SYN + ACK, SeqNum = y, Ack = x + 1 connect() listen() accept() Server resources can be exhausted by flooding the server with SYN packets (SYN flood) Defense: SYN cookies Compute y = secret_hash(client), Communicate y as SeqNum in SYN+ACK packet, Discard y Upon receiving ACK, check whether Ack = secret_hash(client) + 1 Existence of previous SYN packet is verified without building state! client server 63 SYN, SeqNum = x Tearing Down the Connection Normal Termination, One Side at a Time Finish (FIN) to close and receive remaining bytes • FIN occupies one octet in the sequence space Other host ack’s the octet to confirm Closes A’s side of the connection, but not B’s • Until B likewise sends a FIN • Which A then acks time A B Connection now half-closed Connection now closed 65 Normal Termination, Both Together Same as before, but B sets FIN with their ack of A’s FIN time A B 66 Abrupt Termination A sends a RESET (RST) to B • E.g., because app. process on A crashed That’s it • B does not ack the RST • Thus, RST is not delivered reliably • And: any data in flight is lost • But: if B sends anything more, will elicit another RST time A B 67 TCP State Transitions Data, ACK exchanges are in here 68 Reliability: TCP Retransmission Timeouts and Retransmissions Reliability requires retransmitting lost data Involves setting timer and retransmitting on timeout TCP resets timer whenever new data is ACKed Retransmission of packet containing “next byte” when timer goes off 70 Example Arriving ACK expects 100 Sender sends packets 100, 200, 300, 400, 500 • Timer set for 100 ACKs arrive for packets 100, 200, expecting 300 • Timer set for 300 Timer goes off • Packet 300 is resent Arriving ACK expects 600 • Packet 600 sent • Timer set for 600 71 Setting the Timeout Value 1 1 Too long ⇒ inefficient 1 1 Too short ⇒ duplicate packets RTT Timeout Timeout RTT 72 RTT Estimation Use exponential averaging of RTT samplesEstimatedRTT Time SampleRTT 73 Exponential Averaging Example RTT time EstimatedRTT = α*EstimatedRTT + (1 – α)*SampleRTT Assume RTT is constant SampleRTT = RTT 0 1 2 3 4 5 6 7 8 9 EstimatedRTT (α = 0.8) EstimatedRTT (α = 0.5) 74 Problem: Ambiguous Measurements How do we differentiate between the real ACK, and ACK of the retransmitted packet?SampleRTT Sender ReceiverSampleRTT Sender Receiver 75 Karn/Partridge Algorithm Measure SampleRTT only for original transmissions • Do not use retransmits for any measurements • Computes EstimatedRTT using α = 0.875 Timeout value (RTO) = 2 × EstimatedRTT Use exponential backoff for repeated retransmissions • Every time RTO timer expires, set RTO ← 2 RTO • (Up to maximum ≥ 60 sec) • Every time new measurement comes in (= successful original transmission), collapse RTO back to 2 × EstimatedRTT 76 Karn/Partridge in action Packet number RTT & RTO (seconds) RT O RTT samples 77 Karn/Partridge Algorithm Measure SampleRTT only for original transmissions • Do not use retransmits for any measurements • Computes EstimatedRTT using α = 0.875 Timeout value (RTO) = 2 × EstimatedRTT Use exponential backoff for repeated retransmissions • Every time RTO timer expires, set RTO ← 2 RTO • (Up to maximum ≥ 60 sec) • Every time new measurement comes in (= successful original transmission), collapse RTO back to 2 × EstimatedRTT ●Does not account ●for variance 78 The Jacobson/Karels improvement Deviation = | SampleRTT – EstimatedRTT | EstimatedDeviation: exponential average of Deviation RTO = EstimatedRTT + 4 x EstimatedDeviation 79 With Jacobson/Karels Packet number RTT & RTO (seconds) K/P RTT samples J/K 81 In practice … 200 milliseconds in Linux. Incurring a timeout is expensive! Relevance of these algorithms is reduced by use of duplicate ACKs (2.4) Whenever RTO is computed, if it is less than 1 second, then the RTO SHOULD be rounded up to 1 second. [RFC 6298] 82 Loss with cumulative ACKs Sender sends packets with 100B and seqnos.: • 100, 200, 300, 400, 500, 600, 700, 800, 900, … Assume the fifth packet (seqno 500) is lost, but no others Stream of ACKs will be: • 200, 300, 400, 500, 500, 500, 500,… 83 Loss with cumulative ACKs “Duplicate ACKs” are a sign of an isolated loss • The lack of ACK progress means 500 hasn’t been delivered • Stream of ACKs means some packets are being delivered Therefore, could trigger resend upon receiving k duplicate ACKs • TCP uses k=3 We will revisit this in congestion control 84 Congestion control If many packets arrive within the node cannot keep up anymore a short period of time Because of traffic burstiness and lack of BW reservation, congestion is inevitable 87 queue for bursty traffic queue for constant-rate traffic average link loadAverage queuing delay For bursty traffic, average queueing delay depends on difference between average link load and link capacity link capacity Infinite delay Caption link cap link load time avg link load queue length 91 Congestion is not a new problem The Internet almost died of congestion in 1986 throughput collapsed from 32 Kbps to… 40 bps Recent resurgence of research interest after brief lag new methods (ML), context (Data centers), requirements Van Jacobson saved us with Congestion Control his solution went right into BSD 92 The Internet almost died of congestion in 1986 throughput collapsed from 32 Kbps to… 40 bps 93 Original behavior On connection establishment, nodes send full window of packets Upon timer expiration, retransmit packet immediately window-sized burst of packetsnet effect meaning sending rate only limited by flow control 94 Sudden load increased the round-trip time (RTT) by filling up link buffers faster than the hosts’ measurements of RTT As RTT exceeds the maximum retransmission interval, hosts begin to retransmit packets This phenomenon is known as congestion collapse Hosts are sending each packet several times, making congestion even worse eventually some copies arrive at the destination. Increase in network load results in a decrease of useful work done 95 Send time (s) Packet seq number (indexed by KB) 5 repetitions!Ideal behavior 97 Van Jacobson saved us with Congestion Control his solution went right into BSD 98 Flow control Congestion control prevents one fast sender from prevents a set of senders from overloading the network overloading a slow receiver Congestion control differs from flow control Both are provided by TCP 99 TCP solves both using two distinct windows Flow control Congestion control prevents one fast sender from prevents a set of senders from overloading the network overloading a slow receiver solved using a “congestion” window solved using a receiving window 100 Congestion Window CWND How many bytes can be sent without overflowing the routers? Receiving Window RWND How many bytes can be sent without overflowing the receiver buffer? based on network conditions based on the receiver input Sender Window minimum(CWND, RWND) The sender adapts its sending rate based on these two windows 101 bandwidth estimation How to continuously estimate the bottleneck bandwidth from congestion signals and adapt the sending rate appropriately? could be 1 Mbps or 1 Gbps… #2 fairness How to share bandwidth “fairly” among flows, without overloading the network #3 congestion detection How to detect if the network is currently congested? #1 Congestion control aims at solving three problems 102 congestion detection How to detect if the network is currently congested? #1 103 Approach #1 Network could tell the source but signal itself could be lost Approach #2 Measure packet delay but signal is noisy Approach #3 Measure packet loss fail-safe signal that TCP already has to detect delay often varies considerably There are essentially three ways to detect congestion 104 Packet dropping is the easiest solution, if not perfect delay- and signaling-based methods are hard & risky Approach #3 Measure packet loss fail-safe signal that TCP already has to detect 105 duplicated ACKs mild congestion signal timeout severe congestion signal multiple consequent losses packets are still making it Detecting losses can be done using ACKs or timeouts, the two signals differ in their degree of severity 106 bandwidth estimation How to continuously estimate the bottleneck bandwidth from congestion signals and adapt the sending rate appropriately? could be 1 Mbps or 1 Gbps… #2 fairness How to share bandwidth “fairly” among flows, without overloading the network #3 congestion detection How to detect if the network is currently congested? #1 Congestion control aims at solving three problems 107 bandwidth estimation How to continuously estimate the bottleneck bandwidth from congestion signals and adapt the sending rate appropriately? could be 1 Mbps or 1 Gbps… #2 108 Increase cwnd = 1 cwnd += 1 initially policy Intuition Start slow but rapidly increase until a packet drop occurs upon receipt of an ACK The initial goal is to quickly get a first-order estimate of the available bandwidth 109 D A D D A A D D Src Dst D D 1 2 4 A A A A 8 Slow start is slow compared to the start of 1980s TCP (direct burst of large window), but very fast compared to the rate-increase behavior of a TCP flows after the starting phase This increase phase, known as slow start, corresponds to an… exponential increase of CWND! 110 Example Assume that CWND is just enough to “fill the pipe” After one RTT, CWND has doubled All the excess packets are now dropped Solution We need a more gentle adjustment algorithm once we have a rough estimate of the bandwidth The problem with slow start is that it can result in a full window of packet losses 111 Two possible variations cwnd = a * cwnd cwnd = b + cwnd • Multiplicative Increase or Decrease • Additive Increase or Decrease … leading to four alternative designs The goal here is to track the available bandwidth, and oscillate around its current value 115 AIAD AIMD MIAD MIMD increase behavior decrease behavior gentle gentle gentle aggressive aggressive gentle aggressive aggressive 116 AIAD AIMD MIAD MIMD increase behavior decrease behavior gentle gentle gentle aggressive aggressive gentle aggressive aggressive To select one scheme, we need to consider the 3rd problem: fairness 117 bandwidth estimation How to continuously estimate the bottleneck bandwidth from congestion signals and adapt the sending rate appropriately? could be 1 Mbps or 1 Gbps… #2 fairness How to share bandwidth “fairly” among flows, without overloading the network #3 congestion detection How to detect if the network is currently congested? #1 Congestion control aims at solving three problems 118 fairness How to share bandwidth “fairly” among flows, without overloading the network #3 119 TCP notion of fairness: 2 identical flows should end up with the same bandwidth 120 Now let’s look at two senders A and B sharing a link host A host B host C 123 A’s throughput B’s throughput We can analyze the system behavior using a system trajectory plot 124 Link capacity: 1 Mbps A’s throughput B’s throughput 1 1 efficiency line The system is efficient if the capacity is fully used, defining an efficiency line where a + b = 1 125 A’s throughput B’s throughput 1 1 efficiency line The goal of congestion control is to bring the system as close as possible to this line, and stay there 126 A’s throughput B’s throughput 1 1 congestion 127 1 1 under-utilization A’s throughput B’s throughput 128 1 1 efficiency line fairness line A’s throughput B’s throughput The system is fair whenever A and B have equal throughput, defining a fairness line where a = b 129 1 1 fairness line A’s throughput B’s throughput B gets more than A 130 1 1 fairness line A’s throughput B’s throughput A gets more than B 131 A’s throughput B’s throughput 1 1 efficiency line fairness line inefficient & unfair .2 .5 132 A’s throughput B’s throughput 1 1 efficiency line fairness line congested .7 .5 133 A’s throughput B’s throughput 1 1 efficiency line fairness line efficient & unfair .3 .7 134 A’s throughput B’s throughput 1 1 efficiency line fairness line efficient & fair .5 .5 135 AIAD AIMD MIAD MIMD increase behavior decrease behavior gentle gentle gentle aggressive aggressive gentle aggressive aggressive 136 A small algebra-geometry recap Y = X y1 x1 Y X Multiplying both X and Y by some 𝛼 moves them on a line through the origin 137 A small algebra-geometry recap Y X Adding some 𝛼 to both X and Y moves them on a line of slope 45° 138 AIAD AIMD MIAD MIMD increase behavior decrease behavior gentle gentle gentle aggressive aggressive gentle aggressive aggressive 139 A’s throughput B’s throughput 1 1 efficiency line fairness line Adding a constant: move along 45 deg state 1 state 2 AIAD does not converge to fairness, nor efficiency: the system fluctuates between two states 140 0 15 30 45 60 1 16 31 46 61 76 91 106121136151166181196211226241256271286301316331346361376391406421436451466481496 AIAD does not converge to fairness, nor efficiency: the system fluctuates between two states 141 AIAD AIMD MIAD MIMD increase behavior decrease behavior gentle gentle gentle aggressive aggressive gentle aggressive aggressive 142 A’s throughput B’s throughput 1 1 efficiency line fairness line equi-fairness line MIMD does not converge to fairness, nor efficiency: the system fluctuates along an equi-fairness line 143 AIAD AIMD MIAD MIMD increase behavior decrease behavior gentle gentle gentle aggressive aggressive gentle aggressive aggressive 144 A’s throughput B’s throughput 1 1 efficiency line fairness line MIAD converges to a totally unfair allocation, favoring the flow with a greater rate at the beginning 145 A’s throughput B’s throughput 1 1 efficiency line fairness line If flows start along the fairness line, MIAD fluctuates along it, yet deviating from it at the slightest change 146 AIAD AIMD MIAD MIMD increase behavior decrease behavior gentle gentle gentle aggressive aggressive gentle aggressive aggressive 147 A’s throughput B’s throughput 1 1 efficiency line fairness line AIMD converges to fairness and efficiency, it then fluctuates around the optimum (in a stable way) 148 Intuition During increase, both flows gain bandwidth at the same rate During decrease, the faster flow releases more AIMD converges to fairness and efficiency, it then fluctuates around the optimum (in a stable way) 150 0. 15. 30. 45. 60. 1 16 31 46 61 76 91 106121136151166181196211226241256271286301316331346361376391406421436451466481496 AIMD converges to fairness and efficiency, it then fluctuates around the optimum (in a stable way) 151 AIAD AIMD MIAD MIMD increase behavior decrease behavior gentle gentle gentle aggressive aggressive gentle aggressive aggressive In practice, TCP implements AIMD 152 After each ACK, Increment cwnd by 1/cwnd linear increase of max. 1 per RTT Implementation When does a sender leave slow-start and start AIMD? Question Introduce a slow start threshold, adapt it as function of congestion: on timeout, ssthresh = CWND/2 In practice, TCP implements AIMD 153 TCP congestion control in less than 10 lines of code Initially: cwnd = 1 ssthresh = infinite New ACK received: if (cwnd < ssthresh): /* Slow Start*/ cwnd = cwnd + 1 else: /* Congestion Avoidance */ cwnd = cwnd + 1/cwnd Timeout: /* Multiplicative decrease */ ssthresh = cwnd/2 cwnd = 1 154 Tim e cwnd Timeout Slow Start AIMD ssthresh Timeout Slow Start Slow Start AIMD The congestion window of a TCP session typically undergoes multiple cycles of slow-start/AIMD 155 solution Avoid timeout expiration… which are usually >500ms Going back all the way back to 0 upon timeout completely destroys throughput 156 duplicated ACKs mild congestion signal timeout severe congestion signal multiple consequent losses packets are still making it Detecting losses can be done using ACKs or timeouts, the two signals differ in their degree of severity 157 TCP automatically resends a segment after receiving 3 duplicates ACKs for it 158 After a fast retransmit, TCP switches back to AIMD, without going all way the back to 0 159 TCP congestion control (almost complete) Duplicate ACKs received: dup_ack ++; if (dup_ack >= 3): /* Fast Recovery */ ssthresh = cwnd/2 cwnd = ssthresh Initially: cwnd = 1 ssthresh = infinite New ACK received: if (cwnd < ssthresh): /* Slow Start*/ cwnd = cwnd + 1 else: /* Congestion Avoidance */ cwnd = cwnd + 1/cwnd dup_ack = 0 Timeout: /* Multiplicative decrease */ ssthresh = cwnd/2 cwnd = 1 160 Duplicate ACKs received: dup_ack ++; if (dup_ack >= 3): /* Fast Recovery */ ssthresh = cwnd/2 cwnd = ssthresh Initially: cwnd = 1 ssthresh = infinite New ACK received: if (cwnd < ssthresh): /* Slow Start*/ cwnd = cwnd + 1 else: /* Congestion Avoidance */ cwnd = cwnd + 1/cwnd dup_ack = 0 Timeout: /* Multiplicative decrease */ ssthresh = cwnd/2 cwnd = 1 161 Tim e cwnd Timeout Slow Start AIMD Slow Start Slow Start AIMD AIMD 3 dups ACKs Timeout Congestion control makes TCP throughput look like a “sawtooth” 162 AIAD AIMD MIAD MIMD increase behavior decrease behavior gentle gentle gentle aggressive aggressive gentle aggressive aggressive In the {A,M}I{A,M}D design space, AIMD is the only algorithm achieving fairness and efficiency But this design space is far from exhaustive... Congestion-control algorithms (CCAs) are more diverse! 163 TCP Reno Time [s]cwnd / BDP Classic TCP CCA, as seen in this course so far Congestion avoidance: Increase cwnd by 1/RTT in absence of loss Decrease cwnd by half in case of packet loss Loss-based CCA 166 TCP Reno Time [s] Classic TCP CCA, as seen in this course so far Congestion avoidance: Increase cwnd by 1/RTT in absence of loss Decrease cwnd by half in case of packet loss Loss-based CCA RTT unfairness: Given senders with different RTTs, long-RTT senders will increase cwnd more slowly and thus obtain less bandwidthcwnd / BDP 167 TCP CUBIC Time [s] Well-established TCP CCA, default in Linux kernel Congestion avoidance: Keep state variables s (time since last loss) and wmax (cwnd at time of last loss) cwnd size: wmax + 0.4 ( s - (0.75 wmax)1/3 )3 Loss-based CCAcwnd / BDP 168 TCP CUBIC Time [s] Well-established TCP CCA, default in Linux kernel Congestion avoidance: Keep state variables s (time since last loss) and wmax (cwnd at time of last loss) cwnd size: wmax + 0.4 ( s - (0.75 wmax)1/3 )3 Loss-based CCA No RTT unfairness: cwnd growth rate independent of RTTcwnd / BDP 169 TCP CUBIC Time [s] Well-established TCP CCA, default in Linux kernel Congestion avoidance: Keep state variables s (time since last loss) and wmax (cwnd at time of last loss) cwnd size: wmax + 0.4 ( s - (0.7 wmax)1/3 )3 Loss-based CCA Bufferbloat: Since rate is only decreased in case of loss, the link buffers will be mostly filled independent of their size, keeping latency high cwnd / BDP sending rate / link capacity buffer utilization 170 Loss-based CCAs are inherently sub-optimal Kleinrock optimal operating point Operating point of loss-based CCAs Delivery rate Link capacity Data volume in flight Buffer utilizationBuffer capacity Check for latency increase? BDP BDP + Buffer Capacity 171 TCP Vegas Time [s] TCP CCA designed in the 90s, never widely used Congestion avoidance: Estimate propagation delay T (min. RTT measurement) Once per RTT, measure current RTT Tcur Pick α < β If cwnd / Tcur < cwnd / T - β, linearly decrease cwnd If cwnd / Tcur > cwnd / T - α, linearly increase cwnd Latency-based CCA Uncovering propagation delay is difficultcwnd / BDP 172 TCP Vegas Time [s] TCP CCA designed in the 90s, never widely used Congestion avoidance: Estimate propagation delay T (min. RTT measurement) Once per RTT, measure current RTT Tcur Pick α < β If cwnd / Tcur < cwnd / T - β, linearly decrease cwnd If cwnd / Tcur > cwnd / T - α, linearly increase cwnd Latency-based CCA Uncompetitive against loss-based CCAs: When senders with loss-based CCAs build up queue, Vegas senders will reduce rate, leading to unfairnesscwnd / BDP Reno flow Vegas flow 173 TCP BBR Time [s] CCA published by Google in 2016, quickly deployed for Google services Congestion avoidance: Keep two state variables: BtlBw and MinRTT Cycle through periods of 8 phases Each phase has duration MinRTT In general, send at rate BtlBw in each phase In one random phase, increase rate to 1.25 BtlBw In the following phase, reduce rate to 0.75 BtlBw At the end of the period, update BtlBw to maximum observed delivery rate Model-based CCArate / link capacity 174 TCP BBR Time [s]rate / link capacity BBR flow Reno flow CCA published by Google in 2016, quickly deployed for Google services Congestion avoidance: Keep two state variables: BtlBw and MinRTT Cycle through periods of 8 phases Each phase has duration MinRTT In general, send at rate BtlBw in each phase In one random phase, increase rate to 1.25 BtlBw In the following phase, reduce rate to 0.75 BtlBw At the end of the period, update BtlBw to maximum observed delivery rate Model-based CCA Unfairness against loss-based CCAs: Loss-insensitive BBR probing leads to recurring loss, which makes loss-based CCAs refrain 175 TCP BBRv2 and v3 No fairness in competition with loss-based CCAs: BBRv2 overcorrects unfairness of BBRv1, BBRv3 overcorrects under-aggressiveness of BBRv2 176 Documentation of issues in BBRv1 led to release of BBRv2 … and then again in BBRv3 Plot shows BBR share of bottleneck-link capacity obtained by x BBR flows together that are in competition with 10-x CUBIC flows (loss-based) Congestion-control algorithms: Overview Reno RTT unfairness CUBIC RTT fairness not Kleinrock-optimal Vega s almost Kleinrock-optimal uncompetitive against loss-based CCAs BBR Kleinrock-optimal (though only for a single BBR flow in isolation) unfair (v1 and v3) or losing (v2) against loss-based CCAs Designing congestion-control algorithms is still an active research area with many interesting recent ideas (PCC, Copa, DCTCP,...) 177","libVersion":"0.5.0","langs":""}
{"path":"sem3/A&D/UE/s/A&D-s-u04.pdf","text":"Eidgen¨ossische Technische Hochschule Z¨urich Ecole polytechnique f´ed´erale de Zurich Politecnico federale di Zurigo Federal Institute of Technology at Zurich Departement of Computer Science 14 October 2024 Johannes Lengler, David Steurer Kasper Lindberg, Lucas Slot, Hongjie Chen, Manuel Wiedmer Algorithms & Data Structures Exercise sheet 4 HS 24 The solutions for this sheet are submitted on Moodle until 20 October 2024, 23:59. Exercises that are marked by ∗ are challenge exercises. They do not count towards bonus points. You can use results from previous parts without solving those parts. The solutions are intended to help you understand how to solve the exercises and are thus more detailed than what would be expected at the exam. All parts that contain explanation that you would not need to include in an exam are in grey. Master theorem. The following theorem is very useful for running-time analysis of divide-and- conquer algorithms. Theorem 1 (master theorem). Let a, C > 0 and b ≥ 0 be constants and T : N → R+ a function such that for all even n ∈ N, T (n) ≤ aT (n/2) + Cn b. (1) Then for all n = 2k, k ∈ N, the following statements hold (i) If b > log2 a, T (n) ≤ O(nb). (ii) If b = log2 a, T (n) ≤ O(nlog2 a · log n).1 (iii) If b < log2 a, T (n) ≤ O(nlog2 a). If the function T is increasing, then the condition n = 2k can be dropped. If we instead have T (n) ≥ aT (n/2) + C′nb, (2) then we can conclude that T (n) ≥ Ω(nb), T (n) ≥ Ω(nlog2 a · log n), and T (n) ≥ Ω(nlog2 a) in cases (i), (ii), and (iii), respectively. Furthermore if (1) and (2) both hold (with possibly different constants C ̸= C′), then similarly T (n) = Θ(nb), T (n) = Θ(nlog2 a · log n), and T (n) = Θ(nlog2 a) in cases (i), (ii), and (iii), respectively. This generalizes some results that you have already seen in this course. For example, the (worst-case) running time of Karatsuba’s algorithm satisfies T (n) ≤ 3T (n/2) + 100n, so we have a = 3 and b = 1 < log2 3, hence T (n) ≤ O(nlog2 3). Another example is binary search: its running time satisfies T (n) ≤ T (n/2) + 100, so a = 1 and b = 0 = log2 1, hence T (n) ≤ O(log n). Exercise 4.1 Applying the master theorem. 1For this asymptotic bound we assume n ≥ 2 so that n log2 a · log n > 0. For this exercise, assume that n is a power of two (that is, n = 2k, where k ∈ N0). In the following, you are given a function T : N → R+ defined recursively and you are asked to find its asymptotic behavior by applying the master theorem. (a) Let T (1) = 1, T (n) = 4T (n/2) + 100n for n > 1. Using the master theorem, show that T (n) ≤ O(n2). Solution: We can apply the master theorem with a = 4, b = 1 and C = 100. In this case, b < log2 a, and therefore we have T (n) ≤ O(nlog2 a), i.e., T (n) ≤ O(n2) since log2 a = 2. An alternative way of seeing that T (n) ≤ O(n2) is to repeatedly apply the recursive definition of T until we reach n = 1, i.e., T (n) = 4T (n/2) + 100n = 16T (n/4) + 400n/2 + 100n = 64T (n/8) + 1600n/4 + 400n/2 + 100n = 4 log2(n) + log2(n)∑ i=1 100 · 4i−1 n 2i−1 = 2 2 log2(n) + 100n · (2 log2(n) − 1) since we must expand T for log2(n) times until we hit n = 1. Now the first term is n2 and the second term is 100n2 − 100n. (b) Let T (1) = 5, T (n) = T (n/2) + 3 2 n for n > 1. Using the master theorem, show that T (n) ≤ O(n). Solution: We can apply the master theorem with a = 1, b = 1 and C = 3 2 . In this case, b > log2 a, and therefore we have T (n) ≤ O(nb), i.e., T (n) ≤ O(n). Now when expanding the sum, we get T (n) = T (n/2) + 3 2 n = T (n/4) + 3 4 n + 3 2 n = T (n/8) + 3 8 n + 3 4 n + 3 2 n = 5 + 3n log2(n)∑ i=1 2−i. This term is in O(n) since the sum is a geometric sum and thus at most a constant. (c) Let T (1) = 4, T (n) = 4T (n/2) + 7 2 n2 for n > 1. Using the master theorem, show that T (n) ≤ O(n2 log n). 2 Solution: We can apply the master theorem with a = 4, b = 2 and C = 7 2 . In this case, b = log2 a, and therefore we have T (n) ≤ O(nlog2 a · log n), i.e., T (n) ≤ O(n2 log n). An alternative way of seeing that T (n) ≤ O(n2) is to repeatedly apply the recursive definition of T until we reach n = 1, i.e., T (n) = 4T (n/2) + 7 2 n2 = 16T (n/4) + 4 · 7 2 (n/2) 2 + 7 2 n2 = 64T (n/4) + 16 · 7 2 (n/4) 2 + 4 · 7 2 (n/2) 2 + 7 2 n2 = 256T (n/4) + 64 · 7 2 (n/8) 2 + 16 · 7 2 (n/4) 2 + 4 · 7 2 (n/2) 2 + 7 2 n2 = 4 log2(n) + 7 2 log2(n)∑ i=1 4i−1 ( n 2i−1 )2 = 2 2 log2(n) + 7 2 log2(n)∑ i=1 n2. The first term is in O(n2) and the second one in O(n2 log(n)). Exercise 4.2 Asymptotic notations. (a) (This subtask is from January 2019 exam). For each of the following claims, state whether it is true or false. You don’t need to justify your answers. claim true false n log n ≤ O( √n) □ □ log(n!) ≥ Ω(n2) □ □ nk ≥ Ω(kn), if 1 < k ≤ O(1) □ □ log3 n4 = Θ(log7 n8) □ □ Solution: 3 claim true false n log n ≤ O( √n) □ ⊠ log n! ≥ Ω(n2) □ ⊠ nk ≥ Ω(kn), if 1 < k ≤ O(1) □ ⊠ log3 n4 = Θ(log7 n8) ⊠ □ For (1) we can just look at the limit of √ n/ log(n) as n → ∞. For (2) note that log(n!) ≤ log(nn) = n log(n). For (3) we note that e.g. n2 is asymptotically smaller than 2n. For (4), note that log3(n4) = 4 log3(n) = 4 ln(3) ln(n) and that log7(n8) = 8 log7(n) = 8 ln(7) ln(n) so the two terms only differ by a constant. (b) (This subtask is from August 2019 exam). For each of the following claims, state whether it is true or false. You don’t need to justify your answers. claim true false n log n ≥ Ω(n1/2) □ □ log7(n8) = Θ(log3(n√n)) □ □ 3n4 + n2 + n ≥ Ω(n2) □ □ (∗) n! ≤ O(nn/2) □ □ Note that the last claim is challenge. It was one of the hardest tasks of the exam. If you want a 6 grade, you should be able to solve such exercises. Solution: claim true false n log n ≥ Ω(n1/2) ⊠ □ log7(n8) = Θ(log3(n√n)) □ ⊠ 3n4 + n2 + n ≥ Ω(n2) ⊠ □ (∗) n! ≤ O(nn/2) □ ⊠ For (1), consider the limit f (n) g(n) . For (2), note that log7(n8) = Θ(log(n)) but log3(n√n) = Θ( √n log(n)). For (3), consider again the limit f (n) g(n) . The last claim can be verified as follows. Note that for all n ≥ 1, n! ≥ 1 · 2 · · · n ≥ ⌈n/10⌉ · · · n ≥ ⌈n/10⌉0.9n ≥ (n/10)0.9n . 4 Let’s show that (n/10)0.9n grows asymptotically faster than nn/2. lim n→∞ nn/2 (n/10)0.9n = lim n→∞ 10 0.9n · n−0.4n = lim n→∞(10 9/4/n) 0.4n = 0 . Hence it is not true that (n/10)0.9n ≤ O(nn/2) and so it is not true that n! ≤ O(nn/2). Sorting and Searching. Exercise 4.3 Formal proof of correctness for Insertion Sort (1 point). Algorithm 1 Insertion Sort (input: array A[1 . . . n]). for j = 1, . . . , n do if j > 1 then for i = j − 1, . . . , 1 do if A[i + 1] < A[i] then Swap A[i + 1] and A[i] Prove correctness of this algorithm by mathematical induction. Hint: Use the invariant I(j): “After j iterations the first j elements are sorted.” Solution: We prove the invariant in the hint by mathematical induction on j. • Base Case. We prove the statement for j = 1. We have that the first element is sorted with respect to the sublist of only the first element. Therefore I(1) holds. Note that nothing happens with the first iteration since we do not have j > 1. • Induction Hypothesis. We assume that the invariant is true for j = k for some k ∈ N, k < n, i.e. after k iterations the first k are sorted. • Inductive Step. We must show that the invariant also holds for j = k + 1. By the induction hypothesis the first k elements are sorted, i.e. at positions A[1, . . . , k] . We now consider step k + 1. If A[k + 1] ≥ A[k] then our second for loop does nothing in the first step, and by the inductive hypothesis the list A[1, . . . , k] is sorted thus the list A[1, . . . , k + 1] is sorted. Otherwise A[k + 1] < A[k]. Let c = A[k + 1] be the value of the list at the time and let 0 ≤ ℓ ≤ k be the largest index of list A such that A[ℓ] ≤ c and ℓ = 0 if no such element exists. In this case, we can see that the second for loop will keep swapping adjacent elements A[i + 1] and A[i] for i = k, . . . , ℓ + 1. This is because our sublist is sorted so we always satisfy c = A[i + 1] < A[i] when i ≥ ℓ+1 at iteration i. The rest of the inner for loop does nothing since c = A[ℓ+1] ≥ A[i] for i ≤ ℓ. Now since the sublist A[1, . . . , ℓ] is sorted since its unchanged, A[ℓ + 2, . . . , k + 1] is equal to A[ℓ+1, . . . , k] before the inner for loop and thus sorted, as well as A[ℓ] ≤ A[ℓ+1] = c ≤ A[ℓ+2] by definition of ℓ, we can see that A[1, . . . , k + 1] is sorted so I(k + 1) holds. 5 By the principle of mathematical induction, I(j) is true for all j ∈ N, j ≤ n. In particular, I(n) holds, which means that after the first n iterations the first n elements are sorted. This shows that after n steps the array is sorted, which shows correctness of the Insertion Sort algorithm. Guidelines for correction: This exercise consists of one large induction part. Award 1/2 point if the base case and inductive hy- pothesis are set up properly and a partial proof of the inductive step is attempted. Award 1 point if the inductive step is correct. Exercise 4.4 Searching in a weirdly-sorted array (1 point). Let n ≥ 2 and suppose we are given an array A[1 . . . n] containing n unique integers, that satisfies the following property: there is an integer 1 ≤ k ≤ n − 1 such that the subarrays A[1 . . . k] and A[k + 1 . . . n] are sorted (in ascending order), and A[n] < A[1]. We call such an array weirdly-sorted, and we call k the pivot. (a) Given a weirdly-sorted array A[1 . . . n] containing n unique integers, provide an algorithm in pseu- docode that finds the pivot 1 ≤ k ≤ n − 1 such that the subarrays A[1 . . . k] and A[k + 1 . . . n] are sorted (in ascending order). The runtime of your algorithm should be at most O(log n). Hint: Be careful of edge-cases. Hint: For an index 1 ≤ m ≤ n, think of a simple condition involving A[1], A[n] you could check to see if m is to the left or to the right of the pivot. Solution: Let k be the pivot. Note that, for any m > k (i.e., to the right of the pivot), we must have A[m] ≤ A[n] < A[1], while for any m < k (to the left of the pivot), we must have A[m] < A[k]. Therefore, the pivot can be found using the following recursive algorithm: Algorithm 2 Find the pivot function findPivot(A, i, j) if j = i then return i m ← ⌈(i + j)/2⌉ ▷ Mid-point between i and j if A[m] < A[1] then ▷ m is strictly larger than the pivot. return findPivot(A, i, m − 1) ▷ keep searching in the left half else ▷ m is smaller than or equal to the pivot return findPivot(A, m, j) ▷ keep searching in the right half Input: Weirdly-sorted array A of length n. Output: findPivot(A, 1, n) To show that this algorithm really works in O(log n), you can use the Master theorem. (b) Given a weirdly-sorted array A[1 . . . n] containing n unique integers, and an integer ℓ ∈ N, provide an algorithm in pseudocode that determines whether A contains ℓ as an entry. The runtime of your algorithm should be at most O(log n). You may use the algorithm of part (a) as a subroutine even if you did not solve that part. You may also use algorithms from the lecture as subroutines. 6 Solution: Consider the binary search algorithm BS for integer arrays sorted in ascending order. That is, given such an array B of length n, and an integer p ∈ N, the algorithm BS(B, p) returns true if p is an entry of B and false otherwise. It has running time O(log n). The idea for searching in a weirdly- sorted array is to first find the pivot using the algorithm of part (a), and then apply binary search to both (sorted) halves of the array: Algorithm 3 Search in a weirdly-sorted array Input: Weirdly-sorted array A of length n with unique elements, integer ℓ k ← findPivot(A, 1, n) t1 ← BS(A[1 . . . k], ℓ) ▷ search in array A[1 . . . k], sorted in ascending order t2 ← BS(A[k + 1 . . . n], ℓ) ▷ search in array A[k + 1 . . . n], sorted in ascending order Output: t1 or t2 The total runtime of the algorithm is O(log n + log n + log n), i.e. O(log n). Guidelines for correction: Award 1/2 points for each part of the exercise that is solved correctly. Do not award points for algo- rithms that do not meet the runtime requirements. Exercise 4.5 Counting function calls in loops (cont’d) (1 point). For each of the following code snippets, compute the number of calls to f as a function of n ∈ N. We denote this number by T (n), i.e. T (n) is the number of calls the algorithm makes to f depending on the input n. Then T is a function from N to R+. For part (a), provide both the exact number of calls and a maximally simplified asymptotic bound in Θ notation. For part (b), it is enough to give a maximally simplified asymptotic bound in Θ notation. For the asymptotic bounds, you may assume that n ≥ 10. Algorithm 4 (a) i ← 1 while i ≤ n do j ← 1 while i√j ≤ n do f () j ← j + 1 i ← i + 1 Hint: You may use the formula for a finite geometric series without proof n∑ i=0 ari = a(rn+1 − 1) r − 1 for r ̸= 1. Solution: 7 The inner loop increases as long as i√j ≤ n which means j ≤ ni and thus performs ∑ni j=1 1 = ni calls to f . So in total we perform ∑n i=1 ni = ∑n−1 i=0 n(n)i = n(nn−1) n−1 calls to f . So as lim n→∞ n(nn−1) n−1 nn = lim n→∞ n n − 1 · nn − 1 nn = lim n→∞ ( 1 + 1 n − 1 ) · nn − 1 nn = lim n→∞ nn − 1 nn + lim n→∞ 1 n − 1 nn − 1 nn = lim n→∞ nn − 1 nn + 0 = lim n→∞ 1 − 1 nn = 1, we get this equal to Θ(nn). Alternatively, from the sum formula, we have lim n→∞ ∑n i=1 ni nn = n∑ i=1 lim n→∞ ni nn = n∑ i=1 lim n→∞ 1 nn−i = 0 + · · · + 0 + 1 = 1 since all terms go to zero except i = n and thus we can also conclude that this is equal to Θ(nn). Algorithm 5 (b) function A(n) i ← 1 while i ≤ n do j ← i while j ≤ n do f () f () j ← j + 1 i ← i + 1 k ← ⌊ n 2 ⌋ for ℓ = 1 . . . 3 do if k > 0 then A(k) You may assume that the function T : N → R+ denoting the number of calls of the algorithm to f is increasing. Hint: Recall exercise 0.1. If T (n) = aT (n/2) + g(n) for some function g(n), then find a bound Cnb ≤ g(n) ≤ C′nb for two constants C and C′ and then use the Θ version of the master theorem. Equivalently show that g(n) = Θ(nb). Solution: Given i, the innermost loop performs ∑n j=i 2 = 2(n − i + 1) calls to f . Hence, the second loop (guarded by i ≤ n) performs ∑n i=1 2(n − i + 1) = 2n2 − n(n + 1) + 2n = n2 + n calls to f using ∑n i=1 i = n(n+1) 2 from exercise 0.1. If ⌊ n 2 ⌋ = 0 (i.e. n = 1), then k = 0, so the algorithm makes 12 + 1 = 2 calls to f . Thus T (1) = 2. For n ≥ 2, we have k = ⌊ n 2 ⌋ > 0 and thus we get the following relation T (n) = n2 + n + 3T (⌊ n 2 ⌋). For even n, this relation is T (n) = n2 + n + 3T ( n 2 ). 8 As n2 + n ≤ 2n2 and n2 ≤ n2 + n, we have n2 ≤ n2 + n ≤ 2n2. So n2 + 3T ( n 2 ) ≤ T (n) ≤ 2n2 + 3T ( n 2 ). So we can apply the master theorem to get a theta bound with a = 3, b = 2, C = 2 and C′ = 1. We get (2 > log2(3) ≈ 1.584) T (n) = Θ(n2) for any integer n ≥ 1 since T is increasing. In a previous version of the sheet, we could only conclude a theta bound from the master theorem if T satisfies T (n) = aT (n/2) + Cnb. The current version lets us conclude the same theta bound but under the weaker assumption on T that aT (n/2) + C′nb ≤ T (n) ≤ aT (n/2) + Cnb for potentially different constants C and C′ (note that the previous version is equivalent to this version with C = C′). To prove the theta bound using the previous version, we can conclude an upper bound first by using the master theorem for T (n) ≤ 2n2 + 3T ( n 2 ) to get the upper bound T (n) ≤ O(n2) which holds for all n ∈ N (T is increasing). For the lower bound, assume n = 2k for some integer k ∈ N. Define T ′(n) = n2 + 3T ′( n 2 ) with initial condition T (1) = T ′(1). Using the master theorem theta bound for T ′(n) with a = 3, b = 2 and C = 1 we get T ′(n) = Θ(n2) and thus by definition also T ′(n) ≥ Ω(n2). Notice that T (n) = n2 + n + 3T ( n 2 ) ≥ T ′(n), therefore T (n) ≥ T ′(n) ≥ Ω(n2). To get this to hold for all n ∈ N, let C be such that T (n) ≥ Cn2 for n = 2k where k ∈ N. For n not of this form, suppose 2k < n < 2k+1 for some k ∈ N, then 22k > n2 4 . So since T is increasing we have T (n) ≥ T (2 k) ≥ C(2 k) 2 = C(2 2k) > C n2 4 Thus we can conclude that T (n) ≥ Ω(n2) for all n ∈ N. Combining the two bounds T (n) ≤ O(n2) and T (n) ≥ Ω(n2) we can again conclude that T (n) = Θ(n2). (c)* Prove that the function T : N → R+ from the code snippet in part (b) is indeed increasing. Hint: You can show the following statement by mathematical induction: “For all n′ ∈ N with n′ ≤ n we have T (n′ + 1) ≥ T (n′)”. Solution: We show the statement suggested in the hint by mathematical induction. • Base Case. We have T (2) = 22 + 2 + 3T (1) = 12 ≥ 2 = T (1), so the base case holds as the only n′ ∈ N that is at most 1 is n′ = 1. • Induction Hypothesis. Assume that for some k ∈ N we have T (k′ + 1) ≥ T (k′) for all k′ ∈ N with k′ ≤ k. • Inductive Step. We must show that T (k + 2) ≥ T (k + 1). Together with the induction hypothesis this shows that T (k′ + 1) ≥ T (k′) for all k′ ∈ N with k′ ≤ k + 1. We have that ⌊ k + 1 2 ⌋ ≤ k. By the induction hypothesis T (⌊ k + 2 2 ⌋) ≥ T (⌊ k + 1 2 ⌋) . 9 This is true since either ⌊ k+2 2 ⌋ = ⌊ k+1 2 ⌋ or ⌊ k+2 2 ⌋ = ⌊ k+1 2 ⌋+1. For the first case the inequality is actually an equality and the second case is covered by the induction hypothesis. Using the relation from above we get T (k+2) = (k+2) 2+(k+2)+3T (⌊ k + 2 2 ⌋) ≥ (k+1) 2+(k+1)+3T (⌊ k + 1 2 ⌋) = T (k+1). By the principle of mathematical induction, for every n ∈ N we have for n′ ∈ N with n′ ≤ n that T (n′ + 1) ≥ T (n′). In particular, T (n + 1) ≥ T (n) is true for any n ∈ N and the function T is increasing. Guidelines for correction: This exercise consists of two parts (excluding part c). Award 1/2 point for each correct exercise. 10","libVersion":"0.3.2","langs":""}
{"path":"sem4/W&S/UE/s/W&S-s-u03.pdf","text":"Probability and Statistics (D-INFK) Lecturer: Prof. Dr. Dylan Possamaï Coordinator: Daniel Kršek Probability and Statistics Exercise sheet 3 - Solutions MC 3.1. Let (Ω, F, P) be a probability space and let A, B, and C be events with P[A ∩ B] > 0 and P[C] > 0. We assume that P[A|B] > P[A] and P[A|C] > P[A]. Which of the following holds? (Exactly one answer is correct.) (a) P[A|B ∩ C] > P[A]. (b) P[B] = P[C]. (c) P[B|A] > P[B]. (d) None of the above. Solution: Answer (c) is correct. Since P[A ∩ B] > 0, we have P[A] > 0 and P[B] > 0, so P[A ∩ B] = P[A|B]P[B] = P[B|A]P[A]. Then P[A|B] > P[A] =⇒ P[B|A] = P[A ∩ B] P[A] = P[A|B]P[B] P[A] > P[A]P[B] P[A] = P[B]. None of the other options hold in general. MC 3.2. Let Ω = {ω1, ω2, ω3} and F = {∅, Ω, {ω1, ω2}, {ω3}}. Which of the following define random variables on (Ω, F)? (The number of correct answers is between 0 and 4.) (a) X1(ω1) = 1, X1(ω2) = 2, X1(ω3) = 3. (b) X2(ω1) = 1, X2(ω2) = 1, X2(ω3) = 2. (c) X3(ω1) = 1, X3(ω2) = 2, X3(ω3) = 2. (d) X4(ω1) = 1, X4(ω2) = 1, X4(ω3) = 1. Solution: First, we note that in this specific situation, where Xi, i ∈ {1, . . . , 4}, takes values in {1, 2, 3}, we have X −1 i ((−∞, a]) =    ∅, a < 1, X −1 i ({1}), a ∈ [1, 2), X −1 i ({1}) ∪ X −1 i ({2}), a ∈ [2, 3), X −1 i ({1}) ∪ X −1 i ({2}) ∪ X −1 i ({3}), a ≥ 3. 1 Probability and Statistics (D-INFK) Lecturer: Prof. Dr. Dylan Possamaï Coordinator: Daniel Kršek Thus, it suffices to verify measurability of the sets X −1 i ({1}), X −1 i ({2}), and X −1 i ({3}). (a) We have X −1 1 ({1}) = {ω1} /∈ F, and so X1 is not a random variable. (b) We have X −1 2 ({1}) = {ω1, ω2} ∈ F, X −1 2 ({2}) = {ω3} ∈ F and X −1 2 ({3}) = ∅ ∈ F, and so X2 is a random variable. (c) We have X −1 3 ({1}) = {ω1} /∈ F, and so X3 is not a random variable. (d) We have X −1 4 ({1}) = Ω ∈ F and X −1 4 ({2}) = X −1 4 ({3}) = ∅ ∈ F. and so X4 is a random variable. In fact, constant functions are always random variables. MC 3.3. Let (Ω, F, P) be a probability space and let A, B, and C be events in F. Which of the following statements are always true? (The number of correct answers is between 0 and 4.) (a) If A and B as well as A and C are independent, then A and B ∩ C are also independent. (b) If A and B as well as B and C are independent, then A and C are also independent. (c) If A, B, and C are independent, then A and B ∩ C are also independent. (d) If A and A are independent, then P[A] = 1 or P[A] = 0. Solution: (a) is not correct. For instance, consider two independent coin flips, and define A := {The first flip results in tails}, B := {The second flip results in heads} C := {The two flips have the same result}. It is easy to verify that this example disproves (a). (b) is not correct. Take A, B independent and C = A. Then it is clear that (b) is generally false. (c) is corrrect. We have P[A ∩ (B ∩ C)] = P[A ∩ B ∩ C] = P[A]P[B]P[C] = P[A]P[B ∩ C]. (d) is correct. We have that P[A] = P[A ∩ A] = P[A]P[A] = (P[A]) 2 holds only if P[A] = 1 or P[A] = 0. MC 3.4. Let X and Y be two random variables taking values in {1, . . . , 6} and representing two independent rolls of a die. Which of the following pairs of events are independent? (The number of correct answers is between 0 and 4.) (a) {X is odd}, {X + Y is even}. (b) { X ∈ {1, 3} }, {X + Y = 5}. 2 Probability and Statistics (D-INFK) Lecturer: Prof. Dr. Dylan Possamaï Coordinator: Daniel Kršek (c) {X = 1}, {X + Y = 4}. (d) {X = 1}, {X + Y = 13}. Solution: (a) and (d) are correct. We have P[X is odd] = 1 2 , P[X + Y is even] = P[X is even|Y is even]P[Y is even] + P[X is odd|Y is odd]P[Y is odd] = P[X is even]P[Y is even] + P[X is odd]P[Y is odd] = 1 2 × 1 2 + 1 2 × 1 2 = 1 2 , P[X is odd, X + Y is even] = P[X is odd, Y is odd] = P[X is odd]P[Y is odd] = 1 4 . Thus, we see that P[X is odd, X + Y is even] = 1 4 = 1 2 × 1 2 = P[X is odd]P[X + Y is even]. The last option is trivially true because P[X = 1, X + Y = 13] = 0 = P[X = 1]P[X + Y = 13]. Using similar calculations, one can verify that the other options are incorrect. Exercise 3.5. Let X be a random variable with the distribution function F (a) =    0, a < 0, a 2 , 0 ≤ a < 1, 2 3 , 1 ≤ a < 2, a+1 4 , 2 ≤ a < 3, 1, 3 ≤ a. (a) Plot this distribution function. (b) Determine the following probabilities: P[X < 1], P[X = 2], P[X = 3], P[1 < X ≤ 2], P[1 ≤ X < 2] and P[X ≥ 3/2]. 3 Probability and Statistics (D-INFK) Lecturer: Prof. Dr. Dylan Possamaï Coordinator: Daniel Kršek Solution: (a) The graph of F is as follows: −0.5 0 0.5 1 1.5 2 2.5 3 3.5 −0.2 0 0.2 0.4 0.6 0.8 1 1.2 aF(a) (b) We have: P[X < 1] = F (1−) = 1/2, P[X = 2] = F (2) − F (2−) = 3/4 − 2/3 = 1/12, P[X = 3] = 0 (since F is continuous at 3), P[1 < X ≤ 2] = F (2) − F (1) = 3/4 − 2/3 = 1/12, P[1 ≤ X < 2] = F (2−) − F (1−) = 2/3 − 1/2 = 1/6, P[X ≥ 3/2] = 1 − F (1.5−) = 1 − 2/3 = 1/3. Exercise 3.6. [Riemann zeta function] Let X be a discrete random variable with values in N = {1, 2, 3, . . .}. The distribution of X is given by P[X = n] = n −s ζ(s) , n ∈ N, where s > 1 is a parameter of the distribution, and ζ(s) = ∑∞ n=1 n−s denotes the Riemann zeta function. For a number m ∈ N, we define the event Em as {X is divisible by m without remainder}, or equivalently, {There exists a k ∈ N such that X = km}. (a) Show that P[Em] = m −s for all m ∈ N. (b) Let p and q be two distinct prime numbers. Show that Ep and Eq are independent. 4 Probability and Statistics (D-INFK) Lecturer: Prof. Dr. Dylan Possamaï Coordinator: Daniel Kršek Hint: A number n is divisible by two different prime numbers p and q if and only if n is divisible by pq. (c) Determine P[ ⋂ p prime Ec p] . Solution: (a) Let m ∈ N. Then we have P[Em] = P [ ∞⋃ k=1 {X = km} ] disjoint = ∞∑ k=1 P[X = km] = ∞∑ k=1 (km) −s ζ(s) = m−s × ∑∞ k=1 k−s ζ(s) = m−s × ζ(s) ζ(s) = m −s. (b) According to the hint, we have Ep ∩ Eq = Epq, and thus P[Ep ∩ Eq] = P[Epq] = (pq)−s = p−sq−s = P[Ep]P[Eq]. Hence, Ep and Eq are independent. (c) We consider the prime factorization of X. The event ⋂ p prime Ec p corresponds to the situation when no prime number appears in the prime factorization of X, i.e., X must be 1. Thus, we obtain P [ ⋂ p prime Ec p ] = P[X = 1] = 1 ζ(s) . Exercise 3.7. [First six] Two players, Anja and Beatrice, take turns rolling a (fair) die until a six appears. Anja starts rolling. The player who rolls the first six wins the game. Determine the probabilities of winning for both players. Solution: Let A be the event that Anja wins, and B be the event that Beatrice wins. First, note that P[The game never ends] = 1 − ∞∑ i=1 P[The game ends after exactly i rolls] = 1 − ∞∑ i=1 ( 5 6 )i−1 × 1 6 = 1 − 1 6 × ∞∑ i=1 ( 5 6 )i−1 = 1 − 1 6 × 6 = 0. 5 Probability and Statistics (D-INFK) Lecturer: Prof. Dr. Dylan Possamaï Coordinator: Daniel Kršek Thus, since one of them must win, but they cannot both win simultaneously, we have P[A] + P[B] = 1. (1) Let W be the number of the roll in which the first six appears. W follows a geometric distribution with parameter 1/6. If W is odd, Anja wins; otherwise, Beatrice wins. Thus, we obtain P[A] = ∞∑ n=0 P[W = 2n + 1] = ∞∑ n=0 ( 5 6 )2n × 1 6 = 1 6 ∞∑ n=0 (( 5 6 )2)n = 1 6 × 1 1 − (5/6)2 = 6 11 and consequently, P[B] = 1 − P[A] = 5/11. Exercise 3.8. [Construction of random variables] The goal of this problem is to construct random variables from a sequence of independent coin flips. Let (Ω, F, P) be a probability space, and let (Xi)i≥1 be an infinite sequence of independent, Bernoulli(1/2)-distributed random variables. We consider the following algorithm: i := 1 while (Xi = Xi+1 = 1) : i := i + 2 Z := Xi + 2 × Xi+1 return Z (a) Show that the algorithm always terminates after a finite number of steps with probability 1. (b) Show that Z is a uniformly distributed random variable in {0, 1, 2}. (c) [Bonus] Provide an algorithm that outputs a Bernoulli(1/5)-distributed random variable. Solution: (a) To show that the algorithm terminates after a finite number of steps, we need to prove that the while loop runs only a finite number of times. We observe that for j ≥ 0, Aj :={The while loop runs exactly j times} = ( 2j⋂ i=1{Xi = 1} ) ∩ ({X2j+1 = 0} ∪ {X2j+2 = 0}). 6 Probability and Statistics (D-INFK) Lecturer: Prof. Dr. Dylan Possamaï Coordinator: Daniel Kršek Due to the independence of the random variables (Xi)i≥1, we get P [Aj] = P [ 2j⋂ i=1{Xi = 1} ∩ ({X2j+1 = 0} ∪ {X2j+2 = 0} )] = ( 2j∏ i=1 P [Xi = 1] ) × P [{X2j+1 = 0} ∪ {X2j+2 = 0}] ︸ ︷︷ ︸ =1−P[{X2j+1=1}∩{X2j+2=1}]=1− 1 4 = 3 4 = 3 4 × ( 1 2 )2j . Summing over all cases where the algorithm terminates, i.e., over the disjoint events (Aj)j≥1, we obtain P[Algorithm terminates] = ∞∑ j=0 P [Aj] = ∞∑ j=0 3 4 × ( 1 2 )2j = 3 4 × ∞∑ j=0 ( 1 4 )j = 3 4 × 1 1 − 1 4 = 1. (b) From part (a), we know that the event A := {Algorithm terminates} = ⋃∞ j=0 Aj has probability 1 and that the events (Aj)j≥1 are disjoint. Thus, we obtain P[Z = 0] = P[{Z = 0} ∩ A] + P[{Z = 0} ∩ Ac] ︸ ︷︷ ︸ ≤P[Ac]=0 = ∞∑ j=0 P[{Z = 0} ∩ Aj] = ∞∑ j=0 P [ 2j⋂ i=1{Xi = 1} ∩ {X2j+1 = 0} ∩ {X2j+2 = 0} ] = ∞∑ j=0 ( 1 2 )2j+2 = 1 4 × ∞∑ j=0 ( 1 4 )j = 1 4 × 1 1 − 1 4 = 1 3 , where we again use the independence of (Xi)i≥1 and the definition of Z in the algorithm. Similarly, we obtain P[Z = 1] = P[Z = 2] = 1 3 , so Z is uniformly distributed on {0, 1, 2}. 7 Probability and Statistics (D-INFK) Lecturer: Prof. Dr. Dylan Possamaï Coordinator: Daniel Kršek (c) Consider the following algorithm: i := 1 while (Xi = Xi+2 = 1) or (Xi+1 = Xi+2 = 1) : i := i + 3 Z := Xi + 2 × Xi+1 + 4 × Xi+2 if Z = 4 : Z ′ := 1 else : Z ′ := 0 return Z ′ Following similar reasoning as in parts (a) and (b), we can show that the algorithm terminates with probability 1 and that Z is uniformly distributed on {0, 1, 2, 3, 4}, implying that Z ′ is Bernoulli(1/5)-distributed. 8","libVersion":"0.5.0","langs":""}
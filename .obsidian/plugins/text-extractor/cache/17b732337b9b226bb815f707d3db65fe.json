{"path":"sem4/W&S/VRL/extra/W&S-script-2-de.pdf","text":"Teil 2: Statistik V. Tassion (based on a previous version from M. Schweizer) D-INFK Frühling 2022 (Aktualisiert: 24. Mai 2022) Statistische Grundideen Ausgangssituation: Man hat beobachtete Daten und will daraus Rückschlüsse ziehen auf den zugrundeliegenden Mechanismus, der diese Daten generiert hat. Ein häuﬁger erster Schritt ist eine graphische Aufbereitung der Daten; das ist oft nützlich, um einen ersten Eindruck und erste Ideen zu bekommen. Die entsprechenden Methoden gehören zur deskriptiven oder beschreibenden Statistik ; diese Aspekte werden hier aber nicht behandelt. Wir befassen uns im Folgenden mit der induktiven Statistik. Die Grundidee dabei ist relativ einfach. Man fasst die Daten x1, . . . , xn auf als Realisierungen/realisierte Werte X1(ω), . . . , Xn(ω) von Zufallsvariablen X1, . . . , Xn, und sucht dann (unter geeigneten Zu- satzannahmen) Aussagen über die Verteilung von X1, . . . , Xn. Wichtig: Man muss immer sauber unterscheiden zwischen den Daten x1, . . . , xn (be- zeichnet mit kleinen Buchstaben; x1, . . . , xn sind also in der Regel Zahlen) und dem gene- rierenden Mechanismus X1, . . . , Xn (bezeichnet mit grossen Buchstaben; X1, . . . , Xn sind Zufallsvariablen, also Funktionen auf einem Ω). Das wird leider nicht immer eingehalten, obwohl schon der amerikanische Philosoph und Psychologe William James (1842–1910) im 19. Jahrhundert auf diesen Punkt hinwies: “We must be careful not to confuse data with the abstractions we use to analyze them.” Terminologie: Die Gesamtheit der Beobachtungen x1, . . . , xn oder Zufallsvariablen X1, . . . , Xn nennt man oft eine Stichprobe; die Anzahl n heisst dann der Stichproben- umfang. Ausgangspunkt unserer Betrachtungen ist in der Regel ein Datensatz x1, . . . , xn aus einer Stichprobe X1, . . . , Xn, für die wir ein Modell suchen. Dieses ist beschreibbar durch einen (möglicherweise hochdimensionalen) Parameter θ ∈ Θ, und um Begriﬀe und Notatio- nen sauber deﬁnieren und benutzen zu können, muss man genauer speziﬁzieren, in welcher 1 2 Art wahrscheinlichkeitstheoretische Aussagen vom Parameter θ abhängen. Dazu betrach- tet man simultan eine ganze Familie von Wahrscheinlichkeitsräumen; man hat typisch einen festen Grundraum (Ω, F) und für jeden Parameter θ aus dem Parameterraum Θ ein Wahrscheinlichkeitsmass Pθ auf (Ω, F), also einen Wahrscheinlichkeitsraum (Ω, F, Pθ) für jedes θ ∈ Θ. Anschaulich kann man sich vorstellen, dass jemand (“die Natur”) einen Parameter θ ∈ Θ und damit einen konkreten stochastischen Mechanismus Pθ wählt. Als Statistiker weiss man aber nicht, welches θ aus Θ gewählt wurde; man betrachtet also die Daten x1, . . . , xn als Ergebnisse von Zufallsvariablen X1, . . . , Xn unter dem unbekannten Mechanismus Pθ und versucht, daraus Rückschlüsse über θ zu ziehen. Beispiel: Betrachten wir die obigen Ideen einmal für die Situation eines Münzwurfmodells. Wir haben eine Münze, von der wir nicht recht wissen, wie sie sich beim Werfen verhält. Wir nehmen an, dass die Münze bei jedem Wurf Kopf oder Zahl mit (immer der gleichen) Wahrscheinlichkeit p bzw. 1 − p produziert; wir kennen aber p nicht und betrachten es deshalb als einen unbekannten Parameter. Hier ist also Θ = [0, 1], der Parameter θ = p entspricht der Erfolgswahrscheinlichkeit für Kopf bei einem einzelnen Münzwurf, und das Wahrscheinlichkeitsmass Pθ = Pp beschreibt das Münzwurfmodell mit dem Erfolgspara- meter p. Wir nehmen zusätzlich auch noch an, dass die einzelnen Würfe jeweils (d.h. in jedem Modell Pθ) unabhängig sind. Nun werfen wir unsere Münze n Mal, schreiben jeweils 0 für Zahl, 1 für Kopf und erhalten so Daten x1, . . . , xn aus einer Stichprobe X1, . . . , Xn. Unser Modell (oder genauer unsere Modellfamilie) ist die Xi sind unter Pp i.i.d. ∼ Ber(p); der Parameter ist also wie erwähnt θ = p ∈ [0, 1] = Θ, und das Modell Pp beschreibt unabhängige Münzwürfe mit Erfolgsparameter p für “Kopf”. Unser Ziel ist es, aus den Daten Rückschlüsse über p zu ziehen. (Zum Beispiel möchten wir vermutlich wissen, ob die Münze wohl fair ist oder nicht.) In vielen Fällen ist der Parameterraum Θ eine Teilmenge von Rm; wenn man zu ge- gebenen Daten ein passendes Modell ﬁnden und darüber gewisse statistische Aussagen machen möchte, so spricht man dann von einer parametrischen statistischen Analyse. Allgemein gehören dazu die folgenden Etappen: 3 1) Beschreibende Statistik der Daten: In diesem Schritt versucht man mit graphischen Methoden, aufgrund der Daten eine erste Idee für die Wahl einer geeigneten Model- lierung zu ﬁnden. (Diesen Schritt werden wir hier nicht weiter erklären.) 2) Wahl eines (parametrischen) Modells: Hier speziﬁziert man die Parametermenge Θ und die Familie (Pθ)θ∈Θ von Modellen, mit denen man arbeiten will. 3) Schätzung der Parameter: Aufgrund der Daten will man ein möglichst gut passendes Modell wählen. Dazu benutzt man einen Schätzer ; die zugehörige Schätzfunktion ist eine Abbildung, die gegebenen Daten x1, . . . , xn einen Parameter θ ∈ Θ zuordnet. 4) Kritische Modellüberprüfung (Anpassungstest): Hier fragt man, ob die Daten zu dem gewählten Parameter θ bzw. Modell Pθ gut passen; das macht man mit einem geeigneten statistischen Test. 5) Aussagen über Zuverlässigkeit der Schätzungen: Statt eines einzigen Parameter- wertes kann man auch versuchen, einen Bereich in Θ so zu speziﬁzieren, dass alle zugehörigen Modelle Pθ in einem zu präzisierenden Sinn gut zu den Daten passen; man spricht dann von einem Konﬁdenzbereich. Kapitel 1 Schätzer Ziel: Überblick über grundlegende Ideen und Methoden zur Schätzung von Parametern. Setup: • Parameterraum Θ ⊂ R, • Grundraum Ω, • sigma-Algebra F, • (Pθ)θ∈Θ Familie von Wahrscheinlichkeitsmasse auf (Ω, F), • X1, . . . , Xn Zufallsvariablen auf (Ω, F). 4 KAPITEL 1. SCHÄTZER 5 1.1 Grundbegriﬀe Wir suchen dann für der Parameter θ ein Schätzer T aufgrund unserer Stichprobe (X1, . . . , Xn). Deﬁnition 1.1. Ein Schätzer ist eine Zufallsvariable T ∶ Ω → R der Form T = t(X1, . . . , Xn), wobei t ∶ Rn → R. Einsetzen von Daten xi = Xi(ω), i = 1, . . . , n, liefert dann Schätzwerte T (ω) = t(x1, . . . , xn) für θ. Es ist wichtig, die Konzepte “Schätzer” und “Schätzwert” sauber auseinanderzuhalten. Ein Schätzwert ist eine Zahl T (ω) = t(X1(ω), . . . , Xn(ω)) = t(x1, . . . , xn); wie die Daten xi ist das die Realisation T (ω) (im von uns betrachteten konkreten Experiment ω) der Zufallsvariable T . Beispiel: tea tasting lady Eine englische Lady behauptet, bei Tee mit Milch anhand des Geschmacks unterscheiden zu können, ob zuerst die Milch oder zuerst der Tee in die Tasse eingegossen worden ist. Wie kann man überprüfen, ob das stimmen kann? Um zunächst einmal Daten zu bekommen, stellen wir der Lady an n Tagen die Aufga- be, zwei Tassen (je eine vom Typ 1 und Typ 2) zu klassiﬁzieren; sie soll also angeben, in welche der Tassen zuerst Milch eingegossen worden ist. Wir notieren uns dabei die Ergeb- nisse x1, . . . , xn ∈ {0, 1} (falsch bzw. richtig klassiﬁziert) und fassen wie üblich diese Daten als Realisationen von Zufallsvariablen X1, . . . , Xn auf. Dann ist Sn = ∑ n i=1 Xi die (zufäl- lige) Anzahl der korrekt klassiﬁzierten Tassenpaare, und sn = ∑ n i=1 xi ist die beobachtete Anzahl von Erfolgen. Als Modelle nehmen wir nun an, dass die Xi unter Pθ i.i.d. ∼ Ber(θ) mit θ ∈ Θ = [0, 1] sind. Dann ist natürlich Sn ∼ Bin(n, θ) unter Pθ, d.h. im Modell Pθ, das zu θ gehört, ist die Anzahl Sn der Erfolge binomialverteilt mit Parametern n und θ. Weil wir den Parameter θ nicht kennen, liegt es nahe, zuerst einmal dafür einen Schät- zer zu suchen. Eine erste Möglichkeit wäre, einfach das letzte Ergebnis zu nehmen; unser erster Schätzer ˆT für θ wäre also ˆT = Xn. Obwohl das absurd aussieht, werden wir sehen, dass dieser Schätzer durchaus die eine oder andere vernünftige Eigenschaft hat. KAPITEL 1. SCHÄTZER 6 Ein zweiter naheliegender Schätzer wäre die durchschnittliche Anzahl der Erfolge der Lady bei ihren n Versuchen; unser zweiter Schätzer wäre also T = X n = 1 n Sn. Für gegebene Daten x1, . . . , xn gibt uns das dann zwei Schätzwerte ˆt(x1, . . . , xn) = xn und t(x1, . . . , xn) = xn = 1 n ∑n i=1 xi, die wir konkret berechnen könnten. ◇ 1.2 Bias Wie die Xi ist der Schätzer T ein Zufallsvariable, deren Verteilung (unter Pθ) von dem unbekannten Parameter θ abhängt. Nur selten kann man diese Verteilung explizit be- stimmen; siehe später die Resultate für die Normalverteilung. Bevor wir zumindest eine systematische Methode zur Bestimmung von Schätzern betrachten, führen wir einige all- gemeine wünschenswerte Eigenschaften auf. Deﬁnition 1.2. Ein Schätzer T heisst erwartungstreu für θ, falls für alle θ ∈ Θ gilt Eθ[T ] = θ. Interpretation Im Mittel (über alle denkbaren Realisationen ω) schätzt T also richtig, und zwar unabhängig davon, welches Modell Pθ zu Grunde liegt. Deﬁnition 1.3. Sei θ ∈ Θ, und T ein Schätzer. Der Bias (oder erwartete Schätzfeh- ler) von T im Modell Pθ ist deﬁniert als Eθ[T ] − θ. Der mittlere quadratische Schätzfehler (“mean squared error”, MSE) von T im Modell Pθ ist deﬁniert als MSEθ[T ] ∶= Eθ[(T − θ)2]. Erwartungstreu (auf Englisch “unbiased ”) bedeutet also, dass der Bias identisch Null ist. Bemerkung: Man kann den MSE zerlegen als MSEθ[T ] = Eθ[(T − θ)2] = Varθ[T ] + (Eθ[T ] − θ) 2, also in die Summe aus der Varianz des Schätzers T und dem Quadrat des Bias. Für erwartungstreue Schätzer sind Varianz und MSE dasselbe. KAPITEL 1. SCHÄTZER 7 Beispiel: tea tasting lady Beide oben angegebenen Schätzer ˆT = Xn und T = X n sind erwartungstreu. Unter Pθ ist ja ˆT = Xn ∼ Be(θ), also Eθ[ ˆT ] = Eθ[Xn] = θ, und MSEθ[ ˆT ] = Varθ(Xn) = θ(1 − θ). Obwohl aber ˆT erwartungstreu ist, wird er kaum je das richtige Ergebnis für den Parameter θ liefern; für jede konkrete Realisierung ω hat ja ˆT (ω) = Xn(ω) den Wert 0 oder 1, und nur im theoretischen Mittel über alle ω erhalten wir θ. Unser zweiter Schätzer für θ ist T = X n = 1 n ∑ n i=1 Xi; er ist auch erwartungstreu, denn Eθ[T ] = 1 n n Q i=1 Eθ[Xi] = θ für alle θ, und (wegen Unabhängigkeit unter Pθ) Varθ[T ] = 1 n2 n Q i=1 Varθ[Xi] = 1 n θ(1 − θ), weil alle Xi ∼ Ber(θ) unter Pθ sind. Wegen Varθ[ ˆT ] = Varθ[Xn] = θ(1 − θ) hat T kleinere Varianz als ˆT . Das ist einleuchtend, weil T die Information in der Stichprobe X1, . . . , Xn viel besser ausnutzt. ◇ 1.3 Die Maximum-Likelihood-Methode (ML-Methode) In diesem Abschnitt stellen wir eine Methode vor, um systematisch Schätzer zu bestim- men. Diese Methode liefert in sehr vielen Situationen Ergebnisse, die sowohl plausibel sind als auch gute Eigenschaften haben. Ausgangspunkt im Folgenden ist immer eine von zwei Situationen, je nachdem, ob wir es mit diskreten oder mit stetigen Zufallsvariablen zu tun haben. Wir schreiben oft kurz ÑX = (X1, . . . , Xn). In jedem Modell Pθ sind X1, . . . , Xn entweder diskret mit ge- meinsamer Gewichtsfunktion p ÑX(x1, . . . , xn; θ) oder stetig mit gemeinsamer Dichtefunkti- on f ÑX(x1, . . . , xn; θ). Meistens sind sogar die Xi unter Pθ i.i.d. mit individueller Gewichts- KAPITEL 1. SCHÄTZER 8 funktion pX(x; θ) bzw. Dichtefunktion fX(x; θ); dann ist also die gemeinsame Gewichts- funktion p ÑX(x1, . . . , xn; θ) = n M i=1 pX(xi; θ) bzw. die gemeinsame Dichtefunktion f ÑX(x1, . . . , xn; θ) = n M i=1 fX(xi; θ). Anschaulich ist p ÑX(x1, . . . , xn; θ) = Pθ[X1 = x1, . . . , Xn = xn] gerade die Wahrscheinlichkeit im Modell Pθ, dass unsere Stichprobe X1, . . . , Xn die Werte x1, . . . , xn liefert, und f ÑX(x1, . . . , xn; θ) ist das übliche stetige Analogon. Deﬁnition 1.4. Die Likelihood-Funktion ist L(x1, . . . , xn; θ) ∶= ¢¨¨¨ ¦ ¨¨¨¤ p ÑX(x1, . . . , xn; θ) im diskreten Fall, f ÑX(x1, . . . , xn; θ) im stetigen Fall. Die Funktion log L(x1, . . . , xn; θ) heisst log-Likelihood-Funktion. Sie hat gegenüber der Likelihood-Funktion den Vorteil, dass sie im i.i.d.-Fall durch eine Summe (statt ein Produkt) gegeben und damit zum Rechnen oft wesentlich einfacher ist. Nach diesen allgemeinen Vorbereitungen wenden wir uns nun der erwähnten Methode zur Bestimmung von Schätzern zu. Für eine Stichprobe X1, . . . , Xn gibt uns die Likelihood- funktion L(x1, . . . , xn; θ) zumindest im diskreten Fall die Wahrscheinlichkeit im Modell Pθ, dass unsere Stichprobe gerade die Werte x1, . . . , xn liefert. Um eine möglichst gute Anpas- sung des Modells an die Daten zu erreichen, wollen wir diese Wahrscheinlichkeit möglichst gross machen, indem wir den Parameter geschickt wählen. Deﬁnition 1.5. Für jedes x1, . . . , xn, sei tM L(x1, . . . , xn) ∈ R der Wert, der θ ( L(x1, . . . , xn; θ) als Funktion von θ maximiert. D.h., L(x1, . . . , xn; tM L(x1, . . . , xn)) = max θ∈Θ L(x1, . . . , xn; θ). Ein Maximum-Likelihood-Schätzer (ML-Schätzer) TML für θ wird deﬁniert KAPITEL 1. SCHÄTZER 9 durch TML = tML(X1, . . . , Xn). Meistens sind X1, . . . , Xn i.i.d. unter Pθ; die Likelihood-Funktion L ist dann ein Pro- dukt, und es ist bequemer, statt L die log-Likelihood-Funktion log L zu maximieren, weil diese eine Summe ist. Statt zu maximieren sucht man ferner meistens nur Nullstellen der Ableitung (nach θ). Bemerkung: In den Rechnungen arbeitet man oft mit L(x1, . . . , xn; θ), insbesondere beim Maximieren über θ. Das optimale θ∗ ist dann eine Funktion tML(x1, . . . , xn) von x1, . . . , xn. Damit der resultierende Schätzer TML von der Stichprobe X1, . . . , Xn abhängt, muss dann aber x1, . . . , xn durch X1, . . . , Xn ersetzt werden, d.h. der Maximum-Likelihood-Schätzer ist TML = tML(X1, . . . , Xn). Beispiel 1: Bernoulli-Verteilung. Im Modell Pp seien X1, . . . , Xn i.i.d. ∼ Ber(p). Hier ist θ = p, und wir wollen also für eine unbekannte Münze den Erfolgsparameter schätzen. Diese Fragestellung haben wir schon im letzten Abschnitt im Beispiel mit der tea tasting lady angetroﬀen. Die Gewichtsfunktion einer Ber(θ)-Verteilung ist pX(x; θ) = Pθ[X = x] = θx(1 − θ) 1−x für x ∈ {0, 1}. Weil die Xi i.i.d. sind, ist also L(x1, . . . , xn; θ) = n M i=1 pX(xi; θ) = θ∑n i=1 xi(1 − θ) n−∑ n i=1 xi und log L(x1, . . . , xn; θ) = n Q i=1 xi log θ + „n − n Q i=1 xi‚ log(1 − θ). Wir wollen das über θ maximieren und setzen dazu die entsprechende Ableitung Null. Die Ableitung nach θ ist ∂ ∂θ log L(x1, . . . , xn; θ) = 1 θ n Q i=1 xi − 1 1 − θ „n − n Q i=1 xi‚, KAPITEL 1. SCHÄTZER 10 und das ist 0 für (1 − θ) n Q i=1 xi = θ„n − n Q i=1 xi‚, d.h. für θ = 1 n ∑ n i=1 xi. Der ML-Schätzer für θ bzw. p ist hier also T = 1 n n Q i=1 Xi = X n. ◇ 1.4 Modelle mit mehreren Parametern Unsere aktuelle Theorie begrenzt sich auf stochastische Modelle mit einem paramter θ in R. Verschiedene Situationen verlangen aber Modelle mit mehreren Parametern θ1, θ2, . . . , θm, m ≥ 2. Um solche Modelle besser zu verstehen, entwickeln wir nun eine allgemeinere Theorie. Als ersten Schritt betrachten wir folgende Parametermenge Θ ⊂ R m, wobei m gerade der Anzahl an Parametern entspricht und das (stochastische) Modell gegeben ist durch eine Familie von Massen (Pθ)θ∈Θ. Dabei interessieren wir uns für eine Schätzung der Parameter θ = (θ1, . . . , θn). Es ist anzumerken, dass sich alle vorherigen Deﬁnitionen in dieses Setup problemlos übertragen lassen. Beispiel 2: Normalverteilung. Im Modell Pθ seien X1, . . . , Xn i.i.d. ∼ N (µ, σ2). Hier ist die Dimension des unbekannten Parameters m = 2, wir haben θ = (µ, σ2) = (µ, v), und wir wollen µ und σ2 = v schätzen. Die Dichtefunktion von Xi unter Pθ ist fX(x; θ) = 1 σ√ 2π exp ‰− (x − µ)2 2σ2 ’ = 1 √ 2πv e − (x−µ)2 2v . Weil die Xi i.i.d. sind, ist also L(x1, . . . , xn; θ) = n M i=1 fX(xi; θ) KAPITEL 1. SCHÄTZER 11 und log L(x1, . . . , xn; θ) = n Q i=1 log fX(xi; θ) = −n 1 2(log 2π + log v) − n Q i=1 (xi − µ)2 2v . Die Ableitungen nach µ und v sind ∂ ∂µ log L(x1, . . . , xn; θ) = 2 n Q i=1 xi − µ 2v , ∂ ∂v log L(x1, . . . , xn; θ) = − n 2 1 v + 1 2v2 n Q i=1(xi − µ)2, und sie werden beide gleichzeitig 0 für 0 = n Q i=1(xi − µ) = n Q i=1 xi − nµ, d.h. für µ = 1 n n Q i=1 xi = xn, v = 1 n n Q i=1(xi − µ)2 = 1 n n Q i=1(xi − xn) 2. Der ML-Schätzer für θ = (µ, σ2) ist also T1 = 1 n n Q i=1 Xi = X n, T2 = 1 n n Q i=1(Xi − X n) 2 = 1 n n Q i=1 X 2 i − (X n)2, wobei die zweite Gleichheit durch Ausquadrieren folgt. ◇ Der Schätzer T = (T1, T2) im obigen Beispiel ist ganz allgemein auch der sogenannte Momentenschätzer für (Eθ[X], Varθ[X]) in jedem Modell Pθ, wo X1, . . . , Xn i.i.d. sind. Dieser Schätzer hat aber den allgemeinen Nachteil, dass er nicht erwartungstreu für (Eθ[X], Varθ[X]) ist. Zwar ist für jedes θ Eθ[T1] = Eθ[X n] = 1 n n Q i=1 Eθ[Xi] = Eθ[X]; aber Eθ[(X n) 2] = 1 n2 n Q i,k=1 Eθ[XiXk] = 1 n2 „ n Q i=1 Eθ[X 2 i ] + Q i~=k Eθ[XiXk]‚, und wegen Unabhängigkeit ist für i ~= k Eθ[XiXk] = Eθ[Xi]Eθ[Xk] = (Eθ[X]) 2. KAPITEL 1. SCHÄTZER 12 Also ist Eθ[T2] = 1 n n Q i=1 Eθ[X 2 i ] − ‰ 1 nEθ[X 2] + n2 − n n2 (Eθ[X]) 2’ = ‰1 − 1 n’ ›Eθ[X 2] − (Eθ[X]) 2” = n − 1 n Varθ[X]. Um einen erwartungstreuen Schätzer T ′ für (Eθ[X], Varθ[X]) zu haben, benutzt man deshalb meistens T ′ 1 = T1 = X n T ′ 2 = n n − 1T2 = 1 n − 1 n Q i=1(Xi − X n)2 = 1 n − 1 n Q i=1 X 2 i − n n − 1(X n)2. Für T ′ 2 benutzt man oft auch die Notation S2 ∶= 1 n − 1 n Q i=1(Xi − X n)2 und nennt S2 die empirische Stichprobenvarianz. Kapitel 2 Konﬁdenzintervalle Grundidee: Wie in Abschnitt 1 suchen wir aus einer Familie (Pθ)θ∈Θ von Modellen eines, das zu unseren Daten x1, . . . , xn passt. Ein Schätzer für θ gibt uns dabei einen einzelnen zufälligen möglichen Parameterwert. Weil es schwierig ist, mit diesem einen Wert den richtigen (aber unbekannten) Parameter zu treﬀen, suchen wir nun stattdessen eine (zufällige) Teilmenge des Parameterbereichs, die hoﬀentlich den wahren Parameter enthält. Setup: • Parameterraum Θ ⊂ R, • Grundraum Ω, • sigma-Algebra F, • (Pθ)θ∈Θ Familie von Wahrscheinlichkeitsmasse auf (Ω, F), • X1, . . . , Xn Zufallsvariablen auf (Ω, F). 13 KAPITEL 2. KONFIDENZINTERVALLE 14 2.1 Deﬁnition Im vorangegangenen Kapitel haben wir eine Methode zur Schätzung unbekannter Para- meter mittels Formeln kennengelernt. Eine naheliegende Frage ist: Wie reichhalting sind diese Schätzer? Werfen wir zum Beispiel eine Münze n mal, ohne die Wahrscheinlichkeit p von Kopf zu kennen. Falls wir 70 Mal Kopf erhalten, ist der Maximum-Likelihood- Schätzer für p TM L = 0.7. Wie weit liegt TM L von dem wahren Wert p entfernt? Um diese Art von Frage zu beantworten Frage zu beantworten, führen wir den Begriﬀ der Konﬁdenzintervalle ein. Deﬁnition 2.1. Sei α ∈ [0, 1]. Ein Konﬁdenzintervall für θ mit Niveau 1 − α ist ein Zufallsintervall I = [A, B], sodass gilt ∀θ ∈ Θ Pθ[A ≤ θ ≤ B] ≥ 1 − α, (2.1) wobei A, B Zufallsvariablen der Form A = a(X1, . . . , Xn), B = b(X1, . . . , Xn) mittels a, b ∶ Rn → R sind. Bemerkung 2.2. In Eq. (2.1), ist der Paramter θ deterministisch und nicht zufäl- lig. Die stochastischen Elemente sind gerade die Schranken A = a(X1, . . . , Xn) und B = b(X1, . . . , Xn). Example 1: Konﬁdenzintervall eines normalen Modells mit Varianz 1 und unbekannten Mittelwerts Seien X1, . . . , Xn n u.i.v. normalverteilte Zufallsvariablen mit Parametern m und σ2 = 1. Wir betrachten somit ein stochastisches Modell mit bekannter Varianz (σ2 = 1) aber unbekanntem Mittelwert m. Man kann zeigen, dass der Maximum-Likelihood Schätzer gegeben ist durch T = TM L = X1 + \u0005 + Xn n . Wir suchen nun für m Konﬁdenzintervalle der folgenden Form I = [T − c √ n, T + c √ n], wobei c > 0 eine von n unabhängige Konstante ist. Zuerst betrachten wir Pθ[T − c √ n ≤ m ≤ T + c √ n] = Pθ[−c ≤ Z ≤ c], KAPITEL 2. KONFIDENZINTERVALLE 15 wobei Z = √ n(T − m) = X1+\u0005+Xn−nm√n eine standardnormalverteilte Zufallsvariable ist. Somit können wir die obige Wahrscheinlichkeit explizit bestimmen Pθ[−c ≤ Z ≤ c] = Pθ[Z ≤ c] − Pθ[X < −c] ´¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¸¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¶ =1−Pθ[Z≤c] = 2Φ(c) − 1, wobei Φ(c) = 1√2π ∫ c −∞ e−x2~2dx. Nachlesen in einer Tabelle der Standardnormalverteilung ergibt 2Φ(1.96) − 1 ≥ 0.95. Somit erhalten wir mittels Wahl von c = 1.96 nach obiger Rechnung Pθ[T − 1.96 √ n ≤ m ≤ T + 1.96 √ n ] ≥ 95 100. Somit gilt schließlich, dass I = [T − 1.96 √ n , T + 1.96 √ n ] nach Deﬁnition ein Konﬁdenzintervall für m mit Niveau 95% ist. Was bedeutet dies genau? Stellen wir uns n Messungen zu einer physikalischen Größe vor. Man möchte zum Bei- spiel bei Raumtemperatur die Temperatur ermitteln, bei der Wasser anfängt zu kochen. Die Eigenschaften des Thermometers legen nahe, dass jede Messung durch eine normal- verteilte Zufallsvariable N (m, 1) modelliert werden kann, wobei m die Temperatur ist, bei der das Wasser anfängt zu kochen. Man führt einige Messung x1 = 99.2, x2 = 98.7, \u0005 durch. Nach n = 100 aufeinanderfolgenden Versuchen berechnest man den empirischen Durchschnitt ̂m(x) = x1+\u0005+xn n = 99.106. Das obige festgelegte Konﬁdenzintervall besagt, dass unter der Voraussetzung eines korrekten stochastischen Modells der reale Wert m mit 95%iger Wahrscheinlichkeit im obigen Intervall liegt [99.106 − 0.196, 99.106 + 0.196] = [98.910, 99.302]. Was sind die Knackpunkte? Im obigen Beispiel ist die wichtigste Beobachtung, dass die Zufallsvariable Z = √ n(T − m) für jeden Wert des unbekannten Parameters immer normalverteilt ist. All- gemein kann man Konﬁdenzintervalle für einen Parameter θ versuchen zu erhalten, in dem man zuerst einen Schätzer T für θ ermittelt. Anschließend versucht man eine Zufalls- variable der Form Z = f (T, θ) zu ﬁnden, deren Verteilung bestimmt werden kann und nicht KAPITEL 2. KONFIDENZINTERVALLE 16 von θ abhängt. Dies ist im Allgemeinen einfacher, wenn die Zufallsvariablen X1, . . . , Xn normalverteilt sind, da Operationen auf normalverteilten Zufallsvariablen gut nachvoll- ziehbar sind. Zum Beispiel haben wir oben verwendet, dass die Summe von unabhängigen normalverteilter Zufallsvariablen ebenfalls normalverteilt ist. Im nächsten Abschnitt wer- den wir neue Verteilungen einführen, welche sich aus Operationen mittels normalverteilten Zufallsvariablen ergeben. 2.2 Verteilungsaussagen In vielen Situationen ist es nützlich oder nötig, die Verteilung (unter Pθ, für jedes θ ∈ Θ oder für gewisse θ) eines Schätzers zu kennen. Exakte allgemeine Aussagen gibt es dazu nicht viele; für die Normalverteilung folgt das weiter unten in Satz 2.7. Deﬁnition 2.3. Eine stetige Zufallsvariable X heisst χ2-Verteilt mit m Freiheitsgra- den falls ihre Dichte gegeben ist durch fX(y) = 1 2 m 2 Γ( m 2 )y m 2 −1e − 1 2 y für y ≥ 0. Wir schreiben dann X ∼ χ2 m. Dabei ist die sogenannte Gamma-Funktion für v ≥ 0 deﬁniert durch Γ(v) ∶= S ∞ 0 tv−1e−tdt. Es gilt Γ(n) = (n − 1)! für v = n ∈ N. Bemerkung: Die χ2 Verteilung mit m Freiheitsgraden ist der Spezialfall einer Ga(α, λ)- Verteilung mit α = m 2 und λ = 1 2. Für m = 2 ergibt das eine Exponentialverteilung mit Parameter 1 2. Satz 2.4. Sind die Zufallsvariablen X1, . . . , Xm u.i.v. ∼ N (0, 1), so ist die Summe Y ∶= ∑ m i=1 X 2 i ∼ χ2 m. Deﬁnition 2.5. Eine stetige Zufallsvariable X heisst t-verteilt mit m Freiheitsgraden falls ihre Dichte gegeben ist durch fX(x) = Γ( m+1 2 ) √ mπΓ( m 2 ) ‰1 + x2 m ’ − m+1 2 für x ∈ R. Wir schreiben dann X ∼ tm. KAPITEL 2. KONFIDENZINTERVALLE 17 2 4 6 8 10 12 14 x 0.05 0.1 0.15 0.2 0.25 0.3 f HxL Graphische Darstellung der Dichten von Chiquadrat - Verteilungen mit Anzahl der Freiheitsgrade Hvon oben nach untenL n = 1, 3, 5, 10 Abbildung 2.1: Graphische Darstellung der Dichten von χ2-Verteilungen mit Anzahl der Freiheitsgrade (von oben nach unten) m = 1, 3, 5, 10. KAPITEL 2. KONFIDENZINTERVALLE 18 Bemerkung: Für m = 1 ist das eine Cauchy-Verteilung, und für m → ∞ erhält man asym- ptotisch eine N (0, 1)-Verteilung. Wie die N (0, 1)-Verteilung ist die t-Verteilung symme- trisch um 0; sie ist aber langschwänziger (d.h. ihre Dichte geht langsamer gegen 0, wenn das Argument gegen ±∞ geht), und zwar umso mehr, je kleiner m ist. Satz 2.6. Sind X und Y unabhängig mit X ∼ N (0, 1) und Y ∼ χ2 m, so ist der Quotient Z ∶= X ¼ 1 m Y t-verteilt mit m Freiheitsgraden. -4 -2 2 4 x 0.1 0.2 0.3 0.4 f HxL Graphische Darstellung der Dichten von t - Verteilungen mit Anzahl der Freiheitsgrade Hvon unten nach obenL n = 1, 3, 5, 10, 100 Graphische Darstellung der Dichten von t-Verteilungen mit Anzahl der Freiheitsgrade (von unten nach oben) m = 1, 3, 5, 10, 100. 2.3 Normal mit σ und m unbekannt Für normalverteilte Stichproben hat man exakte Aussagen; wir werden das auch bei der Diskussion von Tests später noch ausgiebig benutzen. Wir erinnern an die Notationen X n = 1 n n Q i=1 Xi, S2 = 1 n − 1 n Q i=1(Xi − X n)2 KAPITEL 2. KONFIDENZINTERVALLE 19 für das Stichprobenmittel und die Stichprobenvarianz. Satz 2.7. Seien X1, . . . , Xn i.i.d. ∼ N (µ, σ2). Dann X n und S2 sind unabhängig. Beweis. Siehe [Rice, Abschnitt 6.3]. Beispiel (Strausseneier): Die Australier Mr. Smith und Dr. Thurston streiten sich noch immer über das Gewicht von Strausseneiern. Sie haben von ihrer Afrikareise n = 8 Eier mitgebracht, deren Gewichte (in g) 1090, 1150, 1170, 1080, 1210, 1230, 1180, 1140 betragen. Diese Daten fassen sie auf als Realisationen von Zufallsvariablen X1, . . . , Xn, die alle unter Pθ i.i.d. ∼ N (µ, σ2) sind. Gesucht sind nun Konﬁdenzbereiche für die unbekannten Parameter µ und σ2. Im Gegensatz zum (ersten) Beispiel im letzten Abschnitt wird hier σ2 auch als unbekannt angenommen. Die oﬀensichtlichen Schätzer für µ und σ2 sind das Stichprobenmittel X n = 1 n ∑ n i=1 Xi und die Stichprobenvarianz S2 = 1 n−1 ∑ n i=1(Xi − X n)2. Es liegt nahe, als Konﬁdenzbereich jeweils ein Intervall um diese Schätzer herum anzusetzen, und wir machen das zuerst für µ. Machen wir den Ansatz C(X1, . . . , Xn) = [X n − \u0005, X n + \u0005\u0006, so wollen wir erreichen, dass gilt 1 − α ≤ Pθ[C(X1, . . . , Xn) ∋ θ] = Pθ\u0001[X n − \u0005, X n + \u0005] ∋ µ\u0006 = Pθ\u0001SX n − µS ≤ \u0005\u0006. Nach Satz 2.6 und Satz 2.7 ist für jedes θ ∈ Θ X n − µ S~√ n ∼ tn−1unter Pθ; also wollen wir 1 − α ≤ Pθ\u0004 W X n − µ S~√ n W ≤ \u0005 S~ √ n\t. Um ein möglichst kurzes Intervall zu erhalten, erfüllen wir diese Bedingung mit Gleich- heit, und dann brauchen wir gerade \u0005 S~√ n = tn−1,1− α 2 . KAPITEL 2. KONFIDENZINTERVALLE 20 Also erhalten wir als Konﬁdenzintervall für µ zum Niveau 1 − α C(X1, . . . , Xn) = \u0004X n − tn−1,1− α 2 S √ n, X n + tn−1,1− α 2 S √ n \t . Die konkreten Realisierungen in unserem Beispiel für 1 − α = 99% sind xn = 1156.25, s = 52.90, t7,0.995 = 3.499 und damit C(x1, . . . , xn) = [1090.81, 1221.69]. Wir sehen, dass sowohl 1100 als auch 1200 in diesem realisierten Intervall liegen. Auf- grund der vorliegenden Daten sind also beide Behauptungen (diejenige von Dr. Thurston und die von Mr. Smith) plausibel. Um ein Konﬁdenzintervall für σ2 zu konstruieren, benutzen wir die ebenfalls aus Satz [to add] bekannte Tatsache, dass 1 σ2 (n − 1)S2 = 1 σ2 n Q i=1(Xi − X n)2 ∼ χ 2 n−1unter Pθ. Also ist, mit der Notation χ2 m,γ für das γ-Quantil einer χ2 m-Verteilung, 1 − α = Pθ \u0003χ 2 n−1, α 2 ≤ 1 σ2 (n − 1)S2 ≤ χ2 n−1,1− α 2 \b = Pθ\u0004(n − 1)S2 χ 2 n−1,1− α 2 ≤ σ2 ≤ (n − 1)S2 χ 2 n−1, α 2 \t, und das Konﬁdenzintervall für σ2 zum Niveau 1 − α wird C(X1, . . . , Xn) = \u0004 (n − 1)S2 χ2 n−1,1− α 2 , (n − 1)S2 χ 2 n−1, α 2 \t. Die konkreten Realisierungen in unserem Beispiel für 1 − α = 95% sind s2 = 2798.21, χ 2 7,0.025 = 1.69, χ 2 7,0.975 = 16.01 und damit C(x1, . . . , xn) = [1223.45, 11 ′590.23]. Übersetzt für σ = √ σ2 erhalten wir als realisiertes Konﬁdenzintervall [34.98, 107.66]. ◇ Bemerkung: Im obigen Beispiel haben wir exakte Konﬁdenzintervalle erhalten, weil wir genügend genaue Verteilungsaussagen zur Verfügung haben. In allgemeinen Situationen kann man oft nur approximative Konﬁdenzintervalle mit Hilfe des zentralen Grenzwert- satzes bekommen; siehe Abschnitt 2.2. KAPITEL 2. KONFIDENZINTERVALLE 21 2.4 Approximative Konﬁdenzintervalle Einen allgemeinen approximativen Zugang liefert der zentrale Grenzwertsatz. Oft ist ein Schätzer T eine Funktion einer Summe ∑ n i=1 Yi, wobei die Yi im Modell Pθ i.i.d. sind; das einfachste Beispiel ist T = Y n = 1 n ∑ n i=1 Yi. Nach dem zentralen Grenzwertsatz ist dann für grosse n n Q i=1 Yi approximativ normalverteilt unter Pθ mit Parametern µ = nEθ[Yi] und σ2 = nVarθ[Yi]. Das kann man benutzen, um für die Ver- teilung von T approximative Aussagen zu bekommen und damit gewisse Fragen zumindest approximativ zu beantworten. Beispiel (tea tasting lady): Nehmen wir nochmals an, dass die Lady in n = 10 Versu- chen insgesamt 6 Tassenpaare richtig klassiﬁziert hat. Wie können wir dann einen Konﬁ- denzbereich für ihre Erfolgswahrscheinlichkeit bekommen? Allgemein ist in jedem Modell Pθ die Anzahl Sn der Erfolge Bin(n, θ)-verteilt, und wir suchen einen Konﬁdenzbereich für den unbekannten Parameter θ. Wir wollen den zentra- len Grenzwertsatz benutzen, um einen approximativen Konﬁdenzbereich zu bekommen. Nach dem ZGS ist S∗ n ∶= Sn − nθ »nθ(1 − θ) Approx ≈ N (0, 1)unter Pθ. Also gilt Pθ\u0004W Sn − nθ »nθ(1 − θ)W ≤ z1− α 2 \t = Pθ[SS∗ nS ≤ z1− α 2 ] ≈ 1 − α, und wir können versuchen, diese Ungleichung nach θ aufzulösen. Wir wollen also SSn − nθS ≤ z1− α 2 »nθ(1 − θ) oder (Sn − nθ)2 ≤ z2 1− α 2 nθ(1 − θ), aber das wird eher kompliziert. (Man kann die Ungleichung durch eine Gleichung ersetzen und die resultierende quadratische Gleichung für θ lösen; das ergibt mit der Abkürzung z ∶= z1− α 2 die zwei Lösungen ˆθ± = 2Sn + z2 ± ¼ (2Sn + z2)2 − 4S2 n(1 + z2 n ) 2n(1 + z2 n ) , und das resultierende approximative Konﬁdenzintervall ist dann [ˆθ−, ˆθ+].) Alternativ kann man wie folgt vorgehen: KAPITEL 2. KONFIDENZINTERVALLE 22 Methode 1: Wir gehen davon aus, dass θ(1 − θ) ≈ 1 4 ist und setzen das ein. Dann wollen wir also SSn − nθS ≤ z1− α 2 ½n 4 , und das approximative Konﬁdenzintervall für θ ergibt sich als \u0004Sn − z1− α 2 2 √ n, Sn + z1− α 2 2 √ n\t . Methode 2: Wir benutzen den ZGS, um zuerst Sn Approx ≈ N ‰θ, θ(1 − θ) n ’ zu erhalten. Im approximativen Konﬁdenzintervall für θ mit Grenzen Eθ[Sn] ± z1− α 2 ¼ Varθ[Sn] = θ ± z1− α 2√ n »θ(1 − θ) ersetzen wir dann θ durch seinen Schätzer Sn und erhalten so das “doppelt approximative” Konﬁdenzintervall \u0004Sn − z1− α 2√ n ¼ Sn(1 − Sn), Sn + z1− α 2√ n ¼ Sn(1 − Sn)\t . Für 1 − α = 95% ist z1− α 2 = 1.96. Für n = 10 und sn = 6 ergeben sich dann als Schätz- wert für θ der Wert 0.6 und die realisierten Intervalle [0.290, 0.910] mit Methode 1 und [0.296, 0.904] mit Methode 2. (Mit dem Lösen der quadratischen Gleichung erhält man das realisierte Intervall [0.3127, 0.8318].) Das zeigt zum einen, dass man mit so wenigen Daten (nicht überraschend) keine präzisen Aussagen erwarten kann, und zum anderen auch, dass die zusätzlichen Approximationen hier doch deutliche Abweichungen liefern. Hätte man stattdessen n = 100 Versuche mit sn = 60 Erfolgen, so wäre der Schätz- wert für θ unverändert 0.6. Die realisierten approximativen Konﬁdenzintervalle sind aber wesentlich enger — wir erhalten [0.502, 0.698] mit Methode 1 und [0.504, 0.696] mit Methode 2. (Das Lösen der quadratischen Gleichung liefert das realisierte Intervall [0.502, 0.691].) Hier ergeben also alle drei Ansätze sehr ähnliche Resultate. ◇ Kapitel 3 Tests Ziel: Überblick über grundlegende Ideen und Methoden sowie einige Beispiele zum Tes- ten von Hypothesen. 3.1 Null- und Alternativhypothese Ausgangspunkt ist wie im letzten Abschnitt eine Stichprobe X1, . . . , Xn. Wir betrachten wieder eine Familie von Wahrscheinlichkeiten Pθ mit θ ∈ Θ, die unsere möglichen Mo- delle beschreiben. Wie bisher kann θ ein- oder mehrdimensional sein. Wir haben schon eine Vermutung, wo in Θ der richtige (aber unbekannte) Parameter θ liegen könnte, und wollen diese mit Hilfe der Daten überprüfen (“testen”). Das Grundproblem ist also, eine Entscheidung zwischen zwei konkurrierenden Modellklassen zu treﬀen — der Nullhypo- these Θ0 ⊆ Θ und der Alternativhypothese ΘA ⊆ Θ, wobei Θ0 ∩ ΘA = g ist. Meist schreibt man das als Nullhypothese H0 ∶ θ ∈ Θ0, Alternativhypothese HA ∶ θ ∈ ΘA. Ist keine explizite Alternative speziﬁziert, so hat man ΘA = Θ c 0 = Θ…Θ0. Null- und/oder Al- ternativhypothese heissen einfach, falls Θ0 bzw. ΘA aus einem einzelnen Wert, θ0 bzw. θA, bestehen, also z.B. Θ0 = {θ0} ist; sonst heissen sie zusammengesetzt. Expliziter formu- liert ist also die Nullhypothese H0 ∶ “der wahre (aber unbekannte) Parameter θ liegt in der Menge Θ0” 23 KAPITEL 3. TESTS 24 und die Alternativhypothese HA ∶ “der wahre Parameter liegt in ΘA”. Beispiel: Tea testing lady. Eine englische Lady behauptet, bei Tee mit Milch anhand des Geschmacks unterscheiden zu können, ob zuerst die Milch oder zuerst der Tee in die Tasse eingegossen worden ist. Wie kann man überprüfen, ob das stimmen kann? Wie im letzten Abschnitt stellen wir der Lady an n Tagen die Aufgabe, zwei Tassen (je eine vom Typ 1 und Typ 2) zu klassiﬁzieren; sie soll also angeben, in welche der Tassen zuerst Milch eingegossen worden ist. Wir notieren die Ergebnisse x1, . . . , xn ∈ {0, 1} (falsch bzw. richtig klassiﬁziert) und fassen wie üblich diese Daten als Realisationen von Zufalls- variable n X1, . . . , Xn auf. Dann ist Sn = ∑ n i=1 Xi die Anzahl der korrekt klassiﬁzierten Tassenpaare. Als Modelle nehmen wir wieder an, dass die Xi unter Pθ i.i.d. ∼ Ber(θ) mit θ ∈ Θ = [0, 1] sind. Dann ist natürlich Sn ∼ Binomial(n, θ) unter Pθ, d.h. im Modell Pθ, das zu θ gehört, ist die Anzahl Sn der Erfolge binomialverteilt mit Parametern n und θ. Als Skeptiker zweifeln wir an den Fähigkeiten der Lady; wir wählen deshalb als (ein- fache) Nullhypothese H0 ∶ θ = 1 2, d.h. Θ0 = { 1 2} (“zufälliges Raten — das kann jeder”). Die (zusammengesetzte) Alternativhypothese, dass die Lady besondere Fähigkeiten hat, ist dann HA ∶ θ > 1 2 , d.h. ΘA = ‰ 1 2, 1\b. Um weiterzukommen, müssen wir nun die Entscheidungsﬁndung anhand der Daten for- malisieren. Auf das Beispiel selbst kommen wir später zurück. ◇ 3.2 Test und Entscheidung Deﬁnition 3.1. Ein Test ist ein Paar (T, K), wobei • T eine Zufallsvariable der Form T = t(X1, . . . , Xn) ist, und • K ⊆ R eine (deterministische) Teilmenge von R ist. Die Zufallsvariable T = t(X1, . . . , Xn) heisst dann Teststatistik, und K heisst kriti- schen Bereich oder Verwerfungsbereich. KAPITEL 3. TESTS 25 Gegeben seien n Beobachtungen x1 = X1(ω), . . . , xn = Xn(ω). Ein statistischer Test er- möglicht uns eine systematische Annahme oder Ablehnung der Nullhyphothese H0. Dabei berechnen wir zuerst die Teststatistik T (ω) = t(X1(ω), . . . , Xn(ω)) und gehen dann wie folgt vor Entscheidungsregel: • die Hypothese H0 wird verworfen, falls T (ω) ∈ K, • die Hypothese H0 wird nicht verworfen bzw. angenommen , falls T (ω) ∉ K. Beachte: Die Entscheidung des Tests hängt via T (ω) von der Realisierung ω ab. Weil T eine Zufallsvariable ist, ist die Menge {T ∈ K} ein Ereignis, und wir können ihre Wahrscheinlichkeit Pθ[T ∈ K] in jedem Modell Pθ betrachten. Die Entscheidung bei einem Test kann auf zwei verschiedene Arten falsch herauskom- men: 1) Bei einem Fehler 1. Art wird die Nullhypothese zu Unrecht verworfen, d.h. obwohl sie richtig ist. Das passiert für θ ∈ Θ0 und T ∈ K; deshalb heisst Pθ[T ∈ K] für θ ∈ Θ0 die Wahrscheinlichkeit für einen Fehler 1. Art. 2) Bei einem Fehler 2. Art wird die Nullhypothese zu Unrecht nicht verworfen, d.h. man akzeptiert die Nullhypothese (verwirft sie nicht), obwohl sie falsch ist. Das passiert für θ ∈ ΘA und T ~∈ K, und deshalb heisst Pθ[T ~∈ K] = 1 − Pθ[T ∈ K] für θ ∈ ΘA die Wahrscheinlichkeit für einen Fehler 2. Art. Beispiel: tea testing lady. Ein Fehler 1. Art besteht hier darin, die Nullhypothese des zufälligen Ratens abzulehnen, obwohl sie richtig ist. Anders gesagt glaubt man hier bei einem Fehler 1. Art an verborgene Fähigkeiten der Lady, obwohl ihre Ergebnisse durch zufälliges Raten entstehen (könnten). Bei einem Fehler 2. Art dagegen glaubt man nicht an die Fähigkeiten der Lady, obwohl diese durchaus vorhanden sind. ◇ 3.3 Signiﬁkanzniveau und Macht Bei der Auswahl eines geeigneten Tests ist insbesondere die Minimierung von Fehlern 1. Art entscheidend. Ein Fehler 1. Art tritt ein, falls wir H0 ablehnen (aufgrund von KAPITEL 3. TESTS 26 Pθ[T ∈ K]), obwohl H0 erfüllt ist. Wir würden somit gerne Tests benutzen, welche eine geringe Chance auf einen Fehler 1. Art aufweisen. Hierfür deﬁnieren wir das Signiﬁkanzniveau eines Test. Deﬁnition 3.2. Sei α ∈ (0, 1). Ein Test (T, K) besitzt Signiﬁkanzniveau α, falls ∀θ ∈ Θ0 Pθ[T ∈ K] ≤ α. Als zweites Ziel wollen wir zudem Fehler 2. Art vermeiden. Dies führt direkt zur Deﬁnition der Macht. Deﬁnition 3.3. Die Macht eines Tests (T, K) wird deﬁniert als folgende Funktion β ∶ ΘA → [0, 1], θ ( β(θ) ∶= Pθ[T ∈ K], Unser erstes Ziel ist wie gesagt die Minimierung Fehler 1. Art. Hierfür ﬁxieren wir einen Parameter α, und designen einen Test zum Signiﬁkanzniveau α. Als zweites Ziel wollen wir einen Fehler 2. Art vermeiden. Nachdem wir einen Test mit Signiﬁkanzniveau α gefunden haben, suchen wir nach dem Test mit der grössten Macht. Äquivalent formuliert: Minimiere die Grösse 1 − β(θ) = Pθ[T ~∈ K] für θ ∈ ΘA, also die Wahrscheinlchkeit für einen Fehler 2. Art. Das obige asymmetrische Vorgehen macht es schwieriger, die Nullhypothese zu ver- werfen als sie beizubehalten. Ein seriöser Test wird deshalb als Nullhypothese immer die Negation der eigentlich gewünschten Aussage benutzen. Gelingt es dann nämlich, das trotz der erschwerten Bedingungen zu verwerfen, so kann man viel eher zuversichtlich sein, tatsächlich einen Eﬀekt gefunden zu haben. Aus der asymmetrischen Behandlung von H0 und HA folgt auch, dass die Entscheidung bei einem Test davon abhängt, was man als Nullhypothese und was als Alternativhypo- these wählt. Es kann also passieren, dass die gleiche inhaltliche Frage zu unterschiedlichen Entscheidungen führt, wenn man bei ihrem Test Nullhypothese und Alternativhypothese vertauscht. Wir werden das später mit einem Beispiel explizit illustrieren. Wichtig: Die Entscheidung bei einem Test ist nie ein Beweis, sondern immer nur ei- ne Interpretation der Übereinstimmung zwischen Daten und vermutetem Modell. Ist T (ω) ∈ K, so wird man die Nullhypothese ablehnen und wegen der Daten nicht mehr glauben, dass θ ∈ Θ0 ist. Das kann (muss aber nicht) zur Konsequenz haben, dass man KAPITEL 3. TESTS 27 eher glaubt, dass θ ∈ ΘA ist, so dass man die Alternativhypothese für plausibler hält. Ist T (ω) ~∈ K, so wird man die Nullhypothese nicht verwerfen und sich im Glauben bestärkt fühlen, dass θ ∈ Θ0 ist. Wo aber θ tatsächlich liegt, weiss man genauso wenig wie vorher — ein Test liefert keinen Beweis! Beispiel: tea testing lady. Unter Pθ sind die Zufallsvariablen X1, . . . , Xn wieder i.i.d. ∼ Ber(θ) sowie Sn = ∑n i=1 Xi ∼ Bin(n, θ). Hypothese und Alternative sind hier H0 ∶ θ = 1 2 und HA ∶ θ > 1 2. Weil man für θ > 1 2 eher Einsen bei den Xi erwartet als für θ = 1 2, deuten viele Einsen bzw. ein grosser Wert von Sn eher auf HA als H0 hin. Ein plausibler Test könnte also die Teststatistik T = Sn und einen kritischen Bereich der Form K = (c, ∞) nehmen, d.h. man verwirft die Nullhypothese (des zufälligen Ratens), wenn die Lady viele Erfolge erzielt. Als Nullhypothese haben wir hier θ = 1 2, d.h. “keine besonderen Fähigkeiten”; wir möchten zwar an diese Fähigkeiten eigentlich gerne glauben, aber natürlich nur, wenn sie wirklich von den Daten überzeugend gestützt werden. Wie oben erklärt machen wir es der Lady also bewusst schwer, um bei einem positiven Ergebnis zuversichtlich an ihre Fähigkeiten glauben zu können. Um den kritischen Wert c zu einem Signiﬁkanzniveau α zu bestimmen, brauchen wir die Wahrscheinlichkeiten Pθ[T ∈ K] = Pθ[Sn > c] für θ = 1 2; für die Machtfunktion brauchen wir auch β(θ) = Pθ[T ∈ K] = Pθ[Sn > c] für θ > 1 2. Allgemein formuliert bedeutet das, dass wir die Verteilung der Teststatistik T unter jedem Pθ (d.h. in jedem Modell) brauchen, um solche Wahrscheinlichkeiten ausrechnen zu können. Das ist in der Regel nicht möglich; um aber zumindest das Signiﬁkanzniveau einhalten zu können, brauchen wir wenigstens die Verteilung von T unter der Nullhypo- these H0, d.h. in jedem Modell Pθ mit θ ∈ Θ0 — und wenn wir diese Verteilung nicht exakt kennen, so brauchen wir sie mindestens approximativ. Sei nun n = 10, d.h. wir lassen die Lady 10 Tage lang probieren. Die folgende Tabelle gibt dann die Binomial-Wahrscheinlichkeiten Pθ[S10 > k] für verschiedene θ und k. KAPITEL 3. TESTS 28 θ k = 7 k = 8 k = 9 k = 10 0.7 0.3828 0.1493 0.0282 0 0.6 0.1673 0.0464 0.0060 0 0.5 0.0547 0.0107 0.0010 0 Damit wir ein Signiﬁkanzniveau von α erhalten, muss P 1 2 [S10 > c] ≤ α sein. Wählen wir c = 7, so ist das Niveau α = 0.0547, also rund 5%. Auf diesem Niveau sind wir also bereit, bei 8 oder mehr Erfolgen der Lady unsere skeptische Nullhypothese zu verwerfen und an ihre Fähigkeiten zu glauben. Die Macht des Tests erhalten wir auch aus der Tabelle; z.B. ist für das gewählte c = 7 β(0.6) = P0.6[S10 > 7] = 0.1673 oder β(0.7) = 0.3828. Wir sehen also, dass 1 − β(θ) = 1 − Pθ[S10 > 7] = Pθ[S10 ≤ 7] für θ ∈ ΘA recht gross wird; der Test hat eine beträchtliche Wahrscheinlichkeit für einen Fehler 2. Art, d.h. für einen Unglauben an tatsächlich vorhandene Fähigkeiten. Das ist die Kehrseite unseres allgemeinen skeptischen Ansatzes; bei nur schwachen Indikationen (p grösser als 1 2, aber nicht sehr viel grösser) kann es durchaus vorkommen, dass wir diese Fähigkeiten zu Unrecht nicht bemerken. ◇ Bemerkung 3.4. Weil die Teststatistik T im obigen Beispiel diskret ist, kann ein vor- gegebenes Niveau α in der Regel nicht genau eingehalten werden, d.h. es ist unmöglich, einen kritischen Bereich K mit Pθ0[T ∈ K] = α zu ﬁnden. (Falls Θ0 aus mehr als nur einem einzelnen θ0 besteht, so ist das sowieso schwierig; im diskreten Fall ist das aber sogar schon für eine einfache Nullhypothese Θ0 = {θ0} ein Problem.) Einen Ausweg bietet ein sogenannter randomisierter Test. Man wählt dazu γ ∈ [0, 1] so, dass gilt γPθ0[T > c] + (1 − γ)Pθ0[T > c + 1] = α und entscheidet dann wie folgt: Ist T > c, so verwirft man H0 mit Wahrscheinlichkeit γ, d.h. H0 wird abgelehnt, falls erstens T > c gilt und zweitens eine unabhängige U(0, 1)-verteilte Zufallsvariable einen Wert ≤ γ realisiert. Im obigen Beispiel würde man so das exakte Niveau α = 5% mit c = 7 und γ = α − Pθ0[T > c + 1] Pθ0[T > c] − Pθ0[T > c + 1] = 0.893 KAPITEL 3. TESTS 29 erreichen. Im obigen Beispiel haben wir die Wahl der Teststatistik T = Sn und des kritischen Bereichs K = (c, ∞) mit Plausibilitätsargumenten motiviert. Wir wollen nun kurz einen systematischen Ansatz erklären, der in vielen Situationen zu einem optimalen Test führt. Die Idee dazu geht auf Neyman und Pearson zurück, un wird in nächste Sektion beschreibt. 3.4 Konstruktion von Tests Seien θ0 ≠ θA zwei ﬁxierte Zahlen. In diesem Abschnitt nehmen wir stets an, dass sowohl die Nullhypothese als auch die Alternativhyphothese von der einfachen Form H0 ∶ θ = θ0, HA ∶ θ = θA, ist. Ferner nehmen wir an, dass die Zufallsvariablen X1, . . . , Xn entweder diskret, oder ge- meinsam stetig unter Pθ0 und unter PθA sind. Somit ist nach Annahme auch die Likelihood- Funktion L(x1, . . . , xn; θ) für θ = θ0 und θ = θA wohldeﬁniert (Siehe Deﬁnition 1.4) Deﬁnition 3.5. Für jedes x1, . . . , xn, deﬁnieren wir den Likelihood-Quotienten durch R(x1, . . . , xn) ∶= L(x1, . . . , xn; θA) L(x1, . . . , xn; θ0) . Als Konvention setzten wir R(x1, . . . , xn) = +∞, falls L(x1, . . . , xn; θ0) = 0. Intuitiv gibt es nun direkt mehrere Aussagen. Für einen grossen Quotienten, ist der Zähler wesentlich grösser als der Nenner. Anschaulich bedeutet dies, dass die Beobachtun- gen x1, . . . , xn als Resultate im Modell PθA deutlich wahrscheinlicher sind als im Modell Pθ0. Die Daten widersprechen θ0 im Vergleich zu θA. Es liegt deshalb nahe, als Teststatistik T ∶= R(X1, . . . , Xn) und als kritischen Bereich K ∶= (c, ∞) zu wählen, wenn man θ0 gegen θA testen will. Schließlich wird gerade die Hypothese H0 verworfen, falls der Quotient R gross ist. Deﬁnition 3.6. Sei c ≥ 0. Der Likelihood-Quotienten-Test mit Parameter c ist KAPITEL 3. TESTS 30 ein Test (T, K), wobei Teststatistik und Verwerfungsbereich gegeben sind durch T = R(X1, . . . , Xn) und K = (c, ∞]. Der Likelihood-Quotienten-Test ist dann im folgenden Sinn optimal: Jeder andere Test mit kleiner Signiﬁkanzniveau hat auch kleinere Macht bzw. eine grössere Wahrschein- lichkeit für einen Fehler 2. Art. Theorem 3.7 (Neyman–Pearson-Lemma). Sei c ≥ 0. Sei (T, K) ein Likelihood- Quotienten-Test mit Parameter c und Signiﬁkanzniveau α∗ ∶= Pθ0[T > c] . Ist (T ′, K ′) ein anderer Test mit Signiﬁkanzniveau α ≤ α∗, so gilt PθA[T ′ ∈ K ′] ≤ PθA[T ∈ K]. Beweis. Siehe [Krengel, Satz 6.2]. Die obige Situation mit einfacher Hypothese und Alternative ist so speziell, dass sie in der Praxis kaum je auftritt. Die Grundidee für den Test lässt sich aber verallgemeinern und liefert in gewissen (weniger restriktiven) Situationen immer noch gute oder optimale Tests, so dass man das Vorgehen mit gutem Gewissen als einen systematischen Ansatz empfehlen kann. Wie wir in Beispielen sehen werden, sind die resultierenden Tests oft auch intuitiv sehr einleuchtend. Etwas genauer betrachtet man bei zusammengesetzten Hypothesen und Alternativen den sogenannten verallgemeinerten Likelihood-Quotienten R(x1, . . . , xn) ∶= supθ∈ΘA L(x1, . . . , xn; θ) supθ∈Θ0 L(x1, . . . , xn; θ) oder auch ˜R(x1, . . . , xn) ∶= supθ∈ΘA∪Θ0 L(x1, . . . , xn; θ) supθ∈Θ0 L(x1, . . . , xn; θ) und wählt als Teststatistik T0 ∶= R(X1, . . . , Xn) bzw. ˜T ∶= ˜R(X1, . . . , Xn) mit kritischem Bereich K0 ∶= (c0, ∞). Durch Umformen erhält man daraus oft einen äquivalenten, aber einfacheren Test (T, K) von einer leicht anderen Form; siehe Beispiele. Die Konstante c0 bzw. den Bereich K muss man dabei noch so wählen, dass der Test ein in der Regel a priori gewähltes Signiﬁkanzniveau einhält. Beispiel: tea tasting lady. KAPITEL 3. TESTS 31 Im Modell Pθ sind X1, . . . , Xn i.i.d. ∼ Be(θ); die Gewichtsfunktion eines Xi unter Pθ ist also pX(xi; θ) = θxi(1 − θ)1−xi, und damit wird die Likelihood-Funktion L(x1, . . . , xn; θ) = n M i=1 pX(xi; θ) = θ∑n i=1 xi(1 − θ) n−∑ n i=1 xi. Der Likelihood-Quotient ist also R(x1, . . . , xn; θ0, θA) = L(x1, . . . , xn; θA) L(x1, . . . , xn; θ0) = ‰ θA θ0 ’ ∑n i=1 xi ‰ 1 − θA 1 − θ0 ’ n−∑ n i=1 xi = „ θA(1 − θ0) θ0(1 − θA)‚ ∑ n i=1 xi ‰ 1 − θA 1 − θ0 ’ n . Nun ist ja θ0 = 1 2 und θA > 1 2, also θ0 < θA. Damit ist θA(1 − θ0) θ0(1 − θA) = θA − θ0θA θ0 − θ0θA > 1, und damit ist R(x1, . . . , xn; θ0, θA) genau dann gross, wenn der Exponent ∑ n i=1 xi gross ist. Statt des komplizierten Quotienten wählen wir als Teststatistik also T ∶= n Q i=1 Xi = Sn, und der kritische Bereich “Quotient gross” hat die äquivalente Form “Summe (= Exponent) gross”, also K ∶= (c, ∞). Also liefert hier der Neyman–Pearson-Ansatz genau das Testverfahren, das wir oben schon aufgrund von Plausibilitätsargumenten benutzt haben. ◇ Beispiel: Seien X1, . . . , Xn unter Pθ i.i.d. ∼ N (µ, σ2) mit bekannter Varianz σ2; der unbekannte Parameter ist hier also θ = µ ∈ R. Die Dichtefunktion von Xi ist fX(xi; θ) = 1 σ√ 2π exp ‰−(xi − θ)2 2σ2 ’ , die Likelihood-Funktion ist L(x1, . . . , xn; θ) = n M i=1 fX(xi; θ) = (2πσ2)− n 2 exp „ − 1 2σ2 n Q i=1(xi − θ) 2‚, KAPITEL 3. TESTS 32 und der Likelihood-Quotient wird R(x1, . . . , xn; θ0, θA) = L(x1, . . . , xn; θA) L(x1, . . . , xn; θ0) = exp „ − 1 2σ2 − n Q i=1(xi − θA)2 − n Q i=1(xi − θ0) 2‘‚ = const.(σ, θ0, θA) exp „ 1 σ2 (θA − θ0) n Q i=1 xi‚. Betrachten wir nun die Hypothese H0 ∶ θ = θ0 und die Alternative HA ∶ θ = θA. Der obige Quotient wird tendenziell gross, falls der Exponent (θA − θ0) ∑ n i=1 xi gross ist. Was das für ∑ n i=1 xi bedeutet, hängt vom Vorzeichen von θA − θ0 ab. In jedem Fall wählen wir als Teststatistik T ′ ∶= n Q i=1 Xi. Ist θA > θ0, so ist θA −θ0 > 0, und der Exponent wird dann gross, wenn T ′ gross ist; hier wählen wir den kritischen Bereich also von der Form K ′ > ∶= (c′ >, ∞), d.h. wir lehnen H0 ab, wenn T ′ gross ist. Ist θA < θ0, so ist θA − θ0 < 0 und der Exponent gross für T ′ klein (d.h. negativ). Hier ist also der kritische Bereich von der Form K ′ < ∶= (−∞, c′ <). In beiden Fällen müssen wir den kritischen Bereich, d.h. hier konkret die Konstanten c′ > bzw. c′ <, noch so festlegen, dass der Test ein gewähltes Signiﬁkanzniveau α einhält. Wir wollen also Pθ0[T ′ ∈ K ′] ≤ α erreichen, und um diese Wahrscheinlichkeit zu berechnen, brauchen wir die Verteilung der Teststatistik T ′ unter Pθ0, d.h. unter der Hypothese H0. Im vorliegenden Fall ist das einfach. Unter jedem Pθ sind die Xi i.i.d. ∼ N (θ, σ2); also ist die Summe T ′ = n Q i=1 Xi ∼ N (nθ, nσ2) unter Pθ. Äquivalent ist T = X n − θ σ~√ n ∼ N (0, 1) unter Pθ, und wir können T statt T ′ als Teststatistik benutzen. Man beachte, dass T im Modell Pθ mit θ ∈ Θ0, d.h. mit θ = θ0, also unter der Hypo- these H0, tatsächlich berechenbar ist: die Varianz σ2 ist nach Annahme bekannt, und der zu testende Erwartungswert θ0 ist natürlich auch bekannt. (Dasselbe gilt auch für T ′; die Verteilung von T unter der Nullhypothese H0 ist aber einfacher als diejenige von T ′.) ◇ KAPITEL 3. TESTS 33 Das obige Beispiel zeigt den letzten Schritt, den wir allgemein noch machen müssen. Um den kritischen Bereich K passend zum gewünschten Niveau α festlegen zu können, brauchen wir die Verteilung der Teststatistik T unter der Hypothese H0, d.h. in jedem Modell Pθ mit θ ∈ Θ0. Falls wir diese Verteilung(en) nicht exakt kennen, so ist es wichtig, zumindest eine gute Approximation zu haben. 3.5 Beispiele In diesem Abschnitt illustrieren wir die obigen Überlegungen durch einige Beispiele. Dabei verzichten wir weitgehend auf Herleitungen und präsentieren nur die Ergebnisse mehr oder weniger in der Form von “Kochrezepten”. Beispiel: Normalverteilung, Test für Erwartungswert bei bekannter Varianz: Dieser Test ist unter dem Namen z-Test bekannt. Hier sind X1, . . . , Xn i.i.d. ∼ N (θ, σ2) unter Pθ mit bekannter Varianz σ2, und wir wollen die Hypothese H0 ∶ θ = θ0 testen. Mögliche Alternativen HA sind θ > θ0 oder θ < θ0 (einseitig), oder θ ~= θ0 (zweiseitig). Welche der Alternativen sinnvoll ist, hängt von der konkreten Fragestellung ab. Die Teststatistik hier ist in jedem Fall (siehe letztes Beispiel im Abschnitt 3.4) T ∶= X n − θ0 σ~√ n ∼ N (0, 1)unter Pθ0. Der kritische Bereich K ist von der Form (c>, ∞) für den einseitigen Test gegen die Alternative HA ∶ θ > θ0, bzw. (−∞, c<), bzw. (−∞, −c~=) ∪ (c~=, +∞). Im zweiseitigen Fall verwirft man H0 also zugunsten der Alternative HA ∶ θ ~= θ0, falls ST S > c~= ist. Die Konstanten c>, c<, c~= bestimmt man zum gewählten Niveau mit Hilfe der Verteilung von T unter Pθ0. Zum Beispiel liefert die Bedingung α = Pθ0[T ∈ K>] = Pθ0[T > c>] = 1 − Pθ0[T ≤ c>] = 1 − Φ(c>), dass c> = Φ−1(1 − α) =∶ z1−α das sogenannte (1 − α)-Quantil der N (0, 1)-Verteilung sein muss; für θ > θ0 verwirft man also H0, falls X n > θ0 + z1−α σ √ n ist. Analog ist c< = zα = −z1−α und c~= = z1− α 2 , wobei wir die Symmetrie der N (0, 1)- Verteilung ausnutzen; es gilt nämlich α = Pθ0[T < c<] = Pθ0[T > −c<]für −c< = z1−α KAPITEL 3. TESTS 34 und α = Pθ0[T ∈ K~=] = Pθ0[T < −c~=] + Pθ0[T > c~=] = Φ(−c~=) + 1 − Φ(c~=) = 2›1 − Φ(c~=)”. Die benötigten Quantile ﬁndet man in einer Tabelle für die Standard-Normalverteilung; dort ist die Funktion z ( Φ(z) tabelliert, so dass man in der Tabelle bei den Ergebnissen den Wert 1 − α suchen und dann zurück zu Φ−1(1 − α) = z1−α gehen kann. Alternativ ﬁndet man Quantile der Standard-Normalverteilung oft auch in Tabellen der t-Verteilung für Anzahl der Freiheitsgrade n = ∞. Beispiel: Strausseneier Die Australier Mr. Smith und Dr. Thurston streiten sich über das Durchschnittsge- wicht von Strausseneiern. Beide sind damit einverstanden, das Gewicht approximativ als normalverteilt aufzufassen; Mr. Smith behauptet aber, das mittlere Gewicht sei 1100g, während Dr. Thurston darauf besteht, dass die Eier schwerer seien, und zwar im Schnitt 1200g. Um ihren Streit beilegen zu können, reisen die beiden nach Afrika, um in der Sa- vanne Strausseneier zu suchen. Weil diese aber meistens gut versteckt sind, ﬁnden sie nur acht, und zwar mit folgenden Gewichten (in g): 1090, 1150, 1170, 1080, 1210, 1230, 1180, 1140. Dr. Thurston schlägt nun vor, Mr. Smiths Behauptung als Hypothese µ = µ0 = 1100 gegen seine Alternative µ > 1100 (oder auch µ = 1200) auf dem 5%-Niveau zu testen. Die Varianz σ2 ist beiden bekannt; sie beträgt (in g) σ = 55. Also berechnet Dr. Thurston xn = 1 n n Q i=1 xi = 1156.25 und sucht in der Tabelle z1−α = z0.95 = 1.645. Damit ist TTh(ω) = xn − µ0 σ~ √ n = √ 8 × 1156.25 − 1100 55 = 2.89. Wegen TTh(ω) > z0.95 wird also die Hypothese µ = 1100 auf dem 5%-Niveau verworfen. Mr. Smith kommt sich bei diesem Vorgehen benachteiligt vor und macht deshalb den Gegenvorschlag, doch besser Dr. Thurstons Behauptung als Hypothese µ = µ1 = 1200 gegen seine Alternative µ < 1200 (oder auch µ = 1100) zu testen. Er berechnet deshalb TSm(ω) = xn − µ1 σ~ √ n = √ 8 × 1156.25 − 1200 55 = −2.25. Wegen zα = z0.05 = −z0.95 = −1.645 ist TSm(ω) < z0.05; also wird auch die Hypothese µ = 1200 auf dem 5%-Niveau verworfen. KAPITEL 3. TESTS 35 Dieses Beispiel illustriert sehr schön die Bedeutung der Wahl von Hypothese und Alternative und auch ihre asymmetrische Behandlung. Mit dem ersten Test würde man Dr. Thurston Recht geben, mit dem zweiten hingegen Mr. Smith — und das bei völlig identischen Daten. ◇ Beispiel: Normalverteilung, Test für Erwartungswert bei unbekannter Varianz: Dieser Test ist unter dem Namen t-Test bekannt. Hier sind X1, . . . , Xn i.i.d. ∼ N (µ, σ2) unter PÐ→ θ , wobei Ð→ θ = (µ, σ2) und insbesondere die Varianz σ2 unbekannt ist. Wir wollen wieder die Hypothese µ = µ0 testen. Genaugenommen ist das eine zusammengesetzte Hypothese, weil der Parameter Ð→ θ aus den zwei Komponenten µ und σ2 besteht. Explizit wäre also Θ0 = {µ0} × (0, ∞) = { Ð→ θ = (µ, σ2) ∶ µ = µ0}. Die Teststatistik ist hier T ∶= X n − µ0 S~√ n ∼ tn−1unter Pθ0; wir ersetzen also die unbekannte Varianz durch den Schätzer S2 = 1 n − 1 n Q i=1(Xi − X n)2 für σ2 und nutzen die Verteilungsaussagen aus Satz ?? aus. Der kritische Bereich hat (je nach Alternative) eine der drei Formen aus dem letz- ten Beispiel; die kritischen Werte hier sind c> = tn−1,1−α, bzw. c< = tn−1,α = −tn−1,1−α, bzw. c~= = tn−1,1− α 2 . Hier bezeichnen wir mit tm,γ das sogenannte γ-Quantil einer tm-Ver- teilung, d.h. denjenigen Wert tm,γ, für den gilt P [X ≤ tm,γ] = γ für X t-verteilt mit m Freiheitsgraden, d.h. X ∼ tm. Diese Werte ﬁndet man in Tabellen. ◇ Beispiel: Strausseneier Mr. Smith und Dr. Thurston fragen sich, ob sie bei ihrem ersten Versuch vielleicht eine falsche Information über die Varianz von Strausseneiern benutzt haben. Sie beschliessen deshalb, ihre Tests nochmals ohne die Annahme einer bekannten Varianz durchzuführen, und kommen damit zu einem t-Test. Dr. Thurston beharrt immer noch darauf, die Hypothese µ = 1100 gegen die Alternative µ > 1100 auf dem 5%-Niveau zu testen. Weil die Varianz σ2 nun aber unbekannt ist, berechnet er s2 = n n − 1 „ 1 n n Q i=1 x2 i − (xn) 2‚ = 2798.21, also s = 52.90; t7,0.95 = 1.895. KAPITEL 3. TESTS 36 Damit erhält er als Wert für die Teststatistik ˜TTh(ω) = xn − µ0 s~ √ n = √ 8 × 1156.25 − 1100 52.90 = 3.008. Wegen ˜TTh(ω) > t7,0.95 wird also die Hypothese µ = 1100 auf dem 5%-Niveau wieder verworfen. Nicht überraschend ist Mr. Smith mit diesem Vorgehen immer noch nicht einverstan- den und will lieber Dr. Thurstons Behauptung als Hypothese µ = µ1 = 1200 gegen seine Alternative µ < 1200 (oder auch µ = 1100) testen. Er berechnet deshalb ˜TSm(ω) = xn − µ1 s~ √ n = √ 8 × 1156.25 − 1200 52.90 = −2.339. Wegen tn−1,α = t7,0.05 = −t7,0.95 = −1.895 ist TSm(ω) < −t7,0.95; also wird auch die Hypothese µ = 1200 auf dem 5%-Niveau verworfen — und damit sind die beiden wieder gleich weit wie vorher. ◇ Die obigen zwei Tests heissen auch Einstichproben-Tests, weil man nur Daten aus einer Stichprobe hat. Bei Zweistichproben-Tests geht man aus von Zufallsvariable n X1, . . . , Xn und Y1, . . . , Ym, die unter Pθ alle unabhängig sind; zudem sind die Xi und die Yj unter Pθ jeweils für sich betrachtet i.i.d. Beispiel: Gepaarter Zweistichproben-Test bei Normalverteilung: Hier sind X1, . . . , Xn i.i.d. ∼ N (µX, σ2) und Y1, . . . , Yn i.i.d. ∼ N (µY , σ2) unter Pθ; insbesondere ist m = n und die Varianz σ2 bei beiden Stichproben dieselbe. Eine solche Situation tritt auf, wenn z.B. eine Gruppe von Personen zwei verschiedene Dinge ausprobiert, so dass man eine natürliche Paarbildung zwischen den Xi und Yi hat. In dieser Situation kann man Tests über den Vergleich von µX und µY auf den Fall nur einer Stichprobe zurückführen; die Diﬀerenzen Zi ∶= Xi − Yi sind nämlich unter Pθ i.i.d. ∼ N (µX − µY , 2σ2). Damit kann man die bisherigen Tests in leicht angepasster Form benutzen, sowohl für bekannte wie für unbekannte Varianz σ2. Die resultierenden Tests heissen dann nicht überraschend gepaarter Zweistichproben-z-Test (bei bekanntem σ2) bzw. gepaarter Zweistichproben-t-Test (bei unbekanntem σ2). ◇ Bemerkung 3.8. Wir haben oben angenommen, dass Xi und Yi unabhängig sind. Allge- meiner kann man annehmen, dass die Paare (Xi, Yi), i = 1, . . . , n, unter Pθ unabhängig sind mit einer zweidimensionalen Normalverteilung mit Erwartungswerten µX, µY , be- kannten gleichen Varianzen σ2 und bekannter Korrelation ϱ ∈ (−1, +1). (Der Fall ϱ = 0 ent- KAPITEL 3. TESTS 37 spricht Unabhängigkeit.) Dann sind die Zi = Xi−Yi unter Pθ i.i.d. ∼ N (µX −µY , 2(1−ϱ)σ2), und man kann wie oben die bisherigen Tests benutzen. Beispiel: Ungepaarter Zweistichproben-Test bei Normalverteilung: Hier sind un- ter Pθ X1, . . . , Xn i.i.d. ∼ N (µX, σ2) und Y1, . . . , Ym i.i.d. ∼ N (µY , σ2), wobei die Varianz in beiden Fällen dieselbe ist, aber m ~= n sein kann. Will man einen Vergleich über µX und µY hier testen, so kann man nicht mehr paarweise Diﬀerenzen bilden. Diesen Test muss man auch benutzen, falls zufällig m = n ist, aber die Daten nicht natürlich gepaart sind. Wir nehmen immer noch an, dass X1, . . . , Xn und Y1, . . . , Ym unabhängig sind. a) Ist σ2 bekannt, so ist die Teststatistik T ∶= (X n − Y m) − (µX − µY ) σ¼ 1 n + 1 m ∼ N (0, 1) unter jedem Pθ. Dabei ist σ nach Annahme bekannt, und µX − µY muss sich aus der ge- wünschten Hypothese H0 als bekannt ergeben. Die kritischen Werte für den Verwerfungs- bereich sind wie oben geeignete Quantile der N (0, 1)-Verteilung, je nach Alternative. Das ist der ungepaarte Zweistichproben-z-Test. b) Ist σ2 unbekannt, so brauchen wir zuerst die beiden empirischen Varianzen S2 X ∶= 1 n − 1 n Q i=1(Xi − X n)2, S2 Y ∶= 1 m − 1 m Q j=1(Yj − Y m) 2. Mit S2 ∶= 1 m + n − 2›(n − 1)S2 X + (m − 1)S2 Y ” = 1 m + n − 2 „ n Q i=1(Xi − X n)2 + m Q j=1(Yj − Y m) 2‚ ist dann die Teststatistik T ∶= (X n − Y m) − (µX − µY ) S¼ 1 n + 1 m ∼ tn+m−2 unter jedem Pθ. Der Rest geht dann analog wie oben. Dieser Test heisst ungepaarter Zweistichproben-t-Test. ◇ KAPITEL 3. TESTS 38 Die meisten bisherigen Beispiele für Tests gehen von der Annahme normalverteilter Stichproben aus; diese Situation ist sehr angenehm, weil man dann die Verteilung der Teststatistik einfach in expliziter Form hat. Diese Tests sind sehr gut, falls man tatsächlich Normalverteilungen hat; ist das aber nicht der Fall, so verlieren sie sehr schnell einen grossen Teil ihrer Macht. Deshalb ist es gut, auch alternative Tests zu kennen, die von weniger speziﬁschen Annahmen ausgehen. 3.6 Der p-Wert Sei X1, . . . , Xn eine Stichprobe vom Umfang n. Wir wollen eine Hypothese H0 ∶ θ = θ0 gegen eine Alternativhypothese HA ∶ θ ∈ ΘA testen. Deﬁnition 3.9 (Geordnete Testsammlung). Sei T eine Teststatistik. Eine Familie von Tests (T, (Kt)t≥0) heisst geordert bzgl. T falls Kt ⊂ R und s ≤ t Ô⇒ Ks ⊃ Kt gilt. Typische Beispiele sind Kt = (t, ∞) (rechtsseitiger Test), Kt = (−∞, −t) (linksseitiger Test) der Kt = (−∞, −t) ∪ (t, ∞) (beidseitiger Test). Deﬁnition 3.10. Sei H0 ∶ θ = θ0 eine einfache Nullhypothese. Sei (T, Kt)t≥0 eine geordnete Familie von Test. Der p-Wert ist deﬁniert als Zufallsvariable p-Wert = G(T ), wobei G ∶ R+ → [0, 1] mittels G(t) = Pθ0[T ∈ Kt] deﬁniert ist. Anmerkungen: • Der P-Wert ist als Funktion einer Teststatistik T selbst eine Zufallsvariable. • Der P-Wert hängt direkt von den anfänglichen Beobachtungen X1, . . . , Xn ab. Somit wird das Wiederholen des Test auch einen neuen (zufälligen) P-Wert generieren. • Der p-Wert liegt stets in [0, 1]. Sei T stetig ist und Kt = (t, ∞), dann kann gezeigt werden, dass der P-Wert unter Pθ0 auf [0, 1] gleichverteilt ist. KAPITEL 3. TESTS 39 • Der P-Wert liefert uns die Information, welche Tests in unserer Familie (T, Kt), t ≥ 0 die Nullhypothese H0 ablehnen würden. Für einen P-Wert mit Wert p gilt, dass alle Tests mit Signiﬁkanzniveau α > p die Nullhypothese H0 verwerfen würden und alle Tests mit Signiﬁkanzniveau α ≤ p die Nullhypothese H0 nicht verwerfen würden. • Der P-Wert ist nur von der Nullhypothese abhängig. Die Alternativhypothese spielt keine Rolle in der Deﬁnition des P-Werts. Intuition: Sei Kt = (t, ∞) und nehme an, dass T ∼ Exp(1) unter Pθ0 gilt. Somit gilt nach obiger Deﬁnition G(t) = e−t. Für grosse t ist dies gerade die Wahrscheinlichkeit, dass die Teststatistik ünnatürlich\"gross ist. Nehmen wir also an, dass wir aus gegebenen Daten T (ω) = 1000 erhalten. Unter der Nullhypothese H0, ist die Wahrscheinlichkeit für solch einen grossen Wert sehr gering. Dies legt das Verwerfen von H0 nahe. Der P-Wert signalisiert somit das Folgende: Falls T ungewöhnlich grosse Werte (unter Pθ0) annimmt, dann ist der p-Wert G(T ) sehr klein. Nehmen wir zum Beispiel p = 0.01, dann würden alle Tests Signiﬁkanzniveaus strikt grosser als 0.01 bereits die Nullhyphothese verwerfen. Zusammenfassend kann man sagen, p-Wert ist klein Ô⇒ H0 wird wahrscheinlich verworfen. Umgekehrt muss man mit der Interpretation des p-Wertes mehr als bei einem Test aufpassen; beispielsweise ist die “Aussage” “der p-Wert ist die Wahrscheinlichkeit, dass die Hypothese richtig ist” völlig falsch, denn der p-Wert ist eine Zufallsvariable, während die Hypothese mit Si- cherheit entweder richtig oder falsch ist (wir wissen einfach nicht, welches von beidem der Fall ist). Zudem kann man mit unüberlegtem oder systematischem Wiederholen von Experimenten den p-Wert deutlich verfälschen. Ein Vorteil des p-Wertes ist, dass viele Statistik-Pakete direkt einen p-Wert berechnen. Zudem hat man etwas mehr Information als nur die reine Testentscheidung — der p-Wert gibt eine Indikation dafür, wie weit der Wert der Teststatistik im kritischen Bereich liegt oder nicht. Beispiel: KAPITEL 3. TESTS 40 Wir werfen eine Münze 100 Mal und beobachten dabei 60 Mal Kopf. Ist diese Münze fair? Unser Modell ist, dass X1, . . . , Xn unter Pθ i.i.d. ∼ Be(θ) mit θ ∈ Θ = [0, 1] sind. Als Hypothese wählen wir dann H0 ∶ θ = 1 2, also Θ0 = { 1 2}, und die Alternative ist HA ∶ θ ≠ 1 2, also ΘA = [0, 1]…{ 1 2}. Die (zufällige) Anzahl der Erfolge in den n Versuchen ist Sn = ∑n i=1 Xi, und es gilt Sn ∼ Bin(n, θ) unter Pθ. Um vernünftig rechnen zu können, approximieren wir die Binomialverteilung gemäss dem zentralen Grenzwertsatz durch eine Normalverteilung: es gilt für jedes θ ∈ Θ, dass Sn Approx ≈ N ›nθ, nθ(1 − θ)”unter Pθ und damit T ′ ∶= Sn − nθ »nθ(1 − θ) Approx ≈ N (0, 1)unter Pθ. Für θ = θ0 = 1 2 ist also T = Sn − n~2 »n~4 = 2Sn − n √ n Approx ≈ N (0, 1)unter Pθ0. Für einen Test wählen wir nun den kritischen Bereich von der symmetrischen Form K ∶= (−∞, −c) ∪ (+c, +∞), d.h. wir verwerfen H0 für ST S > c; dabei wählen wir K sym- metrisch, weil die approximative Verteilung von T unter Pθ0 symmetrisch ist. Wollen wir die Bedingung Pθ0[T ∈ K] ≤ α für ein gegebenes Niveau α möglichst scharf (approxima- tiv) erfüllen, so fordern wir Gleichheit; dann brauchen wir also wegen der approximativen Symmetrie der Verteilung von T unter Pθ0 α = Pθ0[T ∈ K] = Pθ0[ST S > c] ≈ 2Pθ0[T > c] ≈ 2›1 − Φ(c)”, und daraus ergibt sich c ≈ Φ−1 ‰1 − α 2 ’ = z1− α 2 = 2.576für α = 1%. Wir verwerfen also die Hypothese H0 einer fairen Münze für ST S > c, und zurückübersetzt passiert das für Sn > 62.88 oder Sn < 37.12. Also glauben wir auf dem 1%-Niveau nicht an eine faire Münze, sofern wir mindestens 63 oder höchstens 37 Erfolge beobachten. Den realisierten approximativen p-Wert berechnen wir hier als p-Wert(ω) = Pθ0[ST S > t0]Tt0=T (ω) ≈ 2Pθ0[T > t0]Tt0=T (ω) ≈ 2›1 − Φ(t0)”Tt0=T (ω). KAPITEL 3. TESTS 41 Wegen T (ω) = 2Sn(ω) − n √ n = 120 − 100 10 = 2 ist also p-Wert(ω) ≈ 2›1 − Φ(2)” = 2(1 − 0.97725) = 0.0455. Bei 60 Erfolgen verwerfen wir die Hypothese einer fairen Münze also auf dem 5%- Niveau, aber (wie oben gesehen) nicht auf dem 1%-Niveau. ◇ 3.6.1 Zusammenfassung zu Tests Zum Abschluss dieses Abschnitts fassen wir das allgemeine Vorgehen bei Tests noch einmal kurz zusammen. Man hat die folgenden 5 Schritte: 1) Wahl des Modells. 2) Formulierung von Hypothese und Alternative. 3) Bestimmung der Teststatistik T und der Form des kritischen Bereichs K; das kann aus einer Herleitung via verallgemeinerten LQ-Test oder direkt aus einem Statistik- Buch stammen. 4) Festlegung des Niveaus α liefert (die Grenze für) den kritischen Bereich K; dazu braucht man die Verteilung von T unter Pϑ für alle ϑ ∈ Θ0 (exakt oder approximativ). 5) Berechnen der Teststatistik T (ω) aus den Daten; ist T (ω) ∈ K, so wird die Hypo- these abgelehnt, andernfalls wird die Hypothese nicht verworfen. 5′) Berechnen von Teststatistik T (ω) und entsprechendem realisiertem p-Wert(ω) aus den Daten; ist letzterer ≤ α, so wird die Hypothese abgelehnt, andernfalls nicht. Literaturverzeichnis [Bronstein et al.] I. N. Bronstein, K. A. Semendjajew, G. Musiol, H. Mühlig, “Taschen- buch der Mathematik”, 4. Auﬂage, Harri Deutsch (1999) [Krengel] U. Krengel, “Einführung in die Wahrscheinlichkeitstheorie und Statistik”, 8. Auﬂage, Vieweg (2005) [LSW21] J. Lengler, A. Steger, and E. Welzl, Algorithmen und Wahrscheinlichkeit, 2021. [Lehn, Wegmann] J. Lehn, H. Wegmann, “Einführung in die Statistik”, 4. Auﬂage, Teub- ner (2004) [Rice] J. A. Rice, “Mathematical Statistics and Data Analysis”, second edition, Duxbury Press (1995) [Sch10] M. Schweizer, Wahrscheinlichkeit und Statistik, 2010. [Stahel] W. A. Stahel, “Statistische Datenanalyse. Eine Einführung für Naturwissenschaft- ler”, 2. Auﬂage, Vieweg (1999) [Williams] D. Williams, “Weighing the Odds. A Course in Probability and Statistics”, Cambridge University Press (2001) 48","libVersion":"0.5.0","langs":""}
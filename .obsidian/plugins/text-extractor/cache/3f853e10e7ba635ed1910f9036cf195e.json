{"path":"sem5/VLSI1/VRL/Top-Down-Digital-VLSI-Design/Appendix-B---Finite-State-Machines_2015_Top-Down-Digital-VLSI-Design.pdf","text":"APPENDIX B FINITE STATE MACHINES This chapter is divided into two major sections. Section B.1 reviews the classes of finite state machines used in electronics design and their equivalence relationships. Although this material is strongly related to automata theory — or actually part of it — no attempt is made to cover the theory since there are excellent and comprehensive textbooks on the subject. Rather, emphasis is on a number of mathematical facts relevant to hardware design that are not normally found in such references. Section B.2 then looks at finite state machines more from an implementation point of view, yet without committing to any specific technology. B.1 ABSTRACT AUTOMATA Automata theory is a mathematical discipline concerned with fundamental issues of discrete computa- tion such as formal languages and grammars, parsing, decidability and computability. The underlying formal models are crude abstractions that essentially simplify computing equipment to transduc- ers that, while changing from state to state, convert a given input string into some output string. Most issues relevant to digital design such as hardware architecture, computer arithmetics, parasitic states, state encoding, transient effects, delays, synchronization, etc. are neglected, which raises the question “Why study the abstract subject of automata theory in the context of electronics design?” The motivation is threefold: Functional specification. Describing what a digital system has to do is not always easy. Automata theory often helps to specify the relationship between a circuit’s inputs and outputs in a more formal way, especially for control- and protocol-oriented tasks. Modeling and verification. When viewed from outside, the behavior of an entire system can be mod- eled as a single finite state machine. While usually not a very efficient approach to constructing a circuit, this abstraction proves useful for verifying a system’s behavior by simulation and testing. Synthesis. Almost any practical system is composed of a number of cooperating subsystems, each of which can in turn be modeled as finite state machine. At a certain level of detail, any synchronous circuit is patterned after a specific type of automaton. 523 524 APPENDIX B FINITE STATE MACHINES “What do we mean by finite state machine then?” Deﬁnition B.1. A deterministic automaton is a system, which at discrete moments of time t = 0, T,2T,3T, ... , kT, (k + 1)T, ... satisfies the following conditions: 1. The input to the system can be chosen from a set of possible stimuli I. 2. The system subject to an input i can be in just one of a set of possible states S and does output one out of a set of possible responses O. 3. The state of the system and the input to it uniquely define the state which the system is going to assume in the next such moment of time. Throughout this text, we will stay within the framework of discrete and deterministic automata so defined. We will further limit our discussion to finite state machines (FSM) where each of the three sets I, S,and O is restricted to a finite number of elements. Please note that, in general, I, S,and O do not have the same cardinality, although they may happen to do so. B.1.1 MEALY MACHINE There is more than one way to express a behavior that conforms with the above. A first approach uses two equations o(k) = g(i(k), s(k)) (B.1) s(k + 1) = f (i(k), s(k)) (B.2) where i ∈ I, s ∈ S,and o ∈ O. g is termed output function and f transition function or next state function. In addition, at k = 0 the automaton is assumed to be in a special state s0 ∈ S which is called start state. Equations (B.1) and (B.2) together form a Mealy model. More precisely, we speak of a Mealy automaton if the present output depends on the present input. Many real-world examples are of more simple nature which gets reflected by the absence of one or more terms from (B.1)and (B.2). See section B.1.5 for a detailed classification scheme. Instead of stating transition function f and output function g as equations, any finite state machine can be completely described by listing next state and output values for any combination of present state and input. Such a list is termed a state table,see fig.B.1 for an example. The well-known state graph, aka state transition diagram, is nothing else than a pictorial representation of a state table. Each state is represented by a vertex and each transition by a directed edge. A short arrow identifies the start state. Where an input symbol causes a state to persist, i.e. to fall back on itself, a loop is drawn. So far, we have been concerned with FSM behavior exclusively, but we should also ask for a hardware structure that behaves accordingly. The result from expressing output function and transition function with a data dependency graph (DDG), is shown in fig.B.2 for a Mealy machine. As will be shown in section B.2.5, this straightforward solution is not necessarily also the most efficient one, however. B.1 ABSTRACT AUTOMATA 525 Example I ={a,b}, S ={p,q,r,t},and O ={0,1}. a/0 b/0 a/1 b/1 a/0b/1 b/0 a/1 p q t r i(k) abab s(k) o(k) s(k +1) p 10 r t q 01 p q r 10 q r t 01 r p FIGURE B.1 Mealy machine with four states. State table (left) and state graph (right). \u0002 g o(k) s(k+1)s(k) i(k) f FIGURE B.2 DDG of a Mealy automaton. B.1.2 MOORE MACHINE The Moore model differs from the Mealy model in that the present output depends on the present state exclusively; there is no input literal i(k) in output function g. As a consequence, the output is allowed to change only as a result of a state transition.1 o(k) = g(s(k)) (B.3) s(k + 1) = f (i(k), s(k)) (B.4) As shown below, the more restrictive formulation for the output function (B.3) gets reflected by omissions in the network structure, state table, and state graph of Moore automata. 1 Because state transitions are restricted to discrete moments of time kT, the Moore model is sometimes said to have a synchronous output. This interpretation commonly found in texts on automata theory abstracts from propagation delay. In practice, a Moore output will settle to its final value a couple of gate delays after the active clock edge and remain constant until the next active clock edge. 526 APPENDIX B FINITE STATE MACHINES o(k) s(k+1)s(k) i(k) f g FIGURE B.3 DDG of a Moore automaton. Example I ={a,b}, S ={u,v,w,x,y,z},and O ={0,1}. u v w x y z a b ba a b a b b a b 1 0 1 0 1 0 a i(k)a b s(k) o(k) s(k +1) u1 z w v0 z w w0 x u x0 y x y1 v y z1 y x FIGURE B.4 Moore machine with six states. State table (left) and state graph (right). \u0002 Both Mealy and Moore automata are pervasive in electronics circuits, primarily in controllers that govern sequential data processing and data exchange operations. B.1.3 MEDVEDEV MACHINE Some particular situations in electronic hardware design prohibit logic operations in the output function.2 Mathematicians use the name Medvedev to designate a subclass of Moore machines where the output function g has degenerated to the identity function.3 o(k) = s(k) (B.5) s(k + 1) = f (i(k), s(k)) 2 E.g. because of the inertial and transient effects associated with the pertaining combinational networks, see section B.2.4. Also, the direct observability and controllability of Medvedev outputs via scan path test structures is welcome in many controller applications. 3 Medvedev automata are also known as “finite acceptors” or as “automata without output” because studying state transitions alone is sufficient for many problems from automata and formal language theory. B.1 ABSTRACT AUTOMATA 527 In the context of digital circuits where state and output symbols are encoded as binary vectors, it makes sense to slightly relax this definition. We will speak of a Medvedev automaton even when state bits are dropped from the output or when state bits are duplicated in the output. State and output vectors are thus allowed to differ in cardinality as long as this is just a matter of wiring and, hence, involves no logic gates. Most counters are practical examples of Medvedev automata, see fig.B.5 for a hardware structure. o(k) s(k+1)s(k) i(k) f FIGURE B.5 DDG of a Medvedev automaton. B.1.4 RELATIONSHIPS BETWEEN FINITE STATE MACHINE MODELS Two questions of both theoretical and practical importance are “Under what conditions is it possible to replace a finite state machine by another one?\" and “How do the various classes of automata relate to each another?\" Since finite state machines can be viewed as transducers that convert some input string into some output string, the most natural way of defining functional equivalence is as follows. Deﬁnition B.2. Two automata are considered equivalent if they always yield identical strings of output symbols for any identical strings of input symbols. It is important to understand that the state graphs of equivalent automata need not be isomorphic. This is because the above definition refers to input and output quantities only. Put in other words, automata are abstracted to black boxes in the context of equivalence. Figs.B.8 and B.9, for instance, show a pair of Mealy machines that are equivalent but not isomorphic. Equivalence of Mealy and Moore machines in the context of automata theory While the above definition of equivalence works fine when comparing Mealy automata with Mealy automata or Moore automata with Moore automata, there is a technical problem when comparing machines across the two classes. A Mealy machine can respond to an input change at any time whereas the response of a Moore machine is necessarily deferred to after the next active clock edge. Put differently, Moore outputs have latency 1 and Mealy outputs latency 0. No matter what the first input i(0) looks like, the first symbol in the output string from a Moore machine is o(0) = g(s0), only later can the input affect the output. This implies that Moore automata take n + 1 computation periods to process a total of n consecutive input symbols while Mealy automata require only n periods. The number of output symbols released from the two models differ accordingly. 528 APPENDIX B FINITE STATE MACHINES As a workaround, the requirement for equivalence is relaxed as follows in the context of automata theory because that theory is primarily concerned with the mapping between symbol strings. Deﬁnition B.3. A Mealy and a Moore automaton are considered equivalent if they always yield identical strings of output symbols for any identicals string of input symbols, when the first output symbol — which is associated with the start state — is deleted from the output string of the Moore automaton. This somewhat academic understanding gives rise to a well-known result Theorem B.1. For any Mealy automaton there exists an equivalent Moore automaton in the broad sense of definition B.3, and vice versa. At first sight this may seem surprising because the output function of the Mealy model is more general than that of the Moore model. We will sketch a constructive proof, i.e. two algorithms for converting a Moore machine into an equivalent Mealy machine, and vice versa. More details can be obtained from [230], an excellent textbook on abstract automata and formal languages. Converting a Moore machine into an equivalent Mealy model is very easy. For every vertex of the state graph delete the output symbol associated with the vertex and attach it to all edges that enter that vertex. Clearly, the procedure will leave the number of states unchanged. Coming up with a Moore model for a Mealy machine cannot simply follow the inverse procedure because any attempt to assign a vertex the output symbol associated with its incoming edges must lead to a conflict unless all incoming edges agree in their outputs. Thus, whenever a conflict arises, the vertex is split into as many copies as there are distinct output symbols attached to its incoming edges. All output symbols can so be transferred from the incoming edges to their respective copy of the vertex. Each copy keeps the full set of outgoing edges attached to the original vertex. The process is repeated for the successor nodes until all vertices have been visited. Please note, that the number of states may — and often will — increase dramatically when going from a Mealy to a Moore machine. Incidentally, we conclude from the two conversion procedures that (a) for any Moore automaton there exists an equivalent Mealy automaton with a smaller or equal number of states, and (b) the above Moore- to-Mealy conversion algorithm does not, in general, lead to a solution with the minimum possible number of states. Example In the broad sense of automata theory, the two state machines described in figs.B.1 and B.4 are actually equivalent. Their respective output strings are opposed in table B.1 for two input strings chosen at random. B.1 ABSTRACT AUTOMATA 529 Table B.1 Output strings of equivalent Mealy and Moore automata compared. k 0 1 2 3 4 7 8 automaton output input a b b Mealy 1 0 0 Moore [1] 1 0 0 input b b a a b a Mealy 0 1 1 1 1 0 Moore [1] 0 1 1 1 1 0 \u0002 Equivalence of Mealy and Moore machines in the context of hardware design From an engineering point of view, the extra output symbol o(0) and the timewise offset of all subsequent symbols cannot be abstracted from. After all, few applications will tolerate replacing a finite state machine by another one the output of which lags or leads by a full clock cycle. Unless latency is indeed uncritical for the application at hand, equivalence must, therefore, be understood in the stricter sense of its original definition which implies that Theorem B.2. A Mealy automaton and a Moore automaton can never be equivalent in the more narrow sense of definition B.2. Equivalence of Moore and Medvedev machines Theorem B.3. For any Moore automaton there exists an equivalent Medvedev automaton in the more narrow sense of definition B.2, and vice versa. The proof is by showing how to build an equivalent Medvedev automaton from a Moore automaton.4 The problem with designing a Medvedev automaton is that |O|=|S| while, in general, this is not the case for Moore automata where |O|≤|S|. To get around this difficulty, we allow the state symbol to be composed of two parts, namely a left part, which we will also use as output symbol, and a right part, that will remain hidden from the outside world. In any case must their concatenation yield a unique state symbol. Note that this trick does not introduce actual logic operations into the output function and is, therefore, consistent with our definition of Medvedev automata. However, it breaks the constraint that forced O = S. The conversion algorithm works as follows. Consider the state graph of the Moore automaton. Assign every state its output symbol as left part of its state symbol. If all states are uniquely labeled, the right parts remain empty and conversion is completed since the automaton had already followed the Medvedev model in the first place. Otherwise, assign each state a right part such as to make it unique. The easiest way to do so is simply to copy the state symbols from the initial Moore automaton. When 4 The inverse transform is trivial since any Medvedev automaton is a Moore automaton by definition. 530 APPENDIX B FINITE STATE MACHINES fed with the same stimuli, the resulting automaton will always output the same responses as the Moore automaton. Perhaps a more intuitive conversion procedure is given in fig.B.6. The number of states of a Medvedev automaton so obtained is always equal to that of the original Moore model. It takes more bits to encode the wider Medvedev state symbols, though. Example The Medvedev automaton shown in fig.B.7 has been obtained from the Moore automaton of fig.B.4 by way of the constructive algorithm stated above. I ={a,b}, S ={0c,0d,0e,1c,1d,1e},and O ={0,1}. o(k) s\"(k+1)s\"(k) i(k) f \" o(k) s\"(k+1)s\"(k) i(k) s(k+1)s(k) s’(k+1)s’(k) o(k) s(k+1)s(k) i(k) g o(k) s(k+1)s(k) i(k) s(k+1)s(k) duplication of state register logic merge reordering f g f gf.... FIGURE B.6 Turning a Moore machine into an equivalent Medvedev machine. a b ba a b a b a b a b 1c 0c 1d 0d 1e 0e i(k)a b s(k) o(k) s(k +1) 1c 1 1e 0d 0c 0 1e 0d 0d 0 0e 1c 0e 0 1d 0e 1d 1 0c 1d 1e 1 1d 0e FIGURE B.7 Medvedev machine with six states. State table (left) and state graph (right). \u0002 B.1 ABSTRACT AUTOMATA 531 B.1.5 TAXONOMY OF FINITE STATE MACHINES The table below, which is patterned after a Karnaugh map, classifies deterministic automata according to what actually determines their next state and their output. Several subclasses, the fields of which are marked with special characters in table B.2, make no sense from a technical point of view. Here are the reasons why: † Unobservable automata are useless in engineering applications. ‡ There is no point in controlling a state that exerts no influence on the output. § Having the output depend on a fixed and thus effectively inexistent state makes no sense. Other subclasses have been given a name because they find widespread applications as digital function blocks. They are identified by capital letters as listed below. Table B.2 Taxonomy of finite state machines. output function g depends on input input — and state state transition — C function state A f input and state O Y depends on input D Moore model Mealy model Subclass Example YFull Mealy automaton5 Controller OFull Moore automaton5 Controller, cell of cellular automaton A Autonomous automaton Clock generator, pseudo random number generator D Delay automaton Pipeline stage (combinational logic plus register) C Combinational logic Full adder, unpipelined multiplier 5 The word “full” is meant to imply that no term has been dropped from the general equations (B.1) (B.2) and (B.3)(B.4) respectively. 532 APPENDIX B FINITE STATE MACHINES B.1.6 STATE REDUCTION Consider the state table of some finite state machine and assume that two states have exactly the same entries in their present output fields and also in their next state fields. As an example, this applies to states “7” and “10” in fig.B.8. From a graph point of view, this means their outgoing edges are labelled in exactly the same way and point to exactly the same vertices. It is intuitively clear that any two such states must appear to be the same when nothing but the machine’s inputs and outputs are observed. Deﬁnition B.4. Two states of a finite state machine are considered indistinguishable if the machine can be placed in either of the two and responds with identical strings of output symbols to any string of input symbols. Indistinguishable states are also known as equivalent states and as redundant states. Merging them has no effect on a machine’s behavior. The new automaton so obtained will necessarily be equivalent to the original one, but simpler to implement. State reduction is the process of collapsing redundant states until no equivalent state machine with a smaller number of states exists. Collapsing all states that have identical state table entries does not suffice, however, as two states can have distinct next state fields and still be perfectly indistinguishable. Theorem B.4. Two states of a finite state machine are indistinguishable iff they have (a) identical outputs and (b) go to indistinguishable successor states for any possible input symbol. The difficulty with applying this theorem to state reduction directly lies in its recursiveness. A more practical approach is the implication chart algorithm due to Paull and Unger and nicely described in [231], for instance. Luckily, there is no need for designers do that manually as automatic state reduction is part of HDL synthesis. We thus refrain from presenting algorithmic details and are content to show an FSM before and after state reduction. Example The state graph depicted in fig.B.8 has been chosen for demonstration purposes with no particular application in mind. B.1 ABSTRACT AUTOMATA 533 5 9 1011 8 2 4 3 6 7 1 00/1 11/1 01/1 10/1 00/0 01/0 10/011/0 00/0 01/0 10/0 11/0 00/0 11/0 01/0 10/0 00/0 01/0 10/0 11/0 00/0 01/0 10/011/0 01/0 10/0 11/0 01/0 10/0 11/0 00/0 01/0 10/0 00/0 11/1 00/1 11/0 10/0 01/0 11/1 00/1 00/0 10/0 01/0 i(k) 000110 11 000110 11 s(k) o(k) s(k +1) 11 1 1 1 1 1 1 2 20 0 0 0 2 8 8 3 30 0 0 0 3 5 5 4 40 0 0 0 4 5 5 2 50 0 0 0 6 5 5 9 60 0 0 0 7 11 11 3 71 0 0 1 1 1 1 1 80 0 0 0 9 8 8 6 90 0 0 0 10 11 11 4 10 1 0 0 1 1 1 11 0 0 0 0 1 11 111 FIGURE B.8 Original state machine. State table (left) and state graph (right). Systematic state reduction not only confirms (7,10) as indistinguishable states, but also reveals equivalences between (2,3,4), (5,8), and (6,9). While the new state machine shown in fig.B.9 preserves the input-to-output relationship, the number of states has dropped from 11 to 6. 5 11 2 6 7 1 00/1 11/1 01/1 10/1 00/0 01/0 10/0 11/0 00/0 01/0 10/0 11/0 01/0 10/0 00/0 11/0 10/0 01/0 11/1 00/1 00/0 10/0 01/0 11/0 i(k) 000110 11 000110 11 s(k) o(k) s(k +1) 11 1 1 1 1 1 1 2 20 0 0 0 2 5 5 2 50 0 0 0 6 5 5 6 60 0 0 0 7 11 11 2 71 0 0 1 1 1 1 1 11 0 0 0 0 1 1 1 1 FIGURE B.9 Reduced state machine. State table (left) and state graph (right). \u0002 534 APPENDIX B FINITE STATE MACHINES B.2 PRACTICAL ASPECTS AND IMPLEMENTATION ISSUES How to turn finite state machines into electronic hardware is discussed in the main text. Yet, several practical issues can be understood from a mathematical background alone. B.2.1 PARASITIC STATES AND SYMBOLS Input symbols, states, and output symbols must ultimately be encoded as binary vectors. As it takes wx ≥⌈log2|X|⌉ bits to uniquely encode the |X| elements of a set X, the code vector may assume is 2wx distinct values. This implies that 2wx −|X|≥ 0 code values exist that do not correspond to any element x ∈ X. Such unused values that result as a side effect from binary coding are termed parasitic or residual. As a consequence, a finite state machine implemented with two-valued electronics will exhibit parasitic input symbols unless 2wi =|I|, parasitic states unless 2ws =|S|, and parasitic output symbols unless 2wo =|O|. Being careful engineers, we ask ourselves “What happens if, by accident, a finite state machine is presented with some parasitic input symbol or falls into some parasitic state?”6 From a mathematical perspective, neither transition function f nor output function g are defined. In practice, the circuit logic will generate some outputs in a deterministic but unspecified way. Thus, while the designer’s intention is to build a state graph of |S| vertices each of which has an out-degree |I|,the actual result is a supergraph of 2ws vertices with out-degree 2wi that includes the original graph as a subgraph. Figure B.10 illustrates this by way of a Medvedev automaton that implements a controllable up/down counting function modulo 5. Depending on the exact characteristics of the supergraph, a physical automaton may react in various ways in response to a parasitic input symbol: The automaton may show no discernible reaction, may produce just one mistaken output symbol, may move to some regular state via a transition unplanned for, or may fall into a parasitic state. In the latter case, two different outcomes are possible: The state machine may either return to the regular subgraph after a number of clocks, or may get trapped in a dead state or in a circular path forever, a dramatic situation known as lockup condition. Fig.B.10a shows all shades of how a physical circuit can fail in response to a parasitic input. Observation B.1. In the presence of irregular conditions, parasitic states and symbols left undealt with hold the dangers of serious circuit malfunctioning and of permanent lockup. “What can the digital designer do about parasitic finite state machine behavior?” 6 Such unforeseen situations may occur as a consequence from interference, transmission errors, switching noise, poor synchronization, ionizing radiation, hot plug-in, or temporary sagging of power. B.2 PRACTICAL ASPECTS AND IMPLEMENTATION ISSUES 535 Broadly speaking, fault tolerance and graceful degradation are the goals of any engineering activity. They imply that a system confronted with irregular input data or some other form of disturbance shall • absorb it with as little impact on its internal functioning as possible, • continue to produce the most meaningful and/or least offensive output, and • confine the consequences of any temporary failure to the shortest possible time span. Example I ={h,u,d}, S ={0,1,2,3,4},and O ={0,1,2,3,4}. 0 1 23 4 u d h h u (a) (b) d h ud # h u d # h u d # d h,u,# 0 1 23 4 u d h,# h,# u d h,# ud h,# u d h,# u d # # parasitic state# parasitic input symbol parasitic transition regular stateh,u,d regular input symbol regular transition FIGURE B.10 State graph of a modulo 5 up/down counter with parasitic states and input symbols left loose (a) compared to a safer version (b). Note that (b) leaves room for further improvement. \u0002 In the context of finite state machines, five measures must contribute towards these goals. 1. Collapse all parasitic input symbols to carefully selected regular ones. 2. Make sure that all parasitic states reconverge to the original subgraph. The standard practice is to explicitly indicate a regular successor state for each parasitic state before logic synthesis is undertaken. 3. Assign inoffensive output symbols to all parasitic states. 4. Provide some means for forcing the automaton into start state s0 from any other state by adding an extra reset mechanism. Finite state machines that adhere to these guidelines are sometimes qualified as fail safe. Note that, from a mathematical point of view, measures 1. and 2. extend the domain of f and g to include all parasitic values of i and s, whereas measure 4. depends on an ancillary mechanism that is independent of f and g. In the occurrence of the above example, a safer version of the modulo 5 up/down counter is shown in fig.B.10b. Albeit at a somewhat different level of abstraction, the measure below is as important as the ones mentioned before. 536 APPENDIX B FINITE STATE MACHINES 5. Notify the next higher level in the system hierarchy, e.g. by way of an error signal or message, whenever a parasitic state or input symbol has been detected. This avoids any innocent interpretation of corrupted FSM output and makes it possible for the superordinate system levels to decide on corrective action. B.2.2 MEALY-, MOORE-, MEDVEDEV-TYPE, AND COMBINATIONAL OUTPUT BITS The fact that output symbols get encoded as binary vectors gives rise to another subtlety. Consider an automaton where a subset of the output bits depends on the present state exclusively, that is, where some of the bits do not get affected by the present input. In analogy to the classification scheme for automata, such outputs are termed Moore-type outputs with “decoded Moore-type outputs” and “unconditional outputs” being synonyms. Clearly, the state machine as a whole remains a Mealy automaton as long as there exist other output bits — called Mealy-type outputs, aka “conditional outputs” — that actually are a function of the present input as well. Similarly, a Mealy or a Moore machine may or may not include Medvedev-type outputs,aka “undecoded Moore-type outputs” and “direct outputs”. As the name suggests, such output lines are nothing else than bits tapped from the state register either in direct or in complemented form. Their switching occurs essentially aligned to the clock. Last but not least, an FSM may or may not feature combinational outputs, i.e. bits that depend on the present input exclusively. Combinational and Mealy-type outputs are sometimes subsumed as through paths; only Mealy machines can sport them. g\" Mealy-type output Moore-type output Medvedev-type output combinational outputg’ g\"’ o’(k) s(k+1)s(k) i(k) f o\"(k) o\"’(k) o\"\"(k) through path g maybe yes maybe maybe machine Mealy no yes no maybe machine Moore no yes no no machine Medvedev yes no no no logic combinational FIGURE B.11 Finite state machine with output bits broken into four subsets. Each subset depends on i(k) and s(k) in a different way and is labeled accordingly. B.2 PRACTICAL ASPECTS AND IMPLEMENTATION ISSUES 537 Being knowledgeable about output types has been found to be useful not only during circuit design, but also during logic simulation, timing analysis, and prototype testing. An example is to follow soon. B.2.3 THROUGH PATHS AND LOGIC INSTABILITY The presence of a through path in a state machine holds a serious danger. Any external circuitry that uses the FSM’s present output to determine the FSM’s present input may give rise to logic contradictions. Uncontrolled oscillations may then develop because Mealy and combinational outputs instantly respond to new input. What makes the problem particularly treacherous is that contradictions and oscillations may actually occur for a limited subset of states and input values exclusively, while the design behaves in a totally inconspicuous way in all other situations. Example Consider the control loop below, where act, ini,and dcr are integer variables and ... stands for some unspecified data manipulations. ... act := ini repeat ... act := act - dcr until act < 0 ... A possible hardware structure is depicted in fig.B.12a. A finite state machine interprets the carry/borrow bit from the ALU and controls ALU operation and data transport paths. Fig.B.12b shows the tiny portion of a Mealy-type state graph relevant to the above loop computations. The intention is to subtract dcr from act until the ALU produces a borrow. Everything works fine as long as act≥dcr. When this relation ceases to hold, however, the circuit enters an oscillatory regime caused by the mutual and contradictory dependency of op2 and borrow in a feedback loop that encompasses the ALU, the controller, and the leftmost multiplexer. This unstable condition is at all made possible by the attempt to carry out subtraction and decision making in a single clock cycle which concept differs from how a microprocessor would evaluate the above piece of code. 538 APPENDIX B FINITE STATE MACHINES Mealy-type controllerdatapath section operation borrowresult ALU 0 select signals dcr act state op1 op2 combinat. network... borrow=true / operation:=sub, op2:=0 borrow=false / operation:=sub, op2:=dcr (a) (b) FIGURE B.12 Instability in a Mealy-type controller subject to combinational feedback. Block diagram (a), portion of controller state graph (b). \u0002 Observation B.2. Instability may or may not develop in Mealy machines if the surrounding logic provides immediate feedback from the output to the input of the same machine. The existence of a zero-latency feedback path from one or more output bits of a through path to one or more input bits of the same through path is a necessary precondition for this to happen. Basically there are four options for staying clear of instability in automata: ◦ Select an automaton with non-zero latency, see table B.5. ◦ Include latency by making feedback paths start from Moore or Medvedev bits exclusively. ◦ Add a latency register to the surrounding circuitry. ◦ Formally prove that no logic instability exists in spite of the zero-latency loop. B.2.4 SWITCHING HAZARDS From our discussion of transient effects in digital circuitry, we know that almost any combinational network has the potential of developing brief unwanted pulses known as hazards. As the output function g of an FSM is no exception, both Mealy and Moore automata must be suspected to generate hazards unless one has proof to the contrary. Medvedev machines, in contrast, cannot give rise to hazards because they lack a combinational network between state register and output. Signals from any automaton can be made hazard-free by adding extra flip-flops at the output to align their switching to the clock if need be. The term registered outputs is often used to discern those bits that pass through such a resynchronization register from the normal ones that are taken from the output logic directly. Practically speaking, when hazard-free outputs are to be combined with minimum latency, one can either add a resynchronization register to a Mealy automaton or build a Medvedev machine by encoding B.2 PRACTICAL ASPECTS AND IMPLEMENTATION ISSUES 539 its state such that the output bits can be tapped from the state register directly, the conversion procedure of fig.B.6 should help. Either option also eliminates the risk of instability, see table B.5 for an overview. B.2.5 HARDWARE COSTS The costs of an FSM are given by the ws bistables that maintain its state, the logic gates for computing transition function f and output function g, plus the necessary wiring. Note that f and g share part of the logic gates in typical hardware implementations. Although the costs of these resources are not the same in a full-custom IC as in field-programmable logic (FPL), a number of observations can be made. Concurrency, hierarchy and modularity are key to efﬁciency Classical state graphs tend to explode in size even when systems of very moderate complexity are being described.7 The reasons are as follows. • State graphs are flat with no levels of abstraction, they lack any notion of hierarchy. • State graphs lack modularity, they do not distinguish between mechanisms. • State graphs cannot model concurrent activities other than by a single global state. More importantly, combinatorial explosion is also a problem for electronic hardware if a circuit is organized as one finite state machine. Beyond a certain complexity, it is much more efficient to partition the desired functionality into a bunch of smaller cooperating automata, a pattern which is sometimes also referred to as linked state machines (LSM). This not only permits one to compose state and complex behavior from many simple models, but also makes it possible to use specialized and highly efficient subcircuits for implementing subfunctions such as counters, lookup tables (LUT), en/decoders, etc. Observation B.3. While it is always possible to model a clocked sequential system as one Mealy-type automaton, a cluster of cooperating smaller automata (including counters, shift registers, etc.) is a much more efficient model for designing and verifying digital circuits. Example A synchronous circuit is to generate a binary pseudo random sequence of length 15 at a rate of 1/4 of its clock. Conceptually, what we need is an autonomous automaton with 60 states. There are two basic options. The entire functionality is either packed into a single FSM, or it is decomposed into a divide- by-4 counter plus a 4 bit linear feedback shift register (LFSR) working under control of that counter. Table B.3 shows the hardware costs. The structured approach saves 4/5 of the area when compared to a flat machine the states of which are randomly encoded. 7 A more succinct visual formalism are the statecharts proposed by David Harel [232] [233]. In a nutshell statecharts = state graphs + hierarchy + concurrency + interprocess communication Statecharts help a lot to expose orthogonalities in behavioral models. CAE tools for editing and simulating statecharts are commercially available. Most of them are capable of generating program code for microprocessors, some of them also generate HDL code for further processing by synthesis tools. Yet, competition seems to disallow companies to give credit to Harel for proposing the statechart formalism that all their tools have in common. 540 APPENDIX B FINITE STATE MACHINES Table B.3 Hardware costs of a pseudo random sequence generator organized in various ways. state ﬂip- std nets size area structure assignment ﬂops cells [GE] [Mλ2] counter & LFSR native 6 9 13 60 0.15 ﬂat Moore FSM adjacent 6 26 33 90 0.23 ”” random (typ.) 6 102 107 261 0.76 ”” one hot 60 69 130 488 1.16 \u0002 State reduction State reduction, see section B.1.6, always has the benefit of eliminating unnecessary clutter from state tables and state graphs. In most cases, state reduction also pays off in terms of circuit complexity and performance because it introduces new don’t care conditions, gives more room for finding a better state encoding, and, thereby, leads to a more economical solution. Example Table B.4 juxtaposes two standard cell implementations of the FSM specified earlier in figs.B.8 (unreduced) and B.9 (reduced). The relevant cost factor is the total area occupied after routing. Although the example is an artificial one, the figures indicate that the benefit from state reduction is mainly due to the simplification of the combinational network and not so much a matter of doing away with a flip-flop or two. Table B.4 Impact of state reduction on hardware costs for the finite state machine of fig.B.8. number state ﬂip- std nets size area of states assignment ﬂops cells [GE] [Mλ2] 11 adjacent 4 35 38 94 0.26 6 adjacent 3 14 20 44 0.12 \u0002 Observation B.4. It normally pays to eliminate redundant states from a state graph or state table prior to translating it into hardware. This need not always be true, however, since using less bits for storing a machine’s state can sometimes increase the number of terms and literals in transition and/or output functions, inflate combinational circuitry, and offset the savings obtained from using fewer bistables. B.2 PRACTICAL ASPECTS AND IMPLEMENTATION ISSUES 541 State encoding State encoding, aka state assignment, is the process of deciding on how the various states are going to be mapped onto vectors of binary digits. An obvious requirement is that each state is assigned a unique bit vector. The number of bits required for uniquely encoding |S| states is ws ≥⌈ log2|S|⌉ (B.6) where ⌈x⌉ denotes the least integer not smaller than x. We speak of minimum bit encoding when (B.6) is made to hold with equality because the number of bistables is then minimal. From a purely functional point of view, state encoding is immaterial because any unique state assignment necessarily leads to a correct circuit that is equivalent to those resulting from all other mappings.8 From an efficiency point of view, some state encodings will yield smaller and faster circuits than others. Energy dissipation and testability are also likely to differ. As the implications from the subsequent steps in the design process — logic synthesis, placement, and routing — are difficult to anticipate, one might be tempted to complete the design and to evaluate different schemes on the grounds of the final result. The number ns of truly distinct state assignments, i.e. those that cannot be derived from others simply by permuting and/or complementing state bits has been known since the late 1950s [234] and is given in (B.7). Numeric evaluation quickly tells that, even for small automata, it is not computationally feasible to find the best state assignment using an enumerative approach. ns = (2ws − 1)! (2ws −|S|)!ws! (B.7) From an engineering point of view, we are not so much interested in the absolute optimum but in finding a good state assignment that results in a near-minimal hardware solution with reasonable effort. A variety of heuristic approaches have been devised, all of which attempt to carry out state encoding such as to minimize the number of literals in the FSM’s logic equations in some way or another. The techniques differ in whether they target two-level or multi-level logic equations and in how they resolve conflicts between contradicting requirements. Adjacent state assignment is the name for a class of heuristics that assumes two-level logic in sum- of-products form. The idea behind all such heuristics essentially is to lower the number of product terms and the number of literals by assigning states that have similar entries in the state table codes that differ in a single bit. Put differently, they make similar states adjacent in the Karnaugh map. Somewhat surprisingly, this approach has been found to have beneficial effects on multi-level logic implementations too and is, therefore, quite popular. As the name suggests, one-hot state encoding uses a binary vector of length |S| and assigns each state a code where a single digit is logic 1 and all others are 0.9 When compared to minimum-bit state encoding, one-hot encoding typically results in many more bistables but, at the same time, also in a 8 Designers typically leave state assignment to a synthesis tool and often ignore the actual binary codes selected. However, testing and debugging will involve gaining access to state registers, e.g. by way of a scan path or by physical probing. Interpreting those binary codes then requires knowledge of the state encoding chosen. 9 Please make sure you understand that one-hot state encoding is not in contradiction to state reduction. 542 APPENDIX B FINITE STATE MACHINES less combinational logic. Whether this pays off or not depends on the application, it certainly did not in the example of table B.3. In FPL devices with limited routing resources it sometimes is the only way to implement substantial finite state machines. On the negative side, one-hot encoding brings about a huge number of parasitic states, namely 2|S| −|S|. Making all of them reconverge to the main subgraph as described in section B.2.1 often proves unwieldy. B.3 SUMMARY • The key characteristics of the most common automata are collected below. Observe that responding to a new input within the on-going computation period (latency 0) and unconditional stability (no through path) are mutually exclusive. Table B.5 Six types of automata and their key characteristics. resynchronization class of automaton register Mealy Moore Medvedev no latency 0 latency 1 latency 1 possibly unstable stable stable hazards likely hazards likely hazard-free yes latency 1 latency 2 latency 2 stable stable stable hazard-free hazard-free hazard-free • Designing with finite state machines involves the following steps: 1. Partitioning the desired functionality into a cluster of cooperating automata whenever this is advantageous from an economy or modularity point of view. 2. Selecting the appropriate type of automaton and the types for its outputs. 3. Detailed specification and verification of statechart, state graph, or state table. 4. State reduction. 5. Deciding on how to safely handle parasitic inputs and states, if any. 6. State assignment. 7. Minimization of combinational functions. 8. Designing the circuit logic from the components or library cells available. Today’s electronic design automation packages routinely cover steps 4 and 6 through 8. Also available are software tools for the editing of state graphs and for visualizing inputs, state transitions, and outputs at a behavioral level.","libVersion":"0.5.0","langs":""}
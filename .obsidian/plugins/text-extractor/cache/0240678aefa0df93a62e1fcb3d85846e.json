{"path":"sem4/FMFP/UE/slides/CN-u04-slides.pdf","text":"Computer Networks - Exercise 4 Congestion Control, Sockets, QUIC and Network Layer ETH Zürich Slides by Ferdinand Brunne and Joël Vögtlin Based on the work of Linus Baumberger, Paul Ellsiepen and Janic Moser March 2025 Table of contents - Congestion Control - Sockets - QUIC - Networking - Demo: netcat - Kahoot! - Exercise #4 2 Congestion Control A lot of packets arrive at a node within a short period of time ➡ Node can’t keep up anymore (queues are full, packets are dropped) Congestion Collapse: Increase in network load ➡ Decrease of useful work done Goal: Prevent senders from overloading the network 4 What is congestion? In-network marking Idea: Indicate congestion through setting a bit in packets. How? ➡ ECN = Explicit Congestion Notiﬁcation Advantages: - Early signal of congestion Disadvantages: - Requires support in the network (i.e routers/switches) - Signal can be lost 5 Congestion Detection 6 Packet delay (latency) Idea: Measure packet delay and use it to reason about network congestion. Advantages: - Can be detected easily - Relatively quick feedback on continuous signal Disadvantages: - Many factors can affect latency - Needs careful parametrization Congestion Detection 7 Packet loss Idea: Measure packet loss and use it to reason about network congestion. Signals: - Duplicated ACKs: mild congestion (packets are still making it) - Timeout: severe congestion (multiple consequent losses) Advantages: - Easily detectable with timers Disadvantages: - Loss can be caused by other factors, not only congestion - Needs careful parametrization Congestion Detection 8 How Classic TCP reacts to Congestion Kleinrock-optimal = Keep highest delivery rate and lowest buffer utilization 9 Congestion-control algorithms (CCAs) Kleinrock-optimal = Keep highest delivery rate and lowest buffer utilization RTT fair = Delivery rate doesn’t depend on RTT Curious what CCA your computer uses? Try this if you’re on Linux: cat /proc/sys/net/ipv4/tcp_congestion_control 10 Congestion-control algorithms (CCAs) Reno Cubic Vegas BBR Type loss-based loss-based latency-based model-based Pros RTT fair Kleinrock-optimal Kleinrock-optimal Cons RTT unfair, Not Kleinrock-optimal Not Kleinrock-optimal Uncompetitive against loss-based CCAs Unfair against loss-based CCAsSockets - They connect (from a programmer's perspective) the application and transport layer - Sockets are used by applications to receive and send data - Together with Ports, they allow using multiple apps on the same IP The OS knows which trafﬁc is for which app by using a mapping between Ports and Sockets - There are well-known (0-1023) ports (e.g. http:80, https:443) and ephemeral (1024-65535) ports that are given (randomly) to clients E.g. (local IP, local port, remote IP, remote port) ↔ socket ↔ application 12 Sockets QUIC “New” transport-layer protocol Implement reliability on top of UDP But why make a new protocol? QUIC – Quick UDP Internet Connections (ofﬁcially no acronym) Image: https://medium.com/@the.real.yushuf/benchmarking-quic-1fd043e944c7 14 ● Faster connection establishment - One RTT is saved since QUIC does not have to make a TCP and a TLS handshake ● 0-RTT data transfer - If a connection has already been established one can establish it in 0-RTT with the help of cookies but it is vulnerable to Replay Attacks 15 QUIC - Why? - QUIC combines TCP and TLS connections - 1 RTT instead of 2 RTT - Using cookies ➡ 0-RTT data transfer - If hosts have communicated before - Problem: Replay Attacks 16 0-RTT data transfer & Faster connection establishment Images: https://techcommunity.microsoft.com/t5/itops-talk-blog/smb-over-quic-ﬁles-without-the-vpn/ba-p/1183449 ● Faster connection establishment - One RTT is saved since QUIC does not have to make a TCP and a TLS handshake ● 0-RTT data transfer - If a connection has already been established one can establish it in 0-RTT with the help of cookies but it is vulnerable to Replay Attacks ● Mobile Connections (The connection stays active after a change of IP) - Done by using Connection IDs 17 QUIC - Why? 18 - TCP connection is speciﬁc to source IP (client) - UDP only needs destination IP and port What happens with the connection if the client IP address changes? - TCPs’ connection is speciﬁc to source IP (client) ➡ connection is broken - QUIC has “connection IDs” separate from IP addresses ➡ connection is ok - Initialized (randomly) in handshake Mobile Connections ● Faster connection establishment - One RTT is saved since QUIC does not have to make a TCP and a TLS handshake ● 0-RTT data transfer - If a connection has already been established one can establish it in 0-RTT with the help of cookies but it is vulnerable to Replay Attacks ● Mobile Connections (The connection stays active after a change of IP) - Done by using Connection IDs ● Reduced Head-of-line blocking - This is a problem with HTTP/2 → see next slide 19 QUIC - Why? HTTP/2 allows multiple HTTP streams to share a single TCP connection Problem: A packet loss could block all HTTP streams, even if they are independent In QUIC, if a packet of a stream is lost, only that stream is affected Why? Because UDP delivers out-of-order packets to the application (QUIC + HTTP/3) 20 Head-of-line blocking ● Faster connection establishment - One RTT is saved since QUIC does not have to make a TCP and a TLS handshake ● 0-RTT data transfer - If a connection has already been established one can establish it in 0-RTT with the help of cookies but it is vulnerable to Replay Attacks ● Mobile Connections (The connection stays active after a change of IP) - Done by using Connection IDs ● Reduced Head-of-line blocking - This is a problem with HTTP/2 → see next slide ● Compatible with middleboxes - Runs on top of existing protocol: UDP 21 QUIC - Why? Networking ● Scalability - Hierarchy, e.g. in the form of preﬁxes ● Heterogeneity - We have a lot of different devices that need to be connected (using IP) ● Bandwidth Control - Lowest-cost routing - QoS (Quality of service) ● Economics - Network trafﬁc needs to be economically viable 24 Network Layer Challenges - Routing (control plane): - Computing where to send the trafﬁc - Global - Expensive - Forwarding (data plane): - Actually sending the trafﬁc - Local - Fast 25 Routing vs Forwarding 26 Routing or 27 Forwarding - How it works: 1. Receive packet 2. Store it in receive buffer 3. Determine correct output 4. Move to output buffer 5. Send 28 Store-and-forward Packet Switching - Datagrams (connectionless) - Virtual circuits (connection-oriented) 29 Network Service Models - Packets contain a destination (IP address) - Routers forward the packet through the network using their forwarding tables (they can change over time) - Each packet might use a different path 30 Datagram Model - Packets do not contain a destination, only a short label for which circuit to use - Forwarding tables per circuit (setup in advance) - Each packet uses the same path - i.e. ISPs setup virtual circuits in the network (using MPLS) 31 Virtual Circuits 32 Datagrams vs Virtual Circuits Datagrams Virtual Circuits Setup phase No Yes Router state Per destination Per connection Addresses Packet carries full address Packet carries short label Routing Per packet Per circuit Failures Easier to mask Difﬁcult to mask Quality of service Difﬁcult to add Easier to add Demo: netcat ● Open 2 terminals ● Type in ○ Terminal 1: netcat -l -p 12345 (Listening on port 12345) ○ Terminal 2: netcat localhost 12345 (Connecting to port 12345 of localhost) ● Open Wireshark and start capturing packets ● Start typing in any of the terminals, same thing should appear in the other one ● Now look at Wireshark and see what packets are transmitted ● Bonus, you can try to send ﬁles like this: ○ Terminal 1: netcat -l -p 12345 > output (Save everything from port 12345 in “output” ﬁle) ○ Terminal 2: netcat localhost 12345 < input (Send the content of the ﬁle “input”) 34 netcat (nc) Kahoot!Exercise #4 Question 1: Reliable transport (exam-style question) 37 ● Consider a Go-Back-N sender and receiver ● Directly connected by a 10 Mbps link (10*10^6 bits) ● with a propagation delay of 100 milliseconds. ● The retransmission timer is set to 3 seconds, restarts on every received ACK (including duplicates). ● The window has a length of 4 segments. ● An ACK is transmitted as soon as the last bit of the corresponding data segment is received, and the size of the ACK is very small. You can neglect: ● transmission delay for ACK packets ● processing delay for all packets ● queuing delay for all packets Total delay: For a segment transmitted at time t the last bit is received at time t + 101ms Transmission delay per segment: Question 1: Reliable transport (exam-style question) 38 Assume a 10 Mbps link, 100ms propagation delay, a retransmission timer of 3s, a window of length 4, and 10 packets of 10000 bits each. 1) Draw the time-sequence diagram for the case where there are no losses. Question 1: Reliable transport (exam-style question) 39 1) Draw the time-sequence diagram for the case where there are no losses. 0 ms 4 ms 201 ms 205 ms 402 ms 404 ms 603 ms 604 ms 101 ms 104 ms 302 ms 305 ms 503 ms 504 ms For a segment transmitted at time t the last bit is received at time t + 101ms Question 1: Reliable transport (exam-style question) 40 0 ms 4 ms 201 ms 203 ms 402 ms 403 ms 101 ms 104 ms 302 ms 303 ms Time to wait until retransmission: 3000 ms 2) Draw the time-sequence diagram for the case where the 3rd (segment 2) and the last (segment 9) are lost once. This means that their ﬁrst transmission fails but their second succeeds. No ACK's are lost. For a segment transmitted at time t the last bit is received at time t + 101ms Question 1: Reliable transport (exam-style question) 41 3403 ms 3407 ms 3604 ms 3608 ms 3805 ms 3807 ms 3504 ms 3507 ms 3705 ms 3707 ms Time to wait until retransmission: 3000 ms 2) Draw the time-sequence diagram for the case where the 3rd (segment 2) and the last (segment 9) are lost once. This means that their ﬁrst transmission fails but their second succeeds. No ACK's are lost. For a segment transmitted at time t the last bit is received at time t + 101ms Question 1: Reliable transport (exam-style question) 42 6807 ms 7008 ms 6908 ms 2) Draw the time-sequence diagram for the case where the 3rd (segment 2) and the last (segment 9) are lost once. This means that their ﬁrst transmission fails but their second succeeds. No ACK's are lost. For a segment transmitted at time t the last bit is received at time t + 101ms Question 2: TCP (adapted Exam Question FS16 Q9) 43 The Transmission Control Protocol (TCP) uses congestion control in order to moderate the rate at which trafﬁc enters the network. Let’s look at the simpliﬁed TCP congestion control algorithm: Question 2: TCP 44 1) Identify the time intervals when congestion control is operating in slow start. Brieﬂy explain slow start and what triggers it. ● [1, 6], [7, 11], [23, 26] ● For every ACK'ed packet, the size of the congestion window grows by one packet ● This leads to a doubling of the window size, every RTT. ● Slow start operates when the cwnd is lower than the ssthresh. Question 2: TCP 45 2) Identify the time intervals when congestion control is operating in congestion avoidance (additive increase). Brieﬂy explain additive inc. and what triggers it. ● [11, 15], [16, 22], [26, 32] ● For every RTT, the size of the congestion window grows by one packet ● If a packet loss is detected the window size is halved. ● Congestion avoidance operates when cwnd is greater or equal than ssthresh. Question 2: TCP 46 3.1) Identify at which point(s) in time there is fast retransmission and explain why. ● At t=16, there is fast retransmission. ● cwnd is halved, and ssthresh = cwnd. If it were a timeout, the cwnd would have gone to 1. ● This is presumably because of three duplicated ACKs being received. Question 2: TCP 47 3.2) Brieﬂy explain how fast retransmission and fast recovery work and the main intuition behind them. ● It does not return to the slow start (by setting cwnd=1) as would be done upon a timeout ● Timeout should only occur if no packets can be transmitted anymore ● Fast retransmission (3 ACKs) indicate less severe congestion, which can be solved by halving the congestion window 48 1) What are the characteristics of best-effort and reliable transport? Best-effort delivery: There is no guarantee for packets to arrive in the correct order, correctly (bit corruption), or even arrive at all. Reliable transport: It provides all the above guarantees by using sequence numbers, checksums, and acknowledgments. An example is TCP. 2) What could be advantages of using an unreliable transport protocol? Better performance/less overhead (No need to wait for ACKs to arrive) Lightweight implementation You can immediately start sending data. (As no connection setup is required e.g., TCP three-way handshake) Question 3: Unreliable transport protocol 49 Applications for which it is more important to have \"live\" data than to have \"complete\" data. e.g., Gaming or Live Streaming. In voice/video-calls, for example, lost packets lead to lower quality, but delayed packets lead to distorted conversations. 4) UDP only provides unreliable transport. Assume you are forced to use a network which only supports UDP as a transport protocol. You must transmit an important document which eventually should be correctly transmitted. Is it possible to implement reliable transport mechanisms despite using UDP? Yes, the reliable transport mechanisms could be implemented by the application/in the application layer. Question 3: Unreliable transport protocol 3) What type of applications are suitable to use unreliable transport protocols? Question 4: QUIC 50 1) At what layer does QUIC operate? Can, and if so how, does it offer the same functionality as the TCP+TLS stack? Note: TLS is a protocol used to establish an encrypted connection on top of the reliable transport TCP. It is not covered in the lecture in detail. QUIC operates at both the transport layer, building on top of UDP, and the application layer. It offers TCP-like guarantees (i.e., reliability), (traditionally ’transport-layer-like functionality’) and also incorporates the TLS handshake (which in the TCP/IP+TLS stack is completely separated from TCP) (traditionally ’application-layer-like functionality’) 51 2) What are the advantages of QUIC over TCP+TLS? QUIC reduces the connection setup time by one RTT, as it combines the connection and TLS handshake. QUIC enables Zero-RTT communication if the hosts have communicated before (cookies) QUIC enables connection hand-over even when IP addresses change, as it uses a connection ID to identify a connection. (TCP can’t do this, since it uses the src & dest IP/ports for identiﬁcation) QUIC resolves head-of-line blocking by the logical abstraction of streams (TCP would require you to open multiple parallel TCP connections) Question 4: QUIC 52 3) Why did QUIC not design its own custom transport layer header instead of UDP? Middleboxes and NAT routers are known to drop unfamiliar transport layer protocols. Using UDP gives interoperability with existing hardware. Question 4: QUICQuestion 5: Packet Switching 53 In packet-switching networks, the source host segments long application-layer messages into smaller packets and sends the packets into the network. The receiver re-assembles the packets back into the original message. 54 Consider a 7.5 * 10^6 bits long message, link capacity 1.5 Mbps We ignore propagation, queuing and processing delays 1) Consider sending the message from source to destination without message segmentation. Keep in mind that each packet switch uses a store and forward packet switching. i) How long does it take to move the message from the source host to the ﬁrst packet switch? Question 5: Packet Switching ii) What is the total time to move the message from the source host to the destination host? 55 2) Now suppose that the message is segmented into 5,000 packets, with each packet being 1500 bits long. How long does it take to move the the ﬁrst packet from the source host to the ﬁrst packet switch? Question 5: Packet Switching Consider a 7.5 * 10^6 bits long message, link capacity 1.5 Mbps We ignore propagation, queuing and processing delays 56 3) How long does it take to move the ﬁle from the source host to the destination host when message segmentation is used? Question 5: Packet Switching Consider a 7.5 * 10^6 bits long message, link capacity 1.5 Mbps We ignore propagation, queuing and processing delays ⇒ This approach takes about ⅓ of the time 4) What are the drawbacks of message segmentation? ● Need to handle out-of-sequence packets ● Additional header necessary Question 6: Timeout value 57 1) What happens, if the timeout is larger than the RTT, what if it's smaller than the RTT? Large timeout results in waiting too long to resend packets (bad timeliness). If the timeout is smaller than the RTT, we resend our packet too fast, and thus send duplicate packets for no reason (bad bandwidth efﬁciency). 2) To get a good estimation for the RTT, current TCP implementations use a form of averaging over the samples. Do they use exponential or linear averaging of RTT samples and how is EstimatedRTT calculated? We use exponential averaging of RTT Question 6: Timeout value 58 3) For the following two examples, ﬁll in the gaps for the EstimatedRTT. (ɑ=0.5) 59.4ms 84.7ms Question 6: Timeout value 59 3) For the following two examples, ﬁll in the gaps for the EstimatedRTT. (ɑ=0.3) 49.1ms 91.7ms Question 6: Timeout value 60 3) What role does alpha play? Alpha decides how much weight we want to give to new Sample values. For small alpha, we weigh our new samples stronger, as we have seen in the second example and therefore adapt changes faster. 4) What if SampleRTT always stays the same? The EstimatedRTT will converge to the SampleRTT. Extra slides 62 Initially - Congestion window = CWND = 1 - Slow start threshold = ssthresh = ∞ Slow Start - CWND += 1 for each ACK ➡ CWND doubles every RTT (Only when “CWND < ssthresh”) - If CWND == ssthresh ➡ Change to Congestion Avoidance Congestion Avoidance - Increase CWND by 1 every RTT (AIMD) On timeout (packet was lost) - ssthresh = CWND/2 - CWND = 1 - Switch to Slow Start if you were in Congestion Avoidance Fast Recovery: On 3 duplicate ACKs - CWND /= 2 - ssthresh = CWND How Classic TCP reacts to Congestion (Reno) Demo: Wireshark - Download Wireshark - Find IP address using dig: - dig ethz.ch +short - Start capturing packets - Click on the button on top left - (Re)load “ethz.ch” in a browser - Stop capturing packets - Click on the red button on top left - Filter by the ip you found (case sensitive): - ip.addr == (the ip you found with dig) - Have fun looking at packets! 64 Wireshark 65 Additive increase, Multiplicative decrease – AIMD Increase in network load ➡ Increases RTT ➡ RTT exceeds the maximum retransmission interval ➡ Hosts begin to retransmit packets ➡ Hosts are sending each packet several times ➡ Decrease of useful work done 66 Congestion Collapse - Network middleboxes interfere with the end-to-end principle - (i.e. Firewalls block unfamiliar packets) - This leads to a phenomenon called network ossiﬁcation - UDP is a well established protocol ➡ provides interoperability - QUIC built on UDP ➡ compatible with middlboxes who drop unknown protocols 67 Difﬁcult to evolve TCP","libVersion":"0.5.0","langs":""}
{"path":"sem4/W&S/UE/s/W&S-s-u05.pdf","text":"Probability and Statistics (D-INFK) Lecturer: Prof. Dr. Dylan Possamaï Coordinator: Daniel Kršek Probability and Statistics Exercise sheet 5 - Solutions MC 5.1. Let X and Y be random variables taking values in N. Which of the following statements are true? (The number of correct answers is between 0 and 6.) (a) If we know all values of P[X = i, Y = j] for i, j ∈ N, then we also know all values of P[X = i] and P[Y = j] for i, j ∈ N. (b) If we know all values of P[X = i] and P[Y = j] for i, j ∈ N, then we also know all values of P[X = i, Y = j] for i, j ∈ N. (c) Statement (b) is true, provided that we know that X and Y are independent. (d) Statement (b) is true, provided that we know that Z1 := e−X and Z2 := √Y are independent. (e) Statement (b) is true, provided that we know that Z1 := e−X and Z2 := Y mod 2 are independent. (f) If we assume P[Y = j] > 0 and we know all values of P[X = i | Y = j] and P[Y = j] for i, j ∈ N, then we also know all values of P[X = i, Y = j] for i, j ∈ N. Solution: (a) is true. We have P[X = i] = ∞∑ j=1 P[X = i, Y = j], i ∈ N, and P[Y = j] = ∞∑ i=1 P[X = i, Y = j], j ∈ N. (b) is not true. We cannot recover the joint probabilities P[X = i, Y = j] knowing only the marginal probabilities P[X = i] and P[Y = j] for i, j ∈ N. (c) is true. We have P[X = i, Y = j] = P[X = i]P[Y = j], i, j ∈ N. (d) is true. We have P[X = j, Y = j] = P[ eX = ei, √Y = √j] = P[eX = ei]P [√Y = √j] = P[X = i]P[Y = j], i, j ∈ N. Equivalently, using Proposition 2.6 from the lecture notes, we have that if Z1 = eX and Z2 = √Y are independent, then X = log(Z1) and Y = Z 2 2 are also independent, and so the statement holds since (c) does. (e) is not true. For instance, consider the following probabilities: P[X = i, Y = j] = P[X = i]P[Y = j] and P[X = i, Y = j] = { P[X = i] if j = 2i, 0 otherwise, i, j ∈ N, both of which define a valid joint distribution of X and Y . 1 Probability and Statistics (D-INFK) Lecturer: Prof. Dr. Dylan Possamaï Coordinator: Daniel Kršek Note that in the first case, X and Y are independent, and thus so are Z1 and Z2. In the second case, we have P[2X = Y ] = 1, meaning X and Y are generally not independent. However, since P[Z2 = 0] = P[(2X mod 2) = 0] = 1, it is easy to verify that Z2 is independent of Z1. Similar argument as in (d) does not work here since the map n ↦→ n mod 2 does not have an inverse. (f) is true. We have P[X = i, Y = j] = P[X = i | Y = j]P[Y = j], i, j ∈ N. Exercise 5.2. Let N ∈ N. Consider the set Ω = {0, 1} N = {(a1, . . . , aN ) : a1, . . . , aN ∈ {0, 1} } and the σ-algebra A = 2 Ω, as well as the probability measure P defined by P[ {(a1, . . . , aN )} ] = { 1 2N −1 , if a1 + · · · + aN is even, 0, otherwise. Let X1, . . . , XN be random variables defined by Xi((a1, . . . , aN )) = ai, (a1, . . . , aN ) ∈ Ω, i ∈ {1, . . . , N }. (a) Show that X1, . . . , XN −1 are independent. (b) Show that X1, . . . , XN are not independent. Solution: (a) For each ai ∈ {0, 1}, there are 2N −2 vectors (a1, . . . , ai−1, ai+1, . . . , aN ) ∈ {0, 1} N −1 such that a1 + · · · + aN is even. Therefore, we have P[Xi = ai] = 2 N −2 2N −1 = 1 2 . Similarly, for each vector (a1, . . . , aN −1) ∈ {0, 1} N −1, there is exactly one value of aN ∈ {0, 1} such that a1 + · · · + aN is even. Hence, P [X1 = a1, . . . , XN −1 = aN −1] = 1 2N −1 = N −1∏ i=1 P[Xi = ai]. We conclude that X1, . . . , XN −1 are independent. (b) It holds that P[X1 = 0, . . . , XN = 0] = 1 2N −1 ̸= N∏ i=1 P[Xi = 0] = 1 2N , and thus X1, . . . , XN are not independent. 2 Probability and Statistics (D-INFK) Lecturer: Prof. Dr. Dylan Possamaï Coordinator: Daniel Kršek Exercise 5.3. Let X be a discrete random variable with the cumulative distribution function FX (a) =    0, if a < 1, 1/5, if 1 ≤ a < 4, 3/4, if 4 ≤ a < 6, 1, if 6 ≤ a. (a) Sketch the cumulative distribution function of X. (b) Find the distribution of X (i.e. the values of p(x) = P[X = x]) and sketch it. (c) Compute the probabilities P[X = 6], P[X = 5], P[2 < X < 5.5], P[0 ≤ X < 4]. Solution: (a) The following sketch illustrates the cumulative distribution function of X: 0 2 4 6 8 100.00.20.40.60.81.0 Verteilungsfunktion xF(x) (b) We observe that P[X = 1] = 1/5, P[X = 4] = 3/4 − 1/5 = 11/20, P[X = 6] = 1/4 and P[X = x] = 0 for all x /∈ {1, 4, 6}. The probability is given by (p(x))x∈{1,4,6} with p(1) = P[X = 1] = 1/5, p(4) = P[X = 4] = 3/4 − 1/5 = 11/20, p(6) = P[X = 6] = 1/4. This is illustrated in the following sketch: 3 Probability and Statistics (D-INFK) Lecturer: Prof. Dr. Dylan Possamaï Coordinator: Daniel Kršek 0 2 4 6 8 100.00.20.40.60.81.0 Gewichtsfunktion xP(x) (c) We compute P[X = 6] = p(6) = 1/4, P[X = 5] = 0, P[2 < X < 5.5] = p(4) = 11/20, P[0 ≤ X < 4] = p(1) = 1/5. Exercise 5.4. Let X and Y be two discrete random variables with the following joint distribution: p(j, k) = P[X = j, Y = k] = { C( 1 2 )k for k = 2, 3, . . . and j = 1, 2, . . . , k − 1 0 otherwise, for some constant C ∈ R. (a) Determine the constant C. (b) Compute the (marginal) distributions pX and pY of X and Y . (c) Are X and Y independent? Solution: (a) Since p is the joint probability mass function of X and Y , it must hold that 1 = ∞∑ k=2 k−1∑ j=1 P [X = j, Y = k] . 4 Probability and Statistics (D-INFK) Lecturer: Prof. Dr. Dylan Possamaï Coordinator: Daniel Kršek We have ∞∑ k=2 k−1∑ j=1 P [X = j, Y = k] = C ∞∑ k=2 k−1∑ j=1 ( 1 2 )k = C ∞∑ j=1 ∞∑ k=j+1 ( 1 2 )k = C ∞∑ j=1 ( 1 2 )j+1 ∞∑ k=0 ( 1 2 )k = C ∞∑ j=1 ( 1 2 )j+1 1 − 1 2 = C ∞∑ j=1 ( 1 2 )j = C 1 2 1 − 1 2 = C. Thus, C = 1. (b) We compute for j ≥ 1, pX (j) = P[X = j] = ∞∑ k=2 P[X = j, Y = k] = ∞∑ k=2 p(j, k) = ∞∑ k=j+1 ( 1 2 )k = ( 1 2 )j+1 ∞∑ k=0 ( 1 2 )k = ( 1 2 )j and for k ≥ 2 pY (k) = P[Y = k] = k−1∑ j=1 P[X = j, Y = k] = k−1∑ j=1 p(j, k) = (k − 1) ( 1 2 )k . (c) The random variables X and Y are independent if and only if for all k ≥ 2 and j ≥ 1, p(j, k) = pX (j)pY (k). This is not the case, for example, for j = 1 and k = 2: p(1, 2) = 1 4 ̸= 1 2 × 1 4 = pX (1)pY (2). Exercise 5.5. [Monty Hall Problem] You are in a game show and have a choice between three doors. Behind one door is a car, while the other two doors hide goats. You select a door, and the host, who knows what is behind the doors, opens another door revealing a goat. The host then asks you: “Would you like to stick with your originally chosen door or switch to another one?” Assuming you prefer cars over goats, what should you do? (a) Construct an appropriate model to answer this question using conditional probabilities. (b) Try to find an alternative solution (which must, of course, yield the same answer). Solution: (a) We number the doors as 1, 2, 3 in such a way that our initial choice is door 1. We define Bi = “The car is behind door i,” for i ∈ {1, 2, 3}, and Aj =“The host opens door j,” for j ∈ {2, 3}. Let Ω = {1, 2, 3} × {2, 3}. Then Bi = {i} × {2, 3} for i ∈ {1, 2, 3} and A2 = {1, 3} × {2} and 5 Probability and Statistics (D-INFK) Lecturer: Prof. Dr. Dylan Possamaï Coordinator: Daniel Kršek A3 = {1, 2} × {3}. We choose the following probabilities: • P[B1] = P[B2] = P[B3] = 1 3 , meaning the car is placed randomly. • P[A2|B1] = P[A3|B1] = 1 2 , meaning the host randomly picks a goat door if we initially choose the door with the car. • P[A2|B2] = 0 and P[A3|B2] = 1, since if the car is behind door 2, the host must open door 3. • P[A2|B3] = 1 and P[A3|B3] = 0. Using Bayes’ theorem, we compute: P[B1|A2] = P[A2|B1]P[B1] P[A2|B1]P[B1] + P[A2|B2]P[B2] + P[A2|B3]P[B3] = 1 2 × 1 3 1 2 × 1 3 + 0 × 1 3 + 1 × 1 3 = 1 6 1 3 = 1 3 and similarly, P[B1|A3] = P[A3|B1]P[B1] P[A3|B1]P[B1] + P[A3|B2]P[B2] + P[A3|B3]P[B3] = 1 2 × 1 3 1 2 × 1 3 + 1 × 1 3 + 0 × 1 3 = 1 6 1 3 = 1 3 . We see that P[B1|A2] = P[B1|A3] = P[B1]. This also gives P[B3|A2] = 1 − P[B1|A2] = 2 3 and P[B2|A3] = 1 − P[B1|A3] = 2 3 . Therefore, you should switch to the other door rather than sticking with your initial choice. You have not gained any additional information about door 1, but you have gained additional information about the final door. (b) Consider Ω = {1, 2, 3} × {1, 2, 3}, F = 2 Ω, and P as the uniform distribution. For ω = (ω1, ω2), ω1 represents the door number containing the car, and ω2 represents the door initially chosen. The decision is whether to switch in the second round or not. If ω1 = ω2, switching results in losing; but if ω1 ̸= ω2, switching results in winning, as one door is already opened. Thus, the probability of winning the car is 6 9 = 2 3 if we switch, but only 3 9 = 1 3 if we do not switch. Therefore, we should abandon our initial choice and switch. 6","libVersion":"0.5.0","langs":""}
{"path":"sem2/PProg/VRL/slides/PProg-L15-behind-locks.pdf","text":"spcl.ethz.ch @spcl_eth @spcl TORSTEN HOEFLER Parallel Programming, Spr. 2024, Lecture 15: Data Races, Solving Mutual Exclusion with Atomic Registers @spcl_eth @spcl spcl.ethz.ch 2 @spcl_eth @spcl spcl.ethz.ch 3 Source: https://medium.com/ Source: https://www.ft.com/ Source: https://www.medpagetoday.com/ What is left for us humans? @spcl_eth @spcl spcl.ethz.ch â€œReally the deciding factor [for the AI revolution] was the increase in compute powerâ€ (26:50) â€œI think a lot of the credit for deep learning goes to [â€¦ others â€¦] and the people who made the computers go fast.â€ (27:00) https://www.youtube.com/watch?v=VsnQf7exv5I 4 @spcl_eth @spcl spcl.ethz.ch 5source: ft.com @spcl_eth @spcl spcl.ethz.ch 6 â€¦ meanwhile in big industry â€¦ @spcl_eth @spcl spcl.ethz.ch 7 OpenAI: Scaling Kubernetes to 7,500 nodes (running MPI!) https://openai.com/research/scaling-kubernetes-to-7500-nodes @spcl_eth @spcl spcl.ethz.ch 8 More on our youtube channel â€¦ https://www.youtube.com/@spcl @spcl_eth @spcl spcl.ethz.ch 9 More on the fascinating world of High-Performance AI and Computing (HPC) @spcl_eth @spcl spcl.ethz.ch 10 Learning goals for today So far: â€¢ Programming with locks and critical sections â€¢ Key guidelines and trade-offs â€¢ Bad interleavings (high level races) Now: â–ª The unfortunate reality of parallel programming in practice â€“ memory models â–ª Why you must avoid data races (= low level races / memory reorderings) â–ª Implementation of a Mutex with Atomic Registers Dekkerâ€™s algorithm Petersonâ€™s algorithm â–ª Context: remember you will likely not implement locks (you will use functions provided by the programming language!) YET: you will learn important principles by â€œdoingâ€ â€“ and watching your (my) mistakes carefully â€œTell me and I forget, teach me and I may remember, involve me and I learn.â€ spcl.inf.ethz.ch @spcl_eth There is no interleaving of f and g that would cause the assertion to fail: Proof by exhaustion (or full enumeration)! class C { private int x = 0; private int y = 0; void f() { x = 1; y = 1; } void g() { int a = y; int b = x; assert(b >= a); } } Motivation A B C D A B C D A BC D A BC D A BC D A BC D D BC A ï ï ï ï ï ï Can this fail? 11 Thread 1 Thread 2 spcl.inf.ethz.ch @spcl_eth â–ª Assuming 2 threads and k statements each, how many interleavings are there? â–ª Any ideas? â–ª Hint 1 â–ª The merged list has length k+k=2k â–ª Once we know which k positions in the merged list are occupied with elements from thread 1 (or 2) then the interleaving is determined! â–ª How many are those? â–ª Hint 2 â–ª This is equivalent to sampling without replacement (draw the k positions out of 2k total) â€œZiehen ohne Zuruecklegenâ€ â–ª 2ğ‘˜ ğ‘˜ = ğ‘‚ 4ğ‘˜ 2ğ‘˜ â–ª If you cannot sleep tonight: â–ª Generalize this to n threads â˜º 12 A little combinatorial excursion spcl.inf.ethz.ch @spcl_eth There is no interleaving of f and g causing the assertion to fail Another proof (by contradiction): Assume b<a â‡’ a==1 and b==0. But if a==1 â‡’ y=1 happened before a=y. And if b==0 â‡’ b=x happened before x=1. Because we assume that programs execute in order: a=y happened before b=x x=1 happened before y=1 So by transitivity, a=y happened before b=x happened before x=1 happened before y=1 happened before a=y â‡’ Contradiction ï€· Another proof 13 class C { private int x = 0; private int y = 0; void f() { x = 1; y = 1; } void g() { int a = y; int b = x; assert(b >= a); } } Thread 1 Thread 2 spcl.inf.ethz.ch @spcl_eth 14 Letâ€™s try that on my laptop spcl.inf.ethz.ch @spcl_eth void f() { x = 1; y = x+1; z = x+1; } Why it still can fail: Memory reordering void f() { x = 1; z = x+1; y = x+1; } Rule of thumb: Compiler and hardware allowed to make changes that do not affect the semantics of a sequentially executed program semantically equivalent? In a sequential world! 15 void f() { x = 1; z = 2; y = 2; } semantically equivalent? spcl.inf.ethz.ch @spcl_eth Modern compilers do not give guarantees that a global ordering of memory accesses is provided: â€¢ Some memory accesses may be even optimized away completely! â€¢ Class question: why? â€¢ Huge potential for optimizations â€“ and for errors, when you make the wrong assumptions â€¢ Dead code elimination â€¢ Register hoisting â€¢ Locality optimizations â€¢ â€¦ many more (beyond this basic class, e.g., advanced dataflow â€“ see DaCe) Memory reordering: A software view 16 spcl.inf.ethz.ch @spcl_eth int x; void wait() { x = 1; while(x==1); } void arrive(){ x = 2; } Example: Fail with self-made rendezvous (C / GCC) Consider thread A calling wait and thread B subsequently calling arrive. What would you naively expect? A B wait arrive 17 spcl.inf.ethz.ch @spcl_eth int x; void wait() { x = 1; while(x==1); } void arrive(){ x = 2; } Example: Fail with self-made rendezvous (C / GCC) Assembly without optimization movl $0x1, x test: mov x, %eax cmp $0x1, %eax je test movl $0x2, x Assembly with optimization movl $0x1, x test: jmp test movl $0x2, x je: jump (only) if equal, i.e., if cmp yields true jmp: jump always 18 spcl.inf.ethz.ch @spcl_eth Modern multiprocessors do not enforce global ordering of all instructions: â€¢ What they actually guarantee varies widely! â€¢ Class question: why? â€¢ For performance! â€¢ Most processors have a pipelined architecture and can execute (parts of) multiple instructions simultaneously. They can (and will) even reorder instructions internally. â€¢ Each processor has a local cache, and thus loads/stores to shared memory can become visible to other processors at different times Memory reordering: A hardware view 19 spcl.inf.ethz.ch @spcl_eth Memory hierachy (one core) Registers L1 Cache L2 Cache System Memory fast, low latency, high cost, low capacity slow, high latency latency, low cost, high capacity 20 ALUs 0.5ns 1 ns 7 ns 100 ns spcl.inf.ethz.ch @spcl_eth Memory hierachy (many cores) Registers L1 Cache Shared L2 Cache System Memory 21 Registers L1 Cache Registers L1 Cache â€¦ ALUs ALUs ALUs spcl.inf.ethz.ch @spcl_eth A real-life analogy Zoe Anna Beat local data global data 22 spcl.inf.ethz.ch @spcl_eth Sharing memory (schematically) CPU 1 CPU 2 Core 1 Core 1Core 2 Core 2 L1 L1L1 L1 L2 L2 System Memory System Bus Registers Registers Registers Registers 23 spcl.inf.ethz.ch @spcl_eth The exact behavior of threads interacting via shared memory usually depends on hardware, runtime system, and programming language. A memory model (e.g., of a programming language like Java) provides (often minimal) guarantees for the effects of memory operations. â–ª leaving optimization possibilities for hardware and compiler â–ª but including guidelines for writing correct multithreaded programs Will come back to this later. Memory models 24 åˆåŒ (contract) spcl.inf.ethz.ch @spcl_eth We need to learn (a bit) more about Javaâ€™s Memory Model. For now, we know that Java gives certain guarantees in the presence of synchronization. Implications 25 spcl.inf.ethz.ch @spcl_eth class C { private int x = 0; private int y = 0; void f() { synchronized(this) { x = 1; } synchronized(this) { y = 1; } } void g() { int a, b; synchronized(this) { a = y; } synchronized(this) { b = x; } assert(b >= a); } } Fixing our example â–ª Can use synchronization to avoid data races â–ª Then, indeed, the assertion cannot fail 26 spcl.inf.ethz.ch @spcl_eth class C { private volatile int x = 0; private volatile int y = 0; void f() { x = 1; y = 1; } void g() { int a = y; int b = x; assert(b >= a); } } Another fix â€¢ Java has volatile fields: accesses do not count as data races â€¢ Implementation: slower than regular fields, faster than locks â€¢ Really for experts: avoid them; use standard libraries instead â€¢ And why do you need code like this anyway? 27 spcl.inf.ethz.ch @spcl_eth class C { boolean stop = false; void f() { while(!stop) { // draw a monster } } void g() { stop = didUserQuit(); } } More realistic example of code that is wrong Thread 1: f() Thread 2: g() No guarantee Thread 1 will ever stop. But honestly it will â€œlikely work in practiceâ€ 28 spcl.inf.ethz.ch @spcl_eth â–ª Compilers and computer architectures will change orders of memory operations â–ª Consistent with sequential semantics! â–ª May impact parallel execution ïŒ â–ª There are some language constructs that forbid such reordering â–ª We saw synchronized and volatile in Java â–ª But what do they really mean? â–ª Now we need to dig a bit deeper (Iâ€™d rather not, but we have to) Itâ€™s quite complex! â–ª Memory models 29 What did we learn? spcl.inf.ethz.ch @spcl_eth â–ª You expect instructions to be executed in program order? â–ª But your compiler, your CPU, and your DRAM reorder! For better performance. â–ª What will be reordered depends on hardware, e.g., AMD64 is different than ARM. â–ª In single threaded programs this does not cause problems. â–ª But we saw a shared-memory multithreading example using x86 fail us 30 Why (architectural) memory models? For real â€¦ Source: wikipedia spcl.inf.ethz.ch @spcl_eth 31 Why memory models, x86 example Answer: i=1, j=1 i=0, j=1 i=1, j=0 i=0, j=0 (but why?) spcl.inf.ethz.ch @spcl_eth â–ª History â€¦ 32 Java Memory Model (JMM): Necessary basics 1995 2005 2016 spcl.inf.ethz.ch @spcl_eth â–ª JMM restricts allowable outcomes of programs â–ª You saw that if we donâ€™t have these operations (volatile, synchronized etc.) â€“ outcome can be â€œarbitraryâ€ (not quite correct, say unexpected â˜º) â–ª JMM defines Actions: read(x):1 â€œread variable x, the value read is 1â€ â–ª Executions combine actions with ordering: â–ª Program Order â–ª Synchronizes-with â–ª Synchronization Order â–ª Happens-before 33 Java Memory Model (JMM): Necessary basics spcl.inf.ethz.ch @spcl_eth â–ª Program order is a total order of intra-thread actions â–ª Program statements are NOT a total order across threads! â–ª Program order does not provide an ordering guarantee for memory accesses! â–ª The only reason it exists is to provide the link between possible executions and the original program. â–ª Intra-thread consistency: Per thread, the PO order is consistent with the threadâ€™s isolated execution 34 JMM: Program Order (PO) spcl.inf.ethz.ch @spcl_eth â–ª Synchronization actions are: â–ª Read/write of a volatile variable â–ª Lock monitor, unlock monitor â–ª First/last action of a thread (synthetic) â–ª Actions which start a thread â–ª Actions which determine if a thread has terminated â–ª Synchronization Actions form the Synchronization Order (SO) â–ª SO is a total order â–ª All threads see SA in the same order â–ª SA within a thread are in PO â–ª SO is consistent: all reads in SO see the last writes in SO 35 JMM: Synchronization Actions (SA) and Synchronization Order (SO) Exercise: List all outcomes (r1,r2) allowed by the JMM. spcl.inf.ethz.ch @spcl_eth â–ª SW only pairs the specific actions which \"see\" each other â–ª A volatile write to x synchronizes with subsequent read of x (subsequent in SO) â–ª The transitive closure of PO and SW forms HB â–ª HB consistency: When reading a variable, we see either the last write (in HB) or any other unordered write. â–ª This means races are allowed! 37 JMM: Synchronizes-With (SW) / Happens-Before (HB) orders spcl.inf.ethz.ch @spcl_eth 38 Example spcl.inf.ethz.ch @spcl_eth Behind Locks Implementation of Mutual Exclusion 39 spcl.inf.ethz.ch @spcl_eth In the following we assume 1) atomic reads and writes of variables of primitive type 2) no reordering of read and write sequences (! not true in practice ! here for simplicity !) 3) threads calling lock (enter a critical section) will eventually call (and complete) unlock Otherwise we assume a multithreaded environment where processes can arbitrarily interleave. We make no assumptions for progress in non-critical section! Assumptions Will make Â«atomicÂ» more precise later. 40 spcl.inf.ethz.ch @spcl_eth Pieces of code with the following conditions 1. Mutual exclusion: statements from critical sections of two or more processes must not be interleaved 2. Freedom from deadlock: if some processes are trying to enter a critical section then one of them must eventually succeed 3. Freedom from starvation: if any process tries to enter its critical section, then that process must eventually succeed Critical sections According to M. Ben Ari, Principles of Concurrent and Distributed Programming 41 spcl.inf.ethz.ch @spcl_eth Process P local variables loop non-critical section preprotocol critical section postprotocol Critical section problem Process Q local variables loop non-critical section preprotocol critical section postprotocol global (shared) variables Easy to implement on a single-core machine. How? 42 spcl.inf.ethz.ch @spcl_eth Process P local variables loop non-critical section ? critical section ? Easy to implement on a single core system ... Process Q local variables loop non-critical section ? critical section ? global (shared) variables Switch off IRQs Switch off IRQs Switch on IRQs Switch on IRQs 43 spcl.inf.ethz.ch @spcl_eth Process P local variables loop p1 non-critical section p2 while(wantq); p3 wantp = true p4 critical section p5 wantp = false Mutual exclusion for 2 processes -- 1st Try Process Q local variables loop q1 non-critical section q2 while(wantp); q3 wantq = true q4 critical section q5 wantq = false volatile boolean wantp=false, wantq=false 44 Do you see the problem? spcl.inf.ethz.ch @spcl_eth State space diagram [p, q, wantp, wantq] p1, q1, false, false p1, q2, false, false p2, q1, false, false p2, q2, false, false p3, q1, false, false p1, q3, false, false p2, q3, false, false p3, q3, false, false p3, q2, false, false p4, q1, true, false p4, q2, true, false p4, q3, true, false p1, q4, false, true p2, q4, false, true p3, q4, false, true p4, q4, true, true no mutual exclusion ! 1 non-critical section 2 while(wantp) 3 wantp = true 4 critical section 5 wantp = false while(wantq) wantq = true wantq = false 45 spcl.inf.ethz.ch @spcl_eth Process P local variables loop p1 non-critical section p2 while(wantq); p3 wantp = true p4 critical section p5 wantp = false Observation: state space diagram too large Process Q local variables loop q1 non-critical section q2 while(wantp); q3 wantq = true q4 critical section q5 wantq = false volatile boolean wantp=false, wantq=falseOnly of interest: state transitions of the protocol. p1/q1 is identical to p2/q2 â€“ call state 2 p4/q4 is identical to p5/q5 â€“ call state 5 Then forbidden: both processes in state 5 46 spcl.inf.ethz.ch @spcl_eth All of interest covered: Reduced state space diagram [p, q, wantp, wantq] â€“ only states 2, 3, and 5 p2, q2, false, false p2, q3, false, false p3, q3, false, false p3, q2, false, false p5, q2, true, false p5, q3, true, false p2, q5, false, true p3, q5, false, true p5, q5, true, true no mutual exclusion ! 1 non-critical section 2 await wantq == false 3 wantp = true 4 critical section 5 wantp = false await wantp == false wantq = true wantq = false 47 spcl.inf.ethz.ch @spcl_eth Process P local variables loop p1 non-critical section p2 wantp = true p3 while(wantq); p4 critical section p5 wantp = false Mutual exclusion for 2 processes -- 2nd Try Process Q local variables loop q1 non-critical section q2 wantq = true q3 while(wantp): q4 critical section q5 wantq = false volatile boolean wantp=false, wantq=false Do you see the problem? 48 spcl.inf.ethz.ch @spcl_eth State space diagram [p, q, wantp, wantq] p2, q2, false, false p2, q3, false, true p3, q3, true, true p3, q2, true, false p5, q2, true, false p5, q3, true, true p2, q5, false, true p3, q5, true, true deadlock ! 49 1 non-critical section 2 wantp = true 3 while(wantp) 4 critical section 5 wantp = false wantq = true while(wantq) wantq = false spcl.inf.ethz.ch @spcl_eth Process P local variables loop p1 non-critical section p2 while(turn != 1); p3 critical section p4 turn = 2 Mutual exclusion for 2 processes -- 3rd Try Process Q local variables loop q1 non-critical section q2 while(turn != 2); q3 critical section q4 turn = 1 volatile int turn = 1; 50 Do you see the problem? spcl.inf.ethz.ch @spcl_eth State space diagram [p, q, turn] p2, q2, 1 p2, q2, 2 p4, q2, 1 p2, q4, 2 starvation! We have not made any assumptions about progress outside of the CS... 51 Process P local variables loop p1 non-critical section p2 while(turn != 1); p3 critical section p4 turn = 2 Process Q local variables loop q1 non-critical section q2 while(turn != 2); q3 critical section q4 turn = 1 spcl.inf.ethz.ch @spcl_eth Process P loop non-critical section wantp = true while (wantq) { if (turn == 2) { wantp = false; while(turn != 1); wantp = true; }} critical section turn = 2 wantp = false A combination of the tries 2 and 3: Deckerâ€™s Algorithm Process Q loop non-critical section wantq = true while (wantp) { if (turn == 1) { wantq = false while(turn != 2); wantq = true; }} critical section turn = 1 wantq = false volatile boolean wantp=false, wantq=false, integer turn= 1 only when q tries to get lock and q has preference let q proceed and wait and try again 52 spcl.inf.ethz.ch @spcl_eth Process P (1) loop non-critical section flag[P] = true victim = P while(flag[Q] && victim == P); critical section flag[P] = false More concise than Decker: Peterson Lock Process Q (2) loop non-critical section flag[Q] = true victim = Q while(flag[P] && victim == Q); critical section flag[Q] = false let P=1, Q=2; volatile boolean array flag[1..2] = [false, false]; volatile integer victim = 1 I am interested but you go first We both are interested And you go first 53 spcl.inf.ethz.ch @spcl_eth that the Peterson Lock satisfies mutual exclusion and that it is starvation free How? Requires some notation first. We want to prove ... 54 spcl.inf.ethz.ch @spcl_eth Threads produce a sequence of events P produces events ğ’‘ğŸ, ğ’‘ğŸ, â€¦ e.g., ğ‘1 = \"flag[P] = true\" j-th occurence of event i in thread P: ğ’‘ğ’Š ğ’‹ e.g., ğ‘5 3 = \"flag[P] = false\" in the third iteration Precedence relation: we write ğ’‚ â†’ ğ’ƒ when a occurs before b. Note that the precedence relation \"â†’\" is a total order for events. Events and precedence programs usually consist of loops, therefore we might need to count occurences 55 spcl.inf.ethz.ch @spcl_eth ğ‘0, ğ‘1 : interval of events ğ‘0, ğ‘1 with ğ‘0 â†’ ğ‘1 With ğ¼ğ´ = (ğ‘0, ğ‘1) and ğ¼ğµ = (ğ‘0, ğ‘1) we write ğ‘°ğ‘¨ â†’ ğ‘°ğ‘© if ğ’‚ğŸ â†’ ğ’ƒğŸ we say \"ğ¼ğ´ precedes ğ¼ğµ\" and \"ğ¼ğµâ€² and ğ¼ğ´â€² are concurrent\" Intervals B time A ğ‘0 ğ‘1 ğ‘0 ğ‘1 ğ¼ğ´ ğ¼ğµ ğ‘2 ğ‘3ğ¼ğ´â€² ğ‘0 ğ‘1ğ¼ğµâ€² ğ¼ğ´ â†’ ğ¼ğµ ğ¼ğµ â†’ ğ¼ğ´â€² ğ¼ğµâ€² â†› ğ¼ğ´â€² ğ¼ğ´â€² â†› ğ¼ğµâ€² 56 spcl.inf.ethz.ch @spcl_eth Register: basic memory object, can be shared or not i.e., in this context register â‰  register of a CPU Register r : operations r.read() and r.write(v) Atomic Register: â–ª An invocation J of r.read or r.write takes effect at a single point ğ‰(ğ‘±) in time â–ª ğ‰(ğ‘±) always lies between start and end of the operation J â–ª Two operations J and K on the same register always have a different effect time ğ‰(ğ‘±) â‰  ğ‰(ğ‘²) â–ª An invocation J of r.read() returns the value v written by the invocation K of r.write(v) with closest preceding effect time ğ‰(ğ‘²) Atomic register 57 spcl.inf.ethz.ch @spcl_eth Example A r.read() B r.write(4) time r.write(8) r.read() C r.write(1) r.read() ğ‰ ğ‘± ğ‰ ğ‘² ğ‰ ğ‘´ ğ‰ ğ‘µ ğ‰ ğ‘³ ğ‰ ğ‘¶ K M J L N Oâ†’1 â†’8 â†’4 58 spcl.inf.ethz.ch @spcl_eth Assumptions for Atomic Registers justify to treat operations on them as events taking place at a single point in time. Will use this in the following proofs. Note that even with atomic registers there can still be non-determinism of programs because nothing is said about the order of effect times for concurrent operations. Atomic register 59 spcl.inf.ethz.ch @spcl_eth By contradiction: assume concurrent CSP and CSQ [A] Assume without loss of generality: WQ(victim=Q) â†’ WP(victim=P) [B] From the code: WP(flag[P]=true) â†’ WP(victim = P) â†’ RP(flag[Q]) â†’ RP(victim) â†’ CSP WQ(flag[Q]=true) â†’ WQ(victim = Q) â†’ RQ(flag[P]) â†’ RQ(victim) â†’ CSQ Proof: Mutual exclusion (Peterson) flag[P] = true victim = P while (flag[Q] && victim == P){} CSP flag[P] = false B â‡’ must read P [C]A + C â‡’ must read false \"write of P\" \"read of Q\" transitivity of \"â†’ \" â‡’ must read true ï€· 60 spcl.inf.ethz.ch @spcl_eth By (exhaustive) contradition Assume without loss of generality that P runs forever in its lock loop, waiting until flag[Q]==false or victim != P. Possibilities for Q: stuck in nonCS â‡’ flag[Q] = false and P can continue. Contradiction. repeatedly entering and leaving its CS â‡’ sets victim to Q when entering. Now victim cannot be changed â‡’ P can continue. Contradiction. stuck in its lock loop waiting until flag[P]==false or victim != Q. But victim == P and victim == Q cannot hold at the same time. Contradiction. Proof: Freedom from starvation flag[P] = true victim = P while (flag[Q] && victim == P){} CSP flag[P] = false 61 spcl.inf.ethz.ch @spcl_eth class PetersonLock { volatile boolean flag[] = new boolean[2]; volatile int victim; public void Acquire(int id) { flag[id] = true; victim = id; while (flag[1-id] && victim == id); } public void Release(int id) { flag[id] = false; } } Peterson in Java Volatile reference to an array and not an array of volatile variables! This example may work in practice. However, for production programs it is recommended to use Javaâ€™s AtomicInteger and AtomicIntegerArray. 62 spcl.inf.ethz.ch @spcl_eth â–ª How to extend Petersonâ€™s lock to more than 2 threads? â–ª Think about it, I will present a solution in tomorrow's lecture. More than two threads 63","libVersion":"0.3.2","langs":""}
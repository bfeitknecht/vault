{"path":"sem4/W&S/UE/s/W&S-s-u07.pdf","text":"Probability and Statistics (D-INFK) Lecturer: Prof. Dr. Dylan Possamaï Coordinator: Daniel Kršek Probability and Statistics Exercise sheet 7 - Solutions MC 7.1. Let Z be a random variable with distribution function: FZ(z) =    0, if z < 0, 0.1, if 0 ≤ z < 1, 0.5, if 1 ≤ z < 3, 0.8, if 3 ≤ z < 5, 1, if z ≥ 5. (Exactly one answer is correct in each question.) 1. Is E[Z] ≥ 3? (a) Yes. (b) No. 2. Is P[Z ≤ 3] = P[Z ≥ 3]? (a) Yes. (b) No. 3. Is P[3.5 ≤ Z ≤ 5.5] = 0.2? (a) Yes. (b) No. 4. What is E[Z 2]? (a) E[Z 2] = 8.1. (b) E[Z 2] = 3.5. (c) E[Z 2] = 21. (d) Doesn’t exist. (e) E[Z 2] = ∞. 5. Is P[Z = 0] = 0? (a) Yes. (b) No. Solution: 1. (b). Z is a discrete random variable and the probabilities are: P[Z = 0] = 0.1, P[Z = 1] = 0.4, P[Z = 3] = 0.3, P[Z = 5] = 0.2. Thus, E[Z] = 0 × 0.1 + 1 × 0.4 + 3 × 0.3 + 5 × 0.2 = 2.3 < 3. 1 Probability and Statistics (D-INFK) Lecturer: Prof. Dr. Dylan Possamaï Coordinator: Daniel Kršek 2. (b). We have P[Z ≤ 3] = 0.8, but P[Z ≥ 3] = 1 − P[Z < 3] = 1 − 0.5 = 0.5. 3. (a). We have P[3.5 ≤ Z ≤ 5.5] = P[Z = 5] = 0.2. 4. (a). We compute: E[Z 2] = 0 2 × 0.1 + 12 × 0.4 + 32 × 0.3 + 52 × 0.2 = 0 + 0.4 + 2.7 + 5 = 8.1. 5. (b). P[Z = 0] = 0.1 ̸= 0. Exercise 7.2. Let r > 1 and define f : R → R by f (x) = {0 for x ≤ 1, cx −r for x > 1, for some constant c ∈ R. (a) Determine the constant c such that f is a density. (b) Let X be a random variable with density fX = f . Compute the cumulative distribution function of X. (c) Compute the expected value of X. For which values of r is the expected value finite? Solution: (a) To make f a probability density function, we require ∫ f (x)dx = 1 and f ≥ 0. We have ∫ ∞ −∞ f (x)dx = ∫ ∞ 1 cx −rdx = c x−r+1 −r + 1 ∣ ∣ ∣ ∣ ∞ x=1 = c r − 1 . Thus, c = r − 1. Checking that f (x) ≥ 0, x ∈ R, is satisfied for c = r − 1 is straightforward. (b) The cumulative distribution function FX is: FX (t) = ∫ t −∞ fX (x)dx, t ∈ R. For t ≤ 1, we have FX (t) = 0 (since fX (x) = 0 on (−∞, 1]). For t > 1: FX (t) = ∫ t −∞ fX (x)dx = ∫ t 1 (r − 1)x−rdx = (r − 1) x−r+1 −r + 1 ∣ ∣ ∣ ∣ t x=1 = 1 − t −r+1. So the cumulative distribution function is: FX (t) = {0 for t ≤ 1, 1 − t −r+1 for t > 1. 2 Probability and Statistics (D-INFK) Lecturer: Prof. Dr. Dylan Possamaï Coordinator: Daniel Kršek (c) Since P[X ≥ 1] = 1, the expectation is defined. For r ̸= 2: E[X] = ∫ ∞ −∞ x · fX (x)dx = ∫ ∞ 1 x · (r − 1)x−rdx = ∫ ∞ 1 (r − 1)x−r+1dx = (r − 1) x−r+2 −r + 2 ∣ ∣ ∣ ∣ ∞ x=1 = { r−1 r−2 , if r > 2, ∞, if 1 < r < 2. For r = 2, we compute: E[X] = ∫ ∞ −∞ x · fX (x)dx = ∫ ∞ 1 x · x−2dx = ∫ ∞ 1 x−1dx = ∞. Therefore, the expected value is finite if and only if r > 2. Exercise 7.3. k ∈ N hunters each shoot once simultaneously at a flock of m ∈ N ducks. They independently choose which duck to aim at, and they hit their chosen duck independently of each other and independently of the duck selected, with probability p ∈ (0, 1). Introduce for each duck n ∈ {1, . . . , m} a random variable Xn indicating whether the duck was hit (by at least one hunter) or not. We define {Xn = 1} = “n-th duck not hit” and {Xn = 0} = “n-th duck hit”. (a) What is the distribution of Xn for n = 1, . . . , m? (b) What is the expected number of unharmed ducks? (c) Are the events {Xn = 0}, n ∈ {1, . . . , m} independent? Consider only the case k < m for simplicity. Solution: (a) Xn can take only values in {0, 1}. The probability that the n-th duck is not hit by the ℓ-th hunter is 1 − p/m. Since the hunters shoot independently, the probability that the n-th duck, and thus any duck, is unharmed is P[Xn = 1] = (1 − p m )k . Hence, all Xn follow a binomial distribution with parameters ˜n = 1 and ˜p = (1 − p/m)k, i.e., a Bernoulli distribution with parameter ˜p. (b) The total number X of unharmed ducks is X = X1 + X2 + · · · + Xm. Due to the linearity of expectation, E[X] = E[X1] + E[X2] + · · · + E[Xm]. Since the Xn are Bernoulli variables, we have E[Xn] = P[Xn = 1] = (1 − p/m)k for all n ∈ {1, . . . , m}, and thus E[X] = m (1 − p m )k . (c) We consider only the case k < m, i.e., fewer hunters than ducks. Then X1, . . . , Xm are not 3 Probability and Statistics (D-INFK) Lecturer: Prof. Dr. Dylan Possamaï Coordinator: Daniel Kršek independent because P[X1 = · · · = Xm = 0] = 0 < (1 − (1 − p m )k)m = m∏ n=1 P[Xn = 0]. Remark: The random variables X1, . . . , Xm are also not independent if k ≥ m and m > 1. In particular, X is not binomially distributed. Exercise 7.4. We consider a circle which has a random radius R. The radius R is exponentially distributed with expectation 1/λ for some λ > 0. Let us denote by A the (random) area of this circle. Determine: (a) The distribution function and the density function of A; (b) The expected value of A. Solution: (a) Let X be exponentially distributed with parameter µ, i.e., the density of X is fX (x) = µe −µx for x ≥ 0, and 0 otherwise. By integration by parts, we have: E[X] = ∫ ∞ 0 xµe−µxdx = −xe−µx∣ ∣ ∣∞ x=0 − ∫ ∞ 0 (−e−µx)dx = 0 + 1 µ ∫ ∞ 0 µe −µxdx = 1 µ ∫ ∞ −∞ fX (x)dx = 1 µ · 1 = 1 µ . Thus, since R has expectation 1/λ, we conclude that R is exponentially distributed with param- eter µ = λ. The area of the circle with radius R is given by the random variable A = πR2. The distribution function of A is: FA(x) = P[A ≤ x] = P[πR2 ≤ x] = P [R ≤ √x/π] = FR(√x/π) = ∫ √x/π −∞ fX (t)dt = ∫ √x/π 0 λe−λtdt = −e−λt∣ ∣ ∣ √x/π t=0 = 1 − e−λ √x/π, for x ≥ 0, and 0 otherwise. The density function is then given by: fA(x) = d dx FA(x) = λ 2 √πx e−λ √x/π, for x ≥ 0, and 0 otherwise. Alternatively, since FA(x) = FR(√x/π), applying the chain rule yields: fA(x) = d dx FA(x) = d dx FR(√x/π) = fR(√x/π) d dx √ x π = 1 2√xπ λe−λ √x/π for x ≥ 0, 4 Probability and Statistics (D-INFK) Lecturer: Prof. Dr. Dylan Possamaï Coordinator: Daniel Kršek and 0 otherwise. Alternatively, we may use substitution as in the sample solution to Exercise 7.5.(c) to obtain the density. (b) Using integration by parts as in (a): E[A] = E[πR2] = ∫ ∞ 0 πt 2fR(t)dt = πλ ∫ ∞ 0 t 2e−λtdt = πλ (t 2 e−λt −λ ∣ ∣ ∣ ∣ ∞ t=0 − ∫ ∞ 0 2t e −λt −λ dt) = 2π ∫ ∞ 0 te−λtdt = 2π λ2 . Remark: Of course, it is also possible to determine the expected value using the density fA from part (a). Exercise 7.5. A random variable X has the density function: f (x) =    c (1 + x)5 , x > 0, 0, x ≤ 0. (a) Find the value of c and the distribution function of X. (b) Find E[X] and E[X 2]. Hint: It might be easier to first compute E[1 + X] and E[(1 + X)2] and then use linearity. (c) What are the distribution function and the density of Y := eX ? Solution: (a) We require that ∫ ∞ −∞ f (x)dx = 1 and f ≥ 0. We compute: ∫ ∞ −∞ f (x)dx = ∫ ∞ 0 c (1 + x)5 dx = c( − 1 4 (1 + x) −4)∣ ∣ ∣∞ x=0 = c 4 yielding c = 4. Checking f ≥ 0 for c = 4 is straightforward. The distribution function is: FX (x) = P[X ≤ x] = ∫ x −∞ f (y)dy = ∫ x 0 4 (1 + y)5 dy = −(1 + y)−4∣ ∣x y=0 = 1 − 1 (1 + x)4 , for x ≥ 0, and 0 otherwise. (b) We first compute: E[1 + X] = ∫ ∞ 0 (1 + x) · 4 (1 + x)5 dx = ∫ ∞ 0 4 (1 + x)4 dx = 4 ( − 1 3 (1 + x)−3)∣ ∣ ∣ ∣ ∞ x=0 = 4 3 , E[(1 + X) 2] = ∫ ∞ 0 4 (1 + x)3 dx = 4 ( − 1 2 (1 + x) −2)∣ ∣ ∣ ∣ ∞ x=0 = 2. 5 Probability and Statistics (D-INFK) Lecturer: Prof. Dr. Dylan Possamaï Coordinator: Daniel Kršek Thus, E[X] = E[1 + X − 1] = E[1 + X] − 1 = 1 3 , E[X 2] = E[(1 + X) 2 − 2X − 1] = E[(1 + X) 2] − 2E[X] − 1 = 2 − 2 3 − 1 = 1 3 . (c) Since X ≥ 0, it follows that Y = eX ≥ 1. For y < 1, the distribution function FY of Y thus satisfies: FY (y) = P[Y ≤ y] = P[eX ≤ y] ≤ P[eX < 1] = P[X < 0] = 0. For y ≥ 1, we get: FY (y) = P[eX ≤ y] = P[X ≤ log y] = FX (log y) = 1 − 1 (1 + log y)4 . By differentiating the distribution function, we get the density fY of Y : fY (y) = d dy FY (y) = { 0 for y < 1, 4 y(1+log y)5 for y ≥ 1. Alternatively, we have for y > 1 that FY (y) = P[eX ≤ y] = P[X ≤ log y] = ∫ log(y) 0 4 (1 + x)5 dx = ∫ y 1 4 t(1 + log t)5 dt = ∫ y −∞ fY (t)dt, where we have used the substitution t = ex in the second-to-last equality. We thus obtain the same result as above. 6","libVersion":"0.5.0","langs":""}
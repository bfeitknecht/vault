{"path":"sem3/LinAlg/PV/cheatsheets/LinAlg-cheatsheet-robin.pdf","text":"LinAlg Cheatsheet Robin Frauenfelder – robinfr@ethz.ch Version: 4. Juni 2019 Dieses Cheatsheet wurde im Laufe meiner ¨Ubungsstunde er- stellt. Falls ihr Fehler entdeckt oder etwas Wichtiges fehlt, bitte schreibt mir eine E-Mail. (robinfr@ethz.ch) 1. Lineare Gleichungssysteme 1.1 Zeilenstufenform Jedes lineare Gleichungssystem kann durch wiederholtes Ausf¨uhren folgender drei Rechenoperationen in die sogenannte Zeilenstufenform gebracht werden (Gaussalgorithmus): 1 Zeilen vertauschen 2 Ein Vielfaches einer Zeile zu einer anderen addieren 3 Eine Zeile mit beliebigem Skalar 0 multiplizieren x1 x2 x3 xj xn 1 b1 00 b2 000 b1 . . . . . . . . . . . . . . . . . . 000 br 000 0 0 br 1 . . . . . . . . . . . . . . . . . . 000 0 0 bmm:AnzahlGleichungenr:Rang n: Anzahl Unbekannte Keine L¨osung: r m und bi 0 i r Eindeutige L¨osung: r n m Unendlich L¨osungen: r n und bi 0 i r Anzahl freie Parameter: n r Ax = b f¨ur beliebiges b l¨osbar: Voller Rang: r m oder m n,und Ax 0 hat nur die triviale L¨osung x 0 Ax = b f¨ur beliebiges b eindeutig l¨osbar: Voller Rang: r m und gleich viele Gleichungen wie Unbekannte: m n 1.2 Homogenes Lineares Gleichungssystem x1 x2 xn 1 a11 a12 a1n 0 a21 a22 a2n 0 . . . . . . . . . . . . am1 am1 amn 0Nullvektor Hat immer die triviale L¨osung x 0 Hat ausschliesslich die triviale L¨osung, wenn Rang vollst¨andig (r n)und dadurch det A 0 Hat zus¨atzlich nichttriviale L¨osungen, wenn Rang nicht vollst¨andig (r n)und dadurch det A 0 2. Matrizen 2.1 Matrixschreibweise Ein lineares Gleichungssystem kann damit in Matrixschreibwei- se dargestellt werden: x1 x2 1 a11 a12 b1 a21 a22 b2 a31 a32 b3 a11 a12 a21 a22 a31 a32 x1 x2 b1 b2 b3 2.2 Matrixmultiplikation Matrizen k¨onnen auf folgende Weise miteinander multipliziert werden: A B C cik n j 1 aij bjk N x L M x N A M x L C B Assoziativ- & Distributivgesetz: A B C A B C A B C A C B C A C D A C A D Achtung! Kommutativgesetz gilt nicht! i.A. A B B A 2.3 Identit¨atsmatrix Die Identit¨ats- oder Einheitsmatrix ist eine quadratische Ma- trix, deren Hauptdiagonalenelemente eins und deren Ausserdia- gonalelemente 0 sind. In 10 0 01 0 . . . . . . . . . 00 1 Rn n Rechenregel: Am n In Im Am n Am n 2.4 Diagonal- und Dreiecksmatrizen Eine Diagonalmatrix ist eine quadratische Matrix, deren Ele- mente ausserhalb der Hauptdiagonalen Null sind. D diag d1,d2,d3 d1 00 0 d2 0 00 d3 Eine Dreiecksmatrix ist eine quadratische Matrix, deren Ele- mente entweder oberhalb oder unterhalb der Hauptdiagonalen Null sind. Man unterscheidet zwischen einer Rechtsdreiecks- matrix und einer Linksdreiecksmatrix. R r11 r12 r13 0 r22 r23 00 r33 L l11 00 l21 l22 0 l31 l32 l33 F¨ur Diagonal- und Dreiecksmatrizen gilt: det A a11 a22 a33 ann eig A a11,a22, ,ann 2.5 Transponierte Die Transponierte einer Matrix erh¨alt man, indem man sie an ihrer Diagonalen ” spiegelt“. Bsp: ab cd ef T ac e bd f Rechenregeln: A B T AT BT A B T BT AT c A T c AT AT T A AT 1 A 1 T rang AT rang A det AT det A eig AT eig A 2.6 Inverse Die Inverse einer quadratischen Matrix ist das Analogon des Kehrwerts eines Skalars. A 1 A A A 1 I Eigenschaften: Nur quadratische Matrizen k¨onnen invertierbar sein. Eine Matrix ist dann invertierbar, wenn sie vollen Rang hat. Eine invertierbare Matrix nennt man regul¨ar,eine nicht in- vertierbare singul¨ar. Die Inverse ist eindeutig. Sind A und B invertierbar, so ist auch AB invertierbar. Ist A invertierbar, so ist auch AT invertierbar. Ist A symmetrisch, so ist auch A 1 symmetrisch. Ist A eine Dreiecksmatrix, so ist auch A 1 eine Dreiecks- matrix. det A 0 Aist invertierbar. Eine Matrix ist invertierbar, wenn kein Eigenwert ⁄ 0 Gauss-Jordan Algorithmus: Methode zur Bestimmung der Inversen. Man schreibt die Ma- trix und die Identit¨at nebeneinander auf bringt die Identit¨at durch gaussen auf die andere Seite. 12 0 10 0 23 0 01 0 34 1 00 1 10 0 320 01 0 2 10 00 1 1 21 A A 1 Adjunktenformel f¨ur 2x2-Matrizen: ab cd 1 1 ad bc d b ca Rechenregeln: I 1 I A 1 1 A Ak 1 A 1 k c A 1 c 1 A 1 A B 1 B 1 A 1 AT 1 A 1 T rang A 1 rang A det A 1 det A 1 eig A 1 eig A 1 2.7 Orthogonale Matrizen Eine quadratische Matrix ist orthogonal, wenn sie aus zuein- ander orthogonalen Vektoren der L¨ange 1 besteht. Dies ist der Fall, wenn eine Matrix mit der Transponierten multipliziert die Identit¨at ergibt. AT A I Multipliziert man einen Vektor mit einer orthogonalen Matrix, kann sich seine Orientierung ¨andern, jedoch nicht seine L¨ange. Abbildungen sind deshalb kongruent. Eigenschaften: A orthogonal Spalten/Zeilen von A sind zueinander or- thogonale Vektoren der L¨ange 1. Nur quadratische Matrizen k¨onnen orthogonal sein. A und B orthogonal A B orthogonal. A orthogonal A 1 orthogonal. A 1 AT det A 1 Drehungs- und Spiegelungsmatrizen: Drehung um Ursprung im R2: R – cos – sin – sin – cos – Drehung um x-Achse im R3: Rx – 10 0 0 cos – sin – 0 sin – cos – Drehung um y-Achse im R3: Ry – cos – 0 sin – 01 0 sin – 0 cos – Drehung um z-Achse im R3: Rz – cos – sin – 0 sin – cos – 0 00 1 Spiegelung an Ebene durch 0 im Rn mit n als Normalenvektor: H I 2 n nT 2.8 LR(P)-Zerlegung P A L R 1 LR Zerlegung durchf¨uhren 2 Ly Pb nach y auﬂ¨osen 3 Rx y nach x auﬂ¨osen L, R und P bestimmen: 10 0 2 3 2 01 0 0 21 00 1 2 11 0 0 1 2 1 1 0 1 0 0 3 2 1 0 0 2 0 1 P 00 1 01 0 10 0 R 2 11 03 2 00 1 L 10 0 01 0 20 1 2 :Von dieserZeilewurdedas2-facheeineranderen subtrahiert 1 1 Eitnwerte 2.7 Symmetrische Matrizen Eine symmetrische Matrix ist eine quadratische Matrix, de- ren Eintr¨age spiegelsymmetrisch bez¨uglich der Hauptdiagona- len sind. Dies ist der Fall, wenn sie gleich ihrer Transponierten ist: ST S Eigenschaften: AT A und AAT sind immer symmetrisch. Die Eigenwerte von S sind alle reell. Ist x ein Eigenvektor von A zum Eigenwert ⁄,sosind auch konj x , Re x , Im x Eigenvektoren zum selben Eigen- wert ⁄ Die Eigenvektoren zu unterschiedlichen Eigenwerten sind or- thogonal zueinander. Aist halbeinfach,alsodiagonalisierbar. Abesitzt eineorthonormaleEigenbasis. Transformationsmatrix in Eigenbasis T orthogonal. 3. Determinante 3.1 Deﬁnition Determinante Die Determinante ist eine Zahl, die einer quadratischen Ma- trix zugeordnet wird und aus ihren Eintr¨agen berechnet werden kann. Die folgenden Spalten/zeileneigenschaften sind Teil ihrer Deﬁnition. Zeileneigenschaften: aa Vertauscht man zwei Zeilen von A, so ¨andert sich das Vor- zeichen der Determinante. Addiert man ein Vielfaches einer Zeile zu einer anderen, so ¨andert sich die Determinante nicht. Spalteneigenschaften: Vertauscht man zwei Spalten von A, so ¨andert sich das Vor- zeichen der Determinante. Addiert man ein Vielfaches einer Spalte zu einer anderen, so ¨andert sich die Determinante nicht. Folgerungen aus Zeilen/Spalteneigenschaften: Hat A zwei gleiche Zeilen/Spalten, so gilt det A 0. Hat A eine Nullzeile/spalte, so gilt det A 0 det – An n – n det A 3.2 Rechenregeln Determinante Neben den Zeilen/Spalteneigenschaften von 3.1 gelten folgen- de Rechenregeln: det AB det A det B det AT det A det diag d1,d2, ,dn d1 d2 dn det Dreiecksmatrix d1 d2 dn det A 1 1 det A 3.3 Berechnungsmethoden Determinante Es gibt verschiedene Methoden, die Determinante zu bestim- men. Je nach Matrix eignen sich unterschiedliche Rechnungs- wege oder Kombinationen davon. Fertige Formeln Eignen sich nur bei kleinen Matrizen. Meistens f¨ur 3x3-Matrix bereits zu kompliziert. 1x1: a a 2x2: - - -ab cd - - - ad cb 3x3: - - - - ab c de f gh i - - - - aei bf g cdh gec hf a idb Laplace’scher Entwicklungssatz: Bei den meisten Matrizen ine\u0000zient. Kann jedoch bei Matrix mit vielen Nullen in einer Zeile oder Spalte geschickt angewen- det werden. 1 Zeile oder Spalte ausw¨ahlen. (Dort wo viele Nullen). 2 Jedem Element dieser Zeile/Spalte ein Vorzeichen zu- ordnen (Schachbrett). 3 F¨ur jedes Element die zugeh¨orige Zeile und Spalte strei- chen und Unterdeterminante bestimmen. 4 Jede Unterdeterminante mit zugeh¨origem Element und Vorzeichen multiplizieren und addieren. Bsp: Entwicklung nach erster Spalte: - - - - 1 21 3 85 0 32 - - - - 1 - - -85 32- - - 3 - - -21 32- - - 0 Anwenden von Zeilen/Spalteneigenschaften Durch vertauschen von Spalten/Zeilen (Vorzeichen¨anderung) oder Zeilen/Spaltenaddition (Determinante bleibt gleich) l¨asst sich die Matrix oft in eine einfachere Form bringen. Blocksatz Oft in Kombination mit ” Anwenden von Zeilen/Spalteneigen- schaften“ n¨utzlich. LR-Zerlegung Nur sinnvoll, wenn LR-Zerlegung bereits vorliegt. det A 1 #Zeilenvertauschungen r11 r22 rnn 3.4 Wichtige Zusammenh¨ange Folgende Aussagen sind f¨ur An n ¨aquivalent: rang A n Das LGS Ax b ist f¨ur beliebiges b l¨osbar. Das LGS Ax b besitzt genau eine L¨osung. Das homogene LGS Ax 0 besitzt nur die triviale L¨osung. Die Zeilen/Spalten von A sind linear unabh¨angig. A ist invertierbar det A 0 Die Spalten von A bilden ein Erzeugendensystem in Rn 4. Vektorr¨aume 4.1 Deﬁnition Vektorraum Sei V eine Menge von Objekten. V heisst Vektorraum, wenn eine innere Operation (Kombination von zwei Objekten) und eine ¨aussere Operation (Kombination eines Objekts mit einem Skalar) deﬁniert sind, und folgende Axiome gelten: Innere Operation: : V V V a, b a b ¨Aussere Operation: : K V V –, a – a Axiome: (A1) u, v V : (A2) u, v, w V : (A3) 0 V, u V : (A4) u V, u V : (M1) –, — R, u V : (M2) –, — R, u, v V : (M3) u V : u v v u u v w u v w u 0 u u u 0 – — u – — u – — u – u — u – u v – u – v 1 u u 4.2 Deﬁnition Unterraum Eine nichtleere Teilmenge eines Vektorraums V heisst Unter- raum von V, falls: 1 a, b U : a b U 2 a U, – K : – a U Ein Unterraum ist selber ein Vektorraum. Ein Unterraum muss den Nullvektor enthalten! 4.3 Linearkombination Eine Linearkombination ist eine Summe von mit Skalaren xi multiplizierten Vektoren vi.(vi V, xi K) w x1 v1 x2 v2 xn vn w V x hat L¨osung (V v 1 ,v 2 , ,v n ) w ist Linearkombination von vi. 4.4 Lineare Unabh¨angigkeit xi vi 0 Die Vektoren vi sind linear unabh¨angig, falls die Summe nur die triviale L¨osung x1 x2 xi 0 hat. Pr¨ufen, ob Vektoren linear unabh¨angig: 1 Matrix mit Vektoren als Spalten erstellen: V v 1 ,v 2 , ,v n 2 Der Rang ist die Anzahl der linear unabh¨angigen Vek- toren. rang V n Vektoren sind linear unabh¨angig. 4.5 Span, Erzeugendensystem und Basis Die lineare H¨ulle span v1,v2, ,vn ist die Menge aller endlichen Linearkombinationen der vi mit Skalaren aus R. Falls f¨ur einen Vektorraum gilt span v1,v2, ,vn V , heisst v1,v2, ,vn ein Erzeugendensystem von V. Falls ein Erzeugendensystem f¨ur V aus linear unabh¨angigen Vektoren besteht, heisst es Basis von V. Jeder Vektor kann eindeutig als Linearkombination von Basisvektoren dargestellt werden. Aus Erzeugendensystem Basis ﬁnden: 1 Matrix aufstellen, deren Zeilen aus den transponierten erzeugenden Vektoren besteht. 2 Mit Gaussalgorithmus in Zeilenstufenform bringen. Da- durch wird lineare Abh¨angigkeit eliminiert. 3 Die verbleibenden Nicht-Nullzeilen sind Basisvektoren. 4.6 Basiswechsel Sei V n ein Vektorraum mit Basen Q q1,q2,..., qn und W w1,w2,...,wn .Sei v ein Vektor V . Basiswechsel von v q nach v w durchf¨uhren: 1 ¨Ubergangsmatrix: Tq w q1 w,..., qn w 2 v w Tq w v q Tipps: Tw q T 1 q w Meist ist eine der beiden Basen die Standardbasis S.Die ¨Ubergangsmatrix Tq s ist dann sehr einfach bestimmbar. Die entegengesetzte ¨Ubergangsmatrix wird am Schnellsten durch invertieren gefunden. Basiswechsel f¨ur Matrizen: A w Tq w A q T 1 q w Falls T orthogonal: T 1 T T 4.7 Koordinaten Sei V ein Vektorraum mit Basis B b1, ,bn .Dann kann jeder Vektor x V in eindeutiger Weise als Linearkombination x n i 1 xi bi dargestellt werden. Die Koe\u0000zienten x1, ,xn heissen Ko- ordinaten von x bez¨uglich der Basis B. 2 2 AllesistvonOl vaderpolynomuswlinearabhängig 5. Lineare Abbildungen 5.1 Deﬁnition Lineare Abbildung Eine Abbildung F heisst linear,falls x, y V, – K 1 F x y F x F y 2 F – x – F x Eine Abbildung ist linear bildet 0 auf 0 ab! Eine Abbildung zwischen endlichdimensionalen VR ist linear kann mit einer m n-Matrix A mit Hilfe der Matri- zenmultiplikation dargestellt werden. 5.2 Kern und Bild einer Matrix Kern: Der Kern einer Matrix ist die Menge aller Vektoren, die durch Multiplikation auf den Nullvektor abgebildet werden. Kern A x Rn A x 0 Kern bestimmen: Gleichungssystem Ax 0 l¨osen. Meistens (wenn Rang nicht voll) gibt es unendlich viele L¨osungen. Der L¨osungsraum (am besten dargestellt als Line- arkombination von mit Parameter multiplizierten Vektoren) ist der Kern der Matrix. Bild: Das Bild einer Matrix A ist die Menge aller Bildvekto- ren, also aller m¨oglichen ” Ergebnisse“einer Multiplikation von Amit einem beliebigen Vektor. Bild A y Rm x Rn sodass y A x Bild bestimmen: Bild span a 1 ,a 2 ...a n Das Bild wird von den Spalten aufgespannt. Es reicht also, einfach die Spaltenvektoren hinzuschreiben. Achtung: Die Spaltenvektoren sind immer ein Erzeugenden- system des Bildes, jedoch nicht unbedingt eine Basis! Um Basis zu erstellen: Siehe 4.5 Zusammenh¨ange dim Bild A Rang A f¨ur Am n: dim Bild A dim Kern A n Bild A Kern AT Fredholm Alternative: Ax b ist l¨osbar (b liegt im Bild) genau dann, wenn b senkrecht auf allen L¨osungen des ad- jungierten LGS AT y 0 steht. 5.3. Abbildungsmatrix von gegebener Abbildung bestimmen Idee: Wir bilden zuerst die Basisvektoren ab und konstruieren uns aus den Ergebnissen unsere Matrix. Bsp: P2 P1 : p x p x 1 Finde Basis f¨ur Vektorraum aus dem man abbildet und f¨ur Vektorraum in den man abbildet. Bsp: Basis f¨ur P2 x 2,x, 1 Basis f¨ur P1 x, 1 2 ¨Uberlege, was nach gegebener Abbildungsvorschrift mit den Basisvektoren passiert und schreibe die Ergebnisse in Vektorschreibweise. Bsp: x 2 2 x 20 T x 1 01 T 1 0 00 T 3 Resultate von Punkt 2 sind Spalten der gesuchten Ma- trix. (Multiplikation mit Basisvektor = Extraktion von Spalte) Bsp: A 20 0 01 0 6. Eigenwertproblem 6.1 Deﬁnition Eigenwerte und Eigenvektoren ⁄ C heisst Eigenwert von An n,falls dieserf¨ur einen be- stimmten Vektor v A v ⁄ v erf¨ullt. Der zum Eigenwert ⁄ zugeh¨orige Vektor v Cn heisst Eigenvektor. 6.2 Eigenwerte bestimmen 1 Bestimme die Determinante det A ⁄ I Das Resultat ist das ”charakteristische Polynom” p ⁄ 2 Bestimme die Nullstellen: p ⁄ 0. Die Nullstellen ⁄i heissen Eigenwerte. Berechnung ¨uberpr¨ufen Spur A a11 a22 ... ann ⁄i det A ⁄i 6.3 Eigenvektoren bestimmen Nach dem Bestimmen der Eigenwerte k¨onnen die zugeh¨origen Eigenvektoren bestimmt werden. 1 Setze einen Eigenwert ⁄k in A ⁄k I ein 2 L¨ose das Gleichungssystem A ⁄k I x 0 3 Das Gleichungssystem hat unendlich viele L¨osungen. Man erh¨alt einen oder mehrere mit freien Parametern multiplizierte Eigenvektoren vk. Eigenschaften Eigenvektoren sind per Deﬁnition 0 Eigenvektoren sind linear unabh¨angig. 6.4 Algebraische und geometrische Vielfachheit 1 gVfh. von ⁄ algVfh. von ⁄ n Algebraische Vielfachheit Die algebraische Vielfachheit ist die Vielfachheit einer Nullstelle im charakteristischen Polynom p ⁄ beim jeweiligen Eigenwert ⁄. Bsp: p ⁄ ⁄ 3 2 ⁄ 2 ⁄ 3 hat algVfh. 2 und ⁄ 2 hat algVfh. 1 Geometrische Vielfachheit Die geometrische Vielfachheit von ⁄ ist die Anzahl der zum EW geh¨origen EV = Anzahl der freien Parameter. 6.5 (Halb)einfache Matrizen und Eigenbasis Einfachheit Eine Matrix ist halbeinfach jedes ⁄ hat algVh = gVfh Eigenbasis: Die Eigenvektoren einer Matrix A Cn n bilden einen Basis f¨ur Cn die Matrix ist halbeinfach. 6.6 Diagonalisierbarkeit Eine quadratische Matrix A heisst diagonalisierbar, falls eine regul¨are Matrix T existiert, sodass D T 1AT eine Diago- nalmatrix ist. A halbeinfach A diagonalisierbar Matrix diagonalisieren 1 Bestimme die Eigenwerte ⁄i und die Eigenvektoren vi 2 Die Matrix D diag ⁄1,..., ⁄n ist eine Diagonal- matrix mit den Eigenwerten auf der Diagonalen. 3 Die Matrix T v1,...,vn hat die Eigenvektoren als Spalten (Gleiche Reihenfolge wie bei D!). 4 Bestimme T 1.FallsEVorthogonal T 1 T T Potenzen und Exponentialfunktion Potenzen/Exponentialfunktionen von diagonalisierbaren Matri- zen k¨onnen einfach berechnet werden: Ak TDT 1 k T diag ⁄ k 1 ,..., ⁄ k n T 1 eA e TDT 1 T diag e⁄1 ,...,e⁄n T 1 6.7 ¨Ahnlichkeit A und B heissen ¨ahnlich, falls f¨ur eine beliebige Matrix T gilt: A T 1BT ¨Ahnliche Matrizen haben: die gleichen Eigenwerte die gleiche Determinante Satz: Ist v ein EV von A zum EW ⁄,so ist y T 1v ein EV von B zum selben EW. 7. Normen 7.1 Deﬁnition Vektornorm Eine Norm im Vektorraum V ordnet jedem Vektor v eine relle Zahl v zu und kann so als eine Art Mass verstanden werden. Sie muss folgende Bedingungen erf¨ullen: 1 v 0 und v 0 v 0 2 – v – v 3 v w v w 7.2 Lp-Normen im Rn Allgemeine Lp-Norm: v p p vi p Beispiele L1-Norm: v 1 v 1 v 2 ... v n L2-Norm: v 2 v 2 1 v 2 2 ... v 2 n L -Norm: v max v 1, v 2,..., v n . 7.3 Lp-Normen f¨ur Funktionen Allgemeine Lp-Norm: f p b a f x pdx 1 p Beispiele L1-Norm: f 1 b a f x dx (Gibt den Betrag der Fl¨ache unter der Kurve an) L -Norm: f max f x : x a, b (Gibt den maximalen Ausschlag an) 7.4 Matrixoperatornormen A max x 2 1 Ax 2 Beispiele A quadratisch: A ⁄max AT A A symmetrisch: A ⁄max A A orthogonal: A 1 A regul¨ar: A 1 1 ⁄min AT A 8. Skalarprodukt 8.1 Deﬁnition Skalarprodukt Ein Skalarprodukt ordnet jedem Paar x, y von Vektoren eine Zahl x, y zu. Es muss folgende Bedingungen erf¨ullen: 1 x, y z x, y x, z 2 x, –y – x, y 3 x, y y, x 4 x, x 0 und x, x 0 x 0 Beispiele f¨ur Skalarprodukte Standardskalarprodukt auf Rn: x, y x T y Funktionenskalarprodukt: f, g b a f x g x dx 8.2 Von Skalarprodukt induzierte Norm Aus einem Skalarpodukt kann eine Norm induziert werden. Die- ser Ausdruck erf¨ullt alle Axiome f¨ur eine Norm (siehe 7.1.) x x, x 8.3 Orthogonalit¨at und Orthogonalprojektion Zwei Vektoren sind orthogonal, falls x, y 0. Notation: x y Die Orthogonalprojektion des Vektors x auf Vektor y ist: z x,y y,y y 8.4 Gram-Schmidtsches Orthonormalisierungsverfahren Ziel des Gram-Schmidtschen Orthonormalisierungsverfahrens ist, aus einer beliebigen Basis eine sogenannte Orthonormal- basis zu erzeugen. 3 3 Vektoraufunter raum sein6 Bei einer Orthonormalbasis sind alle Basisvektoren: orthogonal zueinander: bi,bj 0 Einheitsvektoren: bi bi,bi 1 Orthonormalisierungsverfahren durchf¨uhren: F¨ur die Durchf¨uhrung ben¨otigt man eine beliebige Basis, sowie ein beliebiges Skalarprodukt (meistens gegeben). 1 W¨ahle beliebigen ersten Basisvektor b1 und normiere mit von Skalarprodukt induzierter Norm. e1 b1 b1 b1 b1,b1 2 W¨ahle zweiten Basisvektor b2.Zuerstzu b1 parallelen Teil abziehen, und dann normieren. e2 b2 b2,e1 e1 e2 e 2 e 2 e 2 e 2,e 2 3 Wiederhole f¨ur jeden weiteren Basisvektor bi: ei bi bi,e1 e1 bi,e2 e2 ... bi,ei 1 ei 1 ei ei ei e i ei,e i 9. Quadratische Formen 9.1 Deﬁnition Quadratische Form Quadratische Formen sind bestimmte Funktionen, die mit einer symmetrischen Matrix A und einem Vektor x Rn gebildet werden. Es kommen maximal quadratische Terme vor. qa x1,x2,...,xn q x x T Ax Quadratische Formen, die mit einer diagonalen Matrix ge- bildet werden (siehe qc)nennt man rein quadratisch. Die symmetrische Matrix A legt die Gestalt der entstehen- den Fl¨ache fest. Beispiele: qb x1,x2 x1 x2 12 21 x1 x2 12 x1 x2 x 2 1 4x1x2 x 2 2 x1 2x2 qc x1,x2,x3 x1 x2 x3 20 0 03 0 00 1 x1 x2 x3 2x 2 1 3x 2 2 3x 2 3 9.2 Deﬁnitheit einer quadratischen Form Eine quadratische Form heisst: positiv deﬁnit: q x 0 x 0 negativ deﬁnit: q x 0 x 0 positiv semideﬁnit: q x 0 x 0 negativ semideﬁnit: q x 0 x 0 indeﬁnit: sonst Um die Deﬁnitheit einer quadratische Form zu bestimmen, be- stimme man die Deﬁnitheit der zugeh¨origen symmetrischen Matrix A (siehe 9.3) 9.3 Deﬁnitheit einer symmetrischen Matrix Variante 1: Bestimmung der Eigenwerte Die erste M¨oglichkeit ist, die Deﬁnitheit durch die Eigenwerte zu bestimmen. Eine symmetrische Matrix heisst: positiv deﬁnit: Alle ⁄ 0 negativ deﬁnit: Alle ⁄ 0 positiv semideﬁnit: Alle ⁄ 0 negativ semideﬁnit: Alle ⁄ 0 indeﬁnit: sonst Variante 2: Hurwitz-Kriterium Die zweite M¨oglichkeit ist, die Deﬁnitheit durch Bestimmung von Unterdeterimanten zu bestimmen: A a b c d e f g h i A1 a , A2 ab de , A3 ab c de f ge h positiv deﬁnit: Alle det Ai 0 f¨ur i 1,...,n negativ deﬁnit: Alle det Ai 0 f¨ur i 1, 3, 5,... Alle det Ai 0 f¨ur i 2, 4, 6,... 9.4 Extrema einer quadratischen Form Kritische Punkte ﬁnden: Man setze den Gradienten der quadratischen Form grad q x dq dx1 , dq dx2 ,..., dq dxn T 0.Durch L¨osen des Gleichungssystems erh¨alt man die Koordinaten der kritischen Punkte. Kritische Punkte zuordnen: 1 Bilde Hessesche Matrix in der richtigen Dimension f¨ur jeden kritischen Punkt: Bsp: H2x2 dq x 2 d2x1 dq x 2 dx1x2 dq x 2 dx1x2 dq x 2 d2x2 2 Bestimme Deﬁnitheit der Matrix (siehe 9.3). positiv deﬁnit lokales Minimum negativ deﬁnit lokales Maximum indeﬁnit Sattelpunkt 9.6 Quadriken Setzt man eine quadratische Form in eine Gleichung folgender Form ein (x Rn,a Rn,b R), erh¨alt man eine sogenannte Quadrik: q x a T x b 1 Ist die quadratische Form zweidimensional, erh¨alt man einen sogenannten Kegelschnitt, ist sie dreidimensional erh¨alt man eine Fl¨ache zweiten Grades. 9.6 Hauptachsentransformation einer quadratischen Form Wir k¨onnen durch zwei Koordinatentransformationen (Drehung y Tx und Verschiebung z y c) jede quadratische Form rein quadratisch machen. W¨ahrend der Koordinatenvektor x die quadratische Form in der Standardbasis darstellt, stellt der Koordinatenvektor z die quadratische Form in der neuen Basis dar. Die Basis, in der q x rein quadratisch wird, ist die Eigenbasis der zugeh¨origen symmetrischen Matrix A. Bsp: q x x 2 1 x 2 2 3x 2 3 6x1x2 Vorgehen: Je nach Aufgabe m¨ussen nicht alle Punkte durchgef¨uhrt wer- den. F¨ur ausschliesslich Hauptachsentransformation reicht 1-3. 1 Man bestimme die symmetrische Matrix A Rn n, sodass q x x T Ax Trick: ax 2 1 bx1x2 cx 2 2 A ab 2 b 2 c Bsp: A 1 30 31 0 00 3 2 Man diagonalisiere die Matrix A (siehe 6.6) und be- stimmte die Transformationsmatrix T .Da A symme- trisch ist, ist T orthogonal und T 1 T T . T orthogonal, Spalten von T normieren! Bsp: D 300 0 20 00 4 ,T 01 2 1 2 01 21 2 10 0 3 Multipliziere aus: q y yT D y.Wir haben nun unsere Hauptachsentransformation durchgef¨uhrt. Bsp: yT Dy 3y2 1 2y2 2 4y2 3 4 Falls in Aufgabe gefragt: Bringe Quadrik q x a T x b 1 in Normalform. Bestimme a Rn und b R. Bsp: q x 3x3 1 3 1 a 0 0 3 ,b 1 3 5 Schreibe Quadrik in transformierter Form (ausmultipli- zieren): yT Dy a T Ty b 1 Bsp: yT Dy a T Ty b 3y2 1 2y2 2 4y2 3 2y1 1 3 1 6 Falls noch lineare Terme ¨ubrig: Erg¨anze quadratisch Bsp: 0 3y2 1 2y2 2 4y2 3 2y1 4 3 3 y2 1 2 3 y1 2y2 2 4y2 3 4 3 3 y1 2 2 3 2 2 2 3 2 2y2 2 4y2 3 4 3 3 y1 2 2 3 2 2y2 2 4y2 3 4 3 3 1 3 2 3 y1 1 3 2 2y2 2 4y2 3 1 Durchf¨uhrung der zweiten Koordinatentransformation z y c (Verschiebung). Man bestimme Vektor c. Danach enth¨alt die Gleichung nur noch rein quadrati- sche Terme. Bsp: c 1 3 0 0 Q z 3z2 1 2z2 2 4z2 3 7 Falls gefragt: Gib die zusammengesetzte Koordinaten- transformation an: z T T x c Welche Hauptachse schneidet q x a 0 nicht? Die mit dem negativen Eigenwert. Jeder Vektor auf dieser Ach- se gibt in q x eingesetzt eine negative Zahl. Wie skizziere ich die Quadrik in Normalform? In Normalform ist es nicht schwer, mehrere Punkte einzusetzen und dann Linien durchzuziehen. Wie skizziere ich die Quadrik im urspr¨unglichen System? Skizziere zuerst in Normalform und transformiere Skizze mit Drehungsmatrix T und Verschiebungsvektor c. Welche Punkte sind dem Ursprung am n¨achsten? Falls Koordinatentransformation nur aus Drehung y Tx be- stand, sind die gleichen Punkte dem Ursprung am n¨achsten wie in der Normalform. 10. Kleinste Quadrate 10.1 Kleinste Quadrate Mit dem Prinzip der ” kleinsten Quadrate“ kann man zwar ¨uberbestimmte Gleichungssysteme nicht l¨osen, man kann je- doch eine m¨oglichst ” gute“ L¨osung ﬁnden, indem man den qua- dratischen Fehler minimiert. Bsp: 2x1 3x2 6 3x1 4x2 8 2x1 1x2 3 ¨uberbestimmt Wir bilden die Di\u0000erenz (= Fehler) aus der rech- ten und der linken Seite und nennen sie Residu- envektor r: 2x1 3x2 6 r1 3x1 4x2 8 r2 2x1 1x2 3 r3 Wir suchen x1 x2 T ,sodass r minimal. quadratischer Fehler minimal Vorgehen: Meist ist das Gleichungssystem in Aufgabe bereits in Form A x c r gegeben (siehe oben). 1 Man bestimme A und c Bsp: A 23 34 21 ,c 6 8 3 2 Man berechne AT A und AT c Bsp: AT A 17 20 20 26 ,AT c 42 53 3 Man l¨ose das Gleichungssystem AT A x AT c Bsp: 17 20 20 26 x1 x2 42 53 x 2.67 0.17 10.2 QR-Zerlegung Mit der QR-Zerlegung kann eine beliebige Matrix A Rm n in das Produkt einer orthogonalen Matrix Q Rn n und einer oberen Rechtsdreiecksmatrix R Rm n verwandelt werden: A Q R Vorgehen: Wir wollen nacheinander alle Elemente unterhalb der Haupt- diagonalen von A eliminieren. 1 Man w¨ahle zu eliminierendes Element und benenne es aij . Bsp: A 10 01 1 1 a31 soll eliminiert werden 2 Lese i, j ab und notiere ajj ,aij Bsp: i 3,j 1 ajj 1,aij 1 3 Berechne w a2 jj a2 ij Bsp: w 12 12 2 4 Man ﬁnde die richtige Rotationsmatrix Q T .Man neh- me zuerst die Identit¨atsmatrix I Rm m und set- ze iii cos – , iij sin – , iji sin – , ijj cos – . 4 4 gtformationsmits nurnochquadratischeTerme seite6mehr Normalformin zuordinalensystem T.rs B T.pe P Bsp: I 10 0 01 0 00 1 Q T cos – 0sin – 01 0 sin – 0cos – 5 Setze in Rotationsmatrix sin – aij w und cos – ajj w Bsp: Q T 1 20 1 2 01 0 1 20 1 2 6 Berechne Q T A A Bsp: 1 20 1 2 01 0 1 20 1 2 10 01 11 21 2 01 01 2 7 Falls A keine obere Dreiecksmatrix, wiederhole (ﬁnde Q T etc.) bis alle n¨otigen Elemente eliminiert. Bsp: Q T 10 0 0 2 31 3 0 1 3 2 3 ,A 21 2 0 3 2 00 8 Wenn A R gefunden, berechne Q Q T Q T T A Q R Kleinste Quadrate mit QR-Zerlegung L¨ost man ein Optimierungsproblem mit dem Computer, liefert das in 10.1 beschriebene Verfahren ungenaue L¨osungen (da nu- merisch instabil). Das L¨osungsverfahren mittels QR-Zerlegung ist besser. In Aufgabe nur machen, wenn explizit verlangt! Vorgehen: 1 Man bestimme A und c wie bei 10.1. Bsp: A 10 01 11 ,c 1 0 1 2 Man f¨uhre die QR-Zerlegung durch A QR Bsp: Q 1 21 61 3 0 2 3 1 3 1 21 61 3 ,R 21 2 0 3 2 00 3 Man berechne d Q T c Bsp: d Q T c 0 2 3 2 3 4 Man l¨ose das Gleichungssystem R0 x d0,wobei R0 die extrahierte Dreiecksmatrix aus R ist und d0 die dazugeh¨origen oberen Eintr¨age von d Bsp: R0 21 2 0 3 2 ,d0 0 2 3 11. Lineare Di\u0000’gleichungssysteme 11.1 L¨osen von homogenem Di\u0000’gleichungssystem Man sucht eine L¨osung f¨ur ein System von Di\u0000erentialgleichun- gen, gegeben in folgender Form: y1 t y2 t y3 t a11 a12 a13 a21 a22 a23 a31 a32 a33 y1 t y2 t y3 t , y1 0 y2 0 y3 0 Die Anfangsbedingungen y 0 sowie die Matrix A sei bekannt, gesucht ist y t . Das Problem kann durch Transformation in Eigenbasis (Ent- kopplung) gel¨ost werden. Bsp: y1 t y2 t 32 14 y1 t y2 t , y1 0 y2 0 3 6 Vorgehen: 1 Man diagonalisiere die Matrix A TDT 1 (siehe 6.6) und bestimme die Transformationsmatrizen T und T 1 Bsp: D 20 05 ,T 21 11 ,T 1 1 31 3 1 32 3 2 Sei t i die i-te Spalte von T und dii der i-te Diago- naleintrag von D. Die L¨osung des Di\u0000’gleichungssystems lautet dann: y t z1 0 t 1 ed11t z2 0 t 2 ed22t ... Bsp: y1 t y2 t z1 0 2 1 e2t z2 0 1 1 e5t 3 Falls gegeben: Transformiere die Anfangsbedingungen y 0 in die Eigenbasis. z 0 T 1 y 0 . Ansonsten setze zi 0 Ci. Bsp: 1 31 3 1 32 3 3 6 1 5 z1 0 z2 0 11.2 Umwandlung h¨ohere Ordnung in System 1. Ordnung Man will eine Di\u0000erentialgleichung h¨oherer Ordnung in ein Dif- ferentialgleichungssystem 1. Ordnung umwandeln: Bsp: y t 4 y t 2 y t 3y t 0 y 0 1,y 0 3,y 0 2 Vorgehen: 1 Man substituiere y y1,y y2 etc. Die h¨ochste Ableitung lasse man stehen. Bsp: y t 4 y3 t 2 y2 t 3y1 t 0 2 Man ersetze h¨ochste Ableitung durch einfache Ableitung mit Substitution. Bsp: y3 t 4 y3 t 2 y2 t 3y1 t 0 3 Durch die Substitution hat man automatisch ein Di\u0000’gleichungssystem erster Ordnung erzeugt: Bsp: y1 y2 y2 y3 y3 3 y1 2 y2 4 y3 4 Zum Schluss substituiere noch die Anfangsbedingungen Bsp: y1 0 1,y2 0 3,y3 0 2 11.3 L¨osen von inhomogenem Di\u0000’gleichungssystem Man hat bereits mit dem in 11.1 beschriebenen Verfahren die L¨osung yh t f¨ur das homogene Di\u0000’gleichungssystem y A y gefunden. Jetzt sucht man die L¨osung f¨ur das inhomogene System: y A y b: Das Prinzip ist, dass man eine partikul¨are L¨osung yp t ﬁndet, die die Di\u0000’gleichung sicher erf¨ullt. Die allgemeine L¨osung ist dann y t yh t yp t Vorgehen: 1 Man nimmt an, dass die partikul¨are L¨osung yp t kon- stant ist. Daraus folgt, dass yp t 0.Man l¨ose also das Gleichungssystem A yp b 2 Man addiere die homogene und die Partikul¨are L¨osung zusammen: y t yh t yp t 11.3 Bedingungen im Unendlichen F¨ur das Bestimmen der Konstanten Ci sind nicht immer nur Anfangsbedingungen yi 0 gegeben, sondern manchmal auch die Bedingungen wie lim t yi t a. Bsp: Bestimme Ci von y t C1 3C2e t C3 e 2t mit y 0 2 und lim t y t 5 Vorgehen: 1 Verlangt eine Bedingung, dass y t im Unendlichen be- schr¨ankt sein soll, setze Konstanten vor positiven Expo- nentialfunktionen null. Bsp: Zweite Bedingung lim t y t 5 C3 0 2 Man bestimme weitere Konstanten, indem man t 0 einsetzt. Bsp: lim t y t C1 5 3 Man bestimme die ¨ubrigen Konstanten, indem man t 0 einsetzt. Bsp: y 0 5 3C2 2 C2 1 12. Pers¨onliche Erg¨anzungen 5 5 Permutationsmatrix n oderauch Vertauschmatix ist eine Matrix beiderinjederZeile spalte genauein Eintrageins ist alle andereEinträge undsind Permutationsmationsind orthogonal Euklidischem vom standaratskalarprodukt induzierte Form Istbei ortherrormalen Basen gleichgross wieinder Standartbasis Eigenschaften RangA 2RangA fürjedes Zusammengesetzten n1,43 Aistquadratisch Fg Froh Abbildungen RangAB MinlRanghtRang Ag An.AZ Abbildungsmation Matrixmitvoraussetzung IONß DGLsystem g.imtl G kernlAIEeees nurerste Ableitungen kommenvor Gegeben OrthonormaleBasis es eres Umdieszu erhalten Ableitungen höher gesucht Amitim span es wieeinersetzen somiteineGleichung mehr zu erhalten lauftspan e Es Bsp y 21 tz Geier orthogonale Projektion z 6 Sz aufdenUnterarm y x a ei IIIEI HIHI 6 6 Wichtigkeit orthogonalprojektionvonvektorauf M.eugerufen 2 DUnterraumvon R Vektorraum 0 leere Menge RIH Vektor UnterraumU span µ Fürjeden 2DUnterraum von ey 0 Parabel E Elementvon nicht Elementvon an R gibt es eineMatrix A xe.ae o zweiparallelegeraden z u vereinigtmit mit im U Kult ta O leereMenge beliebigerweiterbarmitmehr a n geschnittenmit c Teilmenge nichtTeilmenge 4 3Matrix Rangliste EigenvektorBi Jeder Eigenvektor Feiner MatrixPliegt Inhomogenes DGLSystem Sei 1eine43Matrix mitRangA 3 iIn 1 0 EllipseKreis Dann folgt aus Au Awnichtzwingend imBild also UmpartikulärLsgzufinden dass er w ist 1 0 Hyperbel IMP stationäres Systemanschauen y Aytb y 0 FallsMatrixAdEigenvektoren gegeben Gleißendem 1 1 0 leereMenge Umformen Gleichungssystemlösen1g Eigenwerte gesucht b Ay yp Beieinem linearen Gleichungssystem µ bzyz.no Zweigeradendie A EU EW.EU Lsgisteinepartikuläre Lösung Arb habe die Koeffizienten sich schneiden matrixA einenkleinerenRangAllgemeine Lsg y yhtypxetb.ly o Punkt laataDKlb.bebD als dieerweiterteMatrix des NormalformeinerQuadrik Die Vektoren a 2µg sind genau Lihängigkeitinn SystemsDann hat das Nurnoch quadratischeThemeübrig dann linear abhängig wenn o Esgibt 4 Vektoren sodassbeliebige Gleichungssystem keineLösung Kegelschnittkannabgelesen werden b oder ab 3davon esgibt4 solche güppchen linear unabhängigsind qgiaoettxtt Matix.A.hnaif Transformations Matix KonONB Invertierbarkeit Esexistiertkeinereguläre sind Aß ähnlicheMatrizen soauch Nach dem ONBgefunden ist sei e 1,901ER gilt füreine 11 11 Matrix so dass 112 A B To fer.ee.es eeY 3 3 Matrixdass AerAhAks ihrerEinträge gleich 1 Um Ts o zufinden eineBasisdes bildendannist sind Tsno To ö invertieren A invertierbar 6 7 Spurn spur E spurA spur A anraut tai DGLSystem mit komplexen Lösungen komplexeLösungen müssen umgeformtwerden bissie reellsind Bsp E Ht et real Ä f komplex xz.sk et cosKttisinKH ölt til RealTeil Imaginärteil xdttetfs.IE xslHetls 4 tczxetcsxs.et.AE tet.af i teteskE 6 b 6 9 6 10","libVersion":"0.3.2","langs":""}
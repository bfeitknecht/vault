{"path":"sem2/DDCA/VRL/slides/DDCA-L22b-memory-overview.pdf","text":"Digital Design & Computer Arch. Lecture 22b: Memory Overview, Organization & Technology Mohammad Sadrosadati Frank K. Gürkaynak Prof. Onur Mutlu (Lecture by Ataberk Olgun) ETH Zürich Spring 2024 17 May 2024 Readings for This Lecture and Next n Memory Hierarchy and Caches n Highly Recommended q H&H Chapters 8.1-8.3 q Kim & Mutlu, “Memory Systems,” Computing Handbook, 2014. n https://people.inf.ethz.ch/omutlu/pub/memory-systems-introduction_computing-handbook14.pdf n Recommended q An early cache paper by Maurice Wilkes n Wilkes, “Slave Memories and Dynamic Storage Allocation,” IEEE Trans. On Electronic Computers, 1965. 2 We Are Done With This… n Dataflow (at the ISA level) n SIMD Processing (Vector and Array processors) n Graphics Processing Units (GPUs) n VLIW n Superscalar Execution 3 Micro-architecture SW/HW Interface Program/Language Algorithm Problem Logic Devices System Software Electrons More on Instruction-Level Concurrency 4 https://safari.ethz.ch/digitaltechnik/spring2023/doku.php Approaches to (Instruction-Level) Concurrency n Pipelining n Fine-Grained Multithreading n Out-of-order Execution n Dataflow (at the ISA level) n Superscalar Execution n VLIW n Systolic Arrays n Decoupled Access Execute n SIMD Processing (Vector and Array processors, GPUs) 5 Now you are very familiar with some processing paradigms Approaches to (Instruction-Level) Concurrency n Pipelining n Fine-Grained Multithreading n Out-of-order Execution n Dataflow (at the ISA level) n Superscalar Execution n VLIW n Systolic Arrays n Decoupled Access Execute n SIMD Processing (Vector and Array processors, GPUs) 6 Food for thought: tradeoffs of these different processing paradigms Tradeoffs of Processing Paradigms 7 Food for thought: tradeoffs of these different processing paradigms Micro-architecture SW/HW Interface Program/Language Algorithm Problem Logic Devices System Software Electrons Tradeoffs of Processing Paradigms 8 Food for thought: what determines the widespread success of a paradigm Micro-architecture SW/HW Interface Program/Language Algorithm Problem Logic Devices System Software Electrons Let Us Now Take A Step Back A Computing System n Three key components n Computation n Communication n Storage/memory 10 Burks, Goldstein, von Neumann, “Preliminary discussion of the logical design of an electronic computing instrument,” 1946. Image source: https://lbsitbytes2010.wordpress.com/2013/03/29/john-von-neumann-roll-no-15/ A Computing System n Three key components n Computation n Communication n Storage/memory 11 Burks, Goldstein, von Neumann, “Preliminary discussion of the logical design of an electronic computing instrument,” 1946. Image source: https://lbsitbytes2010.wordpress.com/2013/03/29/john-von-neumann-roll-no-15/ What is A Computer? n We will cover all three components 12 Memory (program and data) I/O Processing control (sequencing) datapath Memory Is Critically Important Memory in a Modern System 14 CORE 1L2 CACHE 0SHARED L3 CACHEDRAM INTERFACE CORE 0 CORE 2 CORE 3L2 CACHE 1L2 CACHE 2L2 CACHE 3DRAM BANKS DRAM MEMORY CONTROLLER AMD Barcelona, 2006 A Large Fraction of Modern Chips is Memory 15Source: https://www.anandtech.com/show/16252/mac-mini-apple-m1-tested Apple M1, 2021 A Large Fraction of Modern Systems is Memory 16https://www.gsmarena.com/apple_announces_m1_ultra_with_20core_cpu_and_64core_gpu-news-53481.php Apple M1 Ultra System (2022) DRAM DRAM A lot of SRAMStorage Storage A Large Fraction of Modern Systems is Memory 17 By Moshen - http://en.wikipedia.org/wiki/Image:Pentiumpro_moshen.jpg, CC BY-SA 2.5, https://commons.wikimedia.org/w/index.php?curid=2262471 Processor chip Level 2 cache chip Multi-chip module package Intel Pentium Pro, 1995 A Large Fraction of Modern Systems is Memory 18 https://download.intel.com/newsroom/kits/40thanniversary/gallery/images/Pentium_4_6xx-die.jpg L2 Cache Intel Pentium 4, 2000 A Large Fraction of Modern Systems is Memory 19https://wccftech.com/amd-ryzen-5000-zen-3-vermeer-undressed-high-res-die-shots-close-ups-pictured-detailed/ AMD Ryzen 5000, 2020 Core Count: 8 cores/16 threads L1 Caches: 32 KB per core L2 Caches: 512 KB per core L3 Cache: 32 MB shared AMD’s 3D Last Level Cache (2021) 20https://youtu.be/gqAYMx34euU https://www.tech-critter.com/amd-keynote-computex-2021/ https://community.microcenter.com/discussion/5 134/comparing-zen-3-to-zen-2 Additional 64 MB L3 cache die stacked on top of the processor die - Connected using Through Silicon Vias (TSVs) - Total of 96 MB L3 cache AMD increases the L3 size of their 8-core Zen 3 processors from 32 MB to 96 MB A Large Fraction of Modern Systems is Memory 21https://www.it-techblog.de/ibm-power10-prozessor-mehr-speicher-mehr-tempo-mehr-sicherheit/09/2020/ IBM POWER10, 2020 Cores: 15-16 cores, 8 threads/core L2 Caches: 2 MB per core L3 Cache: 120 MB shared A Large Fraction of Modern Systems is Memory 22https://www.tomshardware.com/news/infrared-photographer-photos-nvidia-ga102-ampere-silicon Nvidia Ampere, 2020 Cores: 128 Streaming Multiprocessors L1 Cache or Scratchpad: 192KB per SM Can be used as L1 Cache and/or Scratchpad L2 Cache: 40 MB shared DRAM (not shown): 40 GB GDDR6 80 GB HBM2 Cerebras’s Wafer Scale Engine (2019) 23 Cerebras WSE 1.2 Trillion transistors 46,225 mm2 Largest GPU 21.1 Billion transistors 815 mm2 n The largest ML accelerator chip n 400,000 cores n 18 GB of on-chip memory n 9 PB/s memory bandwidth NVIDIA TITAN V https://www.anandtech.com/show/14758/hot-chips-31-live-blogs-cerebras-wafer-scale-deep-learning https://www.cerebras.net/cerebras-wafer-scale-engine-why-we-need-big-chips-for-deep-learning/ Cerebras’s Wafer Scale Engine-2 (2021) 24 Cerebras WSE-2 2.6 Trillion transistors 46,225 mm2 Largest GPU 54.2 Billion transistors 826 mm2 NVIDIA Ampere GA100 https://cerebras.net/product/#overview n The largest ML accelerator chip n 850,000 cores n 40 GB of on-chip memory n 20 PB/s memory bandwidth Memory System: Most of the Platform 25 Storage Most of the system is dedicated to storing and moving data Yet, system is still bottlenecked by memory Memory is Critical for Performance n Load-related stalls in pipelining q Even with magic “1-cycle” memory assumption n Load/store handling in OoO execution processors n OoO execution and memory latency tolerance n Many memory banks needed in SIMD processors q SIMD vector processing performance example n GPU register files and high-bandwidth memory systems n … 26 The Reason Computing is Bottlenecked by Data 28 Computation is Bottlenecked by Memory n Important workloads are all data intensive q ML/AI, Genomics, Data Analytics, Databases, Graph Analytics, … n They require rapid and efficient processing of large amounts of data n Data is increasing q We can generate much more than we can process 29 Huge Demand for Performance & Efficiency 30Source: https://youtu.be/Bh13Idwcb0Q?t=283 Application Perspective Memory Is Critical for Performance (I) In-Memory Data Analytics [Clapp+ (Intel), IISWC’15; Awan+, BDCloud’15] Datacenter Workloads [Kanev+ (Google), ISCA’15] In-memory Databases [Mao+, EuroSys’12; Clapp+ (Intel), IISWC’15] Graph/Tree Processing [Xu+, IISWC’12; Umuroglu+, FPL’15] 32 Memory Is Critical for Performance (I) In-Memory Data Analytics [Clapp+ (Intel), IISWC’15; Awan+, BDCloud’15] Datacenter Workloads [Kanev+ (Google), ISCA’15] In-memory Databases [Mao+, EuroSys’12; Clapp+ (Intel), IISWC’15] Graph/Tree Processing [Xu+, IISWC’12; Umuroglu+, FPL’15] Memory → bottleneck 33 Memory Is Critical for Performance (II) 34 Chrome Google’s web browser TensorFlow Mobile Google’s machine learning framework Video Playback Google’s video codec Video Capture Google’s video codec Memory Is Critical for Performance (II) 35 Chrome Google’s web browser TensorFlow Mobile Google’s machine learning framework Video Playback Google’s video codec Video Capture Google’s video codec Memory → bottleneck Data is Key for Modern & Future Workloads 36 development of high-throughput sequencing (HTS) technologies http://www.economist.com/news/21631808-so-much-genetic-data-so-many-uses-genes-unzipped Number of Genomes Sequenced Genome Analysis A C T T A G C A C T 0 1 2 A 1 0 1 2 C 2 1 0 1 2 T 2 1 0 1 2 A 2 1 2 1 2 G 2 2 2 1 2 A 3 2 2 2 2 A 3 3 3 2 3 C 4 3 3 2 3 T 4 4 3 2 T 5 4 3 Short Read ... ... Reference Genome Read Alignment CC T A T A AT ACG C C A T A T A T A C G T AT AT AT ACGT ACT AGT ACGT ACGAC T T TAGT ACGT ACGT T AT AT AT ACGT ACT AGT ACGT ACGT ACG CCCCT ACGT A ACGAC T T TAGT ACGT ACGT T AT AT AT ACGT ACT AAAGT ACGT CCCCCCT AT AT AT ACGT ACT AGT ACGT T AT AT AT ACGT ACT AGT ACGT T AT AT AT ACGT ACT AGT ACGT ACG T T T T TAAAACGT A ACGAC GGGGAGT ACGT ACGT Billions of Short Reads 1 2Sequencing Read Mapping 3 4Variant Calling Scientific Discovery 37 Genome Analysis A C T T A G C A C T 0 1 2 A 1 0 1 2 C 2 1 0 1 2 T 2 1 0 1 2 A 2 1 2 1 2 G 2 2 2 1 2 A 3 2 2 2 2 A 3 3 3 2 3 C 4 3 3 2 3 T 4 4 3 2 T 5 4 3 Short Read ... ... Reference Genome Read Alignment CC T A T A AT ACG C C A T A T A T A C G T AT AT AT ACGT ACT AGT ACGT ACGAC T T TAGT ACGT ACGT T AT AT AT ACGT ACT AGT ACGT ACGT ACG CCCCT ACGT A ACGAC T T TAGT ACGT ACGT T AT AT AT ACGT ACT AAAGT ACGT CCCCCCT AT AT AT ACGT ACT AGT ACGT T AT AT AT ACGT ACT AGT ACGT T AT AT AT ACGT ACT AGT ACGT ACG T T T T TAAAACGT A ACGAC GGGGAGT ACGT ACGT Billions of Short Reads 1 2Sequencing Read Mapping 3 4Variant Calling Scientific Discovery Memory → bottleneck 38 New Genome Sequencing Technologies 39 Senol Cali+, “Nanopore Sequencing Technology and Tools for Genome Assembly: Computational Analysis of the Current State, Bottlenecks and Future Directions,” Briefings in Bioinformatics, 2018. [Open arxiv.org version] Oxford Nanopore MinION New Genome Sequencing Technologies 40 Senol Cali+, “Nanopore Sequencing Technology and Tools for Genome Assembly: Computational Analysis of the Current State, Bottlenecks and Future Directions,” Briefings in Bioinformatics, 2018. [Preliminary arxiv.org version] Oxford Nanopore MinION Memory → bottleneck We Need Faster & Scalable Genome Analysis 41 Predicting the presence and relative abundance of microbes in a sample Understanding genetic variations, species, evolution, … Rapid surveillance of disease outbreaks Developing personalized medicine And, many, many other applications … Problems with (Genome) Analysis Today 42 Special-Purpose Machine for Data Generation General-Purpose Machine for Data Analysis FAST SLOW Slow and inefficient processing capability This picture is similar for many “data generators & analyzers” today Large amounts of data movement Future of Genome Sequencing & Analysis 43 SmidgION from ONT MinION from ONT 43 Mohammed Alser, Zülal Bingöl, Damla Senol Cali, Jeremie Kim, Saugata Ghose, Can Alkan, Onur Mutlu “Accelerating Genome Analysis: A Primer on an Ongoing Journey” IEEE Micro, August 2020. Accelerating Genome Analysis n Mohammed Alser, Zulal Bingol, Damla Senol Cali, Jeremie Kim, Saugata Ghose, Can Alkan, and Onur Mutlu, \"Accelerating Genome Analysis: A Primer on an Ongoing Journey\" IEEE Micro (IEEE MICRO), Vol. 40, No. 5, pages 65-75, September/October 2020. [Slides (pptx)(pdf)] [Talk Video (1 hour 2 minutes)] 44 Beginner Reading on Genome Analysis 45 Mohammed Alser, Joel Lindegger, Can Firtina, Nour Almadhoun, Haiyu Mao, Gagandeep Singh, Juan Gomez-Luna, Onur Mutlu “From Molecules to Genomic Variations to Scientific Discovery: Intelligent Algorithms and Architectures for Intelligent Genome Analysis” Computational and Structural Biotechnology Journal, 2022 [Source code] https://arxiv.org/pdf/2205.07957.pdf FPGA-based Near-Memory Analytics n Gagandeep Singh, Mohammed Alser, Damla Senol Cali, Dionysios Diamantopoulos, Juan Gómez-Luna, Henk Corporaal, and Onur Mutlu, \"FPGA-based Near-Memory Acceleration of Modern Data-Intensive Applications\" IEEE Micro (IEEE MICRO), 2021. 46 Near-Memory Acceleration using FPGAs IBM POWER9 CPU HBM-based FPGA board OCAPI Source: AlphaData Source: IBM Near-HBM FPGA-based accelerator 47 Two communication technologies: CAPI2 and OCAPI Two memory technologies: DDR4 and HBM Two workloads: Weather Modeling and Genome Analysis Performance & Energy Greatly Improve 48 5-27× performance vs. a 16-core (64-thread) IBM POWER9 CPU HBM alleviates memory bandwidth contention vs. DDR4 12-133× energy efficiency vs. a 16-core (64-thread) IBM POWER9 CPU GenASM Acceleration Framework [MICRO 2020] n Damla Senol Cali, Gurpreet S. Kalsi, Zulal Bingol, Can Firtina, Lavanya Subramanian, Jeremie S. Kim, Rachata Ausavarungnirun, Mohammed Alser, Juan Gomez-Luna, Amirali Boroumand, Anant Nori, Allison Scibisz, Sreenivas Subramoney, Can Alkan, Saugata Ghose, and Onur Mutlu, \"GenASM: A High-Performance, Low-Power Approximate String Matching Acceleration Framework for Genome Sequence Analysis\" Proceedings of the 53rd International Symposium on Microarchitecture (MICRO), Virtual, October 2020. [Lighting Talk Video (1.5 minutes)] [Lightning Talk Slides (pptx) (pdf)] [Talk Video (18 minutes)] [Slides (pptx) (pdf)] 49 Scrooge: Overcoming GenASM Limitations n Joël Lindegger, Damla Senol Cali, Mohammed Alser, Juan Gómez-Luna, Nika Mansouri Ghiasi, and Onur Mutlu, \"Scrooge: A Fast and Memory-Frugal Genomic Sequence Aligner for CPUs, GPUs, and ASICs\" Bioinformatics, [published online on] 24 March 2023. [Online link at Bioinformatics Journal] [arXiv preprint] [Scrooge Source Code] 50https://arxiv.org/pdf/2208.09985.pdf In-Storage Genome Filtering [ASPLOS 2022] n Nika Mansouri Ghiasi, Jisung Park, Harun Mustafa, Jeremie Kim, Ataberk Olgun, Arvid Gollwitzer, Damla Senol Cali, Can Firtina, Haiyu Mao, Nour Almadhoun Alserr, Rachata Ausavarungnirun, Nandita Vijaykumar, Mohammed Alser, and Onur Mutlu, \"GenStore: A High-Performance and Energy-Efficient In-Storage Computing System for Genome Sequence Analysis\" Proceedings of the 27th International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS), Virtual, February-March 2022. [Talk Slides (pptx) (pdf)] [Lightning Talk Slides (pptx) (pdf)] [Lightning Talk Video (90 seconds)] [Talk Video (17 minutes)] 51 Accelerating Sequence-to-Graph Mapping n Damla Senol Cali, Konstantinos Kanellopoulos, Joel Lindegger, Zulal Bingol, Gurpreet S. Kalsi, Ziyi Zuo, Can Firtina, Meryem Banu Cavlak, Jeremie Kim, Nika MansouriGhiasi, Gagandeep Singh, Juan Gomez-Luna, Nour Almadhoun Alserr, Mohammed Alser, Sreenivas Subramoney, Can Alkan, Saugata Ghose, and Onur Mutlu, \"SeGraM: A Universal Hardware Accelerator for Genomic Sequence-to-Graph and Sequence-to-Sequence Mapping\" Proceedings of the 49th International Symposium on Computer Architecture (ISCA), New York, June 2022. [arXiv version] 52https://arxiv.org/pdf/2205.05883.pdf More on Fast & Efficient Genome Analysis … 53https://www.youtube.com/watch?v=NCagwf0ivT0 Detailed Lectures on Genome Analysis n Computer Architecture, Fall 2020, Lecture 3a q Introduction to Genome Sequence Analysis (ETH Zürich, Fall 2020) q https://www.youtube.com/watch?v=CrRb32v7SJc&list=PL5Q2soXY2Zi9xidyIgBxUz7 xRPS-wisBN&index=5 n Computer Architecture, Fall 2020, Lecture 8 q Intelligent Genome Analysis (ETH Zürich, Fall 2020) q https://www.youtube.com/watch?v=ygmQpdDTL7o&list=PL5Q2soXY2Zi9xidyIgBxU z7xRPS-wisBN&index=14 n Computer Architecture, Fall 2020, Lecture 9a q GenASM: Approx. String Matching Accelerator (ETH Zürich, Fall 2020) q https://www.youtube.com/watch?v=XoLpzmN- Pas&list=PL5Q2soXY2Zi9xidyIgBxUz7xRPS-wisBN&index=15 n Accelerating Genomics Project Course, Fall 2020, Lecture 1 q Accelerating Genomics (ETH Zürich, Fall 2020) q https://www.youtube.com/watch?v=rgjl8ZyLsAg&list=PL5Q2soXY2Zi9E2bBVAgCqL gwiDRQDTyId 54https://www.youtube.com/onurmutlulectures Genomics Course (Fall 2023) n Fall 2023 Edition: q https://safari.ethz.ch/projects_and_seminars/fall2023/do ku.php?id=bioinformatics n Spring 2023 Edition: q https://safari.ethz.ch/projects_and_seminars/spring2023 /doku.php?id=bioinformatics n Youtube Livestream (Fall 2023): q https://youtube.com/playlist?list=PL5Q2soXY2Zi_O0wyO jiMShG4t2QPZoeE3 n Project course q Taken by Bachelor’s/Master’s students q Genomics lectures q Hands-on research exploration q Many research readings 55 https://www.youtube.com/onurmutlulectures Performance Perspective It’s the Memory, Stupid! n “It’s the Memory, Stupid!” (Richard Sites, MPR, 1996) 57http://cva.stanford.edu/classes/cs99s/papers/architects_look_to_future.pdf The Performance Perspective Mutlu+, “Runahead Execution: An Alternative to Very Large Instruction Windows for Out-of-Order Processors,” HPCA 2003. The Performance Perspective n Onur Mutlu, Jared Stark, Chris Wilkerson, and Yale N. Patt, \"Runahead Execution: An Alternative to Very Large Instruction Windows for Out-of-order Processors\" Proceedings of the 9th International Symposium on High-Performance Computer Architecture (HPCA), pages 129-140, Anaheim, CA, February 2003. Slides (pdf) One of the 15 computer arch. papers of 2003 selected as Top Picks by IEEE Micro. HPCA Test of Time Award (awarded in 2021). [Lecture Slides (pptx) (pdf)] [Lecture Video (1 hr 54 mins)] [Retrospective HPCA Test of Time Award Talk Slides (pptx) (pdf)] [Retrospective HPCA Test of Time Award Talk Video (14 minutes)] 59 The Memory Bottleneck n Onur Mutlu, Jared Stark, Chris Wilkerson, and Yale N. Patt, \"Runahead Execution: An Effective Alternative to Large Instruction Windows\" IEEE Micro, Special Issue: Micro's Top Picks from Microarchitecture Conferences (MICRO TOP PICKS), Vol. 23, No. 6, pages 20-25, November/December 2003. 60 The Memory Bottleneck n All of Google’s Data Center Workloads (2015): 61Kanev+, “Profiling a Warehouse-Scale Computer,” ISCA 2015. The Memory Bottleneck n All of Google’s Data Center Workloads (2015): 62Kanev+, “Profiling a Warehouse-Scale Computer,” ISCA 2015. An Informal Interview on Memory n Madeleine Gray and Onur Mutlu, \"‘It’s the memory, stupid’: A conversation with Onur Mutlu\" HiPEAC info 55, HiPEAC Newsletter, October 2018. [Shorter Version in Newsletter] [Longer Online Version with References] 63 Energy Perspective Data Movement vs. Computation Energy 65 Dally, HiPEAC 2015 Data Movement vs. Computation Energy 66 Dally, HiPEAC 2015 A memory access consumes ~100-1000X the energy of a complex addition Data Movement vs. Computation Energy 67 0.1 0.9 1 3.1 3.7 5 640 0.1 1 10 100 1000 10000 ADD (int) ADD (float) Register File MULT (int) MULT (float) SRAM Cache DRAMEnergy for a 32-bit Operation (log scale)Energy (pJ) ADD (int) Relative Cost Han+, “EIE: Efficient Inference Engine on Compressed Deep Neural Network,” ISCA 2016. Data Movement vs. Computation Energy 68 0.1 0.9 1 3.1 3.7 5 640 0.1 1 10 100 1000 10000 ADD (int) ADD (float) Register File MULT (int) MULT (float) SRAM Cache DRAMEnergy for a 32-bit Operation (log scale)Energy (pJ) ADD (int) Relative Cost Han+, “EIE: Efficient Inference Engine on Compressed Deep Neural Network,” ISCA 2016. 6400X A memory access consumes 6400X the energy of a simple integer addition Data Movement vs. Computation Energy 69 32-bit Operation Energy (pJ) ADD (int) Relative Cost ADD (int) 0.1 1 ADD (float) 0.9 9 Register File 1 10 MULT (int) 3.1 31 MULT (float) 3.7 37 SRAM Cache 5 50 DRAM 640 6400 Han+, “EIE: Efficient Inference Engine on Compressed Deep Neural Network,” ISCA 2016. A memory access consumes ~6400X the energy of an integer addition Memory is Critical for Energy n Amirali Boroumand, Saugata Ghose, Youngsok Kim, Rachata Ausavarungnirun, Eric Shiu, Rahul Thakur, Daehyun Kim, Aki Kuusela, Allan Knies, Parthasarathy Ranganathan, and Onur Mutlu, \"Google Workloads for Consumer Devices: Mitigating Data Movement Bottlenecks\" Proceedings of the 23rd International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS), Williamsburg, VA, USA, March 2018. 70 62.7% of the total system energy is spent on data movement Memory is Critical for Energy n Amirali Boroumand, Saugata Ghose, Berkin Akin, Ravi Narayanaswami, Geraldo F. Oliveira, Xiaoyu Ma, Eric Shiu, and Onur Mutlu, \"Google Neural Network Models for Edge Devices: Analyzing and Mitigating Machine Learning Inference Bottlenecks\" Proceedings of the 30th International Conference on Parallel Architectures and Compilation Techniques (PACT), Virtual, September 2021. [Slides (pptx) (pdf)] [Talk Video (14 minutes)] 71 > 90% of the total system energy is spent on memory in large ML models 72 https://ethz.ch/en/industry/industry/news/data/202 2/03/mehr-daten-schneller-und-energiesparender- verarbeiten.html Processing in Memory: Faster & Low EnergyTutorial on Processing in Memory 73https://www.youtube.com/onurmutlulectures https://www.youtube.com/watch?v=4x9nujJtqjM Reliability, Security, Safety Perspectives Memory is Critical for Reliability n Data from all of Facebook’s servers worldwide n Meza+, “Revisiting Memory Errors in Large-Scale Production Data Centers,” DSN’15. 75 As memory capacity increases, system reliability reduces Large-Scale Failure Analysis of DRAM Chips n Analysis and modeling of memory errors found in all of Facebook’s server fleet n Justin Meza, Qiang Wu, Sanjeev Kumar, and Onur Mutlu, \"Revisiting Memory Errors in Large-Scale Production Data Centers: Analysis and Modeling of New Trends from the Field\" Proceedings of the 45th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN), Rio de Janeiro, Brazil, June 2015. [Slides (pptx) (pdf)] [DRAM Error Model] 76 Infrastructures to Understand Such Issues 77Kim+, “Flipping Bits in Memory Without Accessing Them: An Experimental Study of DRAM Disturbance Errors,” ISCA 2014. Temperature Controller PC HeaterFPGAs FPGAs 78 Memory\tTesting\tInfrastructures *\tSoftMC\t[Hassan+,\tHPCA’17]\tenhanced\tfor\tDDR4 79 Updated\tMemory\tTesting\tInfrastructure FPGA-based\tSoftMC\t(Xilinx\tVirtex\tUltraScale+\tXCU200) Fine-grained\tcontrol\tover\tDRAM\tcommands,\t timing\t(±1.5ns),\ttemperature\t(±0.1°C\t), and\tvoltage\t(±1mV) *Hassan\tet\tal.,\t\"SoftMC:\tA\tFlexible\tand\tPractical\tOpen-Source\tInfrastructure\tfor\tEnabling\tExperimental\t DRAM\tStudies,\"\tin\tHPCA,\t2017.\t[Available\ton\tGitHub:\thttps://github.com/CMU-SAFARI/SoftMC] * A Curious Phenomenon [Kim et al., ISCA 2014] One can predictably induce errors in most DRAM memory chips 80 Kim+, “Flipping Bits in Memory Without Accessing Them: An Experimental Study of DRAM Disturbance Errors,” ISCA 2014. DRAM RowHammer A simple hardware failure mechanism can create a widespread system security vulnerability 81 One Can Take Over an Otherwise-Secure System 82 Exploiting the DRAM rowhammer bug to gain kernel privileges (Seaborn+, 2015) Flipping Bits in Memory Without Accessing Them: An Experimental Study of DRAM Disturbance Errors (Kim et al., ISCA 2014) A RowHammer Survey Across the Stack n Onur Mutlu and Jeremie Kim, \"RowHammer: A Retrospective\" IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems (TCAD) Special Issue on Top Picks in Hardware and Embedded Security, 2019. [Preliminary arXiv version] [Slides from COSADE 2019 (pptx)] [Slides from VLSI-SOC 2020 (pptx) (pdf)] [Talk Video (1 hr 15 minutes, with Q&A)] 83 RowHammer is Still a Security Problem n Onur Mutlu, Ataberk Olgun, and A. Giray Yaglikci, \"Fundamentally Understanding and Solving RowHammer\" Invited Special Session Paper at the 28th Asia and South Pacific Design Automation Conference (ASP-DAC), Tokyo, Japan, January 2023. [arXiv version] [Slides (pptx) (pdf)] [Talk Video (26 minutes)] 84https://arxiv.org/pdf/2211.07613.pdf Memory is Critical for Security 85 The Story of RowHammer Tutorial … 86https://www.youtube.com/watch?v=e6G_Vbrqr_c&list=PL5Q2soXY2Zi9uIibswgf8IfNGKYktIEos&index=4 The Story of RowHammer Tutorial … Onur Mutlu, \"Security Aspects of DRAM: The Story of RowHammer\" Invited Tutorial at 14th IEEE Electron Devices Society International Memory Workshop (IMW), Dresden, Germany, May 2022. [Slides (pptx)(pdf)] [Tutorial Video (57 minutes)] 87https://www.youtube.com/watch?v=37hWglkQRG0 10 Years of RowHammer in 20 Minutes n Onur Mutlu, \"The Story of RowHammer\" Invited Talk at the Workshop on Robust and Safe Software 2.0 (RSS2), held with the 27th International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS), Virtual, 28 February 2022. [Slides (pptx) (pdf)] 88https://www.youtube.com/watch?v=ctKTRyi96Bk Memory Is Critical for Computing Memory Is Critical for Computing n Performance n Energy n Reliability n Security & Safety n Cost n Form Factor n Quality of Service & Predictability n Sustainability n … 90 Memory FundamentalsMemory Organization & Technology Memory (Programmer’s View) 93 Abstraction: Virtual vs. Physical Memory n Programmer sees virtual memory q Can assume the memory is “infinite” n Reality: Physical memory size is much smaller than what the programmer assumes n The system (system software + hardware, cooperatively) maps virtual memory addresses to physical memory q The system automatically manages the physical memory space transparently to the programmer + Programmer does not need to know the physical size of memory nor manage it à A small physical memory can appear as a huge one to the programmer à Life is easier for the programmer -- More complex system software and architecture A classic example of the programmer/(micro)architect tradeoff Requires indirection and mapping between virtual and physical address spaces (Physical) Memory System n You need a larger level of storage to manage a small amount of physical memory automatically à Physical memory has a backing store: disk n We will first start with the physical memory system n For now, ignore the virtualàphysical indirection 95 Idealism 96 Instruction Supply Pipeline (Instruction Execution) Data Supply - Zero latency access - Infinite capacity - Zero cost - Perfect control flow - No pipeline stalls - Perfect data flow (no reg/memory dependences) - Zero-cycle interconnect (operand communication) - Enough functional units - Zero latency compute - Zero latency access - Infinite capacity - Infinite bandwidth - Zero cost Ideal Memory n Zero access time (latency) n Infinite capacity n Zero cost n Infinite bandwidth (to support multiple accesses in parallel) n Zero energy 97 Quick Review of Memory Arrays How Can We Store Data? n Flip-Flops (or Latches) q Very fast q Very expensive (one bit costs tens of transistors) n Static RAM (SRAM) q Relatively fast q Expensive (one bit costs 6+ transistors) n Dynamic RAM (DRAM) q Slower, reading and charge leakage destroys content (refresh), needs special process for manufacturing (due to capacitor) q Cheap (one bit costs only one transistor plus one capacitor) n Other storage technology (flash memory, hard disk, tape) q Much slower, special manufacturing needed, non-volatile q Very cheap (one transistor stores many bits or no transistors involved) 99 Array Organization of Memories n Goal: Efficiently store large amounts of data q A memory array (stores data) q Address selection logic (selects one row of the array) q Readout circuitry (reads data out) n An M-bit value can be read or written at each unique N-bit address q All values can be accessed, but only M-bits at a time q Access restriction allows more compact organization Address Data Array N M 100 A Bigger Memory Array (4 locations X 3 bits) Di[2] Di[1] Di[0] D[2] D[1] D[0] Addr[1:0] WE Address Decoder Multiplexer DDCA 2023 Lecture 5 https://www.youtube.com/watch?v=AFK2nL8aaZk&list=PL5Q2soXY2Zi-EImKxYYY1SZuGiOAOBKaf&index=6 Memory Arrays n Two-dimensional array of bit cells q Each bit cell stores one bit n An array with N address bits and M data bits: q 2N rows and M columns q Depth: number of rows (can be number of “words”) q Width: number of columns (can be the “word” size) q Array size: depth × width (rows x columns) = 2N × M Address Data Array N M Address Data 11 10 01 00 depth 0 1 0 1 0 0 1 1 0 0 1 1 width Address Data Array 2 3 102 n 22 × 3-bit array n Number of rows: 4 n Row size: 3 bits n For example, the 3-bit data stored at row 10 is 100 Address Data 11 10 01 00 depth 0 1 0 1 0 0 1 1 0 0 1 1 width Address Data Array 2 3 Memory Array ExampleLarger and Wider Memory Array Example Address Data 1024-word x 32-bit Array 10 32 104 Memory Array Organization (I) n Storage nodes in one column connected to one bitline n Address decoder activates only ONE wordline n Content of one line of storage available at output wordline311 10 2:4 Decoder Address 01 00 stored bit = 0 wordline 2 wordline 1 wordline 0 stored bit = 1 stored bit = 0 stored bit = 1 stored bit = 0 stored bit = 0 stored bit = 1 stored bit = 1 stored bit = 0 stored bit = 0 stored bit = 1 stored bit = 1 bitline2 bitline1 bitline0 Data 2 Data1 Data0 2 105 Memory Array Organization (II) n Storage nodes in one column connected to one bitline n Address decoder activates only ONE wordline n Content of one line of storage available at output wordline311 10 2:4 Decoder Address 01 00 stored bit = 0 wordline 2 wordline 1 wordline 0 stored bit = 1 stored bit = 0 stored bit = 1 stored bit = 0 stored bit = 0 stored bit = 1 stored bit = 1 stored bit = 0 stored bit = 0 stored bit = 1 stored bit = 1 bitline2 bitline1 bitline0 Data 2 Data1 Data0 2 10 1 0 0 Active wordline 106 How is Access Controlled? n Access transistors (that are configured as switches) connect the bit storage to the bitline n Access is controlled by the wordline stored bit wordline bitline wordline bitline bitlinewordline bitline DRAM SRAM 107 Building Larger Memories n Requires larger memory arrays n Large à slow n How do we make the memory large without making it too slow? n Idea: Divide the memory into smaller arrays and interconnect the arrays to input/output buses q Large memories are hierarchical array structures q DRAM: Channel à Rank à Bank à Subarrays à Mats 108 General Principle: Interleaving (Banking) n Interleaving (banking) q Problem: a single monolithic large memory array takes long to access and does not enable multiple accesses in parallel q Goal: Reduce the latency of memory array access and enable multiple accesses in parallel q Idea: Divide a monolithic large array into multiple banks that can be accessed independently (in the same cycle or in consecutive cycles) n Each bank is smaller than the entire memory storage n Accesses to different banks can be overlapped q A Key Issue: How do you map data to different banks? (i.e., how do you interleave data across banks?) 109 Memory Banking n Memory is divided into banks that can be accessed independently; banks share address and data buses (to reduce memory chip pins) n Can start and complete one bank access per cycle n Can sustain N concurrent accesses if all N go to different banks Bank 0 Bank 1 MDR MAR Bank 2 Bank 15 MDR MAR MDR MAR MDR MAR Data bus Address bus CPU DDCA 2023 Lecture 19 https://www.youtube.com/watch?v=gkMaO3yJMz0&list=PL5Q2soXY2Zi-EImKxYYY1SZuGiOAOBKaf&index=24 Generalized Memory Structure 111 Generalized Memory Structure 112 Kim+, “A Case for Exploiting Subarray-Level Parallelism in DRAM,” ISCA 2012. Lee+, “Decoupled Direct Memory Access,” PACT 2015. Cutting Edge: 3D-Stacking of Memory & Logic 113 Logic Memory Other “True 3D” technologies under development Digital Design & Computer Arch. Lecture 22b: Memory Overview, Organization & Technology Mohammad Sadrosadati Frank K. Gürkaynak Prof. Onur Mutlu (Lecture by Ataberk Olgun) ETH Zürich Spring 2024 17 May 2024 Digital Design & Computer Arch. Lecture 23a: Memory Organization & Technology Mohammad Sadrosadati Frank K. Gürkaynak (Lecture by Ataberk Olgun) ETH Zürich Spring 2024 17 May 2024 [Recall] Generalized Memory Structure 116 Kim+, “A Case for Exploiting Subarray-Level Parallelism in DRAM,” ISCA 2012. Lee+, “Decoupled Direct Memory Access,” PACT 2015. [Recall] 3D-Stacking of Memory & Logic 117 Logic Memory Other “True 3D” technologies under development The DRAM Subsystem A Top-Down View DRAM Subsystem Organization n Channel n DIMM n Rank n Chip n Bank n Row/Column 119 The DRAM Subsystem Memory channel Memory channel DIMM (Dual in-line memory module) Processor “Channel” 120 Breaking down a DIMM (module) DIMM (Dual in-line memory module) Side view Front of DIMM Back of DIMM 121 Breaking down a DIMM (module) DIMM (Dual in-line memory module) Side view Front of DIMM Back of DIMM Rank 0: collection of 8 chips Rank 1 122 Rank Rank 0 (Front) Rank 1 (Back) Data <0:63>CS <0:1>Addr/Cmd <0:63><0:63> Memory channel 123 Breaking down a Rank Rank 0 <0:63>Chip 0Chip 1Chip 7. . .<0:7><8:15><56:63> Data <0:63> 124 Breaking down a ChipChip 0<0:7>8 banks Bank 0 <0:7> <0:7> <0:7> ...<0:7> 125 Breaking down a Bank Bank 0<0:7>row 0 row 32k-1... 2kB 1B 1B (column) 1B Row-buffer 1B ...<0:7> 126 Digging Deeper: DRAM Bank Operation 127 Row Buffer (Row 0, Column 0)Row decoder Column mux Row address 0 Column address 0 Data Row 0Empty (Row 0, Column 1) Column address 1 (Row 0, Column 85) Column address 85 (Row 1, Column 0) HITHIT Row address 1 Row 1 Column address 0 CONFLICT ! ColumnsRows Access Address: This view of a bank is an abstraction. Internally, a bank consists of many cells (transistors & capacitors) and other structures that enable access to cells A DRAM Bank Internally Has Sub-Banks 128Kim et al., “A Case for Exploiting Subarray-Level Parallelism in DRAM,” ISCA 2012. Another View of a DRAM Bank 129Seshadri+, “In-DRAM Bulk Bitwise Execution Engine,” ADCOM 2020. Logical Abstraction Physical View More on DRAM Basics & Organization n Vivek Seshadri and Onur Mutlu, \"In-DRAM Bulk Bitwise Execution Engine\" Invited Book Chapter in Advances in Computers, 2020. [Preliminary arXiv version] 130 See Section 2 for comprehensive DRAM Background https://arxiv.org/pdf/1905.09822.pdf DRAM Subsystem Organization n Channel n DIMM n Rank n Chip n Bank n Row/Column 131 Example: Transferring a cache block 0xFFFF…F 0x00 0x40... 64B cache block Physical memory space Channel 0 DIMM 0 Rank 0 Mapped to 132 Example: Transferring a cache block 0xFFFF…F 0x00 0x40... 64B cache block Physical memory space Rank 0 Chip 0 Chip 1 Chip 7<0:7><8:15><56:63> Data <0:63> . . . 133 Example: Transferring a cache block 0xFFFF…F 0x00 0x40... 64B cache block Physical memory space Rank 0 Chip 0 Chip 1 Chip 7<0:7><8:15><56:63> Data <0:63> Row 0 Col 0 . . . 134 Example: Transferring a cache block 0xFFFF…F 0x00 0x40... 64B cache block Physical memory space Rank 0 Chip 0 Chip 1 Chip 7<0:7><8:15><56:63> Data <0:63> 8B Row 0 Col 0 . . . 8B 135 Example: Transferring a cache block 0xFFFF…F 0x00 0x40... 64B cache block Physical memory space Rank 0 Chip 0 Chip 1 Chip 7<0:7><8:15><56:63> Data <0:63> 8B Row 0 Col 1 . . . 136 Example: Transferring a cache block 0xFFFF…F 0x00 0x40... 64B cache block Physical memory space Rank 0 Chip 0 Chip 1 Chip 7<0:7><8:15><56:63> Data <0:63> 8B 8B Row 0 Col 1 . . . 8B 137 Example: Transferring a cache block 0xFFFF…F 0x00 0x40... 64B cache block Physical memory space Rank 0 Chip 0 Chip 1 Chip 7<0:7><8:15><56:63> Data <0:63> 8B 8B Row 0 Col 1 A 64B cache block takes 8 I/O cycles to transfer. During the process, 8 columns are read sequentially. . . . 138 Memory Technology: DRAM and SRAM Memory Technology: DRAM n Dynamic random access memory n Capacitor charge state indicates stored value q Whether the capacitor is charged or discharged indicates storage of 1 or 0 q 1 capacitor q 1 access transistor n Capacitor leaks through the RC path q DRAM cell loses charge over time q DRAM cell needs to be refreshed 140 row enablebitline Accessing a DRAM Cell Sense\t Ampenable bitline wordline capacitor access\t transistor bitline [Seshadri+\tMICRO’17] Accessing a DRAM Cell ½\tVDD\t+\tδ enable bitline wordline capacitor access\t transistor ½\tVDDVDD enable\t wordline enable\t sense\tamp connects\tcell\t to\tbitline cell\tloses\tcharge\t to\tbitline cell\tcharge\t restored Sense\t Amp deviation\tin\t bitline\tvoltage ½\tVDD0 bitline [Seshadri+\tMICRO’17] 1 2 3 4 5 6 n Static random access memory n Two cross coupled inverters store a single bit q Feedback path enables the stored value to stay in the “cell” (as long as powered on) q 4 transistors for storage q 2 transistors for access Memory Technology: SRAM 143 row enablebitline_bitline Memory Bank Organization and Operation n Read access sequence: 1. Decode row address & drive word-lines 2. Selected bits drive bit-lines • Entire row read 3. Amplify row data 4. Decode column address & select subset of row • Send to output 5. Precharge bit-lines • For next access 144 SRAM (Static Random Access Memory) 145 bit-cell array 2n row x 2m-col (n»m to minimize overall latency) sense amp and mux 2m diff pairs 2n n m 1 row enablebitline_bitline n+m Read Sequence 1. address decode 2. drive row enable 3. selected bit-cells drive bitlines (entire row is read together) 4. differential sensing and column select (data is ready) 5. precharge all bitlines (for next read or write) Access latency dominated by steps 2 and 3 Cycling time dominated by steps 2, 3 and 5 - step 2 proportional to 2m - step 3 and 5 proportional to 2n DRAM (Dynamic Random Access Memory) 146 row enable_bitline bit-cell array 2n row x 2m-col (n»m to minimize overall latency) sense amp and mux 2m 2n n m 1 RAS CAS A DRAM die comprises of multiple such arrays Bit stored as charge on node capacitor (non-restorative) - bit cell loses charge when read - bit cell loses charge over time Read Sequence 1~3 same as SRAM 4. a “flip-flopping” sense amp amplifies and regenerates the bitline, data bit is mux’ed out 5. precharge all bitlines Destructive reads Charge loss over time Refresh: A DRAM controller must periodically read each row within the allowed refresh time (10s of ms) such that charge is restored DRAM vs. SRAM n DRAM q Slower access (capacitor) q Higher density (1T 1C cell) q Lower cost q Requires refresh (power, performance, circuitry) q Manufacturing requires putting capacitor and logic together n SRAM q Faster access (no capacitor) q Lower density (6T cell) q Higher cost q No need for refresh q Manufacturing compatible with logic process (no capacitor) 147 An Aside: Phase Change Memory n Phase change material (chalcogenide glass) exists in two states: q Amorphous: Low optical reflexivity and high electrical resistivity q Crystalline: High optical reflexivity and low electrical resistivity 148 PCM is resistive memory: High resistance (0), Low resistance (1) Lee, Ipek, Mutlu, Burger, “Architecting Phase Change Memory as a Scalable DRAM Alternative,” ISCA 2009. PCM-based Main Memory n How should PCM-based (main) memory be organized? n Pure PCM main memory [Lee et al., ISCA’09, Top Picks’10] q How to redesign the system to tolerate PCM shortcomings n Hybrid PCM+DRAM [Qureshi+ ISCA’09, Dhiman+ DAC’09] q How to partition/migrate data between PCM and DRAM 149 Reading: PCM as Main Memory: Idea in 2009 n Benjamin C. Lee, Engin Ipek, Onur Mutlu, and Doug Burger, \"Architecting Phase Change Memory as a Scalable DRAM Alternative\" Proceedings of the 36th International Symposium on Computer Architecture (ISCA), pages 2-13, Austin, TX, June 2009. Slides (pdf) One of the 13 computer architecture papers of 2009 selected as Top Picks by IEEE Micro. Selected as a CACM Research Highlight. 2022 Persistent Impact Prize. 150 Reading: More on PCM As Main Memory n Benjamin C. Lee, Ping Zhou, Jun Yang, Youtao Zhang, Bo Zhao, Engin Ipek, Onur Mutlu, and Doug Burger, \"Phase Change Technology and the Future of Main Memory\" IEEE Micro, Special Issue: Micro's Top Picks from 2009 Computer Architecture Conferences (MICRO TOP PICKS), Vol. 30, No. 1, pages 60-70, January/February 2010. 151 Intel Optane Persistent Memory (2019) n Non-volatile main memory n Based on 3D-XPoint Technology 152 https://www.storagereview.com/intel_optane_dc_persistent_memory_module_pmm DRAM vs. PCM n DRAM q Faster access (capacitor) q Lower density (capacitor less scalable) à higher cost q Requires refresh (power, performance, circuitry) q Manufacturing requires putting capacitor and logic together q Volatile (loses data at loss of power) q No endurance problems q Lower access energy n PCM q Slower access (heating and cooling based ”phase change” operation) q Higher density (phase change material more scalable) à lower cost q No need for refresh q Manufacturing requires less conventional processes – less mature q Non-volatile (does not lose data at loss of power) q Endurance problems (a cell cannot be used after N writes to it) q Higher access energy 153 Charge vs. Resistive Memories n Charge Memory (e.g., DRAM, Flash) q Write data by capturing charge Q q Read data by detecting voltage V n Resistive Memory (e.g., PCM, STT-MRAM, memristors) q Write data by pulsing current dQ/dt q Read data by detecting resistance R 154 Promising Resistive Memory Technologies n PCM q Inject current to change material phase q Resistance determined by phase n STT-MRAM q Inject current to change magnet polarity q Resistance determined by polarity n Memristors/RRAM/ReRAM q Inject current to change atomic structure q Resistance determined by atom distance 155 More on Emerging Memory Technologies 156https://www.youtube.com/watch?v=AlE1rD9G_YU&list=PL5Q2soXY2Zi9xidyIgBxUz7xRPS-wisBN&index=28 More on Emerging Memory Technologies 157https://www.youtube.com/watch?v=pmLszWGmMGQ&list=PL5Q2soXY2Zi9xidyIgBxUz7xRPS-wisBN&index=29 More on Memory Technologies 158https://www.youtube.com/watch?v=pmLszWGmMGQ&list=PL5Q2soXY2Zi9xidyIgBxUz7xRPS-wisBN&index=29 A Bit on Flash Memory & SSDs n Flash memory was a very “doubtful” emerging technology q for at least two decades 159 Proceedings of the IEEE, Sept. 2017 https://arxiv.org/pdf/1711.11427.pdf A Flash Memory SSD Controller 160 Cai+, “Error Characterization, Mitigation, and Recovery in Flash Memory Based Solid State Drives,” Proc. IEEE 2017. https://arxiv.org/pdf/1711.11427.pdf Lecture on Flash Memory & SSDs 161https://www.youtube.com/watch?v=rninK6KWBeM&list=PL5Q2soXY2Zi9xidyIgBxUz7xRPS-wisBN&index=47 SSD Course (Spring 2023) n Spring 2023 Edition: q https://safari.ethz.ch/projects_and_seminars/spring2023/ doku.php?id=modern_ssds n Fall 2022 Edition: q https://safari.ethz.ch/projects_and_seminars/fall2022/do ku.php?id=modern_ssds n Youtube Livestream (Spring 2023): q https://www.youtube.com/watch?v=4VTwOMmsnJY&list =PL5Q2soXY2Zi_8qOM5Icpp8hB2SHtm4z57&pp=iAQB n Youtube Livestream (Fall 2022): q https://www.youtube.com/watch?v=hqLrd- Uj0aU&list=PL5Q2soXY2Zi9BJhenUq4JI5bwhAMpAp13&p p=iAQB n Project course q Taken by Bachelor’s/Master’s students q SSD Basics and Advanced Topics q Hands-on research exploration q Many research readings 162https://www.youtube.com/onurmutlulectures Lectures on Memory Technologies n Computer Architecture, Fall 2020, Lecture 15 q Emerging Memory Technologies (ETH, Fall 2020) q https://www.youtube.com/watch?v=AlE1rD9G_YU&list=PL5Q2soXY2Zi9xidyIgBxUz 7xRPS-wisBN&index=28 n Computer Architecture, Fall 2020, Lecture 16a q Opportunities & Challenges of Emerging Memory Tech (ETH, Fall 2020) q https://www.youtube.com/watch?v=pmLszWGmMGQ&list=PL5Q2soXY2Zi9xidyIgBx Uz7xRPS-wisBN&index=29 n Computer Architecture, Fall 2020, Lecture 3b q Memory Systems: Challenges & Opportunities (ETH, Fall 2020) q https://www.youtube.com/watch?v=Q2FbUxD7GHs&list=PL5Q2soXY2Zi9xidyIgBxU z7xRPS-wisBN&index=6 163https://www.youtube.com/onurmutlulectures Tutorial on Processing in Memory 164https://www.youtube.com/onurmutlulectures https://www.youtube.com/watch?v=4x9nujJtqjM Processing in Memory Review and Open Problems 165 Onur Mutlu, Saugata Ghose, Juan Gomez-Luna, and Rachata Ausavarungnirun, \"A Modern Primer on Processing in Memory\" Invited Book Chapter in Emerging Computing: From Devices to Systems - Looking Beyond Moore and Von Neumann, Springer, to be published in 2021. https://arxiv.org/pdf/2012.03112.pdf PIM Course (Fall 2022) n Fall 2022 Edition: q https://safari.ethz.ch/projects_and_seminars/fall2022 /doku.php?id=processing_in_memory n Spring 2022 Edition: q https://safari.ethz.ch/projects_and_seminars/spring2 022/doku.php?id=processing_in_memory n Youtube Livestream (Fall 2022): q https://www.youtube.com/watch?v=QLL0wQ9I4Dw& list=PL5Q2soXY2Zi8KzG2CQYRNQOVD0GOBrnKy n Youtube Livestream (Spring 2022): q https://www.youtube.com/watch?v=9e4Chnwdovo&li st=PL5Q2soXY2Zi-841fUYYUK9EsXKhQKRPyX n Project course q Taken by Bachelor’s/Master’s students q Processing-in-Memory lectures q Hands-on research exploration q Many research readings 166 https://www.youtube.com/onurmutlulectures Digital Design & Computer Arch. Lecture 23a: Memory Organization & Technology Mohammad Sadrosadati Frank K. Gürkaynak (Lecture by Ataberk Olgun) ETH Zürich Spring 2024 17 May 2024 Goal: Processing Inside Memory n Many questions … How do we design the: q compute-capable memory & controllers? q processors & communication units? q software & hardware interfaces? q system software, compilers, languages? q algorithms & theoretical foundations? Cache Processor Core Interconnect Memory Database Graphs Media Query Results Micro-architecture SW/HW Interface Program/Language Algorithm Problem Logic Devices System Software Electrons Backup Slides: Inside A DRAM Chip 169 DRAM Module and Chip 170 Goals in DRAM Design • Cost • Latency • Bandwidth • Parallelism • Power • Energy • Reliability • Security • … 171 DRAM Chip 172 Row DecoderArray of Sense AmplifiersCell ArrayCell Array Row DecoderArray of Sense AmplifiersCell ArrayCell ArrayBank I/O Sense Amplifier 173 enable top bottom Inverter Sense Amplifier – Two Stable States 174 1 1 0 0VDD VDD Logical “1” Logical “0” Sense Amplifier Operation 175 0 VT VB VT > VB1 0 VDD DRAM Cell – Capacitor 176 Empty State Fully Charged State Logical “0” Logical “1” 1 2 Small – Cannot drive circuits Reading destroys the state Capacitor to Sense Amplifier 177 1 0 VDD 1 VDD 0 DRAM Cell Operation 178 ½VDD ½VDD 01 0 VDD½VDD+δ DRAM Subarray – Building Block for DRAM Chip 179Row DecoderCell Array Cell Array Array of Sense Amplifiers (Row Buffer) 8Kb DRAM Bank 180Row Decoder Array of Sense Amplifiers (8Kb) Cell Array Cell ArrayRow Decoder Array of Sense Amplifiers Cell Array Cell Array Bank I/O (64b)Address Address Data DRAM Chip 181 Row DecoderArray of Sense AmplifiersCell ArrayCell Array Row DecoderArray of Sense AmplifiersCell ArrayCell ArrayBank I/O Row DecoderArray of Sense AmplifiersCell ArrayCell Array Row DecoderArray of Sense AmplifiersCell ArrayCell ArrayBank I/O Row DecoderArray of Sense AmplifiersCell ArrayCell Array Row DecoderArray of Sense AmplifiersCell ArrayCell ArrayBank I/O Row DecoderArray of Sense AmplifiersCell ArrayCell Array Row DecoderArray of Sense AmplifiersCell ArrayCell ArrayBank I/O Row DecoderArray of Sense AmplifiersCell ArrayCell Array Row DecoderArray of Sense AmplifiersCell ArrayCell ArrayBank I/O Row DecoderArray of Sense AmplifiersCell ArrayCell Array Row DecoderArray of Sense AmplifiersCell ArrayCell ArrayBank I/O Row DecoderArray of Sense AmplifiersCell ArrayCell Array Row DecoderArray of Sense AmplifiersCell ArrayCell ArrayBank I/O Row DecoderArray of Sense AmplifiersCell ArrayCell Array Row DecoderArray of Sense AmplifiersCell ArrayCell ArrayBank I/O Shared internal bus Memory channel - 8bits DRAM Operation 182Row DecoderRow Decoder Array of Sense Amplifiers Cell Array Cell Array Bank I/O Data 1 2 ACTIVATE Row READ/WRITE Column 3 PRECHARGERow Address Column Address More on DRAM Operation: Section 2 n Vivek Seshadri and Onur Mutlu, \"In-DRAM Bulk Bitwise Execution Engine\" Invited Book Chapter in Advances in Computers, to appear in 2020. [Preliminary arXiv version] 183 https://arxiv.org/pdf/1905.09822.pdf See Section 2 for comprehensive DRAM Background","libVersion":"0.3.2","langs":""}
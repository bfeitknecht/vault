{"path":"HS23/LinAlg/UE/s/LinAlg-u01-s.pdf","text":"D-INFK Linear Algebra HS 2023 Afonso Bandeira Bernd G¨artner Solution for Assignment 1 1. a) This set of vectors is not linearly independent as v can always be written as a linear combination of any other vector, e.g. 0u = v. b) This set of vectors is linearly independent. To see this, we first check that v cannot be obtained as a linear combination of u: indeed, observe that we cannot obtain the 1 in the third and fourth coordinate of v from u as u contains 0 in both of those coordinates. Next, we check that w cannot be obtained as a linear combination of u and v. Such a linear combination would require scalars c and d such that cu + dv = c     1 1 0 0     + d     0 0 1 1     ! =     0 1 1 0     = w. But notice that the 1 in the second coordinate of w can only be obtained by setting c = 1. Similarly, the 1 in the third coordinate of w can only be obtained with d = 1. But with this choice of c and d, we would get 1 (instead of 0) in the first and forth coordinate. So we conclude that there is no such linear combination. From the lecture we know that checking the three vectors in any order (we did it in the order they were given) suffices to check linear independence. Hence, we conclude that the three vectors are linearly independent. c) In order to determine the rank of A, we have to find out how many of its columns are linearly independent. Let us denote the columns of A by v1, v2, v3, i.e. A =   | | | v1 v2 v3 | | |   . By checking the column vectors in order we quickly see that v2 can be obtained from v1 as v2 = −3v1. But if we try to obtain v3 from v1 we fail, since there is no c ∈ R such that both 1c = 3 and −2c = 0. In other words, the set of vectors {v1, v3} is linearly independent. We found a set of two vectors that is linearly independent and also observed that the set of all three vectors is not linearly independent. Therefore, the rank of A is 2. d) We proceed as in subtask c) and check linear independence of the columns of A. Let us again denote the columns of A by v1, v2, v3, i.e. A =   | | | v1 v2 v3 | | |   . We choose to check the columns in reverse order v3, v2, v1. In particular, we first check whether v2 is independent from v3. Indeed, there is no way of obtaining the 1 in the first coordinate of v2 if we only use v3, hence v2 is linearly independent from v3. It remains to check whether v1 can be obtained as linear combination of v2 and v3. Here we observe that there is no way of obtaining the 2 in the second coordinate of v1 since the second entry of both v2 and v3 is 0. We conclude that the three vectors are linearly independent and hence A has rank 3. 2. a) By definition of matrix-vector multiplication, we have Ax =     |u1||u2|...|um|      x =      u1 · x u2 · x ... um · x      . Assume now that we have Ax = 0. Then we must have ui · x = 0 for all 1 ≤ i ≤ m. By definition, this means that x is perpendicular to each of the vectors u1, u2, . . . , um. Conversely, if x is perpendicular to each of the vectors u1, u2, . . . , um, we must have ui · x = 0 for all 1 ≤ i ≤ m and hence Ax = 0. b) We take a small detour and first consider an arbitrary vector v that is perpendicular to both x and y. By definition, this means that we have v · x = 0 and v · y = 0. Now consider the scalar product v · (cx + dy). We have v · (cx + dy) = v1(cx1 + dy1) + v2(cx2 + dy2) + · · · + vn(cxn + dyn) = cv1x1 + cv2x2 + · · · + cvnxn + dv1y1 + dv2y2 + · · · + dvnyn = c v · x + d v · y = 0. In other words, any vector v that is perpendicular to both x and y is also perpendicular to (cx+dy). Now consider an arbitrary row ui from A. By subtask a), we know that ui is perpendicular to both x and y since we have Ax = 0 and Ay = 0. Hence, ui must also be perpendicular to (cx + dy). c) No, L is not a finite set. Take any non-zero vector x ∈ L (which must exist since |L| ≥ 2). Then every row ui of A must be perpendicular to x by subtask a). Hence, ui must also be perpendicular to cx for any choice of c ∈ R by subtask b). In other words, cx is perpendicular to all rows of A. By using the result from subtask a) again, this implies that A(cx) = 0 and hence cx ∈ L. For every choice of c we obtain a different vector in L. The number of choices of c is infinite/unbounded, hence L is not a finite set. 3. We have A = E , B = F and C = D and also A ̸= B ̸= C ̸= A. The equality of matrices B and F is observed quickly since bij = i + j = (i + 1) + (j − 1) = fij. The equality of the matrices A and E can be seen by using the binomial formula: eij = i ( j2 − 1 j + 1 + 1) = i ( (j − 1)(j + 1) j + 1 + 1) = ij = aij. For the last equality, we distinguish the two cases j ≥ i and j < i. In the first case, we have |i−j| = j −i and hence dij = i + j 2 + |i − j| 2 = j = max{i, j} = cij. In the second case, we instead have |i − j| = i − j and dij = i + j 2 + |i − j| 2 = i = max{i, j} = cij. It remains to prove A ̸= B ̸= C ̸= A. For this, we simply observe that a3,3 = 9, b3,3 = 6, and c3,3 = 3. 4. a) By definition of L, there exists w ∈ Rn such that L = {cw : c ∈ R}. In particular, we can write u = cuw for some cu ∈ R. Observe that we have cu ̸= 0 because u ̸= 0. Now consider an arbitrary vector v ∈ L. There must be cv ∈ R such that v = cvw. Putting these together, we get v = cv cu u. This already proves L ⊆ {cu : c ∈ R} and it remains to prove {cu : c ∈ R} ⊆ L. For this, consider an arbitrary vector v′ = cv′u ∈ {cu : c ∈ R}. Combining v′ = cv′u with u = cuw we get v′ = cv′cuw and hence v′ ∈ L. We conclude that L = {cu : c ∈ R}. b) Let L1 and L2 be two lines of Rn. By definition, there exist w1 and w2 such that L1 = {cw1 : c ∈ R} and L2 = {cw2 : c ∈ R}. In order to see that 0 ∈ L1 ∩ L2, it suffices to observe 0 ∈ L1 and 0 ∈ L2 since we have 0 = 0w1 = 0w2. Now assume L1 ∩ L2 ̸= {0}. Because L1 ∩ L2 is not empty, there exists a non-zero vector u ∈ L1 ∩ L2. By u ∈ L1, we know from part a) that L1 = {cu : c ∈ R}. Analogously, we have L2 = {cu : c ∈ R} and hence L1 = L2. c) By definition, there must be a vector w = [w1 w2 ] ∈ R2 such that L = {cw : c ∈ R2}. We want to find a vector d = [ d1 d2 ] ∈ R2 such that L = {v ∈ R2 : v · d = 0}. In particular, we want w · d = w1d1 + w2d2 ! = 0 since w ∈ L. Choosing d1 := −w2 and d2 := w1 would certainly work, so let this be our “guess” for d. It remains to prove that with this choice of d, we have L = {v ∈ R2 : v · d = 0}. ⊆: Consider an arbitrary element u = cuw ∈ L. We have u · d = (cuw) · d = cuw1d1 + cuw2d2 = cu(w1d1 + w2d2) = 0 and hence u ∈ {v ∈ R2 : v · d = 0}. ⊇: Consider an arbitrary element v ∈ {v ∈ R2 : v · d = 0}. In particular, we have v1d1 + v2d2 = −v1w2 + v2w1 = 0. Our goal is to find c such that v = cw. Recall from the definition of a line that we must have w ̸= 0 and hence either w1 ̸= 0 or w2 ̸= 0. Assume first w1 ̸= 0 and observe that we can rewrite −v1w2 + v2w1 = 0 to v2 = w2 w1 v1. Choosing c = v1 w1 we can see that indeed, we have v1 = cw1 and v2 = cw2, as desired. If we have w1 = 0, then it must be the case that w2 ̸= 0. But then we can rewrite −v1w2 + v2w1 = 0 to v1 = w1 w2 v2 and choose c = v2 w2 . d = [ 1 3 ] 0 [ −3 1 ] xy Figure 1: This figure from the lecture notes illustrates the situation in task c). The yellow line given by {c [ −3 1 ] : c ∈ R} is equal to the hyperplane {v : v · [ 1 3 ] = 0}. 5. We first observe that we have ∥ v ∥ = √ x2 + y2 + z2 = √ z2 + x2 + y2 = ∥ w ∥. In particular, this implies ∥ v ∥ ∥ w ∥ = x2 + y2 + z2. Using the formula from the lecture for the angle α between v and w, we calculate cos(α) = v · w ∥ v ∥ ∥ w ∥ = xz + yx + zy x2 + y2 + z2 . Next, observe that we can rewrite xz + yx + zy = 1 2 (x + y + z)2 − 1 2 (x2 + y2 + z2). By our assumption x + y + z = 0, the first term vanishes and we obtain cos(α) = xz + yx + zy x2 + y2 + z2 = − 1 2 (x2 + y2 + z2) x2 + y2 + z2 = − 1 2 . To find α, it remains to look up (or remember) cos−1(− 1 2 ) = 2 3 π ( = 120◦).","libVersion":"0.3.2","langs":""}
{"path":"var/export/LinAlg-bf-u09.pdf","text":"2     Preserving Inner Products To prove is the following implication. (Qv) ⊤(Qw)= v⊤w ⟹ Q⊤ = Q−1 Assume the LHS of the implication for all vectors v, w ∈ Rm and an arbitrary square matrix Q ∈ Rm×m. Then rewrite (Qv) ⊤(Qw) as v⊤Q⊤Qw, by deﬁnition of transpose and per associativity. Now we have v⊤Q⊤Qw = v⊤w. This implies that the innermost inner product must be equal to the m × m identity matrix, i.e. Q⊤Q = Im. It follows that Q⊤ = Q−1, the deﬁnition of an orthogonal matrix. Thus we have proven the statement above. □","libVersion":"0.5.0","langs":""}
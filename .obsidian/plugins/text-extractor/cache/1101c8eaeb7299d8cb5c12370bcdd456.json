{"path":"sem4/FMFP/VRL/extra/mschlegel/FMFP-mschlegel-w01.pdf","text":"Material zur Übungsstunde von Maximilian Schlegel – mschlegel@student.ethz.ch Woche 1 – Übersicht, Tricks & Aufgaben (Disclaimer: Die hier vorzufindenden Notizen haben keinerlei Anspruch auf Korrektheit oder Vollständigkeit und sind nicht Teil des offiziellen Vorlesungsmaterials. Alle Angaben sind ohne Gewähr.) Allgemeines zur Übungsstunde: Anmerkungen zu den Abgaben: • Wöchentlich erscheinen (Montags) Aufgaben auf Code-Expert und auf der Kurs-Website. Auf Code-Expert erscheinen Programmieraufgaben (Haskell) und auf der Kurs-Website Pen-and-paper-Aufgaben. • Es ist optional, die Aufgaben zu lösen. Es gibt keine Bonuspunkte oder Notenabzüge, wenn ihr Aufgaben nicht löst. Allerdings empfehle ich euch dringend, die Aufgaben wöchentlich zu lösen, da ihr sonst den Anschluss verliert – und nur sehr schwer wieder einsteigen könnt. Die Klausur beinhaltet ausserdem ähnliche Aufgaben. • Es ist vollkommen okay und normal, wenn ihr nicht alles auf Anhieb alleine lösen könnt. Versucht trotzdem, die Aufgaben ohne die Musterlösung zu lösen. • Die Aufgaben sind anfangs noch überwiegend einfach und in vergleichsweise kurzer Zeit lösbar, werden aber - meiner Meinung nach - mit zunehmender Komplexität des Unterrichtsmaterials auch schwieriger und zeitintensiver. Plant also eure Bearbeitungszeit nicht anhand des Eindrucks der ersten 1-3 Wochen. • Abgaben der Theorieaufgaben in diesem Jahr auf Papier in der Übungsstunde, Submission der Programmieraufgaben via Expert. • Es nicht alle Aufgaben korrigiert, sondern nur die Theorieaufgaben mit einem (*). Ich werde mir eure Code-Expert Submissions angucken und allgemeine Fehler in den Übungsstunden ansprechen, allerdings nur falls absolut nötig individuelles Feedback geben. • Mittwochs, 10 Uhr bis 12 Uhr im LEE C114 • Unterrichtssprache ist deutsch. Allerdings spreche ich natürlich auch Englisch und ihr könnt mir sowohl auf Deutsch als auch auf Englisch fragen stellen, sei es per Mail oder in Person • Wie bereits im letzten Jahr möchte ich begleitend zur Übungsstunde eine WhatsApp- Gruppe eröffnen, über die ihr u.a. Fragen (inhaltlich/organisatorisch) stellen könnt. Die Teilnahme an der Gruppe ist selbstverständlich vollkommen optional und alle relevanten Informationen von meiner Seite werden per Mail oder in den Übungsstunden kommuniziert, damit niemand etwas verpasst. Den Link zur Gruppe: https://chat.whatsapp.com/GyJU0la5Ao4FuodifPfvU0 • Da wir alle ungefähr gleich alt und gleich weit im Studium sind, wäre es eigenartig, von euch gesiezt zu werden. Duzt mich bitte und nennt mich gerne einfach Max, egal ob per Mail oder in Person. :) Material zur Übungsstunde von Maximilian Schlegel – mschlegel@student.ethz.ch Recap: Mathematische Induktionsbeweise Ihr werdet in diesem Kurs häufig Induktionsbeweise führen (vermutlich spätestens ab Woche 4). Dabei werdet ihr mit verschiedenen speziellen Induktionsarten vertraut gemacht werden, damit ihr diese aber gut versteht, möchte ich an dieser Stelle noch einmal das Grundprinzip von (starker) Induktion formal vorstellen: Und hier noch der Vollständigkeit halber ein simpler klassischer Induktionsbeweis: Sei: 𝐴(𝑛) ≡ (𝑛2 + 𝑛) 𝑒𝑟𝑔𝑖𝑏𝑡 𝑠𝑡𝑒𝑡𝑠 𝑒𝑖𝑛𝑒 𝑑𝑢𝑟𝑐ℎ 2 𝑡𝑒𝑖𝑙𝑏𝑎𝑟𝑒 𝑍𝑎ℎ𝑙 Beweise, dass gilt: ∀𝑛 ∈ ℕ ∶ 𝐴(𝑛) Behauptung: ∀𝑛 ∈ ℕ ∶ 𝐴(𝑛) Induktionsanfang: (𝑛 = 0): (02 + 0) = 0 und 0 ist durch 2 teilbar. Induktionsvorraussetzung: Sei 𝑚 ∈ ℕ beliebig, wir nehmen an, dass 𝐴(𝑚) gilt. Prinzip der vollst. Induktion: (𝐴(𝑛0) ∧ [∀𝑛 ∈ ℕ, 𝑛 ≥ 𝑛0 ∶ 𝐴(𝑛) ⇒ 𝐴(𝑛 + 1)]) ⇒ ∀𝑛 ∈ ℕ, 𝑛 ≥ 𝑛0 ∶ 𝐴(𝑛) • Behauptung: ∀𝑛 ∈ ℕ, 𝑛 ≥ 𝑛0 : 𝐴(𝑛) • Induktionsanfang / Base Case (IA/BC): Zeige, dass A für kleinstes 𝑛0 gilt • “A(n) gilt für EIN konkretes n” • Induktionshypothese / Induktionsvorraussetzung (IH / IV) 𝐴(𝑚) gilt für bel. fixes 𝑛. “A(m) gilt für EIN allgemeines m” • Induktionsschritt (IS): Beweis von 𝐴(𝑚) ⇒ 𝐴(𝑚 + 1) • “Wenn A(m) für ein m gilt, dann gilt immer auch A(m+1), • da wir m allgemein gehalten haben” ⇒ Induktionsbehauptung (IB): ∀𝑛 ∈ ℕ, 𝑛 ≥ 𝑛0 : 𝐴(𝑛) Prinzip der Starken Induktion: (𝐴(𝑛0) ∧ [∀𝑛 ∈ ℕ, 𝑛 > 𝑛0 ∶ (∀𝑘 ∈ ℕ, 𝑛0 ≤ 𝑘 < 𝑛 ∶ 𝐴(𝑘)) ⇒ 𝐴(𝑛)]) ⇒ ∀𝑛 ∈ ℕ, 𝑛 > 𝑛0 ∶ 𝐴(𝑛) • Behauptung: ∀𝑛 ∈ ℕ, 𝑛 ≥ 𝑛0 : 𝐴(𝑛) • Induktionsanfang / Base Case (IA/BC): Zeige, dass A für kleinstes 𝑛0 ∈ ℕ (oder eine Menge an kleinsten 𝑛0, … , 𝑛𝑥 ∈ ℕ) gilt “A(n) gilt für EIN konkretes 𝑛0 (bzw. EINE konkrete Menge 𝑀 ≔ {𝑛0, … , 𝑛𝑥})” • Induktionshypths. / Induktionsvorstz. (IH / IV): Für bel. fix 𝑚 ≥ 𝑛0 : ∀𝑛0 ≤ 𝑘 < 𝑚 ∶ 𝐴(𝑘) “ “A(k) gilt für alle k < m für EIN allgemeines m” • Induktionsschritt (IS): Beweis von 𝐴(𝑚) ⇒ 𝐴(𝑚 + 1) • “Wenn A für alle 𝑘 ∈ {𝑛0, … , 𝑚} gilt, dann gilt immer auch A(m+1), da wir n allgemein gehalten haben” ⇒ Induktionsbehauptung (IB): ∀𝑛 ∈ ℕ : 𝐴(𝑛) Material zur Übungsstunde von Maximilian Schlegel – mschlegel@student.ethz.ch Induktionsschritt: (𝑚 → 𝑚 + 1): 𝐴(𝑚 + 1) ≡ ((𝑚 + 1)2 + (𝑚 + 1)) 𝑖𝑠𝑡 𝑑𝑢𝑟𝑐ℎ 2 𝑡𝑒𝑖𝑙𝑏𝑎𝑟. Es gilt: ((𝑚 + 1)2 + (𝑚 + 1)) = 𝑚2 + 2𝑚 + 1 + 𝑚 + 1 = (𝑚2 + 𝑚) + 2(𝑚 + 1) Nun sehen wir, dass 2(𝑚 + 1) trivialerweise durch 2 teilbar ist. Ausserdem, haben wir per I.V. angenommen, dass 𝛢(𝑚) gilt, also (𝑚2 + 𝑚) durch 2 teilbar ist. Da die Summe von zwei, durch 2 teilbaren Zahlen auch durch 2 teilbar ist, haben wir damit gezeigt, dass 𝐴(𝑚 + 1) gilt. Nach dem Prinzip der vollständigen mathematischen Induktion folgt: ∀𝑛 ∈ ℕ ∶ 𝐴(𝑛) ∎ Functional Programming – Grundlagen: Haskell – Einführung: Ich werde in meinen Unterrichtsstunden unter anderem Material aus dem sehr empfehlenswerten Buch “Learn You a Haskell for Great Good!”(Lipovaca, 2011) verwenden. Haskell ist: • Lazy (Später mehr dazu): Argumente werden erst dann evaluiert, wenn es nicht anders geht. Das erlaubt bspw. das Verwenden von unendlich langen Listen. • Statically Typed: Variable-Typen stehen bei Compile-Time fest. Bei Haskell muss allerdings nicht der Programmierer explizit den Typ aller Variablen/Funktionen angeben, da Haskell Type-Inference anbietet, also in der Lage ist, selbst die Typen zu erkennen. Damit werden viele typische Bugs schon bei Compile-Time abgefangen (Später mehr dazu) • Konzept, dass seine Wurzeln in der Mathematik hat: “Programm aus Funktionen” • “Pure Functions”: Funktionen die für dieselben Eingaben immer dieselben Ausgaben zurückgibt und keine Side-Effects hat. o “Side-Effects”: Wenn eine Funktionen etwas an bzw. von dem State des Programms verändert oder verwendet, also beispielsweise globale Variablen überschreibt oder liest. • Das Verwenden von Pure Functions garantiert uns sogenannte “referential transparacy”: Wir können eine Funktion in einer Expression mit ihrem Ergebnis vertauschen und erhalten das gleiche Ergebnis, da es keine Nebeneffekte gibt, bspw: (sum 2 2) + 3 == 4 + 3 • Referential Transparacy erlaubt es uns, mathematisch über Programmbausteine zu argumentieren (Später! Aber: Indem wir Funkt. & Ergeb. in Beweisen vertauschen könn.) • Functional Programming verwendet Pure Functions als Grundbausteine, die zu komplexeren Funktionen zusammenkonstruiert, nicht nur selbst Werte berechnen, sondern auch wie Werte in anderen Programmiersprachen behandelt, sprich als Parameter übergeben, als Rückgabewert von anderen Funktionen zurückgegeben oder in komplexen Datenstrukturen verwendet werden können. • Wozu das alles? Functional Programming erlaubt es zuverlässig sehr komplexe Programme zu schreiben, da wir die Korrektheit aller verwendeten Funktionen mathematisch beweisen können. Ausserdem sind Programme ohne mutable state und Funtionen mit Side-Effects deutlich leichter zu parallelisieren → attraktiv auch für ML! Material zur Übungsstunde von Maximilian Schlegel – mschlegel@student.ethz.ch GHC und GHCi: GHC ist der Haskell-Compiler, den wir in FMFP verwenden werden. Theoretisch könnt ihr eine .hs file schreiben, sie mit GHC (“ghc file.hs”) kompilieren und die erhaltene executable file anschliessend ausführen (Dabei wird dann immer zuerst die main Function ausgeführt). Da dies allerdings sehr aufwändig ist, verwenden wir meistens GHCi, den “interactive mode” von GHC. Dafür gehen wir folgendermassen vor: “ghci” eingeben und anschliessend file “laden” mit “:l file.hs”. Nun können einzelne Funktionen oder Haskell Expressions direkt in GHCi ausgeführt werden, bspw. “ghci> mySum 2 3” oder “ghci> 2*4” oder “ghci> let a = 4” oder “ghci> [x|x<-[1..20], (odd x)]”. (Nicht erschrecken, die einzelnen Expressions werden im Laufe des Kurses alle verständlich). Haskell Functions (Grundlagen): In Haskell schreiben wir Funktionen, indem wir ihre Definition angeben. Die Declaration, die aus Funktionenname und den Typen des Parameters und des Rückgabewertes besteht, kann aufgrund von Haskells Type Inference allerdings weggelassen werden: Haskell kann die Typen selbst erkennen. Wir können Funktionen sehr einfach zusammenfügen, um komplexere Funktionen zu erstellen: If-Then-Else-Statements in Haskell: Wir können auch If-Then-Else-Statements, wie wir sie aus anderen Programmiersprachen kennen, in Haskell verwenden. In Haskell sind If-Then-Else-Statements Expressions und müssen dementsprechend wie alle Haskell Funktionen/Expressions einen eindeutigen Rückgabewert haben (Gleicher Input – Gleicher Output). Deshalb müssen alle Fälle definiert sein, es geht also nicht, bspw. einfach den Else-Part wegzulassen, da es sonst nicht für jeden Fall einen Rückgabewert für die Expression gäbe, was verboten ist. Aber dies erlaubt es uns auch, If-Then-Else-Statements bspw. direkt in Berechnungen (wie du es vielleicht von anderen Expressions in anderen Programmiersprachen kennst) zu verwenden, bspw.: Material zur Übungsstunde von Maximilian Schlegel – mschlegel@student.ethz.ch Wir können in If-Then-Else Statement auch eine andere Formatierung (direkt untereinander) und selbstverständlich auch “else if” Fälle verwenden. Haskell Functions (Pattern Matching): Wir setzen in Haskell unter anderem auf ein sehr interessantes Prinzip namens Pattern Matching: Wir können für eine Funktion für verschiedene Inputs verschiedene Funktionen-Definitionen schreiben und je nachdem, welchen Wert der Input hat, wird die entsprechende Definition ausgeführt. Das entspricht ungefähr dieser Funktionen-Definition, die man aus der Mathematik kennt: (Beispiel): 𝑓(𝑥) = {2, if x = 0 −1, if x = 1 𝑥2, else In Haskell sieht das dann beispielsweise so aus: Achtung: wenn ihr einer Funktion einen negativen Wert mit einem Minus übergebt (was hier nicht passiert, das ist eher eine allgemeine Anmerkung) muss dieser Negative Wert mit Klammern umrandet werden. Denn “f -4” ist kein Funktionenaufruf von f mit Eingabewert -1 sondern wird von Haskell als eine Expression verstanden, also eine Subtraktion mit 1 von f. Richtig wäre also: “f (-4)”: Mit Pattern Matching können wir also auch sehr gut rekursive Funktionen schreiben: Dabei definieren wir immer einen oder mehrere Base Cases und den Rekursions-Fall nach dem Prinzip des Pattern Matching: Material zur Übungsstunde von Maximilian Schlegel – mschlegel@student.ethz.ch Allerdings kann es beim Pattern Matching auch zu Problemen kommen: Falls unsere Funktionen- Definitionen nicht alle Definitionen abdecken, kann es passieren, dass wir eine Exception zu “falschen” Inputs bekommen. Sei dies ein Beispiel: Unsere Funktion ist für die Patterns Input = 1 und Input = 2 definiert, allerdings nicht für andere Inputs. Wenn wir nun aber failfunc mit bspw. dem Wert 3 aufrufen, bekommen wir ein Problem: “Non-exhaustive patterns” -Exceptions bedeuten für uns, dass zur Laufzeit kein Pattern gefunden werden konnte, zu dem der Input, mit dem wir die Funktion aufgerufen haben, gematched werden konnte. Haskell Functions (Guards): In Haskell gibt es neben Pattern Matching noch eine andere Möglichkeit, um in Funktionen Fälle zu unterscheiden: Von oben nach unten werden die Guards “abgearbeitet”, indem geprüft wird, ob der guard zu “True” evaluiert → falls ja, wird die zugehörige Funktionendefinition zurückgegeben, falls nein wird mit nem nächsten Guard weitergemacht (Achtung: Auch hier sind Non-exhaustive Patterns möglich!) Um Non-Exhaustive Patterns zu vermeiden oder/bzw. alle allgemeinen Fälle abzudecken, gibt es dass Keyword “otherwise”, das immer zu “True” evaluiert und damit jeden Fall erwischt. Hier ein weiteres Beispiel: Material zur Übungsstunde von Maximilian Schlegel – mschlegel@student.ethz.ch Unterschied zwischen Guards und Pattern Matching: Im Gegensatz zu Guards, bei denen wir komplexe boolsche Expressions evaluieren können, können wir beim Pattern Matching nur – nunja – Patterns abfangen. Also klar, wir können zwar unterscheiden, ob ein Funktionenargument eine 3 oder eine 11 oder eine beliebige andere Zahl ist, aber wir können bspw. nicht direkt prüfen, ob das Argument eine gerade oder ungerade Zahl ist. Dafür können wir mit Pattern Matching Variablen binden, bspw. für Listen (siehe unten) mit x:xs. Insofern haben beide Funktionalitäten ihre Relevanz und finden Verwendung (oft auch gemeinsam!). Haskell Functions (Where): Wenn wir eine bestimmte Variable oder Funktion mehrfach verwenden, können wir sie auch einfach einmal definieren und dann mit dem where-keyword einbinden. Wichtig: “Where-Bindings” sind nur in der jeweiligen “Pattern Definition” sichtbar. Haskell Functions (Let-Bindings): Let <definition> in <expression> ist in etwa so, als würde man <expression> where <definition> schreiben. Aber es gibt einen wichtigen Unterschied, der auch die Existenzberechtigung von Let- Bindings begründet: Sie sind selbst Expressions und können somit überall verwendet werden, wo man Expressions verwenden kann. Unterschied WHERE und LET-IN: „Where“ können wir nur im Kontext von Funktionen verwenden, während Let-In eigenständige Expressions sind. Das bedeutet weiter aber auch, dass Let-In-Expressions immer einen eindeutigen Wert haben, so wie alle Expressions in Haskell. Andererseits erlauben where-bindings einen scope über mehrere guarded Expressions. Daher verwendet man sie oft, wenn man mit Guards eine bestimmte Condition prüft, die (oder von der man Teile) allerdings einmal kompakt beschreibt. Material zur Übungsstunde von Maximilian Schlegel – mschlegel@student.ethz.ch Haskell Functions (Case-Expressions): Es gibt sogar noch mehr Möglichkeiten in Haskell, um verschiedene Fälle zu behandeln: Die expression wird mit den patterns gematched, genau so wie wir es vom pattern matching bei funktionen bereits kennen. Das Gesamtkonstrukt (also die Case Expression selbst) ist wieder eine Expression und kann somit an allen “Orten” verwendet werden, wo wir Case-Expressions erwarten würden. Zum Beispiel so: Haskell Tuples: Tuples in Haskell sehen genau so aus, wie man es sich vorstellen würde. Sie werden mit runden Klammern notiert und können aus beliebigen Typen bestehen (auch Funktionen!). Natürlich können wir auch verschachtelte Tupel haben. Wichtig zu kennen sind die fst und die snd Funktionen aus der Haskell Prelude, deren Beschreibung trivial ist. Haskell Lists: Listen sind eines der Kernelemente von Haskell und sehr interessant da sie sehr vielfältig eingesetzt werden können: Sie werden mit eckigen Klammern notiert und die einzelnen (vom Typ homogenen!) Element emit Kommata getrennt. Beispielsweise [1,2,3,4,5] ist eine Liste aus 5 Integern. Ein String, z.B. “Hello”, ist in Haskell nur syntactic sugar für eine List [‘H’, ‘e’, ‘l’, ‘l’, ‘o’], das heiss, wir behandeln String immer so wie Listen – denn das sind sie. Wir können Elemente an Listen mit diesem Operator: ‘:’ anhängen, bspw. 1:[2,3] = [1,2,3]. Jede Listendarstellung der Form [a,b,c,d,e] ist in Haskell also nur eine vereinfachte Form davon, wie die Listen wirklich gespeichert sind, undzwar als a:b:c:d:e:[] Das können wir für recursive Funktionen, die Listen durchgehen sollen gut verwenden: Material zur Übungsstunde von Maximilian Schlegel – mschlegel@student.ethz.ch Hier habe ich einen typischen Ansatz für das Patternmatching mit Listen verwendet: Es gibt den Base Case der leeren Liste ‘[]’ oder den rekursiven Fall indem die Liste die Form x:xs hat, wobei x also das vorderste Listenelement und xs die restliche Liste ist. Achtung: xs kann auch eine leere Liste repräsentieren, es steht einfach für irgendeine beliebige Liste. Theoretisch könnte man also auch ein Patternmatching der Form (x:y:xs) machen. Hier ist aber wichtig, dass die Liste (noch) mind. 2 Elemente hat, ansonsten kann dieses Pattern nicht gematched werden. Man müsste den Fall mit einem einzigen Element also extra abfangen: Das ist allerdings ein Beispiel, das ich hier nur angebe, um zu erklären was ich meine. Dieses kompliziertere Patternmatching braucht es hier eigentlich nicht. Manchmal aber schon. Wir können Listen mit diesem Operator: ‘++’ konkatinieren, z.B.: [1,2]++[3,4] = [1,2,3,4] (auch das ist bei rekursiven Funktionen mit Listen oft sehr nützlich). Hier einige wichtige Prelude-Funktionen (die also schon von Haskell gegeben sind): Material zur Übungsstunde von Maximilian Schlegel – mschlegel@student.ethz.ch Es ist eine sehr gute und einfache Übung, alle diese Funktionen einmal selbst zu implementieren. Auch wichtig ist zu wissen, dass wir Listen als “Ranges” angeben können: • [1..10] gibt die Liste [1,2,3,4,5,6,7,8,9,10] (alle Zahlen von 0 bis 10) • [0,2..10] gibt die Liste [0,2,4,6,8,10] (gerade Zahlen von 0 bis 10) • [‘a’..’z’] gibt die Liste aller Buchstaben von a bis z (bzw. den String “abcdefghijk...rstuvwxyz”) • [1,2...] gibt die unendliche Liste aller natürlichen Zahlen (wie man damit arbeiten kann erfahrt ihr im Kapitel lazy evaluation, bzw. später im Kurs) Haskell List Comprehension: Falls ihr dem Thema bereits begegnet seid, verweise ich an dieser Stelle auf das Buch Learnyouahaskell, da dieses Thema vorraussichtlich erst in 2-3 Wochen Gegenstand der Übungsstunde sein wird und bis dahin den Rahmen sprengt. Haskell IO: Wir können auch I/O in Haskell verwenden. Das Prinzip dahinter ist ein wenig kompliziert, da I/O grundsätzlich dem Prinzip von Functional Programming widerspricht (Der State eines I/O devices wird verändert), allerdings gibt es in Haskell Funktionen, die uns I/O erlauben. Wieso genau das funktioniert, ist allerdings noch nicht Stoff dieser Einführungsübung: Die Funktion putStrLn x gibt den String x in einer neuen Zeile aus. Die Funktion getLine, genutzt als x <- getLine, liest einen Eingabe-String in x. Die Funktion show, genutzt als show x, wandelt x in einen String um (bspw. show 11 → “11”) Die Funktion read, genutzt als read x :: Type, wandelt x (type String) in typ Type um, (bspw. read “23” :: Double → 23.0) Haskell Lazy Evaluation (Basics): Wie eingangs erwähnt, verwendet Haskell sogenannte Lazy Evaluation. Das heisst vereinfacht gesagt, dass Haskell eine Expression nicht evaluiert, bis das Resultat der Expression gebraucht wird, beziehungsweise konkret für Funktionen, dass Argumente erst in die Funktionendefinition substituiert und erst evaluiert werden, wenn sie gebraucht werden. Hier ein paar Beispiele: [NÄCHSTE SEITE] Material zur Übungsstunde von Maximilian Schlegel – mschlegel@student.ethz.ch [NATURAL DEDUCTION AUF DER NÄCHSTEN SEITE] Material zur Übungsstunde von Maximilian Schlegel – mschlegel@student.ethz.ch Natural Deduction: Übersicht der Regeln: Wichtig: “Recall that → is right-associative, while ∧ and ∨ are left-associative. Moreover, ¬ binds stronger than ∧, which binds stronger than ∨, which in turn binds stronger than →.” (Quelle: Übung 1) Hier einige Beispiele zur Assoziativität: Nun zur grundlegenden Idee von Natural Deduction Proofs und der Notation: 𝐴1, … 𝐴𝑛 ⊢ 𝐴 bedeutet, dass 𝐴 aus 𝐴1, … 𝐴𝑛 folgt, also mit Regeln der Natural Deduction hergeleitet werden kann (in einer sogenannten Derivation). Material zur Übungsstunde von Maximilian Schlegel – mschlegel@student.ethz.ch Derivations in Natural Deduction Proofs verlaufen immer nach einer Baum-Struktur. Das heisst, die Regeln geben an, was aus was hergeleitet werden kann. Trivial gelten also Axiome wie 𝐴 ⊢ 𝐴, das heisst, sie können aus “nichts” hergeleitet werden, denn sie gelten immer. Das Γ (“grosses Gamma”) steht dabei in den Regeln einfach für eine beliebige, von uns gewählte, Variablenmenge, für die wir annehmen, dass sie wahr ist. Da das Derivation System der Natural Deduction sound ist, gilt: wenn 𝐴1, … , 𝐴𝑛 ⊢ 𝐴, dann auch 𝐴1, … , 𝐴𝑛 ⊨ 𝐴. Ein Natural-Deduction Proof ist ein Beweis, dessen Root keine Annahmen/LHS hat, also die Form ⊢ 𝐹𝑜𝑟𝑚𝑒𝑙 hat. Die Derivation-Rules ergeben beim genauen Betrachten sofort Sinn: (Beispiel ∧ −𝐼) Wenn gilt, dass aus der Annahme A folgt und aus der Annahme B folgt, dann folgt aus der Annahme (siehe Holy Chapter 6, Diskrete Mathematik) auch, dass 𝐴 ∧ 𝐵 gilt, also ist diese Regel einfach eine ∧- Introduction, kurz ∧ −𝐼. Genauso haben wir aber auch Regeln, die Eliminationen vornehmen, bspw. ∧ −𝐸𝐿, die mit unsrem jetzigen Wissen sofort Sinn ergibt: Wenn aus unserer Annahme 𝐴 ∧ 𝐵 folgt, können wir daraus herleiten, dass aus unserer Annahme auch 𝐴 folgt. Wollen wir nun also 𝐴 beweisen, müssen wir zeigen, dass 𝐴 eine Tautologie ist, also einen Derivation Tree konstruieren, der die Root ⊢ 𝐴 hat. Hier sind nun einige Beispiele: (Auf der nächsten Seite ist noch ein kompliziertes Beispiel) Material zur Übungsstunde von Maximilian Schlegel – mschlegel@student.ethz.ch","libVersion":"0.5.0","langs":""}
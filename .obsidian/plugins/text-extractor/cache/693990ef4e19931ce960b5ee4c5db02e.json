{"path":"sem4/DMDB/VRL/extra/slides/DMDB-s14-query-optimization.pdf","text":"Data Modeling and Databases Spring Semester 2025 Query Optimization Query Optimization Gustavo Alonso Institute of Computing Platforms Department of Computer Science ETH Zürich 1 Query Optimization 2 QUERY Disk Manager Buffer Pool Management Access Methods Operator Execution Query Optimization SQL Query Result Relation We know how to run each of these operators now ▪ Fundamental Questions: ➢ Q1: How to run a physical plan, given that we know how to run each operator. ➢ Q2: How to search for the best physical plan? Logical Plan: What the user logically wants Physical Plan: DBMS can take it and run Query Optimization Query Optimization 3 SELECT * FROM R, S WHERE R.id = S.id; ▪ Fundamental Questions: ➢ Q1: How to run a physical plan, given that we know how to run each operator. ➢ Q2: How to search for the best physical plan? ▪ 1. Execution Model: How different operators are put together ▪ 2. Cost Model: How to estimate the cost of each physical plan, given our execution model ▪ 3. Search Space: What are the logically equivalent set of physical plans? ▪ 4. Search Algorithm: How can we search the best physical plan, given cost model? Logical Plan: What the user logicall wants Physical Plan: DBMS can take it and run Query Optimization 1. Execution Model 4 ▪ There are different ways to put operators together ➢ Iterator Model ➢ Materialization Model ➢ … ▪ Iterator Model ➢ Each operator is an iterator – it takes as input a set of streams of tuples (each of which provides a next()) interface, and outputs a stream of tuples (that can be accessed by other operators via next()) ➢ A query plan is a tree of iterators. ➢ To get result, call root.next() again and again. ➢ Volcano model: Data flow from bottom to top. Stream of tuples Stream of tuples next() next() next() next() Query Optimization 1. Execution Model 5 ▪ Iterator Model ▪ Pros ➢ generic interface for all operators: great information hiding ➢ easy to implement iterators (clear what to do in any phase) ➢ no overheads in terms of main memory ➢ supports pipelining ➢ supports parallelism and distribution: add special iterators ▪ Cons ➢ high overhead of method calls ➢ poor instruction cache locality Stream of tuples Stream of tuples next() next() next() next() Query Optimization 1. Execution Model 6 ▪ There are different ways to put operators together ➢ Iterator Model ➢ Materialization Model ➢ … ▪ Materialization Model ➢ Each operator processes its input all at once and then emits its output all at once. ➢ Good when the intermediate result is not too much larger than the final result (Why?) • OLTP is one example workload • OLAP might not be a good workload for materialization model Relation Relation Query Optimization 1. Execution Model 7 ▪ There are different ways to put operators together ➢ Iterator Model ➢ Materialization Model ➢ … ▪ Vectorization Model ➢ Similar to iterator model, but each operator returns a batch of tuples instead of a single tuple on the invocation of next(). ▪ Good for OLAP: ➢ Greatly reduces the number of invocations per operator. ➢ Allows for operators to use vectorized (SIMD, AVX) instructions to process batches of tuples. Next Batch Next Batch Query Optimization 2. Search Space 8 ▪ Given an input logical plan, there are different ways that one can construct a physical plan: ➢ Different join order ➢ When should selection happens? ➢ … ▪ We now define a set of transformations (we call them query rewriting rules) that will take as input a query plan and output an equivalent query plan. ➢ Input: Relational Algebra Expression E ➢ Output: Relational Algebra Expression E′ ➢ Property: E is equivalent to E′: ∀I∈I,E(I)=E′(I) where I is all possible DB instances. Query Optimization 2. Search Space 9 ▪ Rule 1. Conjunctive selection operations can be deconstructed into a sequence of individual selections ▪ σθ1∧θ2(E)=σθ1(σθ2(E)) ▪ Proof: ➢ LHS = {t:t∈E∧(θ1∧θ2(t))=true} ➢ RHS = {t:t∈E∧θ1(t)=true∧θ2(t)=true} ➢ Then proof by the definition of θ1∧θ2: ∀E: LHS ⊆ RHS, RHS ⊆ LHS ▪ Many other rules we see might look trivial, but there is always a formal proof underneath the cover. σθ1​∧θ2 σθ1 σθ2 Query Optimization 2. Search Space 10 ▪ Rule 2. Selection operations are commutative ▪ σθ1(σθ2(E))=σθ2(σθ1(E)) ▪ Application: ➢ Allows to put first the one that, e.g., has an index σθ2 σθ1 σθ1 σθ2 Query Optimization 2. Search Space 11 ▪ Rule 3. Only the last in a sequence of projection operations is needed, the others can be omitted ▪ Πt1(Πt2(E))=Πt1(E) ▪ (Because 𝑡1 ⊆ 𝑡2, otherwise it is not a valid expression) ▪ Application: ➢ Avoids going twice over the data Πt1 Πt1 Πt2 Query Optimization 2. Search Space 12 ▪ Rule 4. Selections can be combined with Cartesian products and theta joins. ▪ σθ(E1×E2)=E1⋈θE2 ▪ σθ1(E1⋈θ2E2)=E1⋈θ1∧θ2E2 ▪ Application: ➢ Avoid having to go twice over the data: do the selection while doing the join ⋈𝜃 σθ × Query Optimization 2. Search Space 13 ▪ Rule 5. Theta-join operations (and natural joins) are commutative. ▪ E1⋈θE2=E2⋈θE1 ▪ Application: ➢ Choose as outer table the one that is smaller or as inner the one with an index ⋈𝜃1 ⋈𝜃2 ⋈𝜃1 ⋈𝜃2 Query Optimization 2. Search Space 14 ▪ Rule 6. Natural join operations are associative: ▪ (E1⋈E2)⋈E3=E1⋈(E2⋈E3) ▪ Theta joins are associative in the following manner: (E1⋈θ1E2)⋈θ2∧θ3E3=E1⋈θ1∧θ3(E2⋈θ2E3) where θ2 involves attributes from only E2 and E3 ▪ Application: ➢ Joins can be performed in several orders, allowing to choose the most selective first ⋈ ⋈ ⋈ ⋈ Query Optimization 2. Search Space 15 ▪ Rule 7. Pushdown Selection: ▪ σθ(E1⋈E2)=σθ(E1)⋈(E2) if θ only involves attributes in E1 ▪ Application: ➢ Remove first all data that is not needed before doing more expensive operations σθ ⋈ σθ ⋈ more tuples than Query Optimization 2. Search Space 16 ▪ Rule 8. The projections operation distributes over the theta join operation as follows: ▪ If θ involves only attributes from L1∪L2: ▪ ΠL1∪L2(E1⋈θE2)=(ΠL1(E1))⋈θ(ΠL2(E2)) ▪ Application: ➢ Table width can be reduced before doing the join to minimize data movement ΠL1​∪L2​​ ⋈θ ΠL1​​ ⋈θ ΠL2 Query Optimization 2. Search Space 17 ▪ Rule 9. The set operations union and intersection are commutative: ▪ E1∪E2=E2∪E1 ▪ E1​∩E2=E2​∩E1 ▪ Application ➢ Allows to perform one side before the other depending on resource constraints ∪ ∪ Query Optimization 2. Search Space 18 ▪ Rule 10. Set union and intersection are associative: ▪ (E1∪E2)∪E3=E1∪(E2∪E3) ▪ (E1​∩E2)∩E3=E1​∩(E2​∩E3) ▪ Application: ➢ Allows to change the order in which operations are done and how the operator tree is executed ∪ ∪ ∪ ∪ Query Optimization 2. Search Space 19 ▪ Rule 11. The selection operation distributes over ∪, ∩, and -: ▪ σθ(E1−E2)=σθ(E1)−σθ(E2) ▪ σθ(E1∪E2)=σθ(E1)∪σθ(E2) ▪ σθ(E1 ∩ E2)=σθ(E1) ∩ σθ(E2) ▪ Also: ➢ σθ(E1−E2)=σθ(E1)−E2 ➢ σθ(E1​∩E2)=σθ(E1)∩E2 ➢ Not for ∪. ▪ Application: ➢ Allows to remove unneeded tuples before performing the next operation (e.g., involving comparisons) σθ ∪ ∪ σθ σθ Query Optimization 2. Search Space 20 ▪ Rule 12. The projection operation distributes over union: ▪ ΠL(E1∪E2)=(ΠL(E1))∪(ΠL(E2)) ▪ Application: ➢ Allows to remove columns before the union, requiring less data movement ΠL ∪ ∪ ΠL ΠL Query Optimization 2. Search Space 21 ▪ All these rules give us a way to generate physical plans. Query Optimization 2. Search Space 22 ▪ All these rules give us a way to generate physical plans. Query Optimization Example of Rules in systems (Oracle) 23 Consider this SQL statement, which selects the employee numbers of all employees in the EMP table with an ENAME value of 'CHUNG' and with a SAL value greater than 2000: SELECT empno FROM emp WHERE ename = 'CHUNG' AND sal > 2000; Consider also that the EMP table has these integrity constraints and indexes: • There is a PRIMARY KEY constraint on the EMPNO column that is enforced by the index PK_EMPNO. • There is an index named ENAME_IND on the ENAME column. • There is an index named SAL_IND on the SAL column. Based on the conditions in the WHERE clause of the SQL statement, the integrity constraints, and the indexes, these access paths are available: • A single-column index access path using the ENAME_IND index is made available by the condition ENAME = 'CHUNG'. This access path has rank 9. • An unbounded range scan using the SAL_IND index is made available by the condition SAL > 2000. This access path has rank 11. • A full table scan is automatically available for all SQL statements. This access path has rank 15. Note that the PK_EMPNO index does not make the single row by primary key access path available because the indexed column does not appear in a condition in the WHERE clause. Using the rule-based approach, the optimizer chooses the access path that uses the ENAME_IND index to execute this statement. The optimizer chooses this path because it is the most highly ranked path available. https://docs.oracle.com/cd/F49540_01/DOC/server.815/a67781/c20b_ops.htm#8157 Query Optimization How to chose a plan Usually, the optimizer does not consider the order in which tables appear in the FROM clause when choosing an execution plan. The optimizer makes this choice by applying the following rules in order: a) The optimizer chooses the execution plan with the fewest nested-loops operations in which the inner table is accessed with a full table scan. b) If there is a tie, the optimizer chooses the execution plan with the fewest sort-merge operations. c) If there is still a tie, the optimizer chooses the execution plan for which the first table in the join order has the most highly ranked access path: d) If there is a tie among multiple plans whose first tables are accessed by the single-column indexes access path, the optimizer chooses the plan whose first table is accessed with the most merged indexes. e) If there is a tie among multiple plans whose first tables are accessed by bounded range scans, the optimizer chooses the plan whose first table is accessed with the greatest number of leading columns of the composite index. f) If there is still a tie, the optimizer chooses the execution plan for which the first table appears later in the query's FROM clause. 24 https://docs.oracle.com/cd/F49540_01/DOC/server.815/a67781/c20c_joi.htm Query Optimization 3. Cost Model 25 ▪ How to estimate the performance of a given physical plan without actually running this query? ▪ Q1: How to estimate the performance of each operator? ▪ Q2: How to combine multiple operators together? ➢ This is easier Query Optimization 3. Cost Model 26 ▪ How to estimate the performance of a given physical plan without actually running this query? ▪ Q1: How to estimate the performance of each operator? ▪ The key is to estimate 𝛼 𝐶, 𝑅 -- selectivity ▪ (Other constants can be measured in a query-independent way or easy to acquire) ▪ Cardinality Estimation Query Optimization 3. Cost Model 27 ▪ Q1: How to estimate the performance of each operator? ▪ Cardinality Estimation ▪ How can DB know how many tuples a query would return? ▪ Core of query optimization; not a solved problem at all. ▪ We will only cover the basics. Query Optimization 3. Cost Model 28 ▪ Q1: How to estimate the performance of each operator? ▪ Cardinality Estimation Query Optimization Histograms • Histograms are widely used in all major databases: • Cardinality estimation (CE) in SQL Server is derived primarily from histograms that are created when indexes or statistics are created, either manually or automatically (SQL Server Manual) • By default the optimizer assumes a uniform distribution of rows across the distinct values in a column. For columns that contain data skew (a non- uniform distribution of data within the column), a histogram enables the optimizer to generate accurate cardinality estimates for filter and join predicates that involve these columns. (Oracle Manual) • … in MySQL we have chosen to support two different types: The “singleton” histogram and the “equi-height” histogram. (MYSQL Server Blog) Query Optimization 29 Histograms Query Optimization 30 SELECT * FROM person WHERE 25 < age < 40; 0 10 20 30 40 50 60 20 bis 42 42 bis 48 48 bis 53 53 bis 59 59 bis 70 SELECT * FROM person WHERE 25 < age < 40; EQUI-WIDTH EQUI-DEPTH (EQUI-HEIGHT) Ranges of values are fixed and equal Tells how many values in each range Helps identifying hot-spots May store distinct values and min/max, etc Same number of tuples per bucket Helps to partition data evenly The size of a range helps with cardinality estimates May store distinct values and min/max, etc. Singleton or frequency histogram • The frequency histogram plots the frequency of every distinct item in a table • In essence, how often each value appears in the table • Very useful to compute the selectivity of queries • Highly accurate as it gives counts for every possible value • Can be done if the number of distinct values is not too high Query Optimization 31 Selecting a type of histogram (example) • NDV: This represents the number of distinct values in a column. For example, if a column only contains the values 100, 200, and 300, then the NDV for this column is 3. • n: This variable represents the number of histogram buckets. The default is 254. • p: This variable represents an internal percentage threshold that is equal to (1–(1/n)) * 100. For example, if n = 254, then p is 99.6. Query Optimization 32 https://docs.oracle.com/database/121/TGSQL/tgsql_histo.htm #TGSQL-GUID-FFA0C0AF-3761-4829-995E-9AFA524F96CE 3. Cost Model 33 ▪ Q1: How to estimate the performance of each operator? ▪ Cardinality Estimation ▪ Histogram. ▪ For discrete values ▪ Look up the histogram and know # matching tuples Query Optimization 3. Cost Model 34 ▪ Q1: How to estimate the performance of each operator? ▪ Cardinality Estimation ▪ Histogram. ▪ σage=2∧postcode=8006(R) ▪ This is hard because of the correlation ▪ Baseline: assume that these two attributes are independent. ▪ (# age = 2) * (# postcode = 8006) / total # tuples ▪ But it is easy to see how in many cases this might not give you an accurate answer Age Histogram PostCode Histogram Query Optimization 3. Cost Model 35 ▪ Q1: How to estimate the performance of each operator? ▪ Cardinality Estimation ▪ Histogram. ▪ For continuous values ▪ Baseline: Assume values are uniformly distributed within each bin. Query Optimization 3. Cost Model 36 ▪ Q1: How to estimate the performance of each operator? ▪ Cardinality Estimation ▪ Histogram. ▪ If you really care about correlation: multi-dimensional histogram. ▪ Problem? You cannot build this for all combinations of attributes (too expensive) -- but of course you can (automatically) choose the top-K co- related pairs and just build multi- dimensional histogram just for them. Query Optimization 4. Search 37 ▪ What we have: ➢ Given a logic plan – we know how to generate a set of semantically equivalent physical plans ➢ For each physical plan, we know an estimation of the cost. ▪ How to search? ▪ Real-world queries are very complex, the problem of searching for the best physical plan can be hard. -- start query 14 in stream 0 using template query14.tpl WITH cross_items AS (SELECT i_item_sk ss_item_sk FROM item, (SELECT iss.i_brand_id brand_id, iss.i_class_id class_id, iss.i_category_id category_id FROM store_sales, item iss, date_dim d1 WHERE ss_item_sk = iss.i_item_sk AND ss_sold_date_sk = d1.d_date_sk AND d1.d_year BETWEEN 1999 AND 1999 + 2 INTERSECT SELECT ics.i_brand_id, ics.i_class_id, ics.i_category_id FROM catalog_sales, item ics, date_dim d2 WHERE cs_item_sk = ics.i_item_sk AND cs_sold_date_sk = d2.d_date_sk AND d2.d_year BETWEEN 1999 AND 1999 + 2 INTERSECT SELECT iws.i_brand_id, iws.i_class_id, iws.i_category_id FROM web_sales, item iws, date_dim d3 WHERE ws_item_sk = iws.i_item_sk AND ws_sold_date_sk = d3.d_date_sk AND d3.d_year BETWEEN 1999 AND 1999 + 2) WHERE i_brand_id = brand_id AND i_class_id = class_id AND i_category_id = category_id), avg_sales AS (SELECT Avg(quantity * list_price) average_sales FROM (SELECT ss_quantity quantity, ss_list_price list_price FROM store_sales, date_dim WHERE ss_sold_date_sk = d_date_sk AND d_year BETWEEN 1999 AND 1999 + 2 UNION ALL SELECT cs_quantity quantity, cs_list_price list_price FROM catalog_sales, date_dim WHERE cs_sold_date_sk = d_date_sk AND d_year BETWEEN 1999 AND 1999 + 2 UNION ALL SELECT ws_quantity quantity, ws_list_price list_price FROM web_sales, date_dim WHERE ws_sold_date_sk = d_date_sk AND d_year BETWEEN 1999 AND 1999 + 2) x) SELECT channel, i_brand_id, i_class_id, i_category_id, Sum(sales), Sum(number_sales) FROM (SELECT 'store' channel, i_brand_id, i_class_id, i_category_id, Sum(ss_quantity * ss_list_price) sales, Count(*) number_sales FROM store_sales, item, date_dim WHERE ss_item_sk IN (SELECT ss_item_sk FROM cross_items) AND ss_item_sk = i_item_sk AND ss_sold_date_sk = d_date_sk AND d_year = 1999 + 2 AND d_moy = 11 GROUP BY i_brand_id, i_class_id, i_category_id HAVING Sum(ss_quantity * ss_list_price) > (SELECT average_sales FROM avg_sales) UNION ALL SELECT 'catalog' channel, i_brand_id, i_class_id, i_category_id, Sum(cs_quantity * cs_list_price) sales, Count(*) number_sales FROM catalog_sales, item, date_dim WHERE cs_item_sk IN (SELECT ss_item_sk FROM cross_items) AND cs_item_sk = i_item_sk AND cs_sold_date_sk = d_date_sk AND d_year = 1999 + 2 AND d_moy = 11 GROUP BY i_brand_id, i_class_id, i_category_id HAVING Sum(cs_quantity * cs_list_price) > (SELECT average_sales FROM avg_sales) UNION ALL SELECT 'web' channel, i_brand_id, i_class_id, i_category_id, Sum(ws_quantity * ws_list_price) sales, Count(*) number_sales FROM web_sales, item, date_dim WHERE ws_item_sk IN (SELECT ss_item_sk FROM cross_items) AND ws_item_sk = i_item_sk AND ws_sold_date_sk = d_date_sk AND d_year = 1999 + 2 AND d_moy = 11 GROUP BY i_brand_id, i_class_id, i_category_id HAVING Sum(ws_quantity * ws_list_price) > (SELECT average_sales FROM avg_sales)) y GROUP BY rollup ( channel, i_brand_id, i_class_id, i_category_id ) ORDER BY channel, i_brand_id, i_class_id, i_category_id LIMIT 100; TPC-DS Query 14Query Optimization 4. Search 38 ▪ Real-world queries are very complex, the problem of searching for the best physical plan can be hard. Query Optimization 4. Search 39 ▪ Compromise 1: Constrain the Search Space ▪ Example System: System R (The first relational DB) ▪ Only consider left-deep join trees ▪ Rationale: Left-deep trees allow us to generate all fully pipelined plans: Intermediate results not written to temporary files. ➢ Not all left-deep trees are fully pipelined (e.g., Sort Merge join). ▪ This brings the complexity down to O(n!) where n is the # relations in join Query Optimization 4. Search 40 ▪ Compromise 1: Constrain the Search Space ▪ Example System: System R (The first relational DB) ▪ Only consider left-deep join trees ▪ Search Process: ➢ Enumerate join orders (different left deep tree) ➢ Enumerate plans for each operator (hash join, sort merge join, nested loop join, …) ➢ Enumerate access method for each operator (B+-tree, hash table, sequential scan, …) ▪ Can be done with dynamic programming ➢ Find the best 1-relation plan ➢ Find the best 2-relation plan – find ways to join a relation with the best 1-relation plan ➢ … ▪ Still slow, but faster than enumerate all possible join trees. Query Optimization 4. Search 41 ▪ Compromise 2: Heuristic-based Optimization ▪ Example System: SparkSQL ▪ Cost-based optimization is expensive, even with dynamic programming. ▪ Systems may use heuristics to reduce the number of choices that must be made in a cost-based fashion. ▪ Heuristic optimization transforms the query-tree by using a set of rules that typically (but not in all cases) improve execution performance: ➢ Perform selection early (reduces the number of tuples) ➢ Perform projection early (reduces the number of attributes) ➢ Perform most restrictive selection and join operations before other similar operations. ➢ Some systems use only heuristics, others combine heuristics with partial cost-based optimization. Query Optimization 4. Search 42 ▪ Compromise 2: Heuristic-based Optimization ▪ Example System: SparkSQL ▪ Deconstruct conjunctive selections into a sequence of single selection operations. σθ1∧...∧θn(E)↦σθ1(σθ2(...(σθn(E)) ▪ Push down selection as deep as possible. σθ(E1⋈E2)=σθ(E1)⋈(E2) ▪ Execute the first select/join operator that produce the smallest result. (E1⋈E2)⋈E3=E1⋈(E2⋈E3) ▪ Push down projection as deep as possible ▪ Select algorithms that enables pipelining. Query Optimization Example from systems With the cost-based approach, the optimizer generates a set of execution plans based on the possible join orders, join operations, and available access paths. The optimizer then estimates the cost of each plan and chooses the one with the lowest cost. The optimizer estimates costs in these ways: • The cost of a nested loops operation is based on the cost of reading each selected row of the outer table and each of its matching rows of the inner table into memory. The optimizer estimates these costs using the statistics in the data dictionary. • The cost of a sort-merge join is based largely on the cost of reading all the sources into memory and sorting them. The optimizer also considers other factors when determining the cost of each operation. For example: • A smaller sort area size is likely to increase the cost for a sort-merge join because sorting takes more CPU time and I/O in a smaller sort area. Sort area size is specified by the initialization parameter SORT_AREA_SIZE. • A larger multiblock read count is likely to decrease the cost for a sort-merge join in relation to a nested loops join. If a large number of sequential blocks can be read from disk in a single I/O, an index on the inner table for the nested loops join is less likely to improve performance over a full table scan. The multiblock read count is specified by the initialization parameter DB_FILE_MULTIBLOCK_READ_COUNT. • For join statements with outer join conditions, the table with the outer join operator must come after the other table in the condition in the join order. The optimizer does not consider join orders that violate this rule. 43 https://docs.oracle.com/cd/F49540_01/DOC/server.815/a67781/c20c_joi.htm Query Optimization Ways to simplify the problem • Example from old version of Oracle (for both cost based and rule based): • The optimizer first determines whether joining two or more of the tables definitely results in a row source containing at most one row. The optimizer recognizes such situations based on UNIQUE and PRIMARY KEY constraints on the tables. If such a situation exists, the optimizer places these tables first in the join order. The optimizer then optimizes the join of the remaining set of tables. • For join statements with outer join conditions, the table with the outer join operator must come after the other table in the condition in the join order. The optimizer does not consider join orders that violate this rule. Query Optimization 44 https://docs.oracle.com/cd/F49540_01/DOC/server.815/a67781/c20c_joi.htm Query Optimization: Put everything Together 45 ▪ Fundamental Questions: ➢ Q1: How to run a physical plan, given that we know how to run each operator. ➢ Q2: How to search for the best physical plan? ▪ 1. Execution Model: How different operators are put together ▪ 2. Cost Model: How to estimate the cost of each physical plan, given our execution model ▪ 3. Search Space: What are the logically equivalent set of physical plans? ▪ 4. Search Algorithm: How can we search the best physical plan, given cost model? Query Optimization","libVersion":"0.3.2","langs":""}
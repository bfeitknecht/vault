{"path":"sem3/LinAlg/UE/s/LinAlg-s-u05.pdf","text":"D-INFK Linear Algebra HS 2024 Bernd G¨artner Robert Weismantel Solution for Assignment 5 1. a) We will use the elimination procedure on A in order to get the upper triangular matrix U and the lower triangular matrix L. First, we multiply A with E21 =   1 0 0 − 1 2 1 0 0 0 1   and E31 =   1 0 0 0 1 0 −1 0 1   to get E31E21A =   2 −12 6 0 2 −2 0 1 −11   . We also note down the coefficients ℓ21 = 1 2 and ℓ31 = 1 for L. Note that these are just the negated entries of E21 and E31, respectively. Next, we multiply this with E32 =  1 0 0 0 1 0 0 − 1 2 1   and get E32E31E21A =   2 −12 6 0 2 −2 0 0 −10   =: U which is upper triangular. We also write down ℓ32 = 1 2 . From the lecture we know that we can obtain L as L =   1 0 0 ℓ21 1 0 ℓ31 ℓ32 1   =  1 0 0 1 2 1 0 1 1 2 1   . Indeed, checking LU =  1 0 0 1 2 1 0 1 1 2 1     2 −12 6 0 2 −2 0 0 −10   =   2 −12 6 1 −4 1 2 −11 −5   = A we conclude that this is a valid LU factorization of A. b) Since L is lower triangular, we can start substituting from the top. In particular, writing out the equation gives Ly =  1 0 0 1 2 1 0 1 1 2 1     y1 y2 y3   ! =   4 4 25   = b. Hence, we get y1 = 4, y2 = 4 − 2 = 2, and y3 = 25 − 1 − 4 = 20. c) We first write down the system again as U x =   2 −12 6 0 2 −2 0 0 −10     x1 x2 x3   ! =   4 2 20   = y. 1 By using back substitution we obtain x3 = 20 −10 = −2, x2 = 2−4 2 = −1, and x1 = 4−12+12 2 = 2. d) Using the results from the previous two subtasks we get Ax LU = LU x = L(U x) c) = Ly b) = b. 2. We perform Gauss-Jordan elimination on A =   1 2 0 3 2 4 1 4 3 6 2 5   . Our first pivot is already 1, so we can eliminate in the first column to get   1 2 0 3 0 0 1 −2 0 0 2 −4   . The second column is already done so we move on to eliminate in the third column. Luckily, our pivot is already 1 again so we do not have to normalize. We obtain   1 2 0 3 0 0 1 −2 0 0 0 0   and observe that we are done since this matrix is in row echolon form. In other words, this is our R0 and we can check that it corresponds exactly to R on the first two rows. 3. a) The inverse of A is A−1 =     1 0 0 0 −1 1 0 0 0 −1 1 0 0 0 −1 1    . To justify this, it suffices to check that AA−1 indeed equals I. But let us still explain how we found A−1: Finding A−1 can be done by finding vectors v1, v2, v3, v4 ∈ R4 (columns of A−1) such that Avi = ei for all i ∈ {1, 2, 3, 4}, where ei is the i-th standard unit vector. Using e.g. elimination to solve these systems, we get v1 =     1 −1 0 0     , v2 =     0 1 −1 0     , v3 =     0 0 1 −1     , v4 =     0 0 0 1     and thus A−1 =     ... ... ... ... v1 v2 v3 v4 ... ... ... ...     =     1 0 0 0 −1 1 0 0 0 −1 1 0 0 0 −1 1    . Alternatively, one might also be able to guess the vectors v1, . . . , v4 by noticing that by subtracting the (i + 1)-th column of A from the i-th column of A, we get ei, for all i ∈ {1, 2, 3} (and that v4 = e4). 2 b) We solve this exercise by guessing that the pattern from a) also works in general. Concretely, we define the matrix B ∈ Rm×m with columns v1, . . . , vm ∈ Rm such that vi := ei − ei+1 for all i ∈ {1, 2, . . . , m − 1} and vm := em. We claim that B is the unique inverse of A. To prove this, first observe that the i-th row of A is given by ∑i k=1 e⊤ k . This means that the entry (AB)ij is given by (AB)ij = ( i∑ k=1 e ⊤ k )vj = i∑ k=1 e ⊤ k vj for all i, j ∈ [m]. Let now i, j ∈ [m] be arbitrary. We distinguish three cases. • Assume first j < i. Then we get ∑i k=1 e⊤ k vj = ∑i k=1 e⊤ k (ej − ej+1) = e⊤ j ej − e⊤ j+1ej+1 = 0. • Next, assume j > i. Observe that in this case, we have e⊤ k vj = 0 for all k ∈ [i] and thus (AB)ij = 0. • Finally, we observe that ∑i k=1 e⊤ k vj = e⊤ j ej = 1 for i = j. We conclude that AB = I and thus B is the unique inverse of A. 4. We solve both subtasks at once using the CR-decomposition. Consider the matrix   | | | | u1 u2 u3 b | | | |   obtained by using u1, u2, u3, b as columns. Concretely, we have   | | | | u1 u2 u3 b | | | |   =     2 −1 2 1 −4 5 −5 −2 8 5 5 6 2 2 1 2     . We compute the CR-decomposition of this matrix. After dividing the first row by 2 and eliminating the first column, we get     1 − 1 2 1 1 2 0 3 −1 0 0 9 −3 2 0 3 −1 1     . Next, we divide the second row by 3 and eliminate in the second column to get     1 0 5 6 1 2 0 1 − 1 3 0 0 0 0 2 0 0 0 1     . Finally, we divide the third row by 2 and eliminate in the fourth column to obtain     1 0 5 6 0 0 1 − 1 3 0 0 0 0 1 0 0 0 0     . We conclude that our matrix has CR-decomposition   | | | | u1 u2 u3 b | | | |   =   | | | u1 u2 b | | |     1 0 5 6 0 0 1 − 1 3 0 0 0 0 1   . 3 Interpreting this result, we deduce that b cannot be written as a linear combination of u1, u2, u3 since we have a pivot in the fourth column. Moreover, the reduced row echolon form also shows that u3 is dependent on u1 and u2. Hence, the three vectors u1, u2, u3 are linearly dependent. 5. Each of the four points yields one linear equation with variables a, b, c, d. For example, for x = 4, y = 5 we get the equation a4 3 + b4 2 + c4 + d = 5. In total, we get the linear system a0 3 + b0 2 + c0 + d = 1 a2 3 + b2 2 + c2 + d = 2 a4 3 + b4 2 + c4 + d = 5 a6 3 + b6 2 + c6 + d = 6 with four equations and four variables that we can write in matrix form as     1 0 0 0 1 2 4 8 1 4 16 64 1 6 36 216         d c b a     =     1 2 5 6     . We now want to solve this system by using the elimination technique. For this, it is convenient to apply the row operations to the system matrix and the right-hand side simultaneously by appending the right-hand side to the matrix as follows:     1 0 0 0 1 1 2 4 8 2 1 4 16 64 5 1 6 36 216 6     . After performing elimination in the first column we get     1 0 0 0 1 0 2 4 8 1 0 4 16 64 4 0 6 36 216 5     . Next, we perform elimination in the second columns to get     1 0 0 0 1 0 2 4 8 1 0 0 8 48 2 0 0 24 192 2     . Finally, we obtain     1 0 0 0 1 0 2 4 8 1 0 0 8 48 2 0 0 0 48 −4     . It remains to perform backward substitution. From the last row, we get a = − 4 48 = − 1 12 . Next, we get b = 2−48a 8 = 6 8 = 3 4 . From the second row we obtain c = 1−8a−4b 2 = 1+ 2 3 −3 2 = − 2 3 . Finally, we get d = 1 from the first row. Hence, the function f (x) = − 1 12 x3 + 3 4 x2 − 2 3 x + 1 interpolates all of our datapoints. 4 6. We want to prove that w1, w2, w3 are linearly independent. Consider the matrices W :=   | | | w1 w2 w3 | | |   , V :=   | | | v1 v2 v3 | | |   , and M :=   1 −1 1 1 1 1 0 0 1   . Observe that we have chosen M such that by definition of w1, w2, w3, we have W = V M . Observe first that V has rank 3 and is invertible, since its columns are linearly independent (Inverse Theorem). Next, we compute the rank of M . From the lecture, we know that the rank of a matrix is equal to the number of pivots after using Gauss elimination on the matrix. We use this on M : subtracting the first row of M once from its second row, we get the triangular matrix   1 −1 1 0 2 0 0 0 1   which means that M has rank 3 as well. In other words, the columns of M are linearly independent and hence M is invertible. By Lemma 3.9, we conclude that W is invertible as it can be written as the product of two invertible matrices. By the Inverse Theorem, the columns of W are linearly independent, as desired. 7. We will use statements from Exercise 6 on Assignment 4 without reproving them. a) We know that L is a square lower triangular matrix with 1’s on the diagonal. By Exercise 6 on Assignment 4, it follows that L is invertible. From the lecture we know that this also implies invertibility of L⊤. b) Observe that L⊤ is upper triangular. Using Exercise 6 on Assignment 4, we conclude that (L⊤)−1 is also upper triangular. Moreover, U is upper triangular. It remains to observe that the product of two upper triangular matrices is upper triangular again: Indeed, let i, j ∈ [m] be arbitrary with i > j and consider the entry Dij. Let v ∈ Rm be the i-th row of U , and let w ∈ Rm be the j-th column of (L⊤)−1. By definition of matrix multiplication, we have Dij = v · w. But since the first i − 1 entries of v are zero, the last m − j entries of w are zero, and i > j, we can conclude Dij = v · w = 0. Thus, D is upper triangular. c) Plugging in the definition of D, we indeed get LDL⊤ = LU (L⊤)−1L⊤ = LU = A. d) Since L is invertible, we can rewrite LDL⊤ = A to D = L−1A(L⊤)−1. We further observe that D⊤ = (L−1A(L ⊤) −1)⊤ = L −1A⊤(L ⊤) −1 = L−1A(L ⊤) −1 where we used symmetry of A in the last step. Plugging in A = LU and using L−1L = I, we get D⊤ = U (L⊤)−1 = D. In other words, D is symmetric as well. e) We know that D is upper triangular from subtask b). By symmetry, this implies that D is lower triangular as well. We conclude that D is diagonal. 5","libVersion":"0.3.2","langs":""}
{"path":"sem2/PProg/VRL/slides/PProg-L24-ABA-solved.pdf","text":"spcl.inf.ethz.ch @spcl_eth TORSTEN HOEFLER Parallel Programming ABA + Linearizability How it started: How it’s going: spcl.inf.ethz.ch @spcl_eth ▪ Lock-free programming ▪ Unbounded queue ▪ Stack Summary/recap last lecture 2 spcl.inf.ethz.ch @spcl_eth ▪ Reuse and ABA problem ▪ Pointer tagging ▪ Hazard pointers ▪ Correctness in Parallel Programs ▪ Linearizability Learning goals today 3 spcl.inf.ethz.ch @spcl_eth REUSE AND THE ABA PROBLEM 4 spcl.inf.ethz.ch @spcl_eth public class ConcurrentStack { AtomicReference<Node> top = new AtomicReference<Node>(); public void push(Long item) { … } public Long pop() { … } } 5 For the sake of simplicity: back to the stack ☺ item next item next item next NULL top spcl.inf.ethz.ch @spcl_eth public Long pop() { Node head, next; do { head = top.get(); if (head == null) return null; next = head.next; } while (!top.compareAndSet(head, next)); return head.item; } 6 Lock-free pop A B C NULL top head next Memorize \"current stack state\" in local variable head Action is taken only if \"the stack state\" did not change spcl.inf.ethz.ch @spcl_eth public void push(Long item) { Node newi = new Node(item); Node head; do { head = top.get(); newi.next = head; } while (!top.compareAndSet(head, newi)); } 7 push A B C NULL top head newi Memorize \"current stack state\" in local variable head Action is taken only if \"the stack state\" did not change spcl.inf.ethz.ch @spcl_eth Assume we do not want to allocate for each push and maintain a node pool instead (e.g., inside the OS or in an unmanaged language w/o garbage collection). Does this work? 8 Node reuse public class NodePool { AtomicReference<Node> top new AtomicReference<Node>(); public void put(Node n) { … } public Node get() { … } } public class ConcurrentStackP { AtomicReference<Node> top = newAtomicReference<Node>(); NodePool pool = new NodePool(); ... } spcl.inf.ethz.ch @spcl_eth public Node get(Long item) { Node head, next; do { head = top.get(); if (head == null) return new Node(item); next = head.next; } while (!top.compareAndSet(head, next)); head.item = item; return head; } public void put(Node n) { Node head; do { head = top.get(); n.next = head; } while (!top.compareAndSet(head, n)); } 9 NodePool put and get Main difference to Stack from before: NodePool is in-place. A node can be placed in one and only one in-place data structure. This is ok for a global pool. So far this works. spcl.inf.ethz.ch @spcl_eth public void push(Long item) { Node head; Node new = pool.get(item); do { head = top.get(); new.next = head; } while (!top.compareAndSet(head, new)); } public Long pop() { Node head, next; do { head = top.get(); if (head == null) return null; next = head.next; } while (!top.compareAndSet(head, next)); Long item = head.item; pool.put(head); return item; } 10 Using the node pool spcl.inf.ethz.ch @spcl_eth ▪ run n consumer and producer threads ▪ each consumer / producer pushes / pops 10,000 elements and records sum of values ▪ if a pop returns an \"empty\" value, retry ▪ do this 10 times with / without node pool ▪ measure wall clock time (ms) ▪ check that sum of pushed values == sum of popped values 11 Experiment spcl.inf.ethz.ch @spcl_eth nonblocking stack without reuse n = 1, elapsed= 15, normalized= 15 n = 2, elapsed= 110, normalized= 55 n = 4, elapsed= 249, normalized= 62 n = 8, elapsed= 843, normalized= 105 n = 16, elapsed= 1653, normalized= 103 n = 32, elapsed= 3978, normalized= 124 n = 64, elapsed= 9953, normalized= 155 n = 128, elapsed= 24991, normalized= 195 nonblocking stack with reuse n = 1, elapsed= 47, normalized= 47 n = 2, elapsed= 109, normalized= 54 n = 4, elapsed= 312, normalized= 78 n = 8, elapsed= 577, normalized= 72 n = 16, elapsed= 1747, normalized= 109 n = 32, elapsed= 2917, normalized= 91 n = 64, elapsed= 6599, normalized= 103 n = 128, elapsed= 12090, normalized= 94 12 Result (of one particular run) yieppieh... spcl.inf.ethz.ch @spcl_eth nonblocking stack with reuse n = 1, elapsed= 62, normalized= 62 n = 2, elapsed= 78, normalized= 39 n = 4, elapsed= 250, normalized= 62 n = 8, elapsed= 515, normalized= 64 n = 16, elapsed= 1280, normalized= 80 n = 32, elapsed= 2629, normalized= 82 Exception in thread \"main\" java.lang.RuntimeException: sums of pushes and pops don't match at stack.Measurement.main(Measurement.java:107) nonblocking stack with reuse n = 1, elapsed= 48, normalized= 48 n = 2, elapsed= 94, normalized= 47 n = 4, elapsed= 265, normalized= 66 n = 8, elapsed= 530, normalized= 66 n = 16, elapsed= 1248, normalized= 78 [and does not return] 13 But other runs ... why? spcl.inf.ethz.ch @spcl_eth 14 ABA Problem A NULL top head next Thread X in the middle of pop: after read but before CAS Thread Y pops A A NULL top Thread Z pushes B B NULL top Thread Z' pushes A B NULL Thread X completes pop A NULL top head next BA time Pool Pool top public void push(Long item) { Node head; Node new = pool.get(item); do { head = top.get(); new.next = head; } while (!top.compareAndSet(head, new)); } public Long pop() { Node head, next; do { head = top.get(); if (head == null) return null; next = head.next; } while (!top.compareAndSet(head, next)); Long item = head.item; pool.put(head); return item; } spcl.inf.ethz.ch @spcl_eth \"The ABA problem ... occurs when one activity fails to recognize that a single memory location was modified temporarily by another activity and therefore erroneously assumes that the overall state has not been changed.\" 15 The ABA-Problem A X observes Variable V as A B meanwhile V changes to B ... A .. and back to A A X observes A again and assumes the state is unchanged time spcl.inf.ethz.ch @spcl_eth DCAS (double compare and swap) not available on most platforms (we have used a variant for the lock-free list set) Garbage Collection relies on the existence of a GC much too slow to use in the inner loop of a runtime kernel can you implement a lock-free garbage collector relying on garbage collection? Pointer Tagging does not cure the problem, rather delay it can be practical Hazard Pointers Transactional memory (later) 16 How to solve the ABA problem? spcl.inf.ethz.ch @spcl_eth ABA problem usually occurs with CAS on pointers Aligned addresses (values of pointers) make some bits available for pointer tagging. Example: pointer aligned modulo 32 → 5 bits available for tagging Each time a pointer is stored in a data structure, the tag is increased by one. Access to a data structure via address x – (x mod 32) This makes the ABA problem very much less probable because now 32 versions of each pointer exist. 17 Pointer Tagging MSB 00000XXXXXXXX... spcl.inf.ethz.ch @spcl_eth The ABA problem stems from reuse of a pointer P that has been read by some thread X but not yet written with CAS by the same thread. Modification takes place meanwhile by some other thread Y. Idea to solve: ▪ before X reads P, it marks it hazarduous by entering it in one of the n (n= number threads) slots of an array associated with the data structure (e.g., the stack) ▪ When finished (after the CAS), process X removes P from the array ▪ Before a process Y tries to reuse P, it checks all entries of the hazard array 18 Hazard Pointers spcl.inf.ethz.ch @spcl_eth public class NonBlockingStackPooledHazardGlobal extends Stack { AtomicReference<Node> top = new AtomicReference<Node>(); NodePoolHazard pool; AtomicReferenceArray<Node> hazarduous; public NonBlockingStackPooledHazardGlobal(int nThreads) { hazarduous = new AtomicReferenceArray<Node>(nThreads); pool = new NodePoolHazard(nThreads); } } 19 Hazard Pointers null null null null null null null null null null null null 0 nThreads-1 spcl.inf.ethz.ch @spcl_eth boolean isHazardous(Node node) { for (int i = 0; i < hazarduous.length(); ++i) if (hazarduous.get(i) == node) return true; return false; } void setHazardous(Node node) { hazarduous.set(id, node); // id is current thread id } 20 Hazard Pointers null null null null null null y null x null null 0 nThreads-1id hd spcl.inf.ethz.ch @spcl_eth public int pop(int id) { Node head, next = null; do { do { head = top.get(); setHazardous(head); } while (head == null || top.get() != head); next = head.next; } while (!top.compareAndSet(head, next)); setHazardous(null); int item = head.item; if (!isHazardous(head)) pool.put(id, head); return item; } 21 Hazard Pointers public void push(int id, Long item) { Node head; Node newi = pool.get(id, item); do{ head = top.get(); newi.next = head; } while (!top.compareAndSet(head, newi)); } This ensures that no other thread is already past the CAS and has not seen our hazard pointer null null null null null null y null x null null 0 nThreads-1id hd spcl.inf.ethz.ch @spcl_eth The ABA problem also occurs on the node pool. Solutions: Thread-local node pools ▪ No protection necessary ▪ Does not help when push/pop operations are not well balanced Hazard pointers on the global node pool ▪ Expensive operation for node reuse ▪ Similar to code above: node pool returns a node only when it is not hazarduous Hybrid of both ▪ Node-local + global node pool 22 How to protect the Node Pool? spcl.inf.ethz.ch @spcl_eth The Java code above does not really improve performance in comparison to memory allocation plus garbage collection. But it demonstrates how to solve the ABA problem principally. The hazard pointers are placed in thread-local storage. When thread-local storage can be replaced by processor-local storage, it scales better*. 23 Remarks * e.g., in Florian Negele, Combining Lock-Free Programming with Cooperative Multitasking for a Portable Multiprocessor Runtime System, PhD Thesis, ETH Zürich 2014 spcl.inf.ethz.ch @spcl_eth Lock-free programming: new kind of problems in comparison to lock-based programming: ▪ Atomic update of several pointers / values impossible, leading to new kind of problems and solutions, such as threads that help each other in order to guarantee global progress ▪ ABA problem (which may disappear with a garbage collector) 24 Lessons Learned spcl.inf.ethz.ch @spcl_eth • algorithms to implement critical sections and locks • hardware support for implementing critical sections and locks • how to reason about concurrent algorithms using state diagrams • high-level constructs such as semaphores and monitors that raise the level of abstraction • lock-free implementations that require Read-Modify-Write operations Recap: we have seen … Literature: Herlihy: Chapter 3.1 - 3.6 25 spcl.inf.ethz.ch @spcl_eth developed a clear overview of the theoretical concepts and notions behind such as • consistency • linearizability • consensus • a language to talk formally about concurrency I have been very hand-wavy when answering some tricky questions • now that you appreciate the complexity Let us introduce some non-trivial formalism to capture it But: we have not (yet) … 26 spcl.inf.ethz.ch @spcl_eth class WaitFreeQueue { volatile int head = 0, tail = 0; AtomicReferenceArray<T>[] items = new AtomicReferenceArray<T>(capacity); public boolean enq(T x) { if (tail – head == capacity) return false; items.set((tail+1) % capacity, x); tail++; return true; } public T deq() { if (tail - head == 0) return null; int x = items.get((head+1) % capacity); head++; return x; } } Example: Single-Enqueuer/Dequeuer bounded FIFO queue e a b c d tail head % capacity head 27 Assume that there is only one enqueuer and one dequeuer process. Is the implementation of the FIFO queue from above correct? Why/why not? For a concurrent, locking queue it is easier to argue. Why/why not? spcl.inf.ethz.ch @spcl_eth An object (e.g., in Java or C++) is a container for data and provides • a set of methods to manipulate data An object has a well defined • state being modified during method invocations Well-established as Floyd-Hoare logic to prove correctness ▪ Defining the object’s behavior in terms of a set of pre- and postconditions for each method is inherently sequential Can we carry that forward to a parallel formulation? Sequential Objects – Sequential Specifications (you know this) 28 spcl.inf.ethz.ch @spcl_eth A method call is the interval that starts with an invocation and ends with a response. A method call is called pending between invocation and response. Method Calls Thread q.enq(7) invocation response 29 spcl.inf.ethz.ch @spcl_eth Sequential vs. Concurrent Sequential Concurrent Meaningful state of objects only between method calls. Method calls can overlap. Object might never be between method calls. Exception: periods of quiescence. Methods described in isolation. All possible interactions with concurrent calls must be taken into account. Can add new methods without affecting older methods. Must take into account that everything can interact with everything else. \"Global clock\" \"Object/thread clock\" 30 spcl.inf.ethz.ch @spcl_eth time Blocking Queue Behavior Thread A q.deq() lock unlockdeq Thread B q.enq(…) lock unlockenq enq deq With locking it becomes simple to argue: things become sequential. Can we formalize this? 31 Which thread got the lock first? spcl.inf.ethz.ch @spcl_eth Linearizability 32 “What's the difference between theory and practice? Well, in theory there is none.” - folklore spcl.inf.ethz.ch @spcl_eth Each method should appear to take effect instantaneously between invocation and response events. An object for which this is true for all possible executions is called linearizable. The object is correct if the associated sequential behavior is correct. Linearizability 33 spcl.inf.ethz.ch @spcl_eth Is this particular execution linearizable? A q.enq(x) B q.deq() →y q.deq() →x time 34 q.enq(y) spcl.inf.ethz.ch @spcl_eth Yes A q.enq(x) B q.enq(y) q.deq() →y q.deq() →x time 35 spcl.inf.ethz.ch @spcl_eth Linearizable? A q.enq(x) B q.enq(y) q.deq() →y time 36 spcl.inf.ethz.ch @spcl_eth 37 No A q.enq(x) B q.enq(y) q.deq() →y time x is first in queue","libVersion":"0.3.2","langs":""}
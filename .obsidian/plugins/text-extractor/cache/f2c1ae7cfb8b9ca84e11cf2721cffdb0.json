{"path":"sem2/AuW/PV/summaries/AuW-summary-fschwinn.pdf","text":"Algorithms and Probability Algorithms and Probability Course summary Contents 1 Graph Theory 4 1.1 Connectivity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4 1.1.1 Cut Vertices and Cut Edges . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5 1.1.2 Blocks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7 1.2 Cycles . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8 1.2.1 Eulerian Cycles . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8 1.2.2 Hamiltonian Cycles . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8 1.2.3 Travelling Salesman Problem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9 1.3 Matchings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10 1.3.1 Hall’s Marriage Theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12 1.4 Coloring . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13 2 Probability Theory 15 2.1 Basics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15 1 Algorithms and Probability 2.2 Conditional Probability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17 2.3 Independence . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18 2.4 Random Variables . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18 2.5 Expected Value . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19 2.6 Variance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20 2.7 Probability Distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21 2.7.1 Bernoulli Distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21 2.7.2 Binomial Distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21 2.7.3 Geometric Distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22 2.7.4 Negative Binomial Distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22 2.7.5 Poisson Distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22 2.8 Multiple Random Variables . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23 2.8.1 Independence of Random Variables . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23 2.9 Probability Estimations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23 2.10 Coupon Collector Problem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25 3 Randomized Algorithms 26 3.1 Error Reduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26 3.2 Target Shooting . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27 3.3 Prime Number Test . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28 3.3.1 Euclid Certificate . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28 3.3.2 Fermat Certificate . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28 3.3.3 Miller-Rabin Certificate . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29 3.4 Finding Duplicates . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31 3.5 Bloom Filters . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31 4 Algorithms Highlights 32 4.1 Networks and Flow . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32 4.2 Augmenting Paths . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33 4.2.1 Matchings in Bipartite Graphs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35 4.2.2 Vertex and Edge Disjoint Paths . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36 4.3 Minimal Cuts in Graphs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36 4.4 Smallest Enclosing Circle . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37 4.5 Convex Hull . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39 4.5.1 Jarvis Wrap . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40 4.5.2 Local Repair . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41 2 Algorithms and Probability This document is a summary of the Algorithms and Probability course that is lectured in the 2nd semester of Computer Science at ETH Zurich. I created this document to summarize and repeat the key learnings of this course. It may contain errors. Franz Schwinn, 08.2022. 3 Algorithms and Probability 1 Graph Theory 1.1 Connectivity Definition A graph G = (V, E) is connected if ▶ ∀u, v ∈ V, (u ̸= v), ∃ a u-v-path in G (a path connecting u with v). In order to find out how strongly connected a graph is, we define k-connectivity and k-edge-connectivity. Definition An undirected graph G = (V, E) is k-connected if ▶ |V | ≥ k + 1 and ▶ ∀X ⊆ V, X < k : G(V \\X, E) is connected Definition A graph G = (V, E) is k-edge-connected if ▶ ∀X ⊆ E, X < k : G(V, E\\X) is connected Intuition: \"At least how many vertices / edges do we need to remove from G such that G is not connected anymore?\" Further we have: connectivity ≤ edge-connectivity ≤ δ(G) (minimal degree among all vertices in G) An equivalent definition of connectivity is Menger’s theorem: Theorem Menger’s theorem: Let G = (V, E) be a graph, then ▶ G is k-connected ⇔ ∀u, v ∈ V, (u ̸= v) there are at least k internally-vertex-disjoint u-v-paths ▶ G is k-edge-connected ⇔ ∀u, v ∈ V, (u ̸= v) there are at least k edge-disjoint u-v-paths 4 Algorithms and Probability 1.1.1 Cut Vertices and Cut Edges Definition Let G = (V, E) be a connected graph. A vertex v ∈ V is called a cut vertex if ▶ G(V \\{v}, E) is not connected Definition Let G = (V, E) be a connected graph. An edge e ∈ E is called a cut edge if ▶ G(V, E\\{e}) is not connected An important property of cut edges is the following. Useful Let {u, v} ∈ E be an undirected cut edge. Then for both of its incident vertices u and v it holds that either deg(u) = 1 or u is a cut edge (equivalently for v). A modified version of the DFS allows us to find cut vertices and cut edges in a connected graph in O(|E|) time. Algorithm 1: find_cut_vertices(G, n, root) 1 dfs = int[n]; 2 low = int[n]; 3 iscut = boolean[n]; 4 int num = 0; 5 dfs(root); 6 if deg(root) ≥ 2 then 7 iscut[root] = true; 8 else 9 iscut[root] = false; 10 end Algorithm 2: dfs(u) 1 num = num + 1; 2 dfs[u] = num; 3 low[u] = num; 4 iscut[u] = false; 5 for {u,v} ∈ E do 6 if dfs[v] == 0 then 7 int val = dfs(v); 8 if val ≥ dfs[u] then 9 iscut[u] = true; 10 end 11 low[u] = min(low[u], val); 12 else 13 low[u] = min(low[u], dfs[v]); 14 end 15 end 16 return low[u]; 5 Algorithms and Probability 1 private ArrayList < Integer >[] g ; // graph as adjacency list 2 private int [] dfs ; // used to store dfs values 3 private int [] low ; // used to store low values 4 private boolean [] iscut ; // used to mark cut vertices 5 private int num ; // marks the dfs value 6 7 public static boolean [] find_cut_vertices ( ArrayList < Integer >[] g ) { 8 this . g = g ; // set graph 9 int n = g . length ; // amount of vertices 10 dfs = new int [ n ]; // initialize dfs array 11 low = new int [ n ]; // initialize low array 12 iscut = new boolean [ n ]; // initialize iscut array 13 num = 0; // set dfs value to zero 14 15 dfs (0) // call modified dfs algorithm with vertex 0 as root 16 if ( g [0]. size () >= 2) { // if root has at least 2 children 17 iscut [0] = true ; 18 } else { 19 iscut [0] = false ; 20 } 21 return iscut ; 22 } 23 24 private static int dfs ( int u ) { 25 n += 1; // increase dfs value 26 dfs [ u ] = n ; // set dfs value 27 low [ u ] = n ; // set low value 28 for ( int i = 0; i < g [ u ]. size () ; i ++) { // iterate through all adjacent vertices 29 int v = g [ u ]. get ( i ) ; // get adjacent vertex 30 if ( dfs [ v ] == 0) { // if we didn ’t touch vertex yet ... 31 int val = dfs ( v ) ; // ... call dfs on it and store its low value 32 if ( val >= dfs [ u ]) { // if there is no back edge ... 33 iscut [ u ] = true ; // ... we know that u is a cut vertex 34 } 35 low [ u ] = Math . min ( low [ u ] , val ) ; // compute low value of u 36 } else { 37 low [ u ] = Math . min ( low [ u ] , dfs [ v ]) ; // compute low value of u 38 } 39 } 40 return low [ u ]; 41 } As shown above, we modify the dfs algorithm by adding a low value to every vertex. low[u] stores the smallest dfs value of all vertices that can be reached from u by using indefinitely many edges from the dfs tree but only one edge that is not part of the dfs tree. Using the low value we can determine whether or not a given vertex is a cut vertex. Useful v ∈ V is a cut vertex ⇔ ▶ v is the root of the dfs tree and deg(v) ≥ 2 or ▶ v is not the root of the dfs tree and ∃u ∈ V with {v, u} ∈ E such that low[v] ≥ df s[u] 6 Algorithms and Probability We can also use the low value to find cut edges. Useful {u, v} ∈ E is a cut edge ⇔ ▶ {u, v} is part of the dfs tree and ▶ low[v] > df s[u] (or low[u] > df s[v]) Since we require a connected graph as input, we know that |V | ≤ |E| − 1 (thus |E| is an upper bound of |V |) which means that the run time of our algorithm is simply O(|E|) instead of O(|E| + |V |) for default dfs. 1.1.2 Blocks Definition A block is an equivalence relation between arbitrary edges e, f ∈ E defined by: e ∼ f ⇔ { e = f ∃ a cycle that contains e and f We can construct a block diagram from any given graph as shown below. There are two useful pieces of information regarding blocks. Useful ▶ A vertex is a cut vertex ⇔ it is incident to at least two edges that are in different blocks. ▶ An edge is a cut edge ⇔ it is the only edge in its block. 7 Algorithms and Probability 1.2 Cycles 1.2.1 Eulerian Cycles Definition An Eulerian cycle is a closed walk that traverses every edge of a given graph G exactly once. We know that G is Eulerian if ▶ G is connected and ▶ ∀v ∈ V : deg(v)%2 == 0 (all vertices have even degree) If we know that G is Eulerian, we can find an Eulerian cycle in O(|E|) time. For this we use the \"fast runner / slow runner\" idea. First we pick an arbitrary vertex v ∈ V and let the fast runner start from there. The runner chooses an arbitrary path W and immediately deletes every edge that he traversed. Therefore the runner can traverse every edge at most once. The runner stops as soon as a vertex with no outgoing edge (degree 0) is reached. This vertex must be v (the vertex that the runner started from). So the path W that the runner chose is a circuit. Proof by contradiction: Let us assume that W ends in some vertex u ∈ V \\{v} and that the runner already visited vertex u k times. Then on every of the k visits of u, the runner would have removed two edges incident to u (one edge on the way in to u and one edge on the way out from u). Furthermore, the runner would have removed one additional incident edge on his final way to u (last edge of the run). So in total, the runner would have removed 2k + 1 edges that are incident to u, which means that an odd number of edges would have been removed. As we know that u had even degree in the beginning (requirement of G to be Eulerian), we can conclude that u now must have odd degree (since we subtracted an odd number of incident edges) and in particular u cannot have degree 0. This is a contradiction to our initial assumption that W must end in a vertex that has degree 0. In case W contains all edges of G we successfully found an Eulerian cycle. If not, we know that all vertices in G still have even degree (because the runner always removed an even number of edges from a vertex that was visited). Next, the slow runner goes to search for a vertex v′ in W with deg(v′) > 0. There must be such a v′, because if there was no such vertex we would know that G initially was not connected, which violates the requirements for G to be Eulerian. Once the slow runner found such a v′, we let the fast runner begin another run W ′ starting from v′. We then unite W and W ′ by creating a new circuit W2 that contains all edges from W up until v′, followed by all edges from W ′ and then all remaining edges in W . We repeat this process until Wx contains all edges in G. 1.2.2 Hamiltonian Cycles Definition A Hamiltonian cycle is a cycle that visits every vertex of G exactly once. As of today it is assumed that there is no algorithm with polynomial run time that is able to check if a graph is Hamiltonian. Therefore, determining whether a graph is Hamiltonian is NP hard. However, if a graph fulfills certain conditions we know that it must be Hamiltonian. ▶ Any n × m grid graph is Hamiltonian ⇔ n ∗ m is even ▶ Any d-dimensional hypercube (V : 0, 1 d, E: All pairs of vertices that differ in exactly one coordinate) are Hamiltonian 8 Algorithms and Probability Theorem Dirac’s theorem: Let G = (V, E) be a graph. G is Hamiltonian if ▶ |V | ≥ 3 and ▶ δ(G) ≥ |V | 2 The reverse implication does not hold. G is Hamiltonian ̸⇒ |V | ≥ 3 and δ(G) ≥ |V | 2 Using a dynamic programming algorithm we can check if G is Hamiltonian in O(|V |2 ∗ 2 |V |) time. 1.2.3 Travelling Salesman Problem The Travelling Salesman Problem (TSP) is a well known problem: Calculate the least expensive cycle on a complete graph Kn. So we are looking for the minimal (\"least expensive\") Hamiltonian cycle in a given complete graph Kn. We call the optimal solution to this problem opt(Kn, l) (the function opt takes in the graph Kn, the cost function l, and returns the minimal cost it requires to visit all vertices). Definition In the context of the TSP, we let a α-approximation algorithm be an algorithm that always comes up with a solution C ⊆ E such that the following holds: ∑ e∈C l(e) ≤ α ∗ opt(Kn, l) Or intuitively, an α-approximation algorithm always solves the TSP at least α times as well as the optimal solution. In spite of the fact that the TSP is NP hard, we can come up with efficient solutions if we assume that the triangle inequality (l({x, z}) ≤ l({x, y}) + l({y, z})∀x, y, z ∈ V (x ̸= y ̸= z)) holds. When the triangle inequality holds, the TSP problem is called metric (metric TSP). There is a 2- approximation algorithm for the metric TSP with run time O(n2). 1. We compute an Minimum Spanning Tree T in G. l(T ) ≤ opt(Kn, l) 2. We create a multigraph by doubling every edge in T . 2 ∗ l(T ) ≤ 2 ∗ opt(Kn, l) 3. We find an Eulerian circuit W in T (which works because after doubling, all degrees of T are for sure even). l(W ) = 2 ∗ l(T ) ≤ 2 ∗ opt(Kn, l) 4. We now traverse the Eulerian circuit, but every time we encounter a vertex that we already visited, we skip it and directly move on with the next unvisited vertex in T . This is the point where we make use of the triangle inequality. We now have the Hamiltonian cycle C. 9 Algorithms and Probability l(C) ≤ l(W ) = 2 ∗ l(T ) ≤ 2 ∗ opt(Kn, l) The above statement shows that l(C) is a 2-approximation. There also is an 3 2 -approximation algorithm for the metric TSP with O(n3) run time. 1. Compute MST T in G. 2. Find minimal perfect matching M in G between vertices in T with odd degree. There is always an even number of vertices with odd degree, as this is a direct conclusion of the handshaking lemma: ∑ ∀v∈V deg(v) = 2 ∗ |E| 3. Unite T = T ∪ M . 4. Find Eulerian cycle S in T (S exists because all degrees are even). 5. Traverse S while skipping already visited vertices (making use of the triangle inequality, analogously to step 4 in the 2-approximation algorithm). This gives us the Hamiltonian cycle C. 1.3 Matchings Definition Let G = (V, E) be a graph. A set of edges M ⊆ E is called a matching if no vertex v ∈ V is incident to more than one edge in M . Or formally: ∀e, f ∈ M, (e ̸= f ) : e ∩ f = ∅ We say that a vertex v ∈ V is matched by M if v ∈ e ∈ M . We call a matching perfect if all vertices v ∈ V in the graph are matched by M (or in other words: M is perfect ⇔ |M | = |V | 2 ). What we often care about is to find a matching with the largest cardinality possible. 10 Algorithms and Probability Definition Let G = (V, E) be a graph and M a matching in G. ▶ M is a maximum-cardinality matching if there is no M ′ such that |M ′| > |M | ▶ M is a maximum matching if ∀e ∈ E\\M : M ∪ {e} is not a matching. A maximum-cardinality matching is therefore also a maximum matching. We can determine a maximum matching in O(|E|) by using the below greedy algorithm. Algorithm 3: greedy_max(G) 1 M = ∅ 2 while E ̸= ∅ do 3 pick e ∈ E randomly 4 M = M ∪ {e} 5 delete e with all its incident edges from G 6 end 7 return M Useful The cardinality of Mgreedy can be lower bounded as follows: 1 2 |Mmax−card| ≤ |Mgreedy| ≤ |Mmax−card| Let us introduce augmenting paths. Definition Let G = (V, E) be a graph and M be a matching in G. A path P in G is called an augmenting path if ▶ its edges, alternately, are elements of M and E\\M and ▶ its first vertex, last vertex, first edge, and last edge are unmatched by M We can use augmenting paths to increase the size of a matching. Once we found an augmenting path P , we swap its edges by removing all covered edges in P from M and adding all uncovered edges in P to M . This results in M to increase in size by 1. 11 Algorithms and Probability Using augmenting paths we can build an algorithm that finds a maximum-cardinality matching in a bipartite graph in O(|V ||E|) time. We denote the swap operation as M ⊕ P (XOR operation, M is a matching and P an augmenting path). We can find an augmenting path in a bipartite graph by using a modified version of BFS. Let G = (A ⊎ B, E) be a bipartite graph and M a matching in G. We add two vertices s and t to the graph G and draw a directed edge from s to all unmatched vertices in A and a directed edge from all unmatched vertices in B to t. Additionally, we set the direction of unmatched edges such that they point from A to B and matched edges such that they point from B to A. Then we run BFS on s and return the shortest path from s to t. Algorithm 4: find_augmenting_path(G, M ) 1 add vertices s and t 2 draw directed edge from s to all unmatched vertices in A 3 draw directed edge from all unmatched vertices in B to t 4 set direction of unmatched edges such that they point from A → B 5 set direction of matched edges such that they point from B → A 6 find shortest path P from s to t using BFS 7 return P \\{s, t} There are faster algorithms to find maximum-cardinality matchings. Useful A maximum-cardinality matching can be found in ▶ O(√|V ||E|) if the graph is bipartite using Hopcroft-Karp algorithm ▶ O(|E||V |2) in a general graph using Blossom algorithm 1.3.1 Hall’s Marriage Theorem Theorem Hall’s marriage theorem: Let G = (A ⊎ B, E) be a bipartite graph. G contains a matching of cardinality |A| ⇔ ∀X ⊆ A : |X| ≤ |N (X)|. 12 Algorithms and Probability Or intuitively, G contains a matching with cardinality |A|, if and only if for every subset of A, the neighbor- hood of that subset in B is larger than or equal to the size of the subset itself. Definition Frobenius’ theorem: All k-regular bipartite graphs contain a perfect matching. It can be found in O(|E|) time. For k = 2 k, we can use the below algorithm. Algorithm 5: 2 k_max(G) 1 while k ≥ 2 do 2 find Eulerian cycle T in G 3 delete every second edge of T in G 4 end 5 return G For a general k the procedure is harder and not discussed in this course. 1.4 Coloring Definition A coloring of a graph G = (V, E) using k colors is a function c : V → {1, ..., k} such that ∀{u, v} ∈ E : c(u) ̸= c(v) The chromatic number χ(G) is the minimal number of colors it takes to color G. Useful Graphs with a chromatic number k can be called k-partite, since χ(G) ≤ k ⇔ G is k-partite 13 Algorithms and Probability Finding the chromatic number of a graph is NP hard. However, we can use a greedy algorithm to color a graph in O(|E|) time. Algorithm 6: greedy_coloring(G) 1 generate an arbitrary order of all vertices: {v1, ..., vn} 2 c(v1) = 1 3 for i = 2, ..., n do 4 c(vi) = min(k ∈ N|k ̸= c(u)∀u ∈ N (vi) ∩ {v1, ..., vi−1}) 5 end Useful ▶ For every order {v1, ..., vn} at most ∆(G) + 1 colors are required to color G (∆(G) is the maximum degree among all vertices in G). ▶ There always exists an order {v1, ..., vn} such that the greedy algorithm only needs χ(G) colors. ▶ Therefore we can bound the amount of colors the greedy algorithm needs (C(G)): χ(G) ≤ C(G) ≤ ∆(G) + 1 Theorem Brooks’ theorem: Let G = (V, E) be a connected undirected graph. If G ̸= Kn (complete graph) and G ̸= C2n+1 (cycle with odd number of vertices), then G can be colored in O(|E|) time using at most ∆(G) colors. 14 Algorithms and Probability 2 Probability Theory 2.1 Basics Definition A probability space consists of ▶ a sample space Ω = {ω1, ..., ωn} containing elementary events ωi ∈ Ω ▶ a probability function P r : Ω → [0, 1] The probability function measures the likelihood of an event to happen. The following two properties are required for the probability space to be correct: ▶ ∀ωi ∈ Ω : 0 ≤ P r[ωi] ≤ 1 ▶ ∑n i=1 P r[ωi] = 1 A set E ⊆ Ω is called an event, and its probability is defined as the sum of the elementary events included in E. P r[E] = ∑ ω∈E P r[ω] As an example we can model the act of rolling a dice as a probability space. Ω = {1, 2, 3, 4, 5, 6} and ∀ω ∈ Ω : P r[ω] = 1 6 . We can define an event roll an even number as E = {2, 4, 6}. Useful For all events E we have ▶ P r[∅] = 0 ▶ P r[Ω] = 1 ▶ 0 ≤ P r[E] ≤ 1 ▶ P r[E] = 1 − P r[E] ▶ E ⊆ F ⇒ P r[E] ≤ P r[F ] Theorem Addition theorem: Let the events A1, ..., An be pairwise disjoint (for all pairs i ̸= j: Ai ∩ Aj = ∅), then P r[ n⋃ i=1 Ai] = n∑ i=1 P r[Ai] This only holds for pairwise disjoint events. If we are not sure if the events are pairwise disjoint, we can use the following upper bound. Theorem Union Bound: For events A1, ..., An we have P r[ n⋃ i=1 Ai] ≤ n∑ i=1 P r[Ai] If we want to calculate the probability of a union of some events (they don’t have to be pairwise disjoint), we can use the below procedure. 15 Algorithms and Probability Theorem Inclusion-Exclusion Principle: Let A1, ..., An be some events. Then we have P r[ n⋃ i=1 Ai] = n∑ i=1 P r[Ai] (1) − ∑ 1≤i1≤i2≤n P r[Ai1 ∩ Ai2] (2) + ∑ 1≤i1≤i2≤i3≤n P r[Ai1 ∩ Ai2 ∩ Ai3 ] (3) − ... (4) + (−1)n+1 ∗ P r[A1 ∩ ... ∩ An] (5) Or intuitively: If the number of events we intersect is odd, then we add the probability of the intersection and if the number of events we intersect is even, then we subtract the probability of the intersection. Definition Laplace’s probability space: In case we don’t know anything about the probability function P r, we assume that all elementary events ω ∈ Ω have the same probability to occur. We call such an probability space a Laplace space. ▶ ∀ω ∈ Ω : P r[ω] = 1 |Ω| ▶ for any event E ⊆ Ω : P r[E] = |E| |Ω| Useful formulas for combinatorics: Useful Number of combinations: 16 Algorithms and Probability ▶ with repetition, ordered: n k ▶ with repetition, unordered: (n+k−1 k ) ▶ without repetition, ordered: n! (n−k)! ▶ without repetition, unordered: (n k) Where n is the total number of elements (set size) and k is the number of elements drawn (subset size) and (n k) = n! (n−k!)∗k! . 2.2 Conditional Probability By adding more information the probability for an event to occur may change. Definition Let A and B be events (P r[B] ≥ 0). The conditional probability P r[A|B] (A given B) is defined as: P r[A|B] = P r[A∩B] P r[B] As an example we have the following problem: Family X has two two children. What is the likelihood that both children are girls? The probability space would be Ω = {bb, bg, gb, gg} (b short for boy and g short for girl). Without additional information we assume that P r[ω] = 1 4 . But the parents now tell us that (at least) one of the children is a girl. We can therefore perform the below calculation: P r[X = ”Both are girls”|Y = ”One is girl”] = P r[X∩Y ] P r[Y ] = P r[{gg}] P r[{gg,gb,bg}] = 1 4 3 4 = 1 3 We often use the following equality for conditional probability. It helps us to restructure problems in order to make them easier to calculate. P r[A ∩ B] = P r[A|B] ∗ P r[B] Definition Multiplication theorem: Let A1, ..., An be events. If P r[A1 ∩ ... ∩ An] > 0 then P r[A1 ∩ ... ∩ An] = P r[A1] ∗ P r[A2|A1] ∗ P r[A3|A1 ∩ A2] ∗ ... ∗ P r[An|A1 ∩ ... ∩ An−1] We can use this theorem to solve this problem: What is the probability that at least two persons in a group of m people celebrate their birthday on the same day of the year? We can rephrase this problem to another problem: We randomly throw m balls in n baskets. What is the probability that there is no basket with more than one ball in the end? We define Ai = i-th ball lands in an empty basket. For the 1st throw it is clear that the ball will land in an empty basket, therefore P r[A1] = 1. For A2 there are n − 1 baskets left, so P r[A2|A1] = n−1 n . In general we have P r[Ai|A1 ∩ ... ∩ Ai−1] = n−(i−1) n . Now we apply the multiplication theorem and get: P r[Ai ∩ ... ∩ Am] = 1 ∗ n−1 n ∗ ... ∗ n−(m−1) n Based on the definition of conditional probability there is another important formula. 17 Algorithms and Probability Theorem Law of total probability: Let the events A1, ..., An be pairwise disjoint and B ⊆ A1 ∪ ... ∪ An. Then we have: P r[B] = n∑ i=1 P r[B|Ai] ∗ P r[Ai] Intuition: Every summand P r[B|Ai] ∗ P r[Ai] is equivalent to P r[B ∩ Ai]. Since A1, ..., An are pairwise disjoint and B is a subset of the union all events A1, ..., An we can see that summing up all summands gives us P r[B]. Theorem Bayes’ theorem: Let the events A1, ..., An be pairwise disjoint and B ⊆ A1 ∪ ... ∪ An. Then we have: P r[Ai|B] = P r[Ai ∩ B] P r[B] = P r[B|Ai] ∗ P r[Ai] ∑n j=1 P r[B|Aj] ∗ P r[Aj] Why do we need this? Bayes’ theorem allows us to swap the order of condition (see first factor in numerator of last term). As an example we can look at the evaluation of a medical test: We define P = \"Test is positive\", N = \"Test is negative\", S = \"Sick\", and H = \"Healthy\". Often it’s easy to determine the probability P r[P |S] and P r[P |H]. Thanks to Bayes we can now calculate the potentially more interesting information for the patient P r[S|P ]: P r[S|P ] = P r[P |S] ∗ P r[S] P r[P |S] ∗ P r[S] + P r[P |H] ∗ P r[H] 2.3 Independence It may be that a condition does not affect the probability of an event, so P r[A|B] = P r[A]. Definition Events A and B are called independent ⇔ ▶ P r[A ∩ B] = P r[A] ∗ P r[B] or ▶ P r[A|B] = P r[A] or ▶ P r[B|A] = P r[A] Multiple events A1, ..., An are called independent if ▶ ∀I ⊆ {1, ..., n} with I = {i1, ..., ik} we have: P r[Ai1 ∩ ... ∩ Aik ] = P r[Ai1 ] ∗ ... ∗ P r[Aik ] So for multiple events to be independent all subsets of those events must be independent. Useful Let A, B and C be independent events. Then ▶ A ∪ B and C as well as ▶ A ∩ B and C are independent. 2.4 Random Variables Often we are interested in some properties of an experiment, for instance how many times we flip tails, or what is the sum of results if we roll a dice x times. 18 Algorithms and Probability Definition A random variable is a function X : Ω → R. Also we introduce a shorter notation: X ≤ 5 = {ω ∈ Ω|X(ω) ≤ 5} X ≤ 5 is short for the event that the random variable X takes a value less than or equal to 5. As an example we throw a coin three times (Ω = {h, t} 3, h short for heads and t short for tails) and define the random variable Y as how often we flipped heads. For instance, Y (htt) = 1 and Y (ttt) = 0. Definition The probability density function (PDF) of a random variable X is defined as: fx : R → [0, 1], x ↦→ P r[X = x] We define the cumulative distribution function (CDF) of a random variable X as: Fx : R → [0, 1], x ↦→ P r[X ≤ x] = ∑ x′∈Wx:x′≤x P r[X = x′] Where Wx is the image of the random variable X (all possible values it can take). 2.5 Expected Value What value can we expect from a given random variable? This is where the expected value comes in. Definition Let X be a random variable. We define the expected value E[X] as: E[X] = ∑ x∈Wx x ∗ P r[X = x] Or equivalently: E[X] = ∑ ω∈Ω X(ω) ∗ P r[ω] 19 Algorithms and Probability Intuition for the latter definition: We iterate over all elementary events, we plug in the elementary event to the function X (random variable), multiply the result of X by the probability of that elementary event, and sum up all these summands. In case the image of X is a natural number, we can also use the below definition. Useful Let X be a random variable with Wx ⊆ N0. Then E[X] = ∞∑ i=1 P r[X ≥ i] An important property of the expected value is its linearity. Useful For random variables X1, ..., Xn and X = a1X1 + ... + anXn + b with a1, ..., an, b ∈ R, we have E[X] = a1E[X1] + ... + anE[Xn] + b This simple example illustrates the linearity of expected value: Let X be the sum of a dice throw. What is the expected value of the sum of two dice throws? E[2X] = 2 ∗ E[X] (6) = 2 ∗ (1 ∗ 1 6 + ... + 6 ∗ 1 6 ) (7) = 2 ∗ ( 7 2 ) (8) = 7 (9) Definition For an event A ⊆ Ω the corresponding indicator variable XA is defined as XA(ω) = { 1, if ω ∈ A 0, else The expected value of XA is E[XA] = P r[A] Useful ⊤ ⇒ E[X + Y ] = E[X] + E[Y ] (10) if X, Y are independent ⇒ E[X ∗ Y ] = E[X] ∗ E[Y ] (11) 2.6 Variance Variance helps us to find the average deviation of a random variable from its expected value. Definition For a random variable X with µ = E[X] we define its variance V ar[X] as V ar[X] = E[(X − µ) 2] = E[X 2] − E[X] 2 = ∑ x∈Wx(x − µ) 2 ∗ P r[X = x] 20 Algorithms and Probability These three definitions are equal thanks to the linearity property of the expected value. E[(X − µ) 2] = E[(X − µ) 2] = E[X 2 − 2Xµ + µ 2] binomial theorem = E[X 2] − E[2Xµ] + E[µ 2] linearity of E = E[X 2] − 2E[X]µ + µ 2 = E[X 2] − 2E[X]E[X] + E[X]E[X] µ = E[X] = E[X 2] − E[X]E[X] = E[X 2] − E[X]2 The standard deviation of X is σ = √ V ar[X] Useful For an arbitrary random variable X and a, b ∈ R we have V ar[a ∗ X + b] = a 2 ∗ V ar[X] Useful if X, Y are independent ⇒ V ar[X + Y ] = V ar[X] + V ar[Y ] V ar[X ∗ Y ] ̸= V ar[X] ∗ V ar[Y ] 2.7 Probability Distribution Often we can group random variables into certain classes (probability distributions). 2.7.1 Bernoulli Distribution Definition A random variable X with WX = {0, 1} and density fX (x) =    p, for x = 1 1 − p, for x = 0 0 else is called Bernoulli distributed. If X˜Bernoulli(p) (X is Bernoulli distributed), then E[X] = p and V ar[X] = p(1 − p) Intuition: We flip a coin. Does the coin show heads? Indicator variables are Bernoulli distributed. 2.7.2 Binomial Distribution If we repeat the experiment of flipping a coin n times and ask ourselves how many times we flipped heads, we can call this outcome binomial distributed. 21 Algorithms and Probability Definition A random variable X with WX = {0, 1, ..., n} and density fX (x) = { (n x)p x(1 − p) n−x, x ∈ {0, 1, ..., n} 0, else is called binomial distributed. If X˜Bin(n, p), then E[X] = n ∗ p and V ar[X] = n ∗ p(1 − p) Intuition: We flip a coin n times. How many heads did we get? 2.7.3 Geometric Distribution Definition A random variable X and density fX (x) = { p(1 − p) i−1 for i ∈ N 0, else is called geometrically distributed. If X˜Geo(p), then E[X] = 1 p and V ar[X] = 1−p p2 Intuition: How often do we need to roll a dice until we get a 6? 2.7.4 Negative Binomial Distribution Definition A random variable X with density fX (x) = { (x−1 n−1)(1 − p) k−np n for k = 1, 2, ... 0, else is called negative geometrically distributed. If X˜N egBin(n, p), then E[X] = n p and V ar[X] = n(1−p) p2 Intuition: How many times to we need to roll a dice to get n sixes? 2.7.5 Poisson Distribution The Poisson distribution focuses on events with very low probability, for instance X = Amount of heart attacks in Switzerland in the next hour. For one person living in Switzerland this probability is very low, however there are about three to four heart attacks across all of Switzerland in one hour. The Poisson distribution can be interpreted as the limit of a binomial distribution: If we let X˜Bin(n, λ n ) and n → ∞ then we get the Poisson distribution X˜P o(λ). Definition A random variable X with density fX (x) = { e−λλ i i! for i ∈ N 0, else is called Poisson distributed. If X˜P o(λ), then E[X] = V ar[X] = λ 22 Algorithms and Probability 2.8 Multiple Random Variables Often we are interested in multiple random variables simultaneously. Definition For two random variables X, Y we call the function fX,Y = P r[X = x, Y = y] the joint probability density function of X and Y . Using the joint probability density function we can reverse calculate the densities of the indi- vidual random variables (marginal distributions). fX = ∑ y∈WY FX,Y (x, y) or fY = ∑ x∈WX FX,Y (x, y) 2.8.1 Independence of Random Variables As in events we can also define independence for random variables. Definition Random variables X1, ..., Xn are independent ⇔ ∀(x1, ..., xn) ∈ WX1 × ... × WXn we have P r[X1 = x1, ..., Xn = xn] = P r[X1 = x1] ∗ ... ∗ P r[Xn = xn] Or alternatively fx1,...,xn(x1, ..., xn) = fX1 (x1) ∗ ... ∗ fXn (xn) Useful Two indicator variables are independent if their events are independent. For two indicator variables we have X and Y are independent ⇔ fX,Y (1, 1) = fX (1) ∗ fY (1) Or equivalently P r[X = 1, Y = 1] = P r[X = 1] ∗ P r[Y = 1] Useful For two independent random variables X and Y we can define Z = X + Y as fz(z) = ∑ x∈Wx fX (x) ∗ fy(z − x) Additionally we have Bin(n1, p) + Bin(n2, p) = Bin(n1 + n2, p) and P o(λ1) + P o(λ2) = P o(λ1 + λ2). 2.9 Probability Estimations We want to estimate how likely it is for a random value to differ from its expected value. 23 Algorithms and Probability Definition Markov’s inequality: Let X be a random variable which only takes non-negative values (WX ⊆ N0). Then ∀t ∈ R with t > 0 we have P r[X ≥ t] ≤ E[X] t Or equivalently P r[X ≥ t ∗ E[X]] ≤ 1 t Markov’s inequality comes from ignoring some summands in the definition of the expected value. By applying Markov’s inequality to the definition of variance we get Chebyshev’s inequality, which can be used for random variables that take negative values. Definition Chebyshev’s inequality: Let X be a random value and t ∈ R with t > 0. Then we have P r[|X − E[X]| ≥ t] ≤ V ar[X] t2 Or equivalently P r[|X − E[X]| ≥ t ∗ √ V ar[X]] ≤ 1 t2 And also P r[X ≥ E[X] + t] ≤ V ar[X] t2 As a third estimation we have Chernoff’s inequality. It can only be applied on independent Bernoulli distributed random variables (their sums). Definition Chernoff’s inequality: Let X1, ..., Xn be independent Bernoulli distributed random variables with P r[Xi = 1] = pi and P r[Xi = 0] = 1 − pi. Then we have for X = ∑n i=1 Xi: ▶ P r[X ≥ (1 + δ)E[X]] ≤ e− 1 3 δ2E[X] for all 0 < δ ≤ 1 ▶ P r[X ≤ (1 + δ)E[X] ≤ e− 1 2 δ2E[X]] for all 0 < δ ≤ 1 ▶ P r[X ≥ t] ≤ 2 −t 24 Algorithms and Probability 2.10 Coupon Collector Problem Suppose there are boxes that contain one coupon each. The probability of a certain coupon to be inside a certain box is 1 n where n is the number of coupons. We are interested in collecting all coupons. How many boxes do we expect to open in order to collect all coupons? To solve this problem, we define the random variable X as the number of boxes we need to open until we get all coupons, and Xi as the number of boxes we need to open until we get coupon i. So X = X1 +X2 +...+Xn. X1 is 1, because we need to open one box to get the first coupon. The probability that we get a new coupon (different to the coupon we just got) is n−1 n . Since X2 is geometrically distributed (\"how many times do I need to try until success?\"), the expected value for X2 is 1 p = 1 n−1 n = n n−1 . Analogously E[X3] = n n−2 and E[Xi] = n n−i+1 . Then we have: E[X] = E[X1 + X2 + ... + Xn] = E[X1] + E[X2] + ... + E[Xn] linearity of E = 1 + n n − 1 + ... + n n − n + 1 as calculated above = n−1∑ i=0 n ∗ 1 n − i = n ∗ n−1∑ i=0 1 n − i move constant n out of sum = n ∗ n∑ i=1 1 i As 1 n is the harmonic series, we can approximate E[X] to n ∗ (ln(n) + O(1)) which is the number of expected boxes we need to open until we collected all coupons. 25 Algorithms and Probability 3 Randomized Algorithms Up until now we only looked at deterministic algorithms (given a deterministic algorithm A and input I, then A will always output A(I)). A randomized algorithm however can make use of randomness. We call the output of such an randomized algorithm A(I, R), where R stands for the values the random numbers can take. So generally if we plug in input I to a randomized algorithm and execute it multiple times, we expect different results. Definition Monte Carlo algorithms are algorithms that have a fixed run time but we cannot be sure whether the result is correct. Las Vegas algorithms on the other hand are algorithms that have an unknown run time but once the algorithm terminates we can be sure that the result is correct. 3.1 Error Reduction If we execute a randomized algorithms multiple times we can reduce the probability that the algorithm always returns an incorrect result. For instance, let algorithm A have an error probability of 1 3 (if we execute A once we get an error with probability of 1 3 ). If we however execute A 10 times, the probability that all 10 executions are incorrect results is ( 1 3 )10 = 1.6935 ∗ 10−5. We can calculate how often we have to execute an algorithm with success probability ϵ > 0 in order to get an error probability of δ. Theorem Error reduction Monte Carlo algorithm: Let A be a randomized one-sided error algorithm with ▶ ∀yes-instances: P r[A(I) = yes] = 1 (if input is a yes-instance then A always prints the correct result) and ▶ ∀no-instances: P r[A(I) = no] ≥ ϵ (if input is a no-instance then A prints the correct result with probability greater than ϵ) then ∀δ > 0 we let Aδ be the algorithm that executes A so many times until A returns no (then Aδ 26 Algorithms and Probability also outputs no) or until A has returned yes N = ϵ−1ln(δ−1) times (then Aδ also outputs yes). Then we get P r[Aδ(I) = correct] ≥ 1 − δ Theorem Error reduction Las Vegas algorithm: Let A be a randomized algorithm that never returns an incorrect result but may output an undefined output ??? (??? is printed when we abort the algorithm, for instance if it has been running for too long). Let P r[A(I) doesn’t print ???] ≥ ϵ. Then ∀δ > 0 we let Aδ be the algorithm that executes A so many times until a value other than ??? is returned (then Aδ outputs that value) or until A has returned ??? N = ϵ−1ln(δ−1) times (then Aδ also outputs ???). Then we get P r[Aδ(I) = correct] ≥ 1 − δ We can also reduce the error probability for two-sided error algorithms (as long as the error probability it < 1 2 ). Theorem Error reduction two-sided error algorithm: Let ϵ > 0 and A a randomized algorithm that either prints yes or no. Let P r[A(I)correct] ≥ 1 2 + ϵ. Then ∀δ > 0 we call Aδ the algorithm that calls A N = 4ϵ−2ln(δ−1) times and then prints the result that was received most. Then we have P r[Aδ(I)correct] ≥ 1 − δ Every deterministic algorithm can be seen as a randomized algorithm (with error probability 0). But it is obvious that not every randomized algorithm can be seen as a deterministic one. 3.2 Target Shooting Let’s consider the following problem: Given all residents of Switzerland, what is the percentage of people having a certain type of cancer? Or more generally: Given a set U and a subset S ⊆ U of unknown size, what is |S| |U | ? We assume that there is a way for us to efficiently determine whether an element of U is also an element of S (IS : U → {0, 1}). Now we can approximate |S| |U | by taking a random sample of elements in U and applying IS to every element in our sample as shown below. Algorithm 7: target_shooting(U ) 1 randomly pick u1, ..., un ∈ U 2 return 1 n ∗ ∑n i=1 IS(ui) The next theorem allows us to find the probability that the approximation is within a certain range. Theorem Let δ, ϵ > 0. If N ≥ 3 ∗ |U | |S| ∗ ϵ−2 ∗ ln( 2 δ ) then the output of target_shooting(U) is with probability of at least 1 − δ in the range of [(1 − ϵ) |S| |U | , (1 + ϵ) |S| |U | ]. 27 Algorithms and Probability 3.3 Prime Number Test We will take a look at a few randomized algorithms that can can help us determine whether a number is prime or not. 3.3.1 Euclid Certificate Algorithm 8: Euclid_certificate(n) 1 randomly pick a ∈ {1, ..., n} 2 if gcd(a, n) > 1 then 3 return false 4 end 5 return true 1 public static boolean euclid_certificate ( int n ) { 2 int a = getRandomNumber (1 , n ) ; 3 if ( gc dByE ucli dsAlg orit hm (a , n ) > 1) { 4 return false ; 5 } 6 return true ; 7 } 8 9 private static int getRandomNumber ( int min , int max ) { 10 return ( int ) (( Math . random () * ( max - min ) ) + min ) ; 11 } 12 13 private static int g cdBy Eucli dsAl gori thm ( int n1 , int n2 ) { 14 if ( n2 == 0) { 15 return n1 ; 16 } 17 return g cdByE ucli dsAl gorit hm ( n2 , n1 % n2 ) ; 18 } This is a one-sided error algorithm. If the Euclid certificate returns f alse we know that n cannot be prime. If n is not prime then the Euclid certificate prints true with probability ϕ(n) n−1 = |Z ∗ n| n−1 . gcd(a, n) can be calculated in O(log(an)3) time. 3.3.2 Fermat Certificate We can make use of Fermat’s little theorem. Theorem Fermat’s little theorem: if n ∈ N is prime then ∀a ∈ N with 0 < a < n a n−1 ≡n 1 Algorithm 9: fermat_certificate(n) 1 randomly pick a ∈ {1, ..., n} 2 if gcd(a, n) > 1 or a n−1 ̸≡n 1 then 3 return false 4 end 5 return true 28 Algorithms and Probability 1 public static boolean fermat_certificate ( int n ) { 2 int a = getRandomNumber (1 , n ) ; 3 BigInteger Ba = BigInteger . valueOf ( a ) ; 4 if ( gc dByE ucli dsAlg orit hm (a , n ) > 1 || !( Ba . modPow ( BigInteger . valueOf (n -1) , BigInteger . valueOf ( n ) ) . equals ( BigInteger . ONE ) ) ) { 5 return false ; 6 } 7 return true ; 8 } 9 10 private static int getRandomNumber ( int min , int max ) { 11 return ( int ) (( Math . random () * ( max - min ) ) + min ) ; 12 } 13 14 private static int g cdBy Eucli dsAl gori thm ( int n1 , int n2 ) { 15 if ( n2 == 0) { 16 return n1 ; 17 } 18 return g cdByE ucli dsAl gorit hm ( n2 , n1 % n2 ) ; 19 } The Fermat certificate also has a one-sided error. If it returns f alse we can be sure that n is not prime. But it returns true with an error probability of < 1 2 (assuming n is not a Carmichael number, which is not prime even though it passes the above tests). 3.3.3 Miller-Rabin Certificate Algorithm 10: miller-rabin_certificate(n) 1 if n == 2 then 2 return true 3 end 4 if n is even or n == 1 then 5 return false 6 end 7 randomly pick a ∈ {2, ..., n − 1} 8 calculate k, d ∈ Z with n − 1 = d ∗ 2 k and d odd 9 x = a d (mod n) 10 if x == 1 or x == n − 1 then 11 return true 12 end 13 while i = 0, ..., k − 2 do 14 x = x2 (mod n) 15 if x == 1 then 16 return false 17 end 18 if x == n − 1 then 19 return true 20 end 21 end 22 return false 29 Algorithms and Probability 1 public static boolean m il l e r _ ra b i n _c e r t if i c a te ( BigInteger n ) { 2 BigInteger one = new BigInteger ( \" 1 \" ) ; 3 BigInteger two = new BigInteger ( \" 2 \" ) ; 4 if ( n . equals ( two ) || n . equals ( new BigInteger ( \" 3 \" ) ) ) { 5 return true ; 6 } 7 if ( n . equals ( one ) || ! odd ( n ) ) { 8 return false ; 9 } 10 BigInteger max = n . subtract ( one ) ; 11 BigInteger min = new BigInteger ( \" 2 \" ) ; 12 BigInteger diff = max . subtract ( min ) ; 13 BigInteger a = new BigInteger ( max . bitLength () , new Random () ) ; 14 15 if ( a . compareTo ( min ) < 0) { 16 a = a . add ( min ) ; 17 } 18 if ( a . compareTo ( diff ) >= 0) { 19 a = a . mod ( diff ) . add ( min ) ; 20 } 21 22 int k = 0; 23 BigInteger d = n . subtract ( one ) ; 24 while (! odd ( d ) ) { 25 k += 1; 26 d = d . divide ( two ) ; 27 } 28 BigInteger x = a . modPow (d , n ) ; 29 if ( x . equals ( one ) || x . equals ( n . subtract ( one ) ) ) { 30 return true ; 31 } 32 for ( int i = 0; i < k -1; i ++) { 33 x = x . modPow ( two , n ) ; 34 if ( x . equals ( one ) ) { 35 return false ; 36 } 37 if ( x . equals ( n . subtract ( one ) ) ) { 38 return true ; 39 } 40 } 41 return false ; 42 } 43 44 private static boolean odd ( BigInteger o ) { 45 BigInteger two = new BigInteger ( \" 2 \" ) ; 46 return ! o . mod ( two ) . equals ( BigInteger . ZERO ) ; 47 } The run time of this algorithm is O(log(n)). If n is prime then the algorithm always returns true. If n is not prime then the algorithms returns f alse with probability ≥ 3 4 . As already shown we can minimize the error probability to as much as we like by executing the algorithm multiple times. 30 Algorithms and Probability 3.4 Finding Duplicates Given a set of data S = {s1, ..., sn}, how can we find duplicates efficiently (duplicates are (i, j), 1 ≤ i < j ≤ n such that si = sj)? If we are allowed to manipulate the data set we could sort it and then easily find duplicates by traversing through the sorted list. But if there are a lot of elements in S and compare and swap operations are expensive, then we need to find another procedure. We define a hash function h : U → {1, ..., m} where U is the universe from which the elements in S come from. We assume that the hash function h can be computed efficiently and that ∀u ∈ U, ∀i ∈ {1, ..., m} we have P r[h(u) = i] = 1 m but si = sj ⇒ h(si) = h(sj). We hash every element in S and since we let m be much smaller than |U | we have fewer different values and the sort operation is more efficient. But we need to be aware of collisions (si ̸= sj but h(si) = h(sj)). 3.5 Bloom Filters The idea behind bloom filters is that instead of one hash function, we use k different hash functions h1, ..., hk : U → {1, ..., m}. For every si ∈ S we then have not a single value h(si), but a hash vector (h1(si), ..., hk(si)). Moreover, we have a list L that stores potential duplicates as well as a bit array M with |M | = m. Then we proceed using the following algorithm: Algorithm 11: bloomfilter(S, {h1, ..., hk}) 1 L = ∅ 2 for si ∈ S do 3 for hj ∈ h1, ..., hk do 4 calculate xj = hj(si) 5 end 6 if ∀xj ∈ hash vector : M [xj] = 1 then 7 L = L ∪ {i} 8 else 9 Set ∀xj ∈ hash vector : set M [xj] = 1 10 end 11 end 31 Algorithms and Probability 4 Algorithms Highlights 4.1 Networks and Flow Finding the maximum flow in a network is a problem with many real world applications. First we define a network. Definition A network is a tuple N = (V, A, c, s, t) with ▶ (V, A) is a directed graph ▶ c : A → R+ 0 is the capacity function ▶ s ∈ V is the source ▶ t ∈ V is the target Intuition: we can imagine a network to be a system of water pipelines where c is the function that specifies how much water can go through a specific pipeline section. Now we can define a flow. Definition Let N = (V, A, c, s, t) be a network. A flow in N is a function f : A → R+ 0 which has to meet the following conditions: ▶ capacity constraint: ∀e ∈ A : 0 ≤ f (e) ≤ c(e) (flow on edge cannot be lower than 0 and cannot be higher than capacity) ▶ flow conservation: ∀v ∈ V \\{s, t} we have ∑ u∈V :(u,v)∈A f (u, v) = ∑ u∈V :(v,u)∈A f (v, u) Or intuitively: whatever flows in to a vertex also flows out of it, no water is lost (except for s and t). The value of a flow f is defined as val(f ) = netoutf low(s) = ∑ u∈V :(s,u)∈A f (s, u) − ∑ u∈V :(u,s)∈A f (u, s) Or intuitively: all the water that enters the network in point s minus all the water that leaves the network in s (netoutflow of s). 32 Algorithms and Probability Useful Thanks to flow conservation we have netinf low(t) = ∑ u∈V :(u,t)∈A f (u, t) − ∑ u∈V :(t,u)∈A f (t, u) = val(f ) Or intuitively: all the water that reaches t minus all the water that leaves t is equal to the amount of water that entered the network in s. Definition An S-T -cut of a network N = (V, A, c, s, t) is a partition (S, T ) of V with S ∪ T = V , S ∩ T = ∅, and s ∈ S, t ∈ T . The capacity of such an S-T -cut is cap(S, T ) = ∑ (u,v)∈(S×T )∩A c(u, w) Or intuitively: the capacity of all edges that point from partition S to partition T . Useful Let f be a flow and (S, T ) an S-T -cut in N = (V, A, c, s, t). Then we have val(f ) ≤ cap(S, T ) The value of a flow cannot be bigger than a S-T -cut, as this would violate the capacity constraint condition. Theorem Max-flow min-cut theorem: For every network N = (V, A, c, s, t) max(val(f )) = min(cap(S, T )) holds. 4.2 Augmenting Paths The idea behind many algorithms that try to find the maximum flow in a network is to start from any small flow and to increment it step by step. We now describe the amount by which we increment the flow in each step. 33 Algorithms and Probability Definition Let N = (V, A, c, s, t) be a network without backwards pointing edges and let f be a flow in N . The residual network Nf = (V, Af , rf , s, t) is defined as: 1. If e ∈ A with f (e) < c(e) then e is an edge in Af with rf (e) = c(e) − f (e) 2. Is e ∈ A with f (e) > 0 then e opp (direction reversed) is an edge in Af with rf (eopp) = f (e) 3. Af only contains edges that obey to rule 1 and 2. Furthermore we have: Useful Let N = (V, A, c, s, t) be a network (without backwards pointing edges) then we have ▶ a flow f is a maximum flow in N ⇔ there is no directed s-t-path in the residual network Nf . Ford-Fulkerson’s algorithm lets us find a maximum flow in N = (V, A, c, s, t). Algorithm 12: ford_fulkerson(V, A, c, s, t) 1 f = 0 2 while ∃s − t-path p in Nf do 3 find augmenting path and increment flow 4 end 5 return f 34 Algorithms and Probability We cannot guarantee that Ford-Fulkerson’s algorithm terminates - if the capacities are elements of R+\\N then the algorithm might run forever. We can upper bound the amount of augmentation steps the algorithm performs by (n − 1) ∗ maxe∈Ac(e) because every augmentation increases the flow by at least one so we can have at most val(f ) many augmentation steps (val(f ) ≤ cap(s, V \\{s}) ≤ (n − 1) ∗ maxe∈Ac(e)). One augmentation step takes O(m) time (BFS takes O(n + m) time but in networks m usually dominates which probably is the reason for the run time O(m)). Useful If all capacities in a network are elements of N and have a value of at most U , then there is a maximum flow that can be computet in O(mnU ) time. 4.2.1 Matchings in Bipartite Graphs Networks and flows help us to find maximum-cardinality matchings in bipartite graphs (max(val(f )) = max(|M |)). 35 Algorithms and Probability 4.2.2 Vertex and Edge Disjoint Paths Let G = (V, E) be a graph. If we want to find the amount of edge disjoint u-v-paths between vertices u, v ∈ V, (u ̸= v) we can model the network as shown below. Now we execute Ford-Fulkerson’s algorithm on G which gives us the maximum flow between u and v which is equivalent to the amount of edge disjoint u-v-paths. We can identify these u-v-paths by finding (and removing or marking as read) a u-v-path and repeating this process max(val(f )) times. If we want to calculate vertex disjoint u-v-paths we can replace each vertex a ∈ V \\{u, v} by two vertices ain and aout. All edges pointing to a now point to ain and all edges leaving a now leave from aout. ain and aout are connected by an edge with capacity 1. Calculating max(val(f )) with s = u, t = v gives us the amount of vertex disjoint u-v-paths. Useful Ideas for flow problems ▶ If we consider a network with undirected edges, we need to draw two edges ∀u, v ∈ V, (u ̸= v) : (u, v) and (v, u). ▶ If we want to limit the capacity a certain vertex x is able to take, then we need to replace x by xin and xout and connect them by an edge with desired capacity. ▶ If we want to simulate multiple sources or multiple targets, we can introduce super-sources or super-targets which are connected to all the sources or targets that we desire to model. 4.3 Minimal Cuts in Graphs In this chapter we take a look at undirected multigraphs (multiple edges between vertices are allowed here). We are interested in the smallest number of edges we have to remove from the graph G = (V, E), such that the graph is not connected anymore. We call this number µ(G). µ(G) = min C⊆E:(V,E\\C) is not connected |C| We know that if G is not connected then µ(G) = 0. Furthermore, µ(G) ≤ minv∈V deg(v). We can now introduce the concept of edge contraction. We merge the two vertices u, v that are incident to that edge in order to get one single vertex xu,v. This vertex now is incident to the ones that were incident to u and v, but all edges between u and v are now gone (we can ignore self loops). 36 Algorithms and Probability We denote the graph that was contracted by edge e as G/e. We can use edge contraction to build the following randomized algorithm. Algorithm 13: cut(G) 1 G ′ = G 2 while |V (G ′)| > 2 do 3 e = random edge in G′ 4 G ′ = (G ′/e) 5 end 6 return amount of edges between v1 and v2 in G ′) The above algorithm picks an edge randomly and contracts the graph on that edge until only two vertices are left. Then it returns the size of the final cut. Since µ(G/e) ≥ µ(G) the algorithm may output a result that is larger than µ(G). 4.4 Smallest Enclosing Circle Let’s consider this geometric problem: Given a finite set of points P ⊂ R2, what is the circle C with smallest radius such that all points in P are inside or on C (more formally: P ⊆ C •(P ) where C •(P ) is the set of all points covered by the circle)? Useful For every finite set of points P ⊂ R2 there is a unique smallest enclosing circle C(P ). Additionally, for all P with |P | ≥ 3 there is a subset Q ⊆ P such that |Q| = 3 and C(Q) = C(P ). 37 Algorithms and Probability Now we can build this primitive randomized algorithm. Algorithm 14: CompleteEnumeration(P ) 1 for ∀Q ⊆ P with |Q| = 3 do 2 calculate C(Q) 3 if P ⊆ C •(P ) then 4 return C(Q) 5 end 6 end We iterate through all sets Q ∈ (P 3 ), calculate C(Q) in O(1) and check if P ⊆ C •(P ) in O(n). Therefore the run time is O(n4). We can lower the run time to O(n3) with the below algorithm. Algorithm 15: CleverCompleteEnumeration(P ) 1 r = 0 2 for ∀Q ⊆ P with |Q| = 3 do 3 calculate C(Q) 4 if r < r(C(Q)) then 5 C ′ = C(Q) 6 r = r(C(Q)) 7 end 8 end 9 return C ′ Instead of checking if P ⊆ C •(P ) we only check if the radius (r() function) of the new circle increased. We can further decrease the run time by \"learning\" in each round which points are outside of our circle. Algorithm 16: RandomizedClever(P ) 1 P ′ = P 2 while true do 3 randomly pick Q ⊆ P ′ with |Q| = 11 4 calculate C(Q) 5 if P ⊆ C •(P ) then 6 return C(Q) 7 end 8 P ′ = P ′ with all points outside of C(Q) doubled 9 end If we assume that we can pick Q in O(n) time then we can execute every round in O(n) time. Using the sampling lemma we can show that the run time of RandomizedClever is O(nlog(n)). This algorithm can also be extended for multiple dimensions and there exist faster algorithms for solving the Smallest Enclosing Circle problem. 38 Algorithms and Probability 4.5 Convex Hull Definition ▶Line segment: For v0, v1 ∈ Rd we call v0, v1 = {(1 − λ)v0 + λv1|λ ∈ R, 0 ≤ λ ≤ 1} the line segment that connects v0 with v1. ▶ Convex set: A set C ⊆ Rd is called convex if ∀v0, v1 ∈ C : v0, v1 ∈ C ▶ Convex hull: We define convex hull conv(S) as the intersection of all convex sets that contain the set S ∈ Rd. ⋂ S∈C∈Rd,C convex C For a finite set of points in the plane, the convex hull is a polygon. We are now interested in computing the h vertices of that polygon (q0, q1, ..., qh−1) (counter clockwise). For simplicity reasons we restrict ourselves to the plane (S ∈ R2) and further assume the following: ▶ No three points lie on a line ▶ No two points have the same X coordinate These restrictions are not necessary but make it easier to grasp the concept. Let S ∈ R2 be a set of points and P = conv(S) the convex hull of S. Then we call the pair of points qr ∈ P 2, (q ̸= r) an edge of the convex hull if all points in P \\{q, r} (and therefore all the points in S\\{q, r}) are left to the directed line q, r. This leads us to a more formal definition of the polygon. Definition (q0, ..., qh−1) is the tuple containing the vertices of the polygon P that encloses conv(S) in counter clockwise fashion if ∀i ∈ {1, ..., h} : (qi−1, qi mod h) is an edge of P . How can we determine if a point lies left to a line? Useful Let p, q, r ∈ R2, (q ̸= r). p lies left to qr if and only if det(p, q, r) = det( ∣ ∣ ∣ ∣ ∣ ∣ px py 1 qx qy 1 rx ry 1 ∣ ∣ ∣ ∣ ∣ ∣ ) > 0 ⇔ (qx − px) ∗ (ry − py) > (qy − py) ∗ (rx − px). If the two products are equal, then all three points lie on the same line. 39 Algorithms and Probability Using this we can build an algorithm that finds the polygon (q0, ..., qh−1). For all n(n − 1) pairs qr we check if they are an edge of the polygon (so all remaining n − 2 points must lie left to qr). This allows us to find the polygon in O(n3) time. 4.5.1 Jarvis Wrap We can do better by using the Jarvis Wrap algorithm. Algorithm 17: Jarvis_Wrap(S) 1 List hull (initiate empty hull) 2 x = point in S that has the lowest X coordinate (and therefore definitely a vertex of the polygon) 3 y = x 4 do 5 hull.add(y) 6 y = find_next(y) 7 while x ̸= y; 8 return hull Algorithm 18: find_next(x) 1 pick p0 ∈ P \\{x} arbitrarily 2 qnext = p0 3 for ∀p ∈ P \\{x, p0} do 4 if p is right to xqnext then 5 qnext = p 6 end 7 end 8 return qnext 40 Algorithms and Probability 1 // S contains points in form [[1 x ,1 y ] ,[2 x ,2 y ]... ,[ nx , ny ]] 2 public static ArrayList < Integer > jarvis_wrap ( int [][] S ) { 3 ArrayList < Integer > hull = new ArrayList < Integer >() ; 4 int x = find_lowest ( S ) ; 5 int y = x ; 6 do { 7 hull . add ( y ) ; 8 y = find_next (y , S ) ; 9 } while ( x == y ) ; 10 return hull ; 11 } 12 13 private static int find_lowest ( S ) { 14 int result = 0; 15 int x = Integer . MAX_VALUE ; 16 for ( int i = 0; i < S . length ; i ++) { 17 if ( S [ i ][0] < x ) { 18 x = S [ i ][0]; 19 result = i ; 20 } 21 } 22 return result ; 23 } 24 25 private static int find_next ( int y , int [][] S ) { 26 int q = 0; 27 if ( y == 0) { 28 q = 1; 29 } 30 int q_next = q ; 31 for ( int i = 0; i < S . length ; i ++) { 32 if ( i != y && i != q ) { 33 if (! left (i , y , q_next , S ) ) { 34 q_next = i ; 35 } 36 } 37 } 38 return q_next ; 39 } 40 41 private static boolean left ( int i , int y , int q_next , int [][] S ) { 42 return ( S [ y ][0] - S [ i ][0]) *( S [ q_next ][1] - S [ i ][1]) > ( S [ y ][1] - S [ i ][1]) *( S [ q_next ][0] - S [ i ][0]) ; 43 } We call f ind_next exactly h times and every call needs O(n) time. Useful For a set P ⊂ R2 of n points, Jarvis Wrap can calculate the convex hull in O(nh) time where h is the amount of vertices of the convex hull polygon. 4.5.2 Local Repair Another algorithm to find the convex hull of a set of points in the plane is Local Repair. We know that all points have to be left of an edge of a convex hull polynom. Therefore for all convex hull polynoms (q0, ..., qh−1) it must hold that ∀i ∈ N : qi+1 mod h is left of qi−1 mod hqi mod h. Intuition: 41 Algorithms and Probability Alternatively one can also say that the interior angle ∠qi−1 mod hqi mod hqi+1 mod h cannot be greater than 180 degrees. But this condition is not strong enough for a valid convex hull as shown in the below counter example. The idea behind Local Repair is to start with a polygon that is not necessary convex and to ’repair’ the polygon successively. By ’to repair’ we mean: Given (q0, ..., qk−1), if qi is left of qi−1 mod kqi+1 mod k, remove qi from the tuple. We choose the initial polygon as follows: We sort all points in S ⊂ R2 by their X coordinate and get (s1, ..., sn). Now we define the initial polygon as (s1, ..., sn−1, sn, sn−1, ..., s1). Below is the pseudo code for Local Repair (its input points must be sorted). 42 Algorithms and Probability Algorithm 19: Local_Repair((s1, ..., sn)) 1 q0 = s1 2 h = 0 3 for i = 2,...,n do 4 while h > 0 and qh is left of qh−1si do 5 h = h - 1 6 end 7 h = h + 1 8 qh = si 9 end 10 h’ = h 11 for i = n-1,...,1 do 12 while h > h’ and qh is left of qh−1si do 13 h = h - 1 14 end 15 h = h + 1 16 qh = si 17 end 18 return (q0, ..., qh−1) Useful Given a sequence (s1, ..., sn) of points in R2 that are sorted by their X coordinate, Local Repair can compute the convex hull of {s1, ..., sn} in O(n) time. Since O(nlogn) is the optimal time for sorting these points, the total run time of Local Repair (including sorting its input) is O(nlogn). 43","libVersion":"0.3.2","langs":""}
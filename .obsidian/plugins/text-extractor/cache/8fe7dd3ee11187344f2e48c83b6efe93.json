{"path":"sem5/VLSI1/VRL/extra/Top-Down-Digital-VLSI-Design/Chapter-7---Clocking-of-Synchronous-Circuit_2015_Top-Down-Digital-VLSI-Desig.pdf","text":"CHAPTER 7 CLOCKING OF SYNCHRONOUS CIRCUITS 7.1 WHAT IS THE DIFFICULTY WITH CLOCK DISTRIBUTION? Up to this point, we have ignored the difficulties of distributing a clock signal over a chip or a major portion thereof. We were in good company as systems engineering, automata theory, and other theoretical underpinnings of digital design assume simultaneous updating of state throughout a circuit. Physical reality is different from such abstractions, though. scan in Sci_TI clock domain or entire IC Clk_CI clock input subcircuit a subcircuit b network clock distribution first scan out Sco_TO subcircuit c last xmt scan path rcv t CLK_CI first last tsk xmt rcv population clock arrival times over of bistables skew (tdimin ) (tdimax ) (tdiavg ) |t |skmax tjt clock periods clock arrival times over many jitter distribution delay (a) (b) FIGURE 7.1 Clock distribution. Clock domain with clock distribution network, scan path, and just one combinational propagation path shown (a), relevant timing quantities (b). Top-Down Digital VLSI Design © 2015 Elsevier Inc. All rights reserved. 391 392 CHAPTER 7 CLOCKING OF SYNCHRONOUS CIRCUITS Consider a population of flip-flops or other clocked subcircuits that make part of one clock domain in a synchronous design as shown in fig.7.1. A common clock tells them when to transit to the next state. Ideally, all such bistables are supposed to react to the clock instantly and all at exactly the same moment of time. In practice, however, switching will be retarded due to many small delays inflicted by drivers and wires in the clock distribution network. As most clock signals connect to a multitude of storage elements spread out over an entire clock domain, individual switching times will differ because delays along the various clock propagation paths are not quite the same. This scattering over time is loosely referred to as clock skew. To make things worse, those delays will slightly vary from one clock cycle to the next thereby giving rise to clock jitter. Many causes contribute to the timewise scattering of clocks: • Unevenly distributed fanouts and load capacitances. • Unequal numbers of buffers and/or inverters along different branches. • Unlike drive strengths and timing characteristics of the clock buffers instantiated. • Unbalanced interconnect delays due to dissimilar layout parasitics (R: wire length and thickness, via count; C: plate, fringe and lateral capacitance). • Unequal switching thresholds of bistables (translate clock ramps into staggered switching). • Process, temperature, voltage (PTV) and — more so — on-chip variations (OCV). • Supply noise as caused by ground bounce and supply droop. • Crosstalk from switching activities in the surrounding circuitry. Excessive scattering of switching events must obviously compromise the correct functioning of a digital circuit. Design engineers thus try hard to eliminate any systematic disparities among clock arrival times.1 However, depending on fabrication depth and design level (board, field-programmable logic, semi-custom IC, full-custom IC, hand layout), they are never able to control all of the underlying phenomena, so that a certain amount of unevenness remains. 7.1.1 AGENDA Designing dependable circuits in spite of clock skew and jitter involves two issues, namely (a) knowing and lowering the vulnerability of a design, and (b) minimizing scattering by distributing clock signals over a domain in an adequate way. The two issues will be discussed in sections 7.2 and 7.3 respectively. For simplicity, we will focus on signals that circulate within one clock domain, thereby dropping any input and output signals from our analysis in section 7.2. Synchronous I/O is addressed in section 7.4, whereas the problems associated with assimilating data that arrive asynchronously are postponed to chapter 8. How to safely implement clock gating is the subject of section 7.5. 1 Experienced designers sometimes introduce clock skew on purpose either to accommodate RAMs and other subcircuits with larger-than-normal setup/hold times or to allow for faster clocking by adapting to uneven path delays. A better tolerance with respect to delay variations may also be sought in this way, see problem 2. The process of tuning a clock distribution network to local timing requirements is termed clock skew scheduling, aka useful skew. Please refer to problem 8 andtothe specialized literature [174] [175] [176] for more details on this optimization technique. 7.1 WHAT IS THE DIFFICULTY WITH CLOCK DISTRIBUTION? 393 7.1.2 TIMING QUANTITIES RELATED TO CLOCK DISTRIBUTION In order to study the clocking of synchronous circuits, we need to introduce three timing parameters that specifically relate to clock distribution networks, see fig.7.1 for an illustration. tdi Clock distribution delay. The time lag measured from when a clock edge appears at the clock source until a state transition actually takes place in response to that edge. When referring to an IC, some package pin is normally meant to act as clock source. tsk Clock skew. The inaccuracy of the same clock edge arriving at different locations within a given clock domain. There is a local and a more global view: In a narrow sense, skew refers to the clock terminals of two subcircuits connected by some signal propagation path. Skew is considered positive if the receiver is clocked after the transmitter, and negative if it is clocked before, i.e. tsk = tdi rcv − tdi xmt.2 From a wider perspective, one is interested in knowing the largest difference in clock arrival times between any two clock terminals within a clock domain. The term clock skew then takes on the meaning of overall skew and is defined as max|tsk|= max(tdi) − min(tdi). tjt Clock jitter. The variability of consecutive clock edges arriving at the same location. 2 The sign of clock skew is controversial, some authors have elected to define clock skew the other way round as tsk = tdi xmt − tdi rcv. We prefer to have data and clock delays share the same sense of counting. 394 CHAPTER 7 CLOCKING OF SYNCHRONOUS CIRCUITS 7.2 HOW MUCH SKEW AND JITTER DOES A CIRCUIT TOLERATE? 7.2.1 BASICS Numerous schemes for driving synchronous digital circuits have been devised over the years. Some of them are more vulnerable to clock skew and jitter than others, each asks for different hardware resources, some have an impact on performance, and this section aims at comparing them. Note that while selecting a clocking discipline typically amounts to finding an optimum choice between conflicting goals, it is not concerned with functionality as any decent functionality can be combined with any decent clocking scheme. Before entering the discussion of individual clocking schemes, let us recall from observation 6.1 that any digital signal must be allowed to settle to a valid state before it is accepted into a memorizing subcircuit. Correct and dependable circuit operation is otherwise not possible. The time interval during which data at the input of a flip-flop, latch, RAM or other sequential subcircuit must remain valid is referred to as data-call window, aka aperture time, and is defined by the setup and hold times there. The term data-valid window designates the time interval during which data at the receiver actually do remain valid and is dependent on a circuit’s propagation and contamination delays. As becomes immediately clear when comparing figs.7.2 and 7.3, the fundamental requirement simply is Observation 7.1. Transferring data between two subcircuits requires that the data-call window of the receiving subcircuit be fully encompassed by the transmitter’s data-valid window. In subsections 7.2.2 through 7.2.7, each clocking discipline will be introduced by outlining its operation and elementary characteristics. Then follows a more detailed analysis which establishes conditions for how much skew can be tolerated without causing the circuit to malfunction or to exhibit undeterministic operation. The resulting inequalities will be termed skew margins and are visualized in the Anceau diagram of fig.7.2. While noise margins delimit the safe operating range of a digital circuit with respect to uncertainties in amplitude, skew margins do the same with respect to timewise uncertainties. 7.2 HOW MUCH SKEW AND JITTER DOES A CIRCUIT TOLERATE? 395 transmitter receiver delay delay no difference in arrival times balanced distribution delays tdi xmt di rcvt= active edge at transmitter active edge at receiver clock= hold margin setup margin time time interval during which data at receiver actually do remain stableare required to be stable (data-call window) (data-valid window) clock input Clk_CI =skt 0 (a) (b) FIGURE 7.2 Clocking in the absence of skew and jitter. Circuit (a) and Anceau diagram (b). transmitter receiver delay delay skew tdi xmt di rcvt< clock active edge at transmitter skew active edge at receiver setup margin inflated time interval during which data at receiver actually do remain stableare required to be stable (data-call window) (data-valid window) time → mal- function consumed margin hold >skt 0 clock input Clk_CI (a) (b) FIGURE 7.3 Impact of excessive positive clock skew. Circuit (a) and Anceau diagram (b). 396 CHAPTER 7 CLOCKING OF SYNCHRONOUS CIRCUITS Observation 7.2. A certain amount of clock scattering is unavoidable. What really counts is that clocking discipline and clock distribution network are chosen such that the setup and hold margins they provide can absorb the combined effects of skew and jitter • everywhere within a clock domain, and • under any operating condition.3 Although there are more clocking disciplines than those discussed here, it should be noted that any other scheme can be analyzed along the same lines. Also, the study is easily extended to include interconnect delays by adding appropriate terms to tcd c and tpd c. 7.2.2 SINGLE-EDGE-TRIGGERED ONE-PHASE CLOCKING Hardware resources and operation principle Single-edge-triggered one-phase clocking is the most natural approach from a background in automata theory or abstract systems design. Registers are implemented from flip-flops and all of them get triggered by the same clock edge, henceforth termed the active edge. No bistables other than ordinary single-edge-triggered flip-flops (SETFF) are being used. Each computation cycle starts immediately after an active clock edge and ends with the subsequent one so that Tcp = Tclk. All transient phenomena must die out before the active clock edge, that is within one clock period. The exact moment of occurrence of the passive clock edge is immaterial as long as the clock waveform meets the minimum pulse widths requirements tclk hi min and tclk lo min imposed by the flip-flops. (a) F Clk_C C (b) Tclk Clk_C Tcp time span available for combinational function C FIGURE 7.4 Edge-triggered one-phase clocking (with the rising edge being the active one). Basic hardware organization (a) and simpliﬁed timing diagram (b). 3 Operating conditions are meant to include data patterns, loads, clock frequency, parameter variations (PTV and OCV), ground bounce/supply droop, and crosstalk. 7.2 HOW MUCH SKEW AND JITTER DOES A CIRCUIT TOLERATE? 397 Detailed analysis Starting from setup and hold requirements of flip-flops, let us now find out how much clock skew and jitter can be tolerated without exposing a circuit to timing problems. The corresponding Anceau diagram is shown in fig.7.5. Setup condition Consider a pair of flip-flops with a unidirectional data propagation path in between as shown in fig.7.2. The setup condition of the receiving flip-flop is expressed as tdi xmt + tpd ff xmt + tpd c ≤ Tclk + tdi rcv − tsu ff rcv (7.1) which makes reference to timewise uncertainty of the clock after being recast into tpd ff xmt + tpd c + tsu ff rcv ≤ Tclk + (tdi rcv − tdi xmt) = Tclk + tsk (7.2) active edge cd xmt fft su rcv fft ho rcv fft pd ct cd ct time interval during which data at receiver are required to be stable (data-call window) actually do remain stable (data-valid window) pd xmt fft FIGURE 7.5 Anceau diagram of edge-triggered one-phase system. Note that arcs of different colors are being used to distinguish between timing quantities that relate to the setup condition and others that matter for the hold condition. In the absence of skew and jitter, the inequality stipulates a minimum clock period. It also appears — in this limited context — that positive skew has a beneficial effect and negative skew a detrimental one. This is because a lag of the receiver clock with respect to that of the transmitter facilitates meeting the setup condition, while the opposite is true for a lead. Relation (7.2) thus effectively imposes a lower — and typically negative — bound on clock skew, which becomes even more obvious when the inequality is transformed into tsk ≥ (tpd ff xmt + tpd c + tsu ff rcv) − Tclk < typ. 0 (7.3) For the continuation of our analysis, we will work with the equivalent form −tsk ≤ Tclk − (tpd ff xmt + tpd c + tsu ff rcv) (7.4) 398 CHAPTER 7 CLOCKING OF SYNCHRONOUS CIRCUITS From a broader perspective, one has to consider the ensemble of all flip-flops in a circuit which asks for a separate inequality for any two communicating bistables. A static timing analyzer essentially is a software tool that takes a gate-level netlist, that checks whether inequalities (7.4)and (7.8) are met, and that flags violations, if any. To that end, the software begins by calculating the numeric delay figures along each signal propagation path in a circuit. Rather than checking thousands of mathematical relations, however, humans prefer to come up with one simple worst-case condition which, when satisfied, guarantees that setup times are respected throughout an entire clock domain. Skew plus jitter here appear as the maximum over all signal propagation paths and as a magnitude max|tsk|. After all, a practical clocking scheme must accommodate data transfers between any two flip-flops, explicitly allowing for reciprocal data exchange which renders the distinction between positive and negative skew meaningless. max|tsk|≤ Tclk − max(tpd ff + tpd c + tsu ff ) = Tclk − tlp (7.5) The expression max(tpd ff + tpd c + tsu ff ) reflects the delay along the longest signal propagation path between any two adjacent flip-flops in the circuit. For the sake of brevity, we will refer to this path together with its delay tlp as the longest path.4 Inequality (7.5) indicates that longest path, clock skew and jitter together bound the minimum admissible clock period from below and so define how fast the circuit can be safely clocked. This finding puts us in a position to estimate the performance of a given circuit more accurately than in chapter 3 and gives rise to a first observation. Tclk ≥ max(tpd ff + tpd c + tsu ff ) + max|tsk|= tlp + max|tsk|= ≈ tid ff + max(tc) + max|tsk| (7.6) Observation 7.3. Clock skew is at the expense of maximum performance in circuits that operate with edge-triggered one-phase clocking. In a pipeline, for instance, tff + max|tsk| is nothing else but time unavailable for payload computations which is why this quantity is often referred to as timing overhead. Any positive difference between the left-hand and the right-hand side of (7.6) implies that the clock period is not fully utilized by computations and timing overhead. The surplus amount of time is termed slack and routinely calculated during static timing analysis. While slack must always remain positive, designers strive to minimize it when in search of maximum performance. Example A Sun UltraSPARC-III CPU implemented in 250 nm 6M1P CMOS runs from a 600 MHz clock which amounts to Tclk = 1.67 ns. Some 70% of this time is available for combinational data processing and suffices to accommodate approximately eight consecutive levels of logic, assuming that a 3-input nand with a fanout of three is representative for a typical gate delay. The rest is taken up by the registers and the necessary allowance for clock skew and jitter [177]. \u0002 4 The term critical path is often used as a synonym for longest path. We prefer to understand critical path as a generic term for the longest and the shortest path, however, because meeting the timing conditions along the shortest path is as important for the correct functioning of a circuit as it is along the longest path. 7.2 HOW MUCH SKEW AND JITTER DOES A CIRCUIT TOLERATE? 399 Hold condition Starting from the hold requirement for data travel between two flip-flops, tdi xmt + tcd ff xmt + tcd c ≥ tdi rcv + tho ff rcv (7.7) a second condition is obtained that bounds the acceptable skew and jitter from above this time because it is positive clock delay that puts the hold condition at risk. tsk = (tdi rcv − tdi xmt) ≤ tcd ff xmt + tcd c − tho ff rcv (7.8) Again from a circuit perspective one finds max|tsk|≤ min(tcd ff + tcd c − tho ff ) = tsp (7.9) Here the right-hand side min(tcd ff + tcd c − tho ff ) stands for the shortest path tsp through a circuit which is sometimes being referred to as “race path”. As opposed to the situation found for the setup margin (7.5), the hold margin (7.9) either holds or not, no matter how much the clock period is being stretched. As both conditions must be met, the latitude to clock skew does not depend on the speed at which the circuit is operated. Another interesting observation is that any combinational logic placed between two adjacent flip-flops facilitates meeting (7.9) because of its inherent contamination delay. The same also applies for slow interconnect lines. Implications The most precarious circumstances occur when no combinational logic — and thus no contamination delay — is present between two consecutive flip-flops or other edge-triggered storage elements. Consider a shift register, for instance. The skew margin then collapses to max|tsk|≤ min(tcd ff − tho ff ) (7.10) which also indicates there is no way to improve the situation by adjusting clock waveforms. Whenever an IC suffers from insufficient hold margins, a painful and costly redesign is due. Table 7.1 Timing problems and their remedies in edge-triggered one-phase circuits. Remedies for if identiﬁed during if found once prototypes timing problems the design process have been manufactured on long path(s) redesign circuit such as to extend clock period or reduce its max. prop. delay renegotiate PTV conditions (may be hard) (most likely unacceptable) on short path(s) insert delay buffers between adjusting clock waveform consecutive ﬂip-ﬂops or PTV does not help (comparatively easy) (fatal) 400 CHAPTER 7 CLOCKING OF SYNCHRONOUS CIRCUITS In practice, there is a deplorable difficulty with giving numerical figures for the skew margins defined by (7.9)and (7.10) because most datasheets lack indications on contamination delay.5 Yet, as the inequality 0 ≤ tcd < tpd closely bounds it from both sides, it is safe to state that tcd ff − tho ff always is a very small quantity. Since any differences in clock arrival times are at the expense of this tiny safety margin, edge-triggered one-phase systems must be considered inherently sensitive to clock skew. Note that interconnect delay has a beneficial effect, however. Example Table 7.2 is an excerpt from the datasheet of a CMOS flip-flop.6 The maximum admissible clock skew between any two such flip-flops where the Q output of one cell directly connects to the D input of the next is 124 ps − (−14 ps) = 138 ps. Please keep in mind this is just an estimate that assumes identical MOSFETs and PTV conditions throughout. The beneficial impact of interconnect delay is also ignored, on the other hand. Table 7.2 Timing characteristics of a standard cell flip-flop in a 130 nm CMOS technology. D Flip-ﬂop with reset 1x drive Timing parameter Max. toggle propagation delay for fanout 2 tpd ff tcd ff tsu ff tho ff frequency @ typ. process, 25 C, 2.5V/ 2.5V [ps] [ps] [ps] [ps] [GHz] from a high-density library 160 124 70 −14 4.35 \u0002 Observation 7.4. Matching of clock distribution delays and careful timing analysis are critical when designing circuits and systems with edge-triggered one-phase clocking. Shift registers and scan paths are especially vulnerable to (positive) clock skew. Scan-type testing requires the presence of shift registers A scan path is a feature included in almost all VLSI designs to make the circuit testable from outside. It essentially permits to control and observe circuit nodes hidden deep inside the circuit and works by chaining the existing flip-flops into a shift register while in test mode. Fig.7.6 shows the basic arrangement. What matters here is that a scan path includes no logic between flip-flops because the necessary input multiplexers are part of the standard cells. 5 The reasons for this are given in appendix A.6. 6 As the official datasheets give no indications for contamination delay, the number included in the table is an educated guess obtained from the computer models prepared for simulation and timing analysis. The so-called timing library format (TLF) describes a cell’s overall delay as a sum of an initial inertia followed by output ramping. Both inertial delay and output ramp time are modeled as functions of switching direction (rise, fall), capacitive load, and input ramp time. The contamination delay figure of table 7.2 is the minimum inertial delay for a cell characterized with no external load attached and for clock ramp time zero, or almost so. 7.2 HOW MUCH SKEW AND JITTER DOES A CIRCUIT TOLERATE? 401 DQ SCI CLK SCM Sco_TO 0 1 flip-flop with scan CLK DQ Q Q Q CLK D SCM SCI Q scan in Sci_TI scan mode Scm_TI scan out ...... ...... ...... DQ SCI CLK SCM DQ SCI CLK SCM DQ SCI CLK SCM clock Clk_CI combinational logic ...... scan path clock domain or entire IC (a) (b) (c) FIGURE 7.6 Scan test structures. Scan ﬂip-ﬂop (b), icon (a), and overall circuit structure (c). Scan paths typically traverse many subcircuits and are, therefore, particularly exposed to clock skew at the boundaries in between. In the example of fig.7.1a, hold time violations are most likely to occur in the first flip-flop of subcircuit c.7 When suffering from timing violations in scan mode, a chip will have to be scrapped even if otherwise fully functional because of the inability to complete the mandatory testing procedures. Watch out when mixing cells from different libraries Our previous estimates were based on numerical data from table 7.2. Yet, real circuits are being assembled from flip-flops of many different types which further puts hold margins at risk. A key idea behind the concept of a logic family — whether available as a cell library or as a set of physical SSI/MSI components — is the capability to liberally combine components with others from the same family in spite of fabrication tolerances. Timingwise, this implies that the shortest contamination delay must be greater or equal to the longest hold time over all edge-triggered storage devices. max(tho ff ) ≤ min(tcd ff ) (7.11) Note that no margin whatsoever is left when this relation holds with equality. Only flip-flops with hold time zero warrant free interchange, negative hold times are even safer. High-quality standard cell libraries are usually designed along this line, yet beware of exceptions that do not meet the requirement of (7.11). 7 Scan flip-flops sometimes feature a separate scan out terminal SCO that differs from the ordinary Q output by passing through two extra inverters. We now understand why the dilated contamination delay tcd ff so obtained is very welcome. Similarly, automatic scan insertion tools can splice in so-called lockup latches at the boundaries between major subcircuits to bolster up hold margin. We consider this option as a workaround, however. 402 CHAPTER 7 CLOCKING OF SYNCHRONOUS CIRCUITS Observation 7.5. Timing is particularly at risk when different logic families are mixed so that signals travel from fast storage elements to slower ones. Mixing logic families, a practice with a long tradition at the board level, is finding its way into VLSI design when high-speed and low-power cells are being combined on a single chip in search of the optimum performance-energy tradeoff. Also note that the timing parameters of macrocells, such as on-chip RAMs, tend to differ significantly from those of simple and, hence, much faster flip-flops and latches. Hold time ﬁxing As edge-triggered one-phase-clocking is so vulnerable to clock skew and jitter, modern EDA tools support automatic hold time fixing, a technique whereby buffers get inserted into all signal propagation paths found to provide insufficient hold margins until the extra contamination delay suffices to compensate for the deficit. Extensive buffer chains not only inflate circuit size, however, but also waste energy without contributing to computation. Hint: Wait with hold time fixing until load capacitances and interconnect delays can be estimated with good precision during the routing phase. Have the P&R tool or the timing verifier list the shortest paths as a function of their respective hold margins. You are now in a good position to find out where delay buffers must be inserted to ensure a reasonable minimum hold margin in your design. For a concluding remark of more fundamental nature, reinspect inequalities (7.1) through (7.11). Notice that there is a law that will be confirmed throughout our timing analyses. Observation 7.6. Within timing conditions, quantities always combine as follows: inequality critical path relevant timing parameters setup condition longest propagation delays and setup time hold condition shortest contamination delays and hold time 7.2.3 DUAL-EDGE-TRIGGERED ONE-PHASE CLOCKING Hardware resources and operation principle Dual-edge-triggered clocking has long been left aside before gaining acceptance along with the buzzword double data rate (DDR) in the context of computer memory and mainboard design where it serves to increase memory bandwith while avoiding excessive clock frequencies. Conceptually, this technique is very similar to single-edge-triggered one-phase clocking but rests on special storage elements that operate on both clock edges. As suggested in fig.7.7c, it is possible to construct a dual- edge-triggered flip-flop (DETFF) from a pair of latches and a multiplexer. Exactly as in single-edge clocking, each computation period gets bounded by two consecutive active clock edges. Yet, the fact that either edge causes the state to get updated cuts the clock frequency in half for the same computation or memory access rate. The fundamental timing requirement thus becomes Tcp = 1 2 Tclk ≥ tlp,see fig.7.7b. 7.2 HOW MUCH SKEW AND JITTER DOES A CIRCUIT TOLERATE? 403 (a) F Clk_C C (b) Tclk Tcp Tcp Clk_C time span available for combinational function C (c) 0 1 QD CLKDETFF FIGURE 7.7 Dual-edge-triggered one-phase clocking. Basic hardware organization (a) and simpliﬁed timing diagram (b). Logically equivalent circuit for a dual-edge-triggered ﬂip-ﬂop (c). Implications As a DETFF is described by the same set of timing parameters as a SETFF, analysis yields much the same findings, only the numerical values are bound to differ. The differences relate to clock frequency and energy efficiency. In a single-edge-triggered circuit, the clock net toggles twice per computation cycle. A DDR circuit carries out the same computation with a single clock edge which cuts the energy spent for charging and discharging that net in half, at least in theory. This explains the name half- frequency clocking sometimes being used. Unfortunately, the higher capacitive loads of a DETFF on clock and data inputs partially offset this economy. The slightly more complex circuit does not help either. The economy may even turn negative if the data input is subject to intense glitching [178]. Still, reductions on the order of 10 to 20% of overall power over an equivalent single-edge-triggered design seem more typical. While dual edge clocking has gained acceptance with DDR RAM interfaces, it has yet to make it into cell libraries and EDA tools, notably for synthesis and timing verification. As HDL synthesizers do not currently accept dual-edge-triggered circuit models, one must model for single edge clocking and replace every SETFF by an analogous DETFF following synthesis.8 8 Where qualified DETFF cells are unavailable, one may consider using soft macros. Internal wires shall then be given so much weight that the cells involved always get placed next to each other. As opposed to SETFFs, the output of a DETFF is not connected to a bistable’s output, however, but passes through a multiplexer, that is through a combinational network. Careless design or routing might thus engender hazards. It is imperative that a highly consistent timing be guaranteed in spite of minor variations in the soft macro’s interconnect routing. Also, any decent collection of DETFFs must be made to satisfy (7.11) to ensure interoperability. 404 CHAPTER 7 CLOCKING OF SYNCHRONOUS CIRCUITS Another particularity is that dual-edge-triggered clocking assumes a strictly symmetrical clock wave- form that satisfies tclk lo = tclk hi = 1 2 Tclk. Put differently, the clock must be made to maintain a duty cycle δclk of exactly 1 2 under all operating conditions. 7.2.4 SYMMETRIC LEVEL-SENSITIVE TWO-PHASE CLOCKING Hardware resources and operation principle Circuits are latch-based which is to say that no bistables other than level-sensitive latches are being used. A subset of them is controlled by clock signal Clk1, the complementary set by Clk2.Dataflow occurs exclusively between the two subsets, there is no exchange within a subset. Put differently, the latches together with the data propagation paths in between always form a bipartite graph.9 Violating this rule might lead to unpredictable behavior as a consequence from zero-latency loops that would inevitably form when the latches at either end of a combinational logic become transparent at the same time. Clk1_C Clk2_C L2 C12 1L 21C (a) (b) pass hold pass hold mutual exclusion mutual exclusion mutual exclusion mutual exclusion Tclk T2T1 T3 T4 Clk1_C Clk2_C Ctime for 21 12Ctime for (c) 12t t21 Tclk TclkT3 T1T4++ T3T2T1 ++ illegal legal time borrowing full utilization T2 T4 FIGURE 7.8 Symmetric level-sensitive two-phase clocking. Basic hardware organization (a), simpliﬁed timing diagram (b), and range of operation (c). Ignoring the setup times and propagation delays of the latches, for a moment, one finds the situation shown in fig.7.8. The two clock signals subdivide the clock period Tclk into four intervals labeled T1 through T4. During each computation period, data complete a full circle from latch set L1 through logic 9 A graph is said to be bipartite iff it is possible to decompose the set of its vertices into two disjoint subsets such that every edge connects a vertex from one subset with a vertex from the other. 7.2 HOW MUCH SKEW AND JITTER DOES A CIRCUIT TOLERATE? 405 C12 to latch set L2 and from there through logic C21 back to latch set L1 Computation period and clock period are the same Tcp = Tclk. The earliest moment combinational logic C21 can take up evaluating a new input is when latch set L2 becomes transparent, provided logic C12 has completed its evaluation at that time. Otherwise this point in time is delayed into clock interval T3 until C12 completes. The last possible moment for C21 to complete its evaluation is right before latch set L1 stores the result when switching to hold mode, i.e. at the end of T1. One thus obtains max(t21) ≤ T3 + T4 + T1 (7.12) and analogously for combinational logic C12 max(t12) ≤ T1 + T2 + T3 (7.13) The two inequalities seem to suggest that more than one clock period is available to accommodate the cumulated evaluation times of the two combinational blocks. Of course, this is not possible as C21 and C12 must work strictly one after the other to make sure the circuit operates properly. This condition of mutual exclusion is captured in a third constraint that requires max(t12 + t21) = max(tpd full−circle) ≤ Tclk = T1 + T2 + T3 + T4 (7.14) Note there exists no dead clock interval during which neither C21 nor C12 is allowed to evaluate new input data. Depending on the actual timing figures, any of the intervals T1 through T4 can actually become productive. Also note that one pipeline stage must include two latch sets, L1 and L2,as C21 and C12 do not operate concurrently. As a rule, two latches are needed in a level-sensitive two-phase system where an edge-triggered system has one flip-flop. Together (7.12), (7.13)and (7.14) confine the legal operating range with respect to timing as depicted in fig. 7.8. Full utilization of the clock cycle is achieved, when (7.14) holds with equality, i.e. when max(tpd full−circle) = Tclk. Further observe from fig.7.8 that symmetric level-sensitive two-phase clocking offers the potential for trading evaluation time left unused by C12 against time for C21,and vice versa, without any modification to the clock phases. This somewhat surprising characteristic is referred to as time borrowing. With the above traits, namely mutual exclusion, alternation with no dead time, and time borrowing, symmetric level-sensitive two-phase system resembles a relay race, during which two runners alternate but can decide themselves — within certain bounds — where exactly to hand over the baton. Detailed analysis Incorrect timing is likely to lead to corrupt circuit states when input data are not properly stored by the target latches. This phenomenon, from which there is no recovery other than resetting the entire circuit, is termed latch fall-through or latch race-through. The skew margins necessary to stay clear of this problem are obtained from the setup and hold requirements of the two latch sets L1 and L2,also see figs.7.8 and 7.9. Setup condition More precise formulations of equations (7.13) through (7.14) are obtained when the various delays introduced by the latches themselves are taken into consideration. 406 CHAPTER 7 CLOCKING OF SYNCHRONOUS CIRCUITS max|tsk|≤ Tclk − T2 − max(tpd lc 2 + tpd 21 + tsu la 1) (7.15) max|tsk|≤ Tclk − T4 − max(tpd lc 1 + tpd 12 + tsu la 2) (7.16) 0 ≤ Tclk − max(tpd ld 1 + tpd 12 + tpd ld 2 + tpd 21) (7.17) All three inequalities must hold in order to ensure correct operation. Whatever values the various timing parameters may have, it is always possible to find a minimum for the clock period Tclk that satisfies them all. T2 T1 1L passes T4 T3 L2 passes tsu la tho la pd 21t tpd 12 tsu la tho la tcd 12 tpd lc tpd lc tcd lc time interval during which data at receiver are required to be stable (data-call window) actually do remain stable (data-valid window) 1L 2L actually do remain stable (data-valid window) are required to be stable (data-call window) tpd ld cd 21t tcd lc FIGURE 7.9 Anceau diagram of symmetric level-sensitive two-phase system shown for a time-borrowing situation where C12 occupies approximately 5 8 and C21 2 8 of a clock period. Hold condition Correct timing at the inputs of L1 and L2 requires that max|tsk|≤ T2 + min(tcd lc 2 + tcd 21 − tho la 1) (7.18) max|tsk|≤ T4 + min(tcd lc 1 + tcd 12 − tho la 2) (7.19) respectively. As in edge-triggered circuits, the most critical situation occurs when no logic is present. In contrast to the situation there, however, the margin against hold violations is largely determined by the duration of the two non-overlap intervals T4 and T2. This quality helps to absorb skew and jitter across a single clock distribution net as well as between the two nets. Implications The latitude for skew and jitter is largely determined by the waveforms of the clock signals. Room to accommodate unknown or unpredictable timing variations can be designed into level-sensitive two- phase systems just by sizing the non-overlap intervals accordingly. In principle, the most excessive skew can be coped with even after circuits have been fabricated, provided it is possible define the two clock waveforms from outside the chip, e.g. by driving Clk1 and Clk2 from two separate pins. As both non-overlap intervals are productive, this entails no loss of speed, only the time borrowing capability gets somewhat restricted. 7.2 HOW MUCH SKEW AND JITTER DOES A CIRCUIT TOLERATE? 407 This picture sharply contrasts with edge-triggered one-phase clocking, where the hold margin is imposed by flip-flop parameters that cell-based designers are unable to control. The price paid for this advantage lies in the routing overhead and in the extra design effort for distributing two clock signals. In order to keep variations between the two clocks within reasonable limits, the two nets should be made similar both geometrically and electrically, i.e. they should run close together with similar loads attached at corresponding points. Area is another cost factor because two latches occupy more die area than one flip-flop. Probably the most important handicap, however, is the fact that it is not currently possible to obtain level-sensitive two-phase circuits from HDL synthesis without rewriting the RTL source code. 7.2.5 UNSYMMETRIC LEVEL-SENSITIVE TWO-PHASE CLOCKING Hardware resources and operation principle Unsymmetric level-sensitive two-phase clocking is obtained from the symmetric scheme by transferring combinational logic C12 to the opposite side of latch set L2 and merging it into C21, thereby making intervals T3, T4 and T1 available for evaluating the combined function. Clock interval T2 becomes unproductive due to the absence of combinational logic between L1 and L2. Most often, T2 is shortened at the benefit of the other intervals to utilize the clock period as much as possible. (b) pass hold pass hold T2T1 T3 T4 Clk1_C Clk2_C Ctime for 21 Tclk (a) Clk1_C Clk2_C L2 1L 21C master slave legal (c) 12t t21 Tclk TclkT3 T1T4++ T3T2T1 ++ illegal T2 T4 FIGURE 7.10 Unsymmetric level-sensitive two-phase clocking. Basic hardware organization (a), simpliﬁed timing diagram (b), and range of operation (c). 408 CHAPTER 7 CLOCKING OF SYNCHRONOUS CIRCUITS Detailed analysis Setup condition For latch set L1 and L2 respectively is max|tsk|≤ Tclk − T2 − max(tpd lc 2 + tpd 21 + tsu la 1) (7.20) max|tsk|≤ T2 + T3 − max(tpd ld 1 + tsu la 2) (7.21) Observe that setup time for latch set L2 is minimal when L1 accepts fresh data at the very end of T1.10 Inequality relation (7.21) is uncritical for any case of practical interest and (7.20) can always be met by selecting an adequate clock period. T1 T2 T3 1L passes T4 L2 passes tsu la tho la pd 21t tsu la tho la tpd lc tcd lc tpd ld cd 21t tpd lc time interval during which data at receiver are required to be stable (data-call window) actually do remain stable (data-valid window) actually do remain stable (data-valid window) are required to be stable (data-call window) 1L 2L tcd lc FIGURE 7.11 Anceau diagram of unsymmetric level-sensitive two-phase system shown for near maximum utilization of clock period. Hold condition For latch set L1 and L2 respectively we find max|tsk|≤ T2 + min(tcd lc 2 + tcd 21 − tho la 1) (7.22) max|tsk|≤ T4 + min(tcd lc 1 − tho la 2) (7.23) 10 The finding that (7.21) does not follow from (7.16) whereas (7.20) is identical to (7.15) is irritating at first sight. The underlying reason is as follows. The starting point for formulating setup conditions in the symmetric case was that both C12 and C21 would take up as much time as possible. i.e. they would start as soon as their input latches become transparent and end just before their output latches switch to hold. As a consequence, (7.17) had to be added as a third condition to make sure the clock period suffices to accommodate the cumulated delays of C12 and C21. As there is no C12 in the unsymmetric case, the above way of looking at the setup condition for L2 is ill-guided. Instead, (7.21) is obtained from the assumption that C21 eats as much time as it can thereby leaving the bare minimum for the propagation path from L1 to L2. As a side effect, a third condition is dispensed with. 7.2 HOW MUCH SKEW AND JITTER DOES A CIRCUIT TOLERATE? 409 Either condition provides a non-overlap interval that offers protection in case of excessive skew and jitter. Shortening the unproductive non-overlap interval T2 in search of maximum performance is limited only by the quest for an adequate skew margin. Implications In summary, benefits and costs of unsymmetric level-sensitive two-phase clocking are almost identical to those of its symmetric counterpart. A difference is that wide skew margins are bought at the detriment of operating speed because non-overlap interval T2 is unproductive. Observation 7.7. What makes level-sensitive two-phase clocking disciplines more tolerant to clock skew and jitter are their non-overlap intervals. Liberal skew margins can be designed into such circuits by adjusting the waveforms of their clock signals. Example IBM’s patented level-sensitive scan design (LSSD) technique [180] [181] is a clever combination of unsymmetric level-sensitive two-phase clocking with a scan-type test facility. Fig.7.12 shows the key ideas behind it. The output Q of each LSSD storage element connects to an input labelled SCI on a subsequent LSSD cell much as in an edge-triggered scan path design. The three clock nets notwithstanding, LSSD follows a two-phase clocking scheme. During normal operation, Clk1 and Clk2 exhibit non-overlapping pulses just as in any other unsymmetric level-sensitive two-phase clocking system. Terminal D of each LSSD storage element then acts as data input and Q as data output. Clock Clk0 is made to remain inactive at logic 0 by the clock generator, thereby disabling all scan inputs SCI. In scan mode, the waveforms of Clk0 and Clk1 are swapped which causes all LSSD elements to read data from their respective SCI terminals. Data at the D inputs are being ignored because all CLK1s rest at 0. The LSSD cells together act as a long shift register, which makes it possible to serially write out their state to pin Sco_TO and to read in a new state from pin Sci_TI. 410 CHAPTER 7 CLOCKING OF SYNCHRONOUS CIRCUITS Clk1_C Clk2_C Clk0_C Scm_TI pass hold pass hold pass hold slave master CLK2 DQ CLK1 CLK0 SCI LSSD non-overlapping clocks generator scan out Sco_TO Clk1_C Clk0_C Clk2_C ...... ...... ...... ...... CLK2 DQ CLK1 CLK0 SCI CLK2 DQ CLK1 CLK0 SCI scan path combinational logic clock domain or entire IC scan in Sci_TI clock Clk_CI scan chain mode for circuit test Tclk normal operation Tclk Tclk Tclk TclkTclk scan mode Scm_TI (b) (a) FIGURE 7.12 Level-sensitive scan design. Overall circuit structure (a) and clock waveforms (b). Incidentally, note that the power dissipated in driving the clock nets is roughly the same as for a two- phase scheme because only two out of the three clock nets are active at any time. \u0002 Practically speaking, the relative robustness of the two level-sensitive clocking schemes discussed in sections 7.2.4 and 7.2.5 implies that their clock distribution networks need not necessarily be balanced to the same degree of perfection as in the occurrence of edge-triggered circuits. Clock skew even becomes close to harmless when circumstances permit one to drive a circuit from a slow clock that affords ample non-overlap phases. Relaxed timing constraints are very welcome to experienced designers that take advantage of them for doing with less and lighter clock buffers in order to improve on overall energy efficiency and on switching noise. Distributing two or three clock signals is not always popular, however, because of the extra wiring resources required, the inferior EDA support, the less intuitive circuit operation, and the more complicated timing. Also note that considerable skew can build up between the various clock nets 7.2 HOW MUCH SKEW AND JITTER DOES A CIRCUIT TOLERATE? 411 if they are driven from distant buffers or if they significantly differ in their electrical or geometric characteristics. Thus, one can’t help to ask “Is it possible to design latch-based circuits that are driven by a single clock signal, and what characteristics would such circuits have?” The answer is positive and two very different solutions are going to be examined next. 7.2.6 SINGLE-WIRE LEVEL-SENSITIVE TWO-PHASE CLOCKING Hardware resources and operation principle Single-wire level-sensitive two-phase clocking comes in a symmetric and in an unsymmetric variation. Either variation differs from its two-wire counterpart in that all latches are being driven from one common clock signal. The usage of latches that pass and hold on opposite clock polarities does away with the need for a second clock net. (b) pass hold pass hold mutual exclusion mutual exclusion mutual exclusion T1 T3 Tclk Clk_C (Clk1) (Clk2) Ctime for 21 12Ctime for (a) C12 1L 21C 2L Clk_C passes on L H passes on FIGURE 7.13 Symmetric single-wire level-sensitive two-phase clocking. Hardware organization (a) and simpliﬁed timing diagram (b). As far as timing is concerned, this approach is equivalent to driving the two subsets of latches in the original configuration of fig.7.8 with complementary signals or, which is the same, with clock signals whose non-overlap intervals have been removed. Detailed analysis The critical hold margins are those of (7.18)and (7.19) with zero substituted for T2 and T4. Assuming identical timing figures for either latch bank, these two inequalities reduce to max|tsk|≤ min(tcd lc + tcd c − tho la) (7.24) where min(tcd c) is a shorthand for min(tcd 21, tcd 12). max|tsk|≤ min(tcd lc − tho la) (7.25) then holds in the absence of combinational logic between the latches. This constraint can only be relaxed if the circuitry is organized such as to never connect two latches directly with no logic in between, inserting dummy buffers for their contamination delay where necessary. 412 CHAPTER 7 CLOCKING OF SYNCHRONOUS CIRCUITS Implications With all non-overlap intervals that could protect against timewise variability gone, single-wire level- sensitive two-phase clocking is essentially as exposed to skew and jitter as edge-triggered one-phase clocking is. On the positive side, there is an unrestricted capability for time borrowing between C12 and C21. Yet, level-sensitive two-phase clocking offers another and less obvious opportunity for improving circuit performance. Assume the data input of a latch is being driven from some non-inverting gate, e.g. a 3- input and. We then have a cascade that consists of a 3-input nand, a not, and the bistable’s own inverting input buffer. The circuit can be improved by merging the and operation into the bistable and by collapsing the cascaded inverters. The usage of a “3-input and function latch”, as the combined cell is called, does away with two inverter delays, or almost so.11 Energy efficiency also benefits from the circuit modification. What sets symmetric level-sensitive two-phase clocking apart from other schemes is that it becomes possible to play this trick twice per computation period by embedding logic in both of the two latch subsets. Whether one or two nets are being used for clock distribution does not matter in this context, so most of what has been said here applies to standard [two-wire] level-sensitive two-phase clocking as discussed in section 7.2.4 too. Example Probably the most prominent VLSI circuits constructed along this line were those of the Alpha processor family introduced by the now defunct Digital Equipment Corp.12 Please refer to section 7.3 for details on how the clock is distributed over each of those chips. \u0002 7.2.7 LEVEL-SENSITIVE ONE-PHASE CLOCKING AND WAVE PIPELINING We will now turn our attention to a clocking scheme the properties of which sharply differ from those discussed so far. In spite of advantages in performance and energy efficiency, level-sensitive one-phase clocking can not be recommended for ASICs where limiting the design effort and the design risk are paramount. The subsequent analysis will show why. Hardware resources and operation principle Level-sensitive one-phase clocking stores state in latches exclusively and uses a single clock to drive them. The circuit arrangement corresponds to edge-triggered one-phase design with all flip-flops replaced by latches, see fig.7.14a. The same arrangement can be obtained by bypassing all slave latches in an unsymmetric level-sensitive two-phase design. 11 You may want to see section 3.4.3 for more information on function latches. 12 Depending on the authors, the clocking discipline used in the 21064 is referred to as “level-sensitive single phase with no dead time” or as “single-wire two-phase clocking”. 7.2 HOW MUCH SKEW AND JITTER DOES A CIRCUIT TOLERATE? 413 L T2T1 pass hold Tclk Clk_C Clk_C C time span available for combinational function C Tcp (b)(a) FIGURE 7.14 Level-sensitive one-phase clocking. Basic hardware organization (a) and simpliﬁed timing diagram (b). The fact that a latch must become transparent before it can accept a new data item for storage, together with the simultaneous clocking of all bistables, implies that the combinational logic is fed with new data (at the beginning of T1) before the previous results have been latched (which takes place at the end of T1). As a consequence, the combinational network must assure that data at its output remain unchanged while another wave of data has begun to propagate from the input through that very network. Correct circuit operation rests on inertial effects as transient phenomena are no longer allowed to die out before clocking occurs. Spinning the idea further, one may want to arrange for two or more data waves to propagate through the combinational logic at all times, a bit like a juggler who keeps several objects in the air simultaneously. This bold approach is known as wave pipelining [182] [183] and accepts path delays in excess of one clock period in an attempt to break the barrier that normally limits throughput.13 Tcp = Tclk < tlp = tid la + max(tc)\u0003 = 1 Tcp = 1 Tclk > 1 tlp (7.26) 13 While it is indeed possible to design feedforward wave pipelines that satisfy (7.26), recall from section 3.7 that first order feedback loops are not amenable to pipelining (but must be tackled with loop unfolding instead). Since that finding does not depend on how the necessary latency is obtained, it applies to wave pipelining too. Also note that the clock frequencies and throughputs made possible by wave pipelining will not exceed those obtained from a register-based fine grained pipeline because some minimum separation must always be maintained between any two consecutive waves. Wave pipelining manages with far less registers, though. 414 CHAPTER 7 CLOCKING OF SYNCHRONOUS CIRCUITS T1 L passes tsu la pd ct T2 tho la tcd c tcd lc time interval during which data at receiver are required to be stable (data-call window) actually do remain stable in spite of a (data-valid window) new wave propagating through logic tpd lc FIGURE 7.15 Anceau diagram of level-sensitive one-phase system. The formation of multiple waves becomes apparent by tpd c covering more than a full circle. Detailed analysis Setup condition Combinational logic is fed with new data at the beginning of transparent interval T1 and must yield a stable result no later than at the end of the subsequent transparent interval. max|tsk|≤ Tclk + T1 − max(tpd lc + tpd c + tsu la) (7.27) Once more, the setup condition is easily satisfied by acting on Tclk. Relation (7.27) exhibits a more intriguing characteristic, however, especially when compared to (7.5)or(7.20). More than a full clock period becomes available for the combinational logic, unless the cumulated latch delay, clock skew and jitter eat up more time than T1 provides. In other words, the circuit can be made to operate in a wave pipelined regime as shown in fig.7.15. Hold condition Data applied to latches at the beginning of transparent interval T1 must not change before the end of this very transparent interval. max|tsk|≤ −T1 + min(tcd lc + tcd c − tho la) (7.28) When compared to edge-triggered one-phase clocking, the meagre skew margin has been reduced further by T1 and is bound to become negative in the absence of combinational logic. It is now evident at what expense the extra leeway in the setup condition has been bought. Implications Equation (7.28) imposes an upper bound for clock high phase T1 which contrasts with all other clocking schemes analyzed so far. As any bistable comes with minimum clock widths requirements, the high phase gets bounded from below too. We thus end up with a two-sided constraint for T1. max(tclk hi min la) ≤ T1 ≤ min(tcd lc + tcd c − tho la) −|tsk| (7.29) 7.2 HOW MUCH SKEW AND JITTER DOES A CIRCUIT TOLERATE? 415 Whether there is a solution or not depends on the detailed timing figures of the cells being used. Yet, in the absence of combinational logic and relevant interconnect delay, the remaining upper bound min(tcd lc − tho la) −|tsk| leaves very little room indeed for a comfortable clock high time. The problem is further aggravated by the necessity to find a valid timing for a variety of latch types and under all possible operating conditions. As a consequence, it is impossible to build a shift register — or a scan path — in the normal way, even if skew and jitter are optimistically assumed to be zero. For the circuit to work properly, delay elements must be inserted into each overly short propagation path until (7.28) is safely satisfied. Redundant gates have to be added for their contamination delay alone. There is another peculiarity worthwhile to note. Slowing down a circuit’s operation is often helpful for locating problems. For all clocking disciplines discussed earlier, this could be achieved simply by stretching the clock’s waveform. With (7.28) specifying an upper bound, this is no longer possible. Slowing down a level-sensitive one-phase clocked circuit asks for keeping one clock phase constant (T1 in the occurrence of fig.7.14) while extending the other (T2). From our analysis of level-sensitive one-phase clocking, we conclude: + When compared to two-phase designs, the number of latches and clock nets is cut in half. + In theory, and with the exception of computations organized as first order feedback loops, there is a potential for shortening the clock period to below the logic’s propagation delay. − As a consequence from the feedback loop being closed during the transparent intervals, correct operation critically depends on clock pulse width, gate delays, and interconnect delays. − All library cells must be bindingly characterized for their contamination delays. − Interconnect delays, and hence also layout parasitics, must be precisely controlled. − Unchecked timing variations may prove deadly. − Signals that arrive too early must be delayed artificially at extra costs in terms of area and energy. − Sufficient skew margins must also be bought with additional contamination delay. Delay tuning is a nice word for the process of adjusting circuit delays until a design appears to work for a given set of timing parameters. This practice is not compatible with regular high-productivity EDA design flows. While some HDL synthesizers and automatic place and route (P&R) tools are capable of hold time fixing, most EDA software is designed to meet long path constraints at minimum hardware and energy costs. Also, contamination delays are neither guaranteed by manufacturers nor normally indicated in library datasheets. Most simulation models do not accurately reproduce contamination delay either. Observation 7.8. Level-sensitive one-phase clocking critically depends on fine tuning propagation and contamination delays through both combinational logic and interconnect. This practice is incompatible with existing EDA design flows, with industrial cell libraries, with reliable circuit operation in the pres- ence of timing variabilities, and with the drive towards ever higher productivity in VLSI design and test. However, note that level-sensitive one-phase clocking has been applied successfully to supercomputers such as the Amdahl 580 and the Cray-1 [184] at a time when circuits were assembled at the board level from SSI/MSI parts. A milder form is also being discussed in problem 6. 416 CHAPTER 7 CLOCKING OF SYNCHRONOUS CIRCUITS 7.3 HOW TO KEEP CLOCK SKEW WITHIN TIGHT BOUNDS 7.3.1 CLOCK WAVEFORMS The main problem of clock distribution is to drive many thousands of clocked subcircuits, such as latches, flip-flops and RAMs, spread over a die, a board or a system while keeping the unavoidable skew within narrow limits. Slow clock ramps are problematic for several reasons: • As illustrated in fig.7.16, unavoidable disparities of the switching thresholds across clocked cells translate ramp times into skew. • The timing figures published in datasheets and stored in simulation models are obtained from stimulating cells with clock ramps of 50 ps and less during library characterization. • When clocked with slow ramps, setup and hold times tend to grow, putting correct behavior and timing accuracy at risk. As a consequence, clock signals must literally snap from 0 to 1 and back again. ssUU l =0= Uth min Uth max u(t) switching thresholds tolerance band for ddUU h = t active clock edge large contribution to clock skew slow rampfast ramp small contribution to clock skew ! FIGURE 7.16 Sluggish clocks translate into extra skew. Observation 7.9. Among all signals on a chip or in a system, clocks typically feature the largest fanout, travel over the longest distance, and operate at the highest speed. Yet, their waveforms must be kept particularly clean and sharp. The most innocent idea for distributing a clock is to treat it like any other signal, i.e. to use a standard minimum-width line to connect all clocked subcircuits to a common source. That such an approach is not viable becomes immediately clear from a numerical example. Warning example Consider a clock domain in a CMOS IC that includes a modest 500 flip-flops. Clock distribution is via a metal line 130 nm wide that meanders through the chip’s core area much as in fig.7.17a. Sheet resistance is 70 m\u0004/\u0002, a typical value for a second or third level metal. For simplicity, assume that the flip-flops are connected to that wire at regular intervals thereby forming an RC network of ladder type 7.3 HOW TO KEEP CLOCK SKEW WITHIN TIGHT BOUNDS 417 with #sct = 500 identical sections of length 100 \u0002 and with a capacitance of 12 fF each. The delay and the ramp time at the end of such a net in response to a step at the input then roughly are [185] tpd wire ≈ 0.4 Rsct Csct # 2 sct = 0.4 Rwire Cwire = 0.4 · 3500 \u0004 · 6pF = 8.4 ns (7.30) tra wire ≈ Rsct Csct # 2 sct = Rwire Cwire = 3500 \u0004 · 6pF = 21 ns (7.31) where Rsct and Csct refer to the lumped resistance and capacitance of one section respectively as illustrated in fig.7.18a. Obviously, such figures are totally inadmissible for a clock. \u0002 The above example suggests two starting points. Firstly, the clock net must be reshaped and resized such as to cut down, control and balance interconnect delays in a better way. Secondly, interconnect lengths, capacitances and resistances must be lowered by subdividing a chip-wide clock net into many smaller nets each with a driver of its own. These are indeed the basic ideas behind two alternative approaches that we are going to discuss next. 7.3.2 COLLECTIVE CLOCK BUFFERS The collective approach has one single buffer that connects to all clocked cells directly via metal lines. To handle the huge fanout, the buffer consist of multiple stages of increasing drive strengths. The idea failed in the above example because the clock net was shaped like a long, narrow and winding alpine road. The picture improves if length, width and shape are chosen more carefully. As the ensemble of clocked cells sets a lower bound for the load capacitance, it is the resistance of the distribution network that must be kept low, while, at the same time, attempting to make all interconnect delays about the same. The subsequent countermeasures all help to improve the situation: • Keep clock wires as short as possible, place the driver close to the center of the circuit. • Make clock distribution wires reasonably wide. Narrow wires yield a high resistance whereas plate capacitance dominates in excessively wide wires. • Use the upper metal layers as only they combine low resistance with low capacitance. • Avoid unnecessary layer changes as contacts and vias contribute to resistance. • Equalize delays by making all clock paths electrically and geometrically similar. Three layout arrangements developed with these rules in mind are shown in figs.7.17b to d. Although the recursive H-tree immediately strikes as the optimal solution, it is difficult to implement in practice unless clock loads are uniformly distributed and unless one is prepared to set aside one metal layer for the sole purpose of clock distribution. Spine, comb and grid topologies similar to those adopted for power distribution purposes are or — rather — were more realistic. Yet, wide clock lines unnecessarily inflate parasitic capacitance and, hence, power dissipation. Another difficulty is that the important switching currents associated with driving large loads concentrate at a few points in a chip’s floorplan. 418 CHAPTER 7 CLOCKING OF SYNCHRONOUS CIRCUITS Clk_CI core chip padframe ............... ! ! Clk_CI Clk_CI Clk_CIClk_CI Clk_CI (c) (e) (a) (d) (f) (b) FIGURE 7.17 On-chip clock distribution schemes (simpliﬁed). Narrow meander (a), central buffer combined with a balanced H-tree layout (b), collective buffer combined with spine-like wiring (c), central buffer combined with grid-like wiring (d), distributed buffer tree (e), distributed buffer tree combined with a grid (f). 7.3 HOW TO KEEP CLOCK SKEW WITHIN TIGHT BOUNDS 419 Example Consider a circuit with 10 000 bistables. Clocking is from a collective buffer with a voltage swing of 1.2 V. Let the aggregate load capacitance per bistable be the same as in the previous example since the clock lines are shorter but also much wider this time. Further assume that the drive current follows a triangular waveform during the signal’s ramp time of 100 ps. It then peaks out at ˆIclk ≈ 2 Cclk Udd tra clk = 2 10 000 · 12 fF · 1.2 V 100 ps ≈ 2.9 A (7.32) At a clock frequency of 500 MHz, the final inverter stage driving the clock net dissipates Pclk > αclk 2 Cclk U2 dd fclk = 1 · 10 000 · 12 fF (1.2 V) 2 500 MHz ≈ 86 mW (7.33) \u0002 Current spikes as strong as this necessitate special precautions. Older cell libraries used to provide special clock drivers designed to fit into a chip’s padframe where they were fed from dedicated power and ground pads in order to avoid ground bounce problems. Example The original Alpha processor, the 21064, followed a collective driver approach in its purest form. Total capacitive load of the clock node was 3.25 nF, requiring final driver transistors with Wn = 100 mm and Wp = 250 mm [186]. Power dissipation was 30 W from a 3.3 V supply at a clock frequency of 200 MHz. Clock rise and fall times were 500 ps and a peak switching current of 43 A had been measured. Clock distribution roughly followed fig.7.17d with the central driver extending along more than half of the chip’s centerline. Transmitting a clock edge from the chip’s center to a corner was found to take less than 300 ps, which compared favorably to the 5 ns clock period and paved the way for single-wire level-sensitive two-phase clocking where there are no non-overlap intervals that could provide extra room for skew. \u0002 7.3.3 DISTRIBUTED CLOCK BUFFER TREES The concern for energy efficiency subsequently mandated the introduction of gated clocks and drove designers away from the flat distribution schemes that were popular at the time when the Alpha 21064 was developed. What’s more, observe from (7.30) that interconnect delay grows quadratically with line length l because Rwire ∝ l and Cwire ∝ l (and #sct ∝ l too). Let us examine what happens when a long line gets turned into a repeated wire by subdividing it into #seg shorter segments separated by #seg − 1 inverting or non- inverting buffers in between as shown in fig.7.18b. To first order, overall propagation delay then becomes tpd rept ≈ #seg ( tpd buf + 0.4 Rsct Csct ( #sct #seg )2 ) = #seg tpd buf + 0.4 #seg Rwire Cwire (7.34) which means that the overall delay can be made a linear function of line length just by choosing #seg ∝ l. To minimize the overall delay, the propagation delay of each wire segment should be made to match that of one repeater, in which case one speaks of an optimally repeated wire. In practice, repeaters are typi- cally spaced further apart such as not to unnecessarily inflate the overhead in terms of area and power. 420 CHAPTER 7 CLOCKING OF SYNCHRONOUS CIRCUITS section 1 section 2 section 3 section 4 section 5 section 6driver tpd buf Rsct Csct repeater 2 repeater 3 tpd buf Rsct Csct driver = repeater 1 segment 1 segment 2 segment 3 (a) (b) FIGURE 7.18 Lumped RC model of a bare wire (a) vs. that of a repeated wire (b). #sct = 6and#seg = 3inthisexample. A distributed clock tree thus consists of a multitude of repeaters of moderate size physically located close to the loads they drive and inserted into every major branch, see fig.7.17e. As opposed to the collective approach, no large currents need to flow over large distances. Also, the power dissipated for driving the clock net is distributed over the chip’s area. Conversely, a tree-like structure requires careful delay matching. The goal is to equalize the delays along all branches in spite of unevenly distributed loads and distances. This implies: • Hierarchically partition the design such as to balance clock loads to a reasonable degree. • Plan for local subtrees and size clock buffers as a function of the load they must drive. • Prefer the upper metal layers for their lower resistance and capacitance. • Retard overly fast clock distribution paths by inserting extra buffers. • For fine tuning, consider adding dummy loads and detours to early branches. While both collective clock buffers and distributed clock trees have been made to work in commercial circuits, distributed trees won because they support clock gating, help to keep distribution delay low, and tend to be less demanding in terms of routing resources, overall power, and current crowding. One difficulty in implementing them is that accurate data on which to base detailed delay calculations do not become available until late in the design cycle. Another problem is that the clock tree must be readjusted whenever a design modification entails a minor change in the loads to drive or in their geometric locations. The EDA industry has come to the rescue by developing automatic software tools that are capable of inserting balanced clock trees into circuits of substantial size, largely doing away with the need for manual delay budgeting and iterative tuning. As a matter of fact, distributed trees prevail since the introduction of automatic clock tree generators that are run as part of physical design, e.g. between place and route. At that point, calculations can be based on fairly accurate estimates for layout parasitics and interconnect delays. Hint: Restricting repeaters in a clock tree to non-inverting buffers (no inverters) eliminates the risk of ending up with contradictory branches that differ in their numbers of negations. 7.3 HOW TO KEEP CLOCK SKEW WITHIN TIGHT BOUNDS 421 Example An unprecedented degree of sophistication has been achieved with Intel’s Itanium 2 9000, a dual core design clocked at 1.6 GHz with 1.72 · 109 transistors manufactured in a 90 nm bulk CMOS process with seven layers of Cu interconnect. The sub 100 nm technology, the huge die size of 27.7 mm by 21.5 mm, the maximum power dissipation of 104 W in conjunction with local hot spots all contribute to important and unpredictable on-chip variations (OCV). While an oversize clock grid would have helped to contain skew, designers were afraid of the large equalizing currents and of the power overhead this would have entailed [187]. Instead of contenting themselves with statically balancing clock distribution delays at design time, their regional active deskew scheme adaptively fine-tunes delays in the different clock tree branches at run time with the aid of multiple phase comparators and adjustable delay lines. \u0002 7.3.4 HYBRID CLOCK DISTRIBUTION NETWORKS Hybrid schemes have been devised for high-performance VLSI in an attempt to combine the efficiency of a distributed clock tree with the robustness of the grid approach. Instead of having the leaf cells of a distributed buffer tree drive the clocked cells directly, their outputs are shorted together by a domain- wide metal grid as sketched in fig.7.17f. The grid minimizes local skew by providing low-resistance current paths between nearby points. The fairly stiff and uniform structure so obtained facilitates circuit design as timing does not depend too much on details of cell placement. This approach results in a small distribution delay and acceptable power without eating too much wiring resources [188] [181]. Example The clock distribution concept pursued by Sun Microsystems in their Niagara processor that includes 279 · 106 transistors manufactured on a die of 378 mm2 in 90 nm 9LM (Cu) bulk CMOS technology and rated with a maximum power of 63 W at 1.2 GHz and 1.2 V is comparatively straightforward. By cleverly combining a global H-tree with multiple regional clock-gated grids and with local subtrees, its designers were able to keep clock skew below 50 ps without recurring to complex active deskewing circuitry [189]. While overall power density is comparable to the above example, the smaller die and the better spreading of heat afforded by the concurrent operation of eight relatively modest processor cores was certainly helpful in avoiding inordinate delay variabilities. Another particularity is post-layout hold time fixing with the aid of metal-programmable delay buffers. Following static timing analysis, delays get statically adjusted using a local metal with no impact on the previously frozen detailed signal routing. \u0002 7.3.5 CLOCK SKEW ANALYSIS Functional simulation is inadequate for uncovering clock skew problems. As exhaustive simulation is not practical, it is very likely that not all critical patterns get applied and that some skew-related timing problems pass unnoticed. The good news is that there is no need to simulate a circuit functionally to find out whether timing conditions are met or not in synchronous designs. Timing verification, aka static timing analysis, is much more appropriate as it 422 CHAPTER 7 CLOCKING OF SYNCHRONOUS CIRCUITS • Circumvents all coverage problems, • Quantifies the timing margins on all signal propagation paths, both short and long, • Locates slack, if any, and • Does with a more reasonable computational effort. Do not forget to include layout parasitics, to use adequate interconnect models, and to account for crosstalk, PTV and OCV variations during static timing verification. 10 0 2.5 5 7.5 10 20 30 40 50 10 20 30 FIGURE 7.19 Clock skew map for a Cell processor chip measuring roughly 17.8 mm by 12.3 mm. Horizontal dimensions are given in arbitrary units, skew is in [ps] (photo copyright IEEE, reprinted from [190] with permission). Observation 7.10. Whatever the clocking discipline and clock distribution scheme, careful design and timing verification are essential. 7.4 HOW TO ACHIEVE FRIENDLY INPUT/OUTPUT TIMING 423 7.4 HOW TO ACHIEVE FRIENDLY INPUT/OUTPUT TIMING 7.4.1 FRIENDLY AS OPPOSED TO UNFRIENDLY I/O TIMING We now extend our discussion to the board-level interface of entire chips that are part of the same clock domain, see fig.7.20a.14 The basic requirement of observation 7.1 that any data-call window must be fully enclosed by the pertaining data-valid window remains exactly the same as for data transfers between simple flip-flops within a chip. (a) (b) (c) (d) 2 data-valid window ends previous output data are held until this point 3 data-valid window begins new output data have settled at this point data-valid window during which transmitter provides stable data 1 data-call window ends previous input data are held until this point 4 data-call window begins new input data have settled at this point data-call window during which receiver accepts data and requires them to be stable board-level clock transmitting IC tdi xmtdelay receiving IC di rcvt interconnect board-level ..........delay BA output logic (if any) input logic (if any) clock distribution delay clock distribution delay tsu rcv active clock edge tpd xmt tsu rcv time active clock edge tcd xmt tho rcv 2 4 1 3 2 4 1 active clock edge tpd xmt tsu rcv tho rcvtcd xmt 3 2 4 1 3tpd xmt tcd xmt tho rcv Clk_CI Oup_DO Inp_DI FIGURE 7.20 Two VLSI chips with a data transfer path (a). Anceau diagrams for friendly (b), average (c), and incompatible I/O timing characteristics (d). Any counterclockwise arrow implies a negative sign. 14 Note that much the same argument also applies to virtual components and other major circuit blocks that contain a clock distribution network of their own. How to synchronize data at the boundaries between distinct clock domains is to be addressed in chapter 8. 424 CHAPTER 7 CLOCKING OF SYNCHRONOUS CIRCUITS Interfacing with outputs that provide valid data for most of a clock period is straightforward as there is plenty of time for the receiving circuit to evaluate and store the acquired data. Similarly, most of the clock period is available for the transmitting circuit to settle if the receiver calls for stable data during a brief time slot just prior to the active clock edge. Note the ample setup and hold margins in fig.7.20b. As opposed to this, interfacing with a circuit that just flashes output data for a brief moment of time is a real nuisance. Data are likely to settle too late or to vanish too early for the receiver to get hold of them. Similarly, inputs that ask for stable data for an extended period leave little time for output logic and interconnect delays. A long hold time proves especially awkward since it obliges the transmitter to maintain its former output long after the active clock edge has sparked off a transition to a new state. The two I/O timings shown in fig.7.20d are in effect incompatible: it is impossible to transfer data if transmitter and receiver are to be driven from a common clock. Engineers are then forced to recur to delay lines, stopover registers, adventurous clocking schemes, and other makeshift improvisations. The desiderata for friendly input-output timing are as follows. I/O data-call inputs data-valid outputs timing window tsu inp tho inp window tpd oup tcd oup friendly narrow small close to zero or, wide small large, as close to better, negative tpd oup as possible unfriendly wide large large (positive) narrow large close to zero How to express timing constraints for commercial synthesis and timing verification tools has been the subject of section 4.4.5. 7.4.2 IMPACT OF CLOCK DISTRIBUTION DELAY ON I/O TIMING Driving the huge capacitances associated with clock nets necessitates large multi-stage drivers which bring about important clock distribution delays. So far, we have not cared much about this effect as only skew matters within a circuit. Yet, the impact of clock distribution delay on I/O timing is twofold, just compare figs.7.21 and 7.22. 7.4 HOW TO ACHIEVE FRIENDLY INPUT/OUTPUT TIMING 425 zero-delay clock distribution tdi = 0 (b) time 2 4 1 3 tsu inp tpd oup tho inp tcd oup active edge at clock terminal active edge at flip-flops= CB D tsu inp tho inp tcd oup tpd oup input-to-state path state-to-output path state-to-state path tcd c tpd c tcd b tpd b tcd d tpd dtsu ff tho ff tcd ff tpd ff (a) IC FFFF Oup_DOInp_DI Clk_CI FIGURE 7.21 I/O timing of a VLSI chip in the absence of clock distribution delay. Circuit (a) and Anceau diagram (b). Note: Events refer to input and output terminals of a single circuit here, which view contrasts with all Anceau diagrams shown so far in this chapter where events related to the interface between two circuits. On outgoing signals, distribution delay simply adds to both propagation and contamination delays. The resulting data lag remains largely uncritical unless a system is to operate at high clock frequencies in which case the prolonged propagation delay will be felt. On incoming signals, distribution delay shortens setup and extends hold time. Even a moderate distribution delay is likely to render setup time negative on those inputs that directly connect to a register. More importantly, however, the same amount of delay will inflate hold time way beyond any realistic value for a transmitter’s contamination delay. tsu inp tho inp tcd oup tpd oup input-to-state path state-to-output path state-to-state pathdelayclock distribution delay tcd c tpd c tcd b tpd b tcd d tpd dtsu ff tho ff tcd ff tpd ff (a) (b) at flip-flops active edge tcd oup tdi 2 4 1 3 active edge at clock terminal tpd oup tsu inp tho inp IC DCBFFFF Oup_DOInp_DI Clk_CI tdi >0 FIGURE 7.22 Impact of excessive clock distribution delay. Circuit (a) and Anceau diagram (b). 426 CHAPTER 7 CLOCKING OF SYNCHRONOUS CIRCUITS For a quantitative analysis, assume the circuit operates with edge-triggered one-phase clocking. The circuit’s input and output terminals then exhibit these timing parameters tsu inp = max(tpd b + tsu ff ) − tdi (7.35) tho inp = max(−tcd b + tho ff ) + tdi (7.36) tpd oup = max(tpd ff + tpd d) + tdi (7.37) tcd oup = min(tcd ff + tcd d) + tdi (7.38) In conclusion, distribution delay adds to input hold time and may so easily turn a circuit with perfect I/O timing characteristics into an unacceptable one. What’s more, within a population of digital components, any differences between clock distribution delays translate into clock skew unless they get counterbalanced within the board- or system-level clock distribution network. Observation 7.11. While it is imperative to minimize clock skew, it is also important to keep on-chip clock distribution delay within tight bounds to avoid the awkward timing characteristics at the chip’s I/O interface that otherwise result. Example FPGAs of the Actel SX-A family include three dedicated low-skew clock networks. One of them is referred to as hardwired which is to say that there are no more than two programmable links between the clock input and any on-chip flip-flop. This is done not only to minimize clock skew but also distribution delay. The resulting skew is said to be as low as 0.1ns and the pin-to-pin delay from the clock input to any register output is specified as 5.3ns (A54SX72A-3 under worst case commercial conditions). \u0002 7.4.3 IMPACT OF PTV VARIATIONS ON I/O TIMING Keeping a receiver’s data-call window within the transmitter’s data-valid window under all circum- stances is particularly difficult at the interface between two components because • I/O timing is subject to vary with the off-chips loads attached, • I/O timing is affected by board-level interconnect delays, • What matters is the difference between the distribution delays of receiver and transmitter, • The PTV conditions of two chips are bound to differ, and because • PTV variations notoriously have a large impact on timing figures.15 While clock distribution delay is of little importance as long as all clocked subcircuits are affected alike, it becomes highly critical at the interface between two components and at the interface between two supply domains. It is not uncommon to find that maintaining all components properly synchronized within a clock domain is impossible when those components are subject to moderate but non-uniform PTV variations. Observation 7.12. PTV variations put data transfers between ICs at risk. A healthy latitude to timing variations is thus even more important at the I/O interfaces than within a chip itself. 15 It is not exceptional to see timing quantities vary by a factor of three from the slowest to the fastest operating conditions acceptable for some given CMOS technology. 7.4 HOW TO ACHIEVE FRIENDLY INPUT/OUTPUT TIMING 427 Before discussing a more radical solution for all the above problems in section 7.4.8, let us suggest a few countermeasures that alleviate the undesirable effects of clock distribution delay. 7.4.4 REGISTERED INPUTS AND OUTPUTS Reconsider fig.7.22. An obvious idea for simplifying I/O timing is to insert data registers between the input circuitry from Inp_DI and combinational logic B and/or between combinational logic D and the pad drivers for Oup_DO. Let us see whether that helps. On the output side, signals should not be made to propagate through deep combinational networks. Including an output register right before the pad drivers maximizes the data-valid window and — as a welcome side effect — also yields hazard-free signals. A price to pay is the extra latency. If needed, the circuit’s contamination delay can be extended by driving the output register from a local clock designed with a slight lag. Input registers, on the other hand, must not be allowed to suffer from substantial and/or unpre- dictable clock distribution delay as input hold time otherwise becomes unmanageable. The remedies to be presented next are, therefore, particularly important on the input side. 7.4.5 ADDING ARTIFICIAL CONTAMINATION DELAY TO DATA INPUTS As data lag compensates for clock distribution delay, any combinational network inserted between the input pads and the first bistable helps because of its contamination delay. After all, it is the timing of the clock relative to the data signals that decides when exactly data voltages get interpreted, also see problem 8. Example Various Xilinx FPGA families include a user-configurable multiplexer in each I/O block that selects or bypasses a delay line in the data input propagation path, see fig.7.23. Note that the data-call window is being shifted and observe the impact on the FPGA’s hold time requirement. 428 CHAPTER 7 CLOCKING OF SYNCHRONOUS CIRCUITS clock distribution network configuration bit delay line ...... ...... clock input data input FPGA clocked cells to FIGURE 7.23 Compensating clock distribution delay with conﬁgurable delay lines on FPGA data inputs. Principle (top) and excerpts from Xilinx data sheets (bottom). \u0002 7.4.6 DRIVING INPUT REGISTERS FROM AN EARLY CLOCK The interfacing of ICs or virtual components (VC) that share a common clock would be easier if their input registers — and possibly their output registers too — could be driven from a separate clock that does not suffer from a distribution delay as important as the rest of the circuit. This is indeed possible based on the observation that I/O registers account only for a small fraction of a circuit’s total clock load. An early clock is tapped from the main tree close to its root, see fig.7.24. The resulting lead of the input registers must be taken into account when designing the remainder of the circuit, however. 7.4.7 CLOCK TAPPED FROM SLOWEST COMPONENT IN CLOCK DOMAIN Complex circuits often feature comparatively long hold times, making it difficult to interface them with smaller and faster components. This is mainly because clock distribution delay tends to grow with circuit size and clock load. The practice of mixing high-density CMOS core functions with fast SSI/MSI components — such as high-speed CMOS, bipolar or BiCMOS — for glue logic functions on a circuit board exacerbates the problem. 7.4 HOW TO ACHIEVE FRIENDLY INPUT/OUTPUT TIMING 429 A workaround exists provided that the component that exhibits the longest clock distribution delay within the clock domain can be arranged to have a special output tapped from the its clock distribution network close to its leafs and brought to an extra package pin, see fig.7.24. The original clock is then first fed into that slower part and redistributed from its clock tap to all faster components within the same clock domain. original clock OrigClk_CI to clocked core cells to clocked core cells to input registers system-level clock SysClk_CO large IC or virtual component ..... ..... clock domain ..... ..... to other circuits clock buffers FIGURE 7.24 Two more options for compensating clock distribution delay (data I/O not shown.) 7.4.8 “ZERO-DELAY” CLOCK DISTRIBUTION BY WAY OF A DLL OR PLL All problems of I/O timing would be gone if clock distribution delay could be made zero as the events that trigger state changes and the external clock would then perfectly align. This is indeed possible with an on-chip delay locked loop (DLL) or phase locked loop (PLL). Once locked, both DLLs and PLLs act as a servo loop that keeps a local signal in phase with a reference signal supplied from externally. The difference essentially relates to the actuator in the servo loop: PLLs use a controlled oscillator whereas DLLs include an adjustable delay line or — which is the same — a controlled phase shifter. In either case, the servo loop is made to compensate for the cumulated propagation delays of clock buffers and interconnects, see fig.7.25. The overall circuit then behaves like a distribution network with zero or close to zero insertion delay. Better still, PTV variations are automatically compensated for. As every overclocker knows, most microprocessors operate at rates that are an integer multiple of the clock frequency distributed over the motherboard. This is achieved by inserting a frequency divider into the PLL feedback path as shown in fig.7.25a. Both DLLs and PLLs take a number of cycles to lock and have a limited lock range which makes them intolerant to abrupt frequency changes and vetoes single-cycle operation. Unless frequency multiplication is truly required, DLLs are preferred for their unconditional stability, faster lock times, and low jitter. 430 CHAPTER 7 CLOCKING OF SYNCHRONOUS CIRCUITS DLL and PLL subcircuits are not always part of ASIC design libraries. They can be designed either from voltage-controlled delay lines and oscillators or around numerically adjustable delay lines. [191] [192] [193] [194] include material on the design of integrated PLLs and DLLs. A particular difficulty with adjustable delay lines in the context of clocking is that the respective propagation delays for rising and for falling edges must closely match. phase discri- minator loop filter ....to clocked cells to clocked cells controlled delay linephase discri- minator loop filter ExtClk_CI frequency divider (optional) ....to clocked cells to clocked cells controlled oscillator IC or clock domain clock buffers clock buffers ExtClk_CI Clk_C Clk_C (b)(a) FIGURE 7.25 Using a PLL (a) or a DLL (b) to minimize and stabilize clock distribution delay. Fast lock-in and stable phase alignment in spite of PTV variations heavily depend on the phase discriminator. So-called bang-bang PLLs use a simple D-type flip-flop where the reference signal is applied to data input D and the local clock to flip-flop terminal CLK so that the Q output essentially reflects the sign of the phase difference. The servo loop is then designed such as to drive the local clock into alignment with the external reference signal. Bang-bang PLLs do not obey the standard linear PLL theory, though. Please refer to [195] [196] [197] for details. The injection-locked oscillator (ILO) is another special case of a PLL where the reference clock is injected directly into an LC- or ring-type oscillator (ILRO) with no special phase discriminator. Rather than continuing to oscillate at its free-running frequency, the oscillator will lock to the injected frequency provided the difference between the two is sufficiently small. Because of the simple circuit, ILOs dissipate less power than full-fledged PLLs and lend themselves for use in clock distribution networks [198]. 7.4 HOW TO ACHIEVE FRIENDLY INPUT/OUTPUT TIMING 431 Examples An analog and a mostly digital DLL circuit designed for clock alignment in the context of a memory system have been compared by [199] and the results are summarized below. Both circuits have been fabricated on the same chip with a 400 nm 3.3 V standard CMOS process. Nominal clock frequency is 400 MHz, yet data are transferred on both edges of the clock so that the time interval is a mere 1.25 ns per bit. Also consider that the digital circuit takes less effort to design and is more easily ported to a new process than the analog alternative. DLL architecture analog digital area 0.68 0.96 mm2 power dissipation 175 340 mW @ 3.3 V maximum clock frequency 435 > 667 MHz minimum supply voltage 2.1 1.7 V lock time 2.0 2.9 ms clock jitter 195 245 ps peak-to-peak Actel’s ProASICPLUS FPGAs include two clock conditioning blocks each of which consists of a PLL, four programmable clock dividers, and a few delay lines. The output frequency range is 6 to 240 MHz with a maximum acquisition time of 20 μs. A lock signal indicates that the PLL has locked onto the incoming clock signal. Delay lines are programmable in increments of 250 ps. Supply voltage must be within 2.3 V and 2.7 V, nominal power dissipation is 10 mW. The clock distribution subsystem in Intel’s Itanium CPU is by itself very complex and organized into global, regional, and local clock distribution. It makes use of one PLL at the global and of 30 (sic!) DLLs at the regional level. Implemented in 180 nm CMOS technology, the sophisticated distribution scheme limits clock skew to 28 ps for a 1.25 ns (800 MHz) clock [200]. Intel’s Nehalem multi-core architecture includes multiple clock domains and implements a dynamic voltage and frequency scaling (DVFS) scheme whereby supply voltages and clock frequencies get adjusted as a function of the momentary workload on a per-core basis. The PLLs have been designed such that clock rate tracks supply droop, i.e. transient voltage variations caused by changing current demands of the load circuitry. Those PLLs fabricated in 45 nm CMOS HKMG technology exhibit 1 μs lock time and 3.7 ps RMS jitter for a 375 ps (2.67 GHz) clock [201]. A duty cycle correction mechanism is made necessary by the fact that the circuit includes double data rate (DDR) subcircuits.16 \u0002 In conclusion, the adoption of sophisticated closed-loop phase control schemes not only improves I/O timing but must be understood as a yield enhancement measure without which it would not have been possible to run chips as complex as modern microprocessors at extreme clock rates in spite of unpredictable process variations and aging. 16 Duty cycle correction and DLLs are also part of Intel’s so-called Quickpath on-chip interconnects that transmit multiple data bits in a differential format along with the pertaining clock. 432 CHAPTER 7 CLOCKING OF SYNCHRONOUS CIRCUITS 7.5 HOW TO IMPLEMENT CLOCK GATING PROPERLY 7.5.1 TRADITIONAL FEEDBACK-TYPE REGISTERS WITH ENABLE In most designs, part of the flip-flops operate at a lower rate than others. Just compare a pipeline register against a mode register that preserves its state for millions of clock cycles or even until power down. Other registers occupy positions in between. This situation suggests the usage of enable signals to control register operation as shown in the code fragments below. ..... process (Clk_C) begin -- activities triggered by rising edge of clock if Clk_C’event and Clk_C=’1’ then if Ena_S=’1’ then -- control signal that governs State_P <= State_N; -- register update end if; end if; end process; ..... ..... always_ff @(posedge Clk_C) // activities triggered by rising edge of clock if (Ena_S) // control signal that governs State_P <= State_N; // register update ..... When presented with such code, synthesizers call upon a multiplexer to close and open a feedback loop around a basic D-type flip-flop under control of the enable signal as shown in the example of fig.7.26b. As the resulting circuit is simple, robust, and compliant with the rules of synchronous design,17 this is a safe and often also a reasonable choice. Some libraries indeed offer an E-type flip-flop that combines a flip-flop and a mux in a single cell. 17 Notably with the dissociation principle presented in section 6.4. 7.5 HOW TO IMPLEMENT CLOCK GATING PROPERLY 433 (a) CLK D Q ENA Q State_P[w-1:0] CLK DQ Q 0 1 Clk_C State_N[w-1:0] Ena_S (b) w w w FIGURE 7.26 Register with enable. Icon (a) and safe E-type ﬂip-ﬂop circuit (b). On the negative side, this approach takes one fairly expensive multiplexer per bit and does not use energy efficiently. This is because any toggling of the clock input of a disabled flip-flop wastes energy in discharging and recharging the associated node capacitances for nothing. Note that the capacitance of the Clk_C input is not the only contribution as any clock edge causes further nodes to toggle within the flip-flop itself. Also, the wider a register, the larger the overhead in terms of energy and transistor count. Most of the energy could be conserved by selectively turning off the clock within those circuit regions that are currently disabled.18 Any such conditional clocking or clock gating scheme must be implemented very carefully, however, as safe circuit operation is otherwise compromised. 7.5.2 A CRUDE AND UNSAFE APPROACH TO CLOCK GATING Using a simple and gate to shut off the clock of positive-edge-triggered D-type flip-flops is particularly tempting, but also particularly dangerous, see fig.7.27a. This is because any glitch of the enable signal Ena_S is passedontothe gated clock Ckg_C while the clock input Clk_C is 1. All downstream bistables are exposed to hazards during the clock’s first phase where hazards are particularly likely, jeopardizing their correct functioning. To make the circuit work, designers would have recourse to extensive hazard control with all its undesirable implications.19 18 Refer to [202] for a conceptually different approach to conditional clocking that does not depend on the presence of a special enable signal but compares the data value at the input of a flip-flop against that stored. 19 Such as complicated timing analysis, redundant logic for hazard suppression, finicky delay tuning, layout dependencies, difficult design verification, low design productivity, and all the other side-effects of ad hoc (i.e. non-self-timed) asynchronous operation. 434 CHAPTER 7 CLOCKING OF SYNCHRONOUS CIRCUITS h a z a r d s (b) Ckg_C Clk_C Ena_S h a z a r d s (d) ! !(a) Ena_S Clk_C Ckg_C (c) ! CLK D Q Q Ena_S Clk_C Ckg_C Ena_S Clk_C Ckg_C Ckg_C Clk_C Ena_S CLK D Q Q FIGURE 7.27 Unsafe clock gating circuits (a,c) along with the waveforms they produce (b,d). 7.5.3 A SIMPLE CLOCK GATING SCHEME THAT MAY WORK UNDER CERTAIN CONDITIONS The circuit of fig.7.27c fares better because the not-nand gate in the clock net is transparent for glitches during the second clock phase rather than during the first phase. This approach can be made to operate safely provided • The timewise position of the passive clock edge on clock Clk_C is always well defined, • All transients on the enable signal Ena_S are guaranteed to die out before the end of the first clock phase under any circumstance, • The gated clock Ckg_C is rechecked for hazards following layout, the enable signal Ena_S is checked for hazard conditions during timing analysis, and • The extra delay introduced by the gate is accounted for in the clock distribution network. Making sure all of these requirements are consistently met complicates the design process, however. On the positive side, this approach minimizes circuit overhead, clock load, and energy dissipation during those periods when the clock remains disabled. 7.5.4 SAFE CLOCK GATING SCHEMES More robust schemes are based on a special clock gate, a three-port cell that accepts the enable signal at terminal ENA plus the main clock at CLK and that outputs at CKG an intermittent clock signal which is to toggle only when the enable asks it to do so. Here come the specifications for such a contraption in the context of edge-triggered clocking: 7.5 HOW TO IMPLEMENT CLOCK GATING PROPERLY 435 • No latency, that is the enable input must affect the next active clock edge. • The gated clock output CKG must be free of hazards under all circumstances. • The enable input ENA must be immune to hazards (the absence of glitches from the input clock applied at CLK is taken for granted). • The only timing constraints imposed on the enable input ENA must be the observation of reasonable setup and hold times (exactly as for an ordinary E-type flip-flop), any signal that emerges from combinational logic must qualify as enable. • The gated clock must have the same duty cycle as the input clock (applies to single-edge-triggering exclusively). • The propagation delay from terminal CLK to CKG must be small and fixed. • Overall power dissipation must be low, especially while the clock is disabled. • The gated clock should come up with a predictable polarity after circuit reset. Table 7.3 Truth tables for safe conditional clocking in single-edge (left) and dual-edge triggered circuits (right). ENA CLK CKG ENA CLK CKG 1 ↑ ↑ forward active clock edge 1 ↑ CKG toggle output 0 clamp output to zero 1 ↓ CKG idem ↑ 1 CKG maintain output - 0 0 - CKG maintain output ↓ 1 CKG idem ↑ - CKG idem ↓ - CKG idem The corresponding subcircuits are shown in fig.7.28 b) and e).20 Ideally, clock gates are available from the standard cell library. If not so, such components should be added before HDL synthesis begins.21 Compliance with the specifications must be checked and numeric timing figures must be obtained by way of transistor-level simulations exactly as for any other library cell. 20 Though unnecessary from a purely functional point of view, a reset facility serves to bring the subcircuit into a predictable start state following power up. 21 A soft macro that pieces together a clock gate from regular standard cells shall only be considered as a workaround because uncontrollable interconnect delays between the bistable and the combinational gate may put correct operation at risk. The internal wires must then be given so much weight that the cells involved get placed next to each other in an attempt to tightly control interconnect delays and their variations. Also, soft macros must be prevented from being torn apart by latter logic (re)optimization steps, see observation 4.42 for practical advice. 436 CHAPTER 7 CLOCKING OF SYNCHRONOUS CIRCUITS (d) (a) (e) CLK DQ Q (b) CLK DQ RST Q ENA CLK RST CKG RST hazards (f) h a z a r d s (c) hazards CKG CLK ENA CKG CLK ENA Q data-call window CLK ENA CKG CLK ENA CKG ENA CLK RST CKG single-edge-triggered clock gate dual-edge-triggered clock gate data-call window clean clean c l e a n (g) Ena_S Clk_C Ckg_C CLK D Q Q CLK ENA CKG (h) Ena_S Clk_C Ckg_C CLK D Q Q CLK ENA CKG FIGURE 7.28 Safe clock gates for single-edge (b) and dual-edge-triggered circuits (e). Suggested icons (a,d). Pertaining clock waveforms (c,f). Final register circuits (g,h). Make sure you understand that one clock gate gets shared by all flip-flops in a register as indicated in fig.7.28 g) and h). The overall power dissipated for clocking a w-bit register will be much lower than if w individual E-type flip-flops were being used as in fig.7.26. And the idea extends to larger storage arrays and even to entire circuit regions. The more flip-flops get served by a common clock gate, the more important the economy. It goes without saying that the propagation delay from CLK to CKG must be taken into account during clock tree generation much as with any regular clock buffer. Table 7.4 compares all four options. The quest for optimum energy efficiency puts pressure on designers to resort to a multitude of local clocks with a small fanout each and, as a consequence, to prefer not- nand-type gates over latch-based clock gates. Keep in mind this is dangerous unless you exactly know what you do. Further note that situations where a hierarchy of conditions is to exert control over local clocks require special attention, see problem 11. As a last word of caution, recall that scan testing mandates that all flip-flops of a scan path be enabled during scan-in and scan-out operations. Hint: Before opting for a clock gating scheme, check what kind of subcircuits the EDA tool suite available can handle properly as part of clock tree generation. 7.5 HOW TO IMPLEMENT CLOCK GATING PROPERLY 437 Table 7.4 Conditional clocking techniques for single-edge-triggered clocking compared. Enable/disable feedback AND NOT-NAND latch-based mechanism via MUX gate gate clock gate Illustration ﬁg.7.26b ﬁg.7.27a ﬁg.7.27c ﬁg.7.28b Robustness safe unsafe vulnerable safe Circuit overhead for 1w... 3wa 1.5 1.5 ≈ 4.5 a w-bit register [GE] Energy balance wasteful if optimal optimal good if many disabled most ﬂip-ﬂops get of the time gated together Impact on clock tree none must compen- must compen- must compen- synthesis sate for skew sate for skew sate for skew Design effort minimal, not an option recurring for one-time to HDL only each clock net establish cell a The lower bound refers to an E-type ﬂip-ﬂop library cell, the upper to a separate MUX. Warning example In search of energy efficiency, the developers of a low-power DSP core marketed as virtual component had come up with sophisticated clocking and clock gating schemes that synthesized properly for cell- based ASICs. Troubles began when one of their customers asked for rapid prototyping with field- programmable logic to speed up software development. The relatively few nets and buffers dedicated to clock distribution in the target FPGA did not suffice to accommodate the complex fine-grained clock gating scheme. To make things worse, reverting to standard E-type flip-flops turned out to be exceedingly difficult as a consequence from clock gating being entangled with functional operation at many places in the latch-based design. \u0002 Observation 7.13. A good clocking scheme and HDL coding style must always allow for a straight- forward conversion from enable-controlled bistables to clock gating and back with no impact on functional behavior. It further should be compatible with both ASICs and field-programmable logic devices. 438 CHAPTER 7 CLOCKING OF SYNCHRONOUS CIRCUITS 7.6 SUMMARY • The prime problem in clock engineering is not the lack of solutions but the plethora of divergent alternatives, see table 7.5. Strictly adhering to a consistent clocking discipline throughout is paramount to successfully designing large and dependable digital circuits. - Edge-triggered clocking disciplines are most simple conceptually. However, their small latitude to clock skew and jitter requires careful balancing of the clock distribution network all the way to physical design. Careful timing verification is crucial, hold time fixing may help. - Single-edge-triggered one-phase clocking is most popular with both ASIC designers and EDA vendors. - All latch-based clocking disciplines with non-overlapping clocks boast a large tolerance with respect to skew and jitter. This is at the expense of performance in the unsymmetric case only. - Symmetric level-sensitive two-phase clocking provides room for optimizing the clock subsystem either for performance or for energy efficiency. - Translating an edge-triggered one-phase design into an equivalent unsymmetric level-sensitive two-phase design is straightforward which greatly helps in designing circuits of the latter category. - Level-sensitive one-phase clocking is hardly applicable to ICs due to its fatal dependency on stable contamination and interconnect delays. • Macrocells, megacells and subcircuits synthesized from third-party HDL code tend to exhibit unexpected, undesirable and often undocumented timing features such as excessive hold times, massive internal clock distribution delays, absence of adequate clock buffers, a mix of rising- and falling-edge-triggered flip-flops, amalgams of level-sensitive and edge-triggered bistables, and more. Watch out for such peculiarities. • Experience tells us that any departure from a plain one-phase-edge-triggered-flip-flops-only approach complicates the design process and asks for a more substantial engineering effort. Just about everything from interface design down to timing verification and design for test (DFT) tends to become more onerous to handle in the presence of - Asynchronous subcircuits and constructs, - Hybrid clocking schemes (e.g. mixes of edge-triggered with level-sensitive bistables), - Unclocked memories or other macrocells that have timing characteristics incompatible with standard flip-flops, - Multiple clock domains, - Multi-cycle paths,22 - Conditional clocking, and — to a lesser extent — also 22 A multi-cycle path is a signal propagation path that extends over more than one clock period (computation period in the occurrence of dual-edge triggering). Multicycle paths come into existence when VLSI architects decide to have parts of a circuit run at a lower rate than others, or when they accept to wait two — or more — clock cycles for the results from complex combinational operations to appear at the output of the pertaining logic in exchange for being allowed to clock the entire circuit at a faster rate than the longest path would normally permit. 7.6 SUMMARY 439 - Latch-based design, and - Dual-edge triggering. Especially in combination, such departures tend to strain EDA tools beyond what they have been designed for. • Ideally, one could think of a synthesis tool that accepts some functional model and that lets the designer select among the more popular clocking disciplines before generating a circuit netlist. Commercial HDL software does not work in this way, though, and designers have to adjust their RTL source code whenever they opt for a different clocking discipline. • A good clock distribution network exhibits - Low clock skew and jitter, - Fast clock slopes, - Modest distribution delay, and - A good tolerance towards PTV and OCV as well as towards diverse circuit arrangements that emanate from automatic placement and routing (P&R). While distributed trees and hybrid clock distribution networks prevail, careful design and post-layout timing verification are critical in any case. • Designing clock distribution networks must be considered part of back-end design. In the occurrence of distributed clock buffering, use a trustworthy clock tree generator to synthesize, place and route the clock distribution networks. Never entrust clock tree insertion to standard logic synthesis tools as such products have not normally been designed to handle clock distribution. • Circuit simulation does not suffice to detect skew-related problems. Rather, the circuit together with its clock distribution network must be subject to static timing verification. In synchronous designs, this basically implies the checking of setup and hold conditions along all signal propagation paths between any two bistables. Layout parasitics must be accounted for by working from post-layout netlists as obtained from layout extraction. Software tools for doing so are commonplace. • Conditional clocking requires particular attention as it interferes with scan test, and as the simplest and most efficient clock gates are highly exposed to malfunction. The presence of logic gates other than buffers and inverters in clock distribution networks should always alert the expert during a design review. • Most cell libraries are written with no particular clocking discipline or clock distribution scheme in mind. Thus, when evaluating a clocking strategy, do not let you be misguided by some arbitrary feature of your design environment. Put your system requirements first. That is, take into account - The compatibility with other subsystems to be integrated on the same chip, if any, - The library elements available such as flip-flops, latches, LSSD elements, memories, clock drivers, clock gates, PLLs, etc. along with the timing data that go with them, - The tools available for load estimation, layout extraction, circuit simulation, timing verification, clock tree generation, and circuit synthesis in general, 440 CHAPTER 7 CLOCKING OF SYNCHRONOUS CIRCUITS - The accuracy of the timing model(s) being used, - The available software tools for inserting test structures, - The available EDA tools for generating and grading of test vectors, - The hardware test equipment at your disposal, and, last but not least, - Personal experience. • Clock skew and jitter have become more acute with the ever shrinking feature sizes and clock periods. Luckily, today’s semiconductor manufacturing processes provide many low resistance metal layers of which designers can take advantage for better clock distribution. Table 7.5 Comparison of the most important clocking disciplines along with their compatibility and usage with clock distribution schemes. Synchronous clocking discipline edge-triggered level-sensitive single dual two-phase one- edge edge sym- unsym- single phase Characteristics metric metric wire Bistables per computation stage SETFF DETFF two latches latch Clock nets, wiring resources 1 1 2 2 1 1 Relative clock power (approx.)a 1·1·2 1· 1.3 · 1 2· 1 2 ·2 2· 1 2 ·2 1·1· 2 1· 1 2 ·2 All timing constraints one-sided yes yes yes yes yes no Relatively tolerant to skew no no yes yes no no Allows for time-borrowing n.a. n.a. yes no no n.a. Utilization of clock period ≤ 1 ≤ 1 ≤ 1 <1 ≤ 1 >1 Function latches [0,1] [0,1] [0,1,2] [0,1] [0,1,2] [0,1] EDA support full limited limited limited limited poor Key quality slim, slower highly easily high risky, straight clock ﬂexible derived perf. onerous Applied in conjunction with past DEC not for collective buffer ASICs Alpha ASICs Applied in conjunction with most DDR some IBM not for distributed tree ASICs circuits ASICs LSSDb ASICs a expressed as # clock nets· # FF load caps per net· # edges per computation cycle bThreeclock nets twoof which areactiveatany time. 7.7 PROBLEMS 441 7.7 PROBLEMS 1. ∗∗ For all clocking disciplines discussed in this chapter visualize the skew margins in their Anceau diagrams. Use different colors for margins that (a) are a function of the operating speed of the circuit, (b) vanish unless the components involved have non-zero delays, and (c) do not depend on either one. 2. ∗ Old hands among IC designers have long known that edge-triggered shift registers are particularly in danger of malfunctioning. As a remedy, they used to oppose the flows of clock and data during physical design, e.g. they had the clock wire run from right to left in a shift register where data travel from left to right. Explain why this helped. 3. ∗ Reconsider the flip-flop timing data given in table 7.2. What do you think, is this a well-behaved flip-flop or does it impose timing conditions that are awkward to meet? 4. ∗ Some designers like to combine rising-edge-triggered flip-flops with others that trigger on the falling edge in the same clock domain. Analyze the timing characteristics of this scheme and discuss its merits (wrt skew tolerance, performance, scan path insertion, energy efficiency, design verification, engineering effort, etc.). Does it offer any advantage over the disciplines discussed in this chapter? 5. ∗ Yet another approach to edge-triggered clocking uses flip-flops that are built from three latches instead of two, see fig.7.29b. Consider a circuit where all standard flip-flops have been replaced by such bistables and carry out the same analysis as before. (a) D Q CLK (b) QD CLK FIGURE 7.29 Master-slave-slave ﬂip-ﬂop. Proposed icon (a) and logically equivalent circuit (b). 6. ∗∗ The circuit of fig.7.30 occupies a position somewhere between single-edge-triggered and level-sensitive one-phase clocking. The motivation behind replacing part of the flip-flops by (pulse-clocked) latches is the search for improved energy efficiency. Savings are expected from a lighter clock load and from the reduced node count and switching activities in a latch when compared to those in the more complex master-slave flip-flop. Substitution takes place only where the combinational logic between two consecutive bistables can be demonstrated to meet the setup and hold time conditions of the receiver due to the circuitry’s inherent contamination delay alone, i.e. with no extra gates or wiring detours. Draw the Anceau diagram assuming that clock frequency remains the same as in the original circuit. Establish all relevant setup and hold margins. Formulate adequate replacement rules in a more formal way. Comment on the viability and effectiveness of this hybrid clocking scheme. 442 CHAPTER 7 CLOCKING OF SYNCHRONOUS CIRCUITS (a) Clk_C C F L T2T1 pass hold Tclk (b) Clk_C time span available for combinational function C Tci Tci FIGURE 7.30 A hybrid clocking scheme that combines latches with ﬂip-ﬂops. Basic hardware organization (a) and simpliﬁed timing diagram (b). 7. ∗ Reconsider the timing data in fig.7.23 and calculate the length of the FPGA data-call windows for the various situations. What do you observe? Do you have an explanation? 8. ∗∗ Assume you want to include an on-chip RAM in a clock domain to be designed from a standard cell library. The edge-triggered synchronous RAM is to interface with a 14 bit address register and two 24 bit data registers, one for reading and one for writing. For simplicity, let’s assume all flip-flops are identical. Both RAM and flip-flops trigger on the rising edge, their timing data are given next. Cell Timing parameters tpd tcd tsu tho [ns] [ns] [ns] [ns] Flip-ﬂop 0.5 0.2 0.3 0.1 RAM macrocell 2.5 1.5 1.0 0.8 a) Assuming zero skew, estimate the setup and hold margins if the circuit is to run at a clock frequency of 250 MHz. Where’s the difficulty? b) Make several proposals for solving the problem and evaluate them! c) Study the options of inserting some delay τ in the various input and output lines of the RAM macrocell. Compile a table that lists the impact on the RAM’s apparent timing figures if inserted (α) in address and data inputs, (β) in the data outputs, and (γ ) in the clock input. d) What is the result of deliberately designing the clock tree such as to slightly retard or advance the clock signal to the RAM? Does one of these help? e) Can you imagine situations where it makes sense to apply such tricks? Is it possible to improve performance by designing a carefully imbalanced clock distribution network? 9. ∗∗ A commercial synthesis tool from the 1990s claimed to construct FSMs with hazard-free outputs by adding latches to all input and output lines of a Mealy type automaton. These extra latches were controlled by the same clock signal that drove the edge-triggered state register 7.7 PROBLEMS 443 such as to always have either the input latches transparent and the output latches on hold, or vice versa. Find out when outputs are supposed to switch! As both latch sets are not allowed to be transparent simultaneously, outputs were believed to be isolated from asynchronous input changes. Show this is not always true! Note: If you find it hard to analyze this state machine, imagine the difficulty of designing a larger circuit that mixes level-sensitive with edge-triggered clocking. 10. ∗ The impact of clock distribution delay on I/O timing has been illustrated in fig.7.22.Comeup with a revised Anceau diagram for an analogous circuit with registered input and output this time. 11. ∗ Fig.7.31 shows two clock distribution trees that make use of clock gating. Whether local clocks Ckg1_C, Ckg2_C, Ckg3_C and Ckg34_C are to be active or not obviously depends on enable signals Ena1_S through Ena4_S generated from within the circuit itself. Circuit testing is supposed to happen via a full scan path that gets turned on from the Scm_TI scan mode terminal. Unfortunately, though, fig.7.31a includes four oversights. Locate them and explain what’s wrong! Ena3_S Ena4_S ..... flip-flops ..... Ena1_S Ena2_S Ckg1_C Clk_CI Ckg1_C Ena1_S Clk_CI ..... flip-flops ..... Ena4_S Ckg34_CCkg3_C Ena3_S Ena2_S Ckg2_CClk_C Scm_TI Scm_TI Clk_C Ckg34_CCkg3_CCkg2_C (b)(a) FIGURE 7.31 Hierarchical clock gating and scan test.","libVersion":"0.5.0","langs":""}
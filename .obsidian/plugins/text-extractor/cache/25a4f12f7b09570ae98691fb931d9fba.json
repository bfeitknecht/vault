{"path":"sem3/AuD/UE/s/AuD-u04-s.pdf","text":"Eidgen¨ossische Technische Hochschule Z¨urich Ecole polytechnique f´ed´erale de Zurich Politecnico federale di Zurigo Federal Institute of Technology at Zurich Departement of Computer Science 16 October 2023 Johannes Lengler, David Steurer Lucas Slot, Manuel Wiedmer, Hongjie Chen, Ding Jingqiu Algorithms & Data Structures Exercise sheet 4 HS 23 The solutions for this sheet are submitted at the beginning of the exercise class on 23 October 2023. Exercises that are marked by ∗ are challenge exercises. They do not count towards bonus points. You can use results from previous parts without solving those parts. Master theorem. The following theorem is very useful for running-time analysis of divide-and- conquer algorithms. Theorem 1 (master theorem). Let a, C > 0 and b ≥ 0 be constants and T : N → R+ a function such that for all even n ∈ N, T (n) ≤ aT (n/2) + Cn b. (1) Then for all n = 2k, k ∈ N, • If b > log2 a, T (n) ≤ O(nb). • If b = log2 a, T (n) ≤ O(nlog2 a · log n).1 • If b < log2 a, T (n) ≤ O(nlog2 a). If the function T is increasing, then the condition n = 2k can be dropped. If (1) holds with “=”, then we may replace O with Θ in the conclusion. This generalizes some results that you have already seen in this course. For example, the (worst-case) running time of Karatsuba’s algorithm satisfies T (n) ≤ 3T (n/2) + 100n, so we have a = 3 and b = 1 < log2 3, hence T (n) ≤ O(nlog2 3). Another example is binary search: its running time satisfies T (n) ≤ T (n/2) + 100, so a = 1 and b = 0 = log2 1, hence T (n) ≤ O(log n). Exercise 4.1 Applying the master theorem. For this exercise, assume that n is a power of two (that is, n = 2k, where k ∈ N0 := N ∪ {0}). (a) Let T (1) = 1, T (n) = 4T (n/2) + 100n for n > 1. Using the master theorem, show that T (n) ≤ O(n2). Solution: We can apply the master theorem with a = 4, b = 1 and C = 100. In this case, b < log2 a, and therefore we have T (n) ≤ O(nlog2 a) = O(n2). 1For this asymptotic bound we assume n ≥ 2 so that n log2 a · log n > 0. (b) Let T (1) = 5, T (n) = T (n/2) + 3 2 n for n > 1. Using the master theorem, show that T (n) ≤ O(n). Solution: We can apply the master theorem with a = 1, b = 1 and C = 3 2 . In this case, b > log2 a, and therefore we have T (n) ≤ O(nb) = O(n). (c) Let T (1) = 4, T (n) = 4T (n/2) + 7 2 n2 for n > 1. Using the master theorem, show that T (n) ≤ O(n2 log n). Solution: We can apply the master theorem with a = 4, b = 2 and C = 7 2 . In this case, b = log2 a, and therefore we have T (n) ≤ O(nlog2 a · log n) = O(n2 log n). Exercise 4.2 Asymptotic notations. (a) (This subtask is from January 2019 exam). For each of the following claims, state whether it is true or false. You don’t need to justify your answers. claim true false n log n ≤ O(√n) □ □ log(n!) ≥ Ω(n2) □ □ nk ≥ Ω(kn), if 1 < k ≤ O(1) □ □ log3 n4 = Θ(log7 n8) □ □ Solution: claim true false n log n ≤ O( √n) □ ⊠ log n! ≥ Ω(n2) □ ⊠ nk ≥ Ω(kn), if 1 < k ≤ O(1) □ ⊠ log3 n4 = Θ(log7 n8) ⊠ □ (b) (This subtask is from August 2019 exam). For each of the following claims, state whether it is true or false. You don’t need to justify your answers. 2 claim true false n log n ≥ Ω(n1/2) □ □ log7(n8) = Θ(log3(n√n)) □ □ 3n4 + n2 + n ≥ Ω(n2) □ □ (∗) n! ≤ O(nn/2) □ □ Solution: claim true false n log n ≥ Ω(n1/2) ⊠ □ log7(n8) = Θ(log3(n√n)) □ ⊠ 3n4 + n2 + n ≥ Ω(n2) ⊠ □ (∗) n! ≤ O(nn/2) □ ⊠ Note that the last claim is challenge. It was one of the hardest tasks of the exam. If you want a 6 grade, you should be able to solve such exercises. Solution: All claims except for the last one are easy to verify using either the theorem about the limit of f (n) g(n) or simply the definitions of O, Ω and Θ. Thus, we only present the solution for the last one. Note that for all n ≥ 1, n! ≥ 1 · 2 · · · n ≥ ⌈n/10⌉ · · · n ≥ ⌈n/10⌉0.9n ≥ (n/10)0.9n . Let’s show that (n/10)0.9n grows asymptotically faster than nn/2. lim n→∞ nn/2 (n/10)0.9n = lim n→∞ 10 0.9n · n−0.4n = lim n→∞(10 9/4/n) 0.4n = 0 . Hence it is not true that (n/10)0.9n ≤ O(nn/2) and so it is not true that n! ≤ O(nn/2). Sorting and Searching. Exercise 4.3 Formal proof of correctness for Bubble Sort (1 point). Recall the bubble sort algorithm that was introduced in the lecture. 3 Algorithm 1 Bubble Sort (input: array A[1 . . . n]). for j = 1, . . . , n do for i = 1, . . . , n − 1 do if A[i] > A[i + 1] then Swap A[i] and A[i + 1] Prove correctness of this algorithm by mathematical induction. Hint: Use the invariant I(j) that was introduced in the lecture: “After j iterations the j largest elements are at the correct place.” Solution: We prove the invariant in the hint by mathematical induction on j. • Base Case. We prove the statement for j = 1. Assume that the largest element of A is at position l in the beginning. After the first l − 1 iterations of the second for-loop, it is still at position l. For all further steps with i ≥ l, A[i] contains the largest element and thus the largest element is swapped to position i + 1. Hence, in the end the largest element is at position n, which shows I(1). • Induction Hypothesis. We assume that the invariant is true for j = k for some k ∈ N, k < n, i.e. after k iterations the k largest elements are at the correct position. • Inductive Step. We must show that the invariant also holds for j = k + 1. By the induction hypothesis the k largest elements are at the correct position after k steps, i.e. at the positions A[n − k + 1 . . . n]. We now consider step k + 1. Note that in this iteration the positions of the k largest elements are not changed since for i ≥ n − k, we will never have A[i] > A[i + 1]. Thus, in order to show I(k + 1) it is enough to show that after step k + 1 also the (k + 1)st largest element is at the correct position. The (k + 1)st largest element is the largest element of A[1 . . . n − k] (all elements that are larger than it come later by I(k)). Thus, by the argumentation in the base case, after i = n − k − 1 iterations in the second for-loop, it is at position A[n − k]. But for the other k iterations of the second for-loop, nothing changes as was already argued before (the largest elements do not change their position). Thus, after step k + 1, the k + 1 largest elements are at the correct position, which shows I(k + 1). By the principle of mathematical induction, I(j) is true for all j ∈ N, j ≤ n. In particular, I(n) holds, which means that after the first n iterations the n largest elements are at the correct position. This shows that after n steps the array is sorted, which shows correctness of the Bubble Sort algorithm. Exercise 4.4 Exponential search (1 point). Suppose we are given a positive integer N ∈ N, and a monotonically increasing function f : N → N, meaning that f (i) ≥ f (j) for all i, j ∈ N with i ≥ j. Assume that limn→∞ f (n) = ∞. We are tasked to determine the smallest integer T ∈ N such that f (T ) ≥ N . (a) Describe an algorithm that finds an upper bound Tub ∈ N on T , such that f (Tub) ≥ N and Tub ≤ 2T , making O(log T ) function calls to f .2 Prove that your algorithm is correct, and uses 2For the asymptotic bounds here and also in the following we assume T ≥ 2 such that log(T ) > 0. 4 at most the desired number of function calls. Solution: We loop over k = 1, 2, 3, . . ., setting Tk = 2k. We terminate the loop at step k if f (Tk) ≥ N , and return Tub = Tk. To see that Tub satisfies Tub ≤ 2T , note that Tk−1 < T (as otherwise, we would have terminated the loop at step k − 1). For the runtime, note that T⌈log2 T ⌉ = 2⌈log2 T ⌉ ≥ T , meaning f (T⌈log2 T ⌉) ≥ N (since f is monotonically increasing, and f (T ) ≥ N by assumption). We conclude that the loop is executed at most ⌈log2 T ⌉ = O(log T ) times, making one call to f each loop. Algorithm 2 T ← 1 while f (T ) < N do T ← T · 2 Return T (b) Describe an algorithm that determines the smallest integer T ∈ N such that f (T ) ≥ N , making O(log T ) function calls to f . Prove that your algorithm is correct, and uses at most the desired number of function calls. Hint: Consider using a two-step approach. In the first step, apply the algorithm of part (a). For the second step, modify the binary search algorithm and apply it to the array {1, 2, . . . , Tub}. Use helper variables ilow, ihigh ∈ N, that satisfy ilow ≤ T ≤ ihigh at all times during the algorithm. In each iteration, update ilow and/or ihigh so that the number of remaining options for T is halved. Solution: We first run the algorithm of part (a) to obtain an integer Tub with Tub ≤ 2T , making O(log T ) function call to f . Then, we run a modified binary search on the array [1, 2, . . . , Tub] to find its smallest element T for which f (T ) ≥ N . The steps are given in the pseudo-code below. Algorithm 3 ilow ← 1 ihigh ← Tub ▷ Using the algorithm of part (a). imid ← ⌈(ilow + ihigh)/2⌉ while ilow < ihigh do if f (imid) ≥ N then ▷ This implies T ≤ imid. if f (imid − 1) < N then ▷ This implies T ≥ imid, thus T = imid. Return imid else ▷ This implies ilow ≤ T < imid. ihigh ← imid − 1 imid ← ⌈(ilow + ihigh)/2⌉ else ▷ This implies imid ≤ T ≤ ihigh. ilow ← imid imid ← ⌈(ilow + ihigh)/2⌉ Return ilow For correctness, note that at all times during the algorithm, we have ilow ≤ T ≤ ihigh. The al- gorithm terminates only when it returns T = imid, or when ilow = ihigh, in which case it also 5 returns T = ilow. For the number of calls to f , note that the algorithm makes at most 2 calls per iteration (of the outer while-loop). In each iteration, the value of (ihigh − ilow + 1) is halved. As ihigh − ilow + 1 is initially equal to Tub ≤ 2T , we have at most ⌈log2(2T )⌉ iterations, leading to at most 2 · ⌈log2(2T )⌉ = O(log T ) function calls in total. Note: we could have set ilow = Tub/2 + 1 at the start of the algorithm (instead of ilow = 1), but this does not lead to an asymptotic improvement in the number of function calls! Exercise 4.5 Counting function calls in loops (cont’d) (1 point). For each of the following code snippets, compute the number of calls to f as a function of n ∈ N. We denote this number by T (n), i.e. T (n) is the number of calls the algorithm makes to f depending on the input n. Then T is a function from N to R+. For part (a), provide both the exact number of calls and a maximally simplified asymptotic bound in Θ notation. For part (b), it is enough to give a maximally simplified asymptotic bound in Θ notation. For the asymptotic bounds, you may assume that n ≥ 10. Algorithm 4 (a) i ← 1 while i ≤ n do j ← i while 2j ≤ n do f () j ← j + 1 i ← i + 1 Hint: To find the asymptotic bound, it might be helpful to consider n of the form n = 2k. Solution: If i ≤ ⌊log2 n⌋, the inner loop performs ∑⌊log2 n⌋ j=i 1 = ⌊log2 n⌋ − i + 1 calls to f . If i > ⌊log2 n⌋, it performs none. The full algorithm thus performs ∑⌊log2 n⌋ i=1 (⌊log2 n⌋ − i + 1) = ⌊log2 n⌋(⌊log2 n⌋ + 1)/2 = Θ((log n)2) calls to f . Algorithm 5 (b) function A(n) i ← 0 while i < n2 do j ← n while j > 0 do f () f () j ← j − 1 i ← i + 1 k ← ⌊ n 2 ⌋ for l = 0 . . . 3 do if k > 0 then A(k) A(k) 6 You may assume that the function T : N → R+ denoting the number of calls of the algorithm to f is increasing. Hint: To deal with the recursion in the algorithm, you can use the master theorem. Solution: Given i, the innermost loop performs ∑n j=1 2 = 2n calls to f . Hence, the second loop (guarded by i < n2) performs ∑n2−1 i=0 2n = 2n3 calls to f . If ⌊ n 2 ⌋ = 0 (i.e. n = 1), then k = 0, so the algorithm makes just 2 calls to f . Thus, we have T (1) = 2. For n ≥ 2, we have k = ⌊ n 2 ⌋ > 0 and thus we get the following relation T (n) = 2n3 + 8T (⌊ n 2 ⌋). Using the master theorem with a = 8, b = 3 and C = 2, we get (log2(8) = 3) T (n) = Θ(n3 log(n)) for any integer n ≥ 2 (we need n ≥ 2 so that log(n) > 0) since T is increasing. In conclusion, the algorithm performs Θ(n3 log(n)) calls to the function f . (c)* Prove that the function T : N → R+ from the code snippet in part (b) is indeed increasing. Hint: You can show the following statement by mathematical induction: “For all n′ ∈ N with n′ ≤ n we have T (n′ + 1) ≥ T (n′)”. Solution: We show the statement suggested in the hint by mathematical induction. • Base Case. We have T (2) = 16 + 16T (1) = 32 ≥ 2 = T (1), so the base case holds as the only n′ ∈ N that is at most 1 is n′ = 1. • Induction Hypothesis. Assume that for some k ∈ N we have T (k′ + 1) ≥ T (k′) for all k′ ∈ N with k′ ≤ k. • Inductive Step. We must show that T (k + 2) ≥ T (k + 1). Together with the induction hypothesis this shows that T (k′ + 1) ≥ T (k′) for all k′ ∈ N with k′ ≤ k + 1. We have that ⌊ k + 1 2 ⌋ ≤ k. By the induction hypothesis T (⌊ k + 2 2 ⌋) ≥ T (⌊ k + 1 2 ⌋) . This is true since either ⌊ k+2 2 ⌋ = ⌊ k+1 2 ⌋ or ⌊ k+2 2 ⌋ = ⌊ k+1 2 ⌋+1. For the first case the inequality is actually an equality and the second case is covered by the induction hypothesis. Using the relation from above we get T (k + 2) = 2(k + 2)3 + 8T (⌊ k + 2 2 ⌋) ≥ 2(k + 1)3 + 8T (⌊ k + 1 2 ⌋) = T (k + 1). By the principle of mathematical induction, for every n ∈ N we have for n′ ∈ N with n′ ≤ n that T (n′ + 1) ≥ T (n′). In particular, T (n + 1) ≥ T (n) is true for any n ∈ N and the function T is increasing. 7","libVersion":"0.3.2","langs":""}